Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='c1c2d88d-e9f1-4e62-b380-434694b9488c', conf_timestamp='2023-08-09 13:02:47.336565', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 87.1 % 	 [Task-IL]: 54.3 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 60.5 % 	 [Task-IL]: 40.98 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 36.72 % 	 [Task-IL]: 39.73 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 30.2 % 	 [Task-IL]: 35.16 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 28.38 % 	 [Task-IL]: 34.79 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 27.41 % 	 [Task-IL]: 34.52 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 20.49 % 	 [Task-IL]: 34.55 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 17.76 % 	 [Task-IL]: 33.57 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.22 % 	 [Task-IL]: 33.82 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 13.67 % 	 [Task-IL]: 33.68 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 13.51 % 	 [Task-IL]: 34.09 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 12.26 % 	 [Task-IL]: 33.67 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 10.65 % 	 [Task-IL]: 33.01 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 9.11 % 	 [Task-IL]: 33.05 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 7.97 % 	 [Task-IL]: 32.21 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 9.16 % 	 [Task-IL]: 32.4 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 9.94 % 	 [Task-IL]: 32.25 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 7.66 % 	 [Task-IL]: 32.1 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.74 % 	 [Task-IL]: 32.21 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 7.99 % 	 [Task-IL]: 31.65 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.07 % 	 [Task-IL]: 31.8 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 6.87 % 	 [Task-IL]: 31.56 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 6.89 % 	 [Task-IL]: 31.33 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.01 % 	 [Task-IL]: 31.42 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.59 % 	 [Task-IL]: 31.27 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.26 % 	 [Task-IL]: 31.52 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 5.79 % 	 [Task-IL]: 31.47 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.13 % 	 [Task-IL]: 31.64 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 5.89 % 	 [Task-IL]: 31.37 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 5.76 % 	 [Task-IL]: 31.32 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 4.83 % 	 [Task-IL]: 30.99 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 4.43 % 	 [Task-IL]: 30.72 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 3.86 % 	 [Task-IL]: 30.04 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.18 % 	 [Task-IL]: 29.67 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.22 % 	 [Task-IL]: 30.09 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 4.44 % 	 [Task-IL]: 29.57 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.59 % 	 [Task-IL]: 29.5 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.28 % 	 [Task-IL]: 29.34 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.24 % 	 [Task-IL]: 29.55 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.5 % 	 [Task-IL]: 28.95 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 3.82 % 	 [Task-IL]: 29.27 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 3.8 % 	 [Task-IL]: 29.17 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.49 % 	 [Task-IL]: 28.89 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72
  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108
 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({668: 31, 443: 30, 521: 28, 284: 28, 272: 28, 304: 27, 330: 27, 213: 26, 456: 26, 633: 26, 766: 26, 89: 26, 136: 25, 661: 25, 196: 25, 177: 25, 713: 24, 210: 24, 417: 24, 215: 24, 271: 24, 688: 24, 837: 24, 585: 24, 547: 23, 359: 23, 760: 23, 27: 23, 336: 23, 195: 23, 859: 23, 878: 23, 707: 23, 238: 23, 650: 23, 557: 23, 154: 22, 357: 22, 748: 22, 629: 22, 280: 22, 702: 22, 478: 22, 601: 22, 852: 22, 360: 21, 389: 21, 169: 21, 829: 21, 1: 21, 301: 21, 771: 21, 676: 21, 207: 21, 57: 21, 80: 21, 467: 21, 218: 21, 674: 21, 403: 21, 684: 21, 15: 21, 127: 21, 242: 21, 124: 20, 603: 20, 708: 20, 312: 20, 303: 20, 354: 20, 599: 20, 351: 20, 229: 20, 341: 20, 162: 20, 31: 20, 188: 20, 570: 19, 738: 19, 554: 19, 404: 19, 730: 19, 866: 19, 509: 19, 113: 19, 823: 19, 56: 19, 334: 19, 318: 19, 754: 19, 453: 19, 818: 19, 591: 19, 332: 19, 11: 19, 450: 19, 144: 19, 91: 19, 559: 19, 376: 19, 733: 19, 699: 19, 455: 19, 319: 19, 142: 19, 722: 18, 779: 18, 289: 18, 631: 18, 262: 18, 558: 18, 261: 18, 52: 18, 839: 18, 608: 18, 325: 18, 731: 18, 593: 18, 23: 18, 687: 18, 873: 18, 677: 18, 807: 18, 639: 17, 531: 17, 529: 17, 313: 17, 120: 17, 343: 17, 2: 17, 83: 17, 279: 17, 623: 17, 461: 17, 825: 17, 584: 17, 809: 17, 747: 17, 400: 17, 763: 17, 853: 17, 150: 16, 413: 16, 307: 16, 171: 16, 626: 16, 295: 16, 119: 16, 655: 16, 373: 16, 429: 16, 353: 16, 197: 16, 851: 16, 204: 16, 519: 16, 781: 16, 448: 16, 361: 16, 765: 16, 653: 16, 706: 16, 175: 16, 139: 15, 156: 15, 804: 15, 208: 15, 178: 15, 410: 15, 375: 15, 855: 15, 430: 15, 253: 15, 847: 15, 395: 15, 890: 15, 665: 15, 786: 15, 663: 15, 846: 15, 534: 15, 355: 15, 683: 15, 494: 15, 138: 15, 577: 15, 103: 15, 729: 15, 187: 15, 641: 15, 371: 15, 737: 15, 99: 15, 732: 15, 112: 15, 516: 15, 84: 14, 500: 14, 817: 14, 659: 14, 445: 14, 840: 14, 405: 14, 468: 14, 880: 14, 727: 14, 182: 14, 44: 14, 45: 14, 419: 14, 115: 14, 572: 14, 333: 13, 64: 13, 224: 13, 222: 13, 472: 13, 88: 13, 785: 13, 199: 13, 53: 13, 283: 13, 432: 13, 604: 13, 128: 13, 217: 13, 185: 13, 70: 13, 679: 13, 339: 13, 802: 13, 602: 13, 691: 12, 168: 12, 148: 12, 265: 12, 107: 12, 388: 12, 135: 12, 440: 12, 537: 12, 305: 12, 662: 12, 174: 12, 640: 12, 538: 12, 827: 12, 574: 12, 856: 12, 424: 12, 249: 12, 594: 12, 173: 12, 464: 12, 200: 12, 435: 12, 439: 12, 735: 12, 546: 12, 234: 12, 862: 12, 60: 12, 469: 12, 874: 12, 471: 12, 578: 12, 225: 12, 861: 12, 664: 12, 858: 12, 876: 12, 642: 12, 26: 12, 209: 12, 49: 12, 211: 12, 258: 11, 745: 11, 505: 11, 3: 11, 795: 11, 274: 11, 198: 11, 247: 11, 383: 11, 228: 11, 507: 11, 560: 11, 74: 11, 39: 11, 444: 11, 22: 11, 348: 11, 502: 11, 571: 11, 782: 11, 838: 11, 805: 11, 372: 11, 390: 11, 542: 11, 94: 11, 784: 11, 201: 11, 189: 11, 712: 11, 166: 11, 117: 11, 63: 11, 489: 11, 367: 11, 721: 11, 882: 11, 425: 11, 47: 11, 368: 11, 581: 11, 72: 11, 881: 11, 418: 11, 769: 11, 181: 11, 667: 11, 671: 11, 749: 11, 872: 11, 230: 10, 596: 10, 62: 10, 256: 10, 848: 10, 616: 10, 244: 10, 563: 10, 648: 10, 508: 10, 129: 10, 527: 10, 79: 10, 514: 10, 41: 10, 792: 10, 501: 10, 251: 10, 646: 10, 820: 10, 167: 10, 164: 10, 860: 10, 759: 10, 202: 10, 637: 10, 329: 10, 753: 10, 7: 10, 20: 10, 141: 10, 483: 10, 442: 10, 473: 10, 758: 10, 647: 10, 555: 10, 627: 10, 114: 10, 776: 10, 98: 10, 740: 10, 693: 10, 216: 10, 609: 10, 109: 10, 447: 10, 356: 10, 121: 10, 411: 10, 474: 9, 9: 9, 720: 9, 415: 9, 686: 9, 346: 9, 619: 9, 50: 9, 106: 9, 67: 9, 746: 9, 25: 9, 193: 9, 77: 9, 176: 9, 8: 9, 649: 9, 104: 9, 143: 9, 532: 9, 773: 9, 93: 9, 125: 9, 416: 9, 863: 9, 806: 9, 689: 9, 883: 9, 835: 9, 787: 9, 402: 9, 476: 9, 316: 9, 597: 9, 550: 9, 398: 9, 311: 9, 122: 9, 744: 9, 615: 9, 428: 9, 828: 9, 299: 9, 790: 9, 427: 9, 214: 9, 490: 9, 340: 9, 292: 9, 314: 9, 893: 9, 73: 9, 888: 9, 869: 9, 824: 9, 833: 9, 796: 9, 497: 9, 526: 9, 293: 9, 717: 8, 407: 8, 535: 8, 867: 8, 95: 8, 770: 8, 190: 8, 331: 8, 328: 8, 291: 8, 510: 8, 158: 8, 788: 8, 51: 8, 275: 8, 709: 8, 780: 8, 212: 8, 203: 8, 644: 8, 397: 8, 282: 8, 634: 8, 506: 8, 78: 8, 595: 8, 309: 8, 186: 8, 243: 8, 43: 8, 620: 8, 643: 8, 221: 8, 783: 8, 767: 8, 145: 8, 183: 8, 257: 8, 116: 8, 491: 8, 849: 8, 630: 8, 831: 8, 628: 8, 369: 8, 541: 8, 777: 8, 108: 8, 352: 8, 680: 8, 475: 8, 327: 8, 705: 8, 678: 8, 741: 8, 350: 8, 520: 8, 294: 8, 358: 8, 394: 8, 14: 8, 399: 8, 59: 8, 460: 8, 277: 8, 451: 8, 800: 8, 891: 8, 793: 8, 844: 8, 798: 8, 146: 7, 522: 7, 151: 7, 96: 7, 845: 7, 479: 7, 100: 7, 87: 7, 654: 7, 832: 7, 694: 7, 377: 7, 614: 7, 380: 7, 512: 7, 102: 7, 544: 7, 723: 7, 290: 7, 552: 7, 133: 7, 724: 7, 255: 7, 315: 7, 728: 7, 61: 7, 613: 7, 344: 7, 288: 7, 495: 7, 267: 7, 513: 7, 700: 7, 298: 7, 385: 7, 739: 7, 742: 7, 666: 7, 463: 7, 579: 7, 241: 7, 673: 7, 556: 7, 342: 7, 401: 7, 157: 7, 681: 7, 822: 7, 482: 7, 323: 7, 163: 7, 493: 7, 434: 7, 436: 7, 111: 7, 870: 7, 755: 7, 498: 7, 226: 7, 260: 7, 775: 7, 29: 7, 58: 7, 692: 7, 180: 7, 814: 7, 24: 7, 76: 7, 16: 7, 488: 7, 656: 7, 153: 7, 324: 7, 477: 7, 778: 7, 757: 7, 492: 7, 266: 7, 36: 7, 0: 7, 762: 7, 540: 7, 278: 7, 30: 7, 276: 7, 110: 7, 636: 7, 618: 7, 48: 7, 566: 7, 452: 7, 672: 7, 165: 7, 622: 7, 764: 7, 632: 7, 363: 6, 38: 6, 231: 6, 248: 6, 625: 6, 347: 6, 565: 6, 842: 6, 349: 6, 884: 6, 409: 6, 459: 6, 21: 6, 841: 6, 264: 6, 797: 6, 259: 6, 12: 6, 588: 6, 237: 6, 161: 6, 592: 6, 610: 6, 82: 6, 18: 6, 751: 6, 551: 6, 553: 6, 320: 6, 6: 6, 772: 6, 337: 6, 466: 6, 743: 6, 564: 6, 457: 6, 34: 6, 252: 6, 54: 6, 695: 6, 821: 6, 281: 6, 750: 6, 803: 6, 503: 6, 816: 6, 752: 6, 384: 6, 528: 6, 524: 6, 240: 6, 652: 6, 611: 6, 736: 6, 704: 6, 433: 6, 302: 6, 19: 6, 690: 6, 600: 6, 387: 6, 246: 6, 422: 6, 37: 6, 137: 6, 539: 6, 854: 6, 155: 6, 441: 6, 549: 6, 587: 6, 819: 6, 220: 6, 465: 6, 28: 6, 81: 6, 370: 6, 696: 6, 545: 6, 718: 6, 205: 6, 13: 6, 134: 6, 245: 6, 85: 6, 590: 6, 836: 6, 606: 6, 511: 6, 66: 6, 734: 6, 879: 6, 638: 6, 263: 6, 875: 5, 675: 5, 518: 5, 569: 5, 172: 5, 710: 5, 515: 5, 285: 5, 381: 5, 892: 5, 239: 5, 864: 5, 605: 5, 530: 5, 446: 5, 269: 5, 789: 5, 10: 5, 366: 5, 485: 5, 219: 5, 300: 5, 481: 5, 499: 5, 42: 5, 386: 5, 420: 5, 297: 5, 69: 5, 414: 5, 548: 5, 612: 5, 716: 5, 865: 5, 4: 5, 589: 5, 887: 5, 582: 5, 580: 5, 345: 5, 682: 5, 801: 5, 685: 5, 703: 5, 799: 5, 33: 5, 562: 5, 335: 5, 406: 5, 774: 5, 621: 5, 118: 5, 843: 5, 392: 5, 470: 5, 487: 5, 364: 5, 756: 5, 308: 5, 462: 5, 310: 5, 322: 5, 235: 5, 140: 5, 35: 5, 92: 5, 437: 5, 393: 5, 725: 5, 586: 5, 412: 5, 306: 5, 635: 5, 449: 4, 617: 4, 149: 4, 105: 4, 233: 4, 408: 4, 583: 4, 396: 4, 223: 4, 504: 4, 236: 4, 657: 4, 645: 4, 365: 4, 170: 4, 321: 4, 607: 4, 454: 4, 857: 4, 568: 4, 152: 4, 438: 4, 382: 4, 86: 4, 374: 4, 715: 4, 791: 4, 5: 4, 486: 4, 885: 4, 573: 4, 576: 4, 378: 4, 426: 4, 698: 4, 714: 4, 75: 4, 160: 4, 338: 4, 567: 4, 40: 4, 669: 4, 32: 4, 286: 4, 68: 4, 575: 4, 811: 4, 889: 4, 46: 4, 194: 4, 768: 4, 533: 4, 761: 4, 517: 4, 719: 4, 130: 4, 159: 4, 523: 4, 90: 4, 126: 4, 868: 4, 810: 4, 496: 4, 179: 4, 834: 4, 421: 4, 886: 4, 561: 4, 815: 4, 536: 4, 543: 4, 670: 4, 326: 3, 132: 3, 458: 3, 270: 3, 287: 3, 726: 3, 268: 3, 101: 3, 484: 3, 71: 3, 123: 3, 480: 3, 296: 3, 624: 3, 697: 3, 254: 3, 871: 3, 317: 3, 97: 3, 147: 3, 250: 3, 65: 3, 191: 3, 525: 2, 131: 2, 17: 2, 379: 2, 273: 2, 850: 2, 658: 2, 830: 2, 431: 2, 423: 2, 192: 2, 813: 2, 660: 2, 598: 2, 794: 2, 701: 2, 232: 2, 812: 2, 711: 2, 206: 2, 362: 2, 877: 1, 826: 1, 651: 1, 184: 1, 227: 1, 391: 1, 808: 1})
fit_time: 28.722702916999964

Accuracy for 44 task(s): 	 [Class-IL]: 67.09 % 	 [Task-IL]: 30.27 %

CLASS_IL_ACC: 
	[60.215053763440864, 75.53191489361703, 65.95744680851064, 79.46428571428571, 68.62745098039215, 75.43859649122807, 52.17391304347826, 69.36936936936937, 73.58490566037736, 78.57142857142857, 63.55140186915887, 63.8095238095238, 58.333333333333336, 68.69565217391305, 66.39344262295081, 60.526315789473685, 76.78571428571429, 69.92481203007519, 69.3069306930693, 71.1864406779661, 76.69902912621359, 69.72477064220183, 59.25925925925925, 70.52631578947368, 69.79166666666666, 55.96330275229357, 67.67676767676768, 68.37606837606837, 68.46846846846847, 62.096774193548384, 62.38532110091744, 64.60176991150442, 70.58823529411765, 68.54838709677419, 71.81818181818181, 66.94214876033058, 71.02803738317756, 69.23076923076923, 76.76767676767676, 62.37623762376238, 67.88990825688074, 52.21238938053098, 65.09433962264151, 46.601941747572816]
TASK_IL_ACC: 
	[53.76344086021505, 27.659574468085108, 32.97872340425532, 16.964285714285715, 32.35294117647059, 34.21052631578947, 31.30434782608696, 25.225225225225223, 30.18867924528302, 34.12698412698413, 30.8411214953271, 29.523809523809526, 25.0, 31.30434782608696, 25.40983606557377, 30.701754385964914, 33.92857142857143, 31.57894736842105, 29.7029702970297, 23.728813559322035, 31.06796116504854, 25.688073394495415, 25.0, 31.57894736842105, 31.25, 31.19266055045872, 29.292929292929294, 35.8974358974359, 26.126126126126124, 27.419354838709676, 22.93577981651376, 25.663716814159294, 22.689075630252102, 27.419354838709676, 27.27272727272727, 18.181818181818183, 32.71028037383177, 24.786324786324787, 29.292929292929294, 17.82178217821782, 31.19266055045872, 26.548672566371685, 30.18867924528302, 90.29126213592234]
f1_micro: 66.99206833435022
f1_macro: 62.772771801419495
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.53      0.89      0.67         9
           2       0.17      0.11      0.13         9
           3       0.83      1.00      0.91         5
           4       1.00      0.75      0.86         4
           5       0.00      0.00      0.00         4
           6       0.50      0.50      0.50         4
           7       0.80      1.00      0.89         4
           8       0.42      1.00      0.59         5
           9       1.00      1.00      1.00         5
          10       1.00      0.75      0.86         4
          11       1.00      0.67      0.80         9
          12       0.00      0.00      0.00         5
          13       0.75      0.75      0.75         4
          14       1.00      0.50      0.67         4
          15       1.00      1.00      1.00         9
          16       0.12      0.25      0.17         4
          17       0.00      0.00      0.00         4
          18       0.13      0.50      0.21         4
          19       0.25      0.50      0.33         4
          20       0.08      0.11      0.09         9
          21       1.00      1.00      1.00         4
          22       0.67      0.50      0.57         4
          23       1.00      0.67      0.80         9
          24       1.00      0.25      0.40         4
          25       0.00      0.00      0.00         4
          26       0.67      0.67      0.67         9
          27       0.75      0.67      0.71         9
          28       1.00      0.75      0.86         4
          29       0.33      0.40      0.36         5
          30       0.10      0.50      0.16         4
          31       1.00      1.00      1.00         9
          32       1.00      0.75      0.86         4
          33       0.33      0.50      0.40         4
          34       0.50      1.00      0.67         4
          35       0.33      1.00      0.50         4
          36       0.80      1.00      0.89         4
          37       0.80      1.00      0.89         4
          38       1.00      0.80      0.89         5
          39       0.83      1.00      0.91         5
          40       0.67      1.00      0.80         4
          41       0.83      1.00      0.91         5
          42       0.25      0.25      0.25         4
          43       0.50      0.25      0.33         4
          44       0.00      0.00      0.00         4
          45       0.60      0.75      0.67         4
          46       1.00      0.75      0.86         4
          47       0.50      0.75      0.60         4
          48       0.33      0.20      0.25         5
          49       0.70      0.78      0.74         9
          50       0.80      1.00      0.89         4
          51       1.00      1.00      1.00         4
          52       1.00      0.89      0.94         9
          53       0.50      0.50      0.50         4
          54       1.00      1.00      1.00         4
          55       0.00      0.00      0.00         4
          56       0.90      1.00      0.95         9
          57       1.00      1.00      1.00         9
          58       0.38      1.00      0.56         5
          59       0.33      0.50      0.40         4
          60       0.60      0.75      0.67         4
          61       0.00      0.00      0.00         4
          62       0.80      1.00      0.89         4
          63       0.50      0.25      0.33         4
          64       0.29      0.50      0.36         4
          65       0.80      1.00      0.89         4
          66       0.50      0.50      0.50         4
          67       0.62      1.00      0.77         5
          68       0.00      0.00      0.00         4
          69       1.00      1.00      1.00         4
          70       0.30      0.60      0.40         5
          71       0.00      0.00      0.00         4
          72       0.83      1.00      0.91         5
          73       0.00      0.00      0.00         4
          74       1.00      1.00      1.00         4
          75       0.00      0.00      0.00         4
          76       0.67      1.00      0.80         4
          77       1.00      1.00      1.00         4
          78       1.00      0.75      0.86         4
          79       1.00      1.00      1.00         4
          80       0.50      1.00      0.67         9
          81       0.25      0.50      0.33         4
          82       0.40      0.50      0.44         4
          83       0.86      0.67      0.75         9
          84       1.00      1.00      1.00         9
          85       1.00      1.00      1.00         5
          86       1.00      1.00      1.00         5
          87       0.57      1.00      0.73         4
          88       0.78      0.78      0.78         9
          89       1.00      1.00      1.00         9
          90       0.00      0.00      0.00         4
          91       0.89      0.89      0.89         9
          92       0.80      1.00      0.89         4
          93       0.00      0.00      0.00         4
          94       1.00      1.00      1.00         5
          95       0.80      1.00      0.89         4
          96       0.80      0.89      0.84         9
          97       0.00      0.00      0.00         4
          98       0.80      1.00      0.89         4
          99       0.90      1.00      0.95         9
         100       0.80      1.00      0.89         4
         101       0.00      0.00      0.00         4
         102       0.80      1.00      0.89         4
         103       0.80      0.80      0.80         5
         104       0.11      0.25      0.15         4
         105       0.00      0.00      0.00         4
         106       0.21      1.00      0.35         4
         107       0.33      0.75      0.46         4
         108       0.67      0.50      0.57         4
         109       0.60      0.75      0.67         4
         110       0.75      0.75      0.75         4
         111       1.00      1.00      1.00         4
         112       0.00      0.00      0.00         9
         113       1.00      0.89      0.94         9
         114       1.00      1.00      1.00         5
         115       1.00      0.78      0.88         9
         116       1.00      0.75      0.86         4
         117       0.86      0.67      0.75         9
         118       1.00      1.00      1.00         5
         119       0.73      0.89      0.80         9
         120       0.62      0.56      0.59         9
         121       1.00      1.00      1.00         5
         122       0.75      0.75      0.75         4
         123       1.00      0.50      0.67         4
         124       0.57      0.89      0.70         9
         125       0.00      0.00      0.00         4
         126       1.00      1.00      1.00         4
         127       0.73      0.89      0.80         9
         128       0.71      1.00      0.83         5
         129       0.33      0.50      0.40         4
         130       1.00      1.00      1.00         4
         131       0.67      0.50      0.57         4
         132       0.00      0.00      0.00         4
         133       1.00      1.00      1.00         4
         134       1.00      1.00      1.00         5
         135       0.75      0.60      0.67         5
         136       1.00      0.89      0.94         9
         137       0.00      0.00      0.00         4
         138       1.00      0.89      0.94         9
         139       0.83      0.56      0.67         9
         140       0.00      0.00      0.00         4
         141       0.67      0.40      0.50         5
         142       0.00      0.00      0.00         9
         143       0.83      1.00      0.91         5
         144       0.90      1.00      0.95         9
         145       0.80      1.00      0.89         4
         146       0.33      0.20      0.25         5
         147       1.00      0.75      0.86         4
         148       1.00      0.75      0.86         4
         149       0.50      0.25      0.33         4
         150       0.00      0.00      0.00         9
         151       0.10      0.25      0.14         4
         152       0.67      0.50      0.57         4
         153       0.00      0.00      0.00         4
         154       0.90      1.00      0.95         9
         155       1.00      0.50      0.67         4
         156       0.50      0.80      0.62         5
         157       0.00      0.00      0.00         4
         158       0.40      0.50      0.44         4
         159       0.00      0.00      0.00         4
         160       1.00      0.50      0.67         4
         161       0.33      1.00      0.50         4
         162       0.90      1.00      0.95         9
         163       1.00      0.60      0.75         5
         164       1.00      1.00      1.00         4
         165       1.00      0.50      0.67         4
         166       0.86      0.86      0.86         7
         167       1.00      0.25      0.40         4
         168       0.50      0.50      0.50         4
         169       0.64      0.78      0.70         9
         170       1.00      0.80      0.89         5
         171       1.00      1.00      1.00         9
         172       0.00      0.00      0.00         4
         173       0.78      0.78      0.78         9
         174       0.75      0.75      0.75         4
         175       0.33      0.11      0.17         9
         176       0.44      1.00      0.62         4
         177       0.56      1.00      0.72         9
         178       0.62      0.89      0.73         9
         179       0.00      0.00      0.00         4
         180       1.00      0.75      0.86         4
         181       0.80      1.00      0.89         4
         182       0.42      1.00      0.59         5
         183       1.00      1.00      1.00         5
         184       0.00      0.00      0.00         4
         185       0.80      1.00      0.89         4
         186       1.00      1.00      1.00         4
         187       0.90      1.00      0.95         9
         188       1.00      0.43      0.60         7
         189       0.57      1.00      0.73         4
         190       0.60      0.75      0.67         4
         191       1.00      1.00      1.00         5
         192       0.00      0.00      0.00         4
         193       0.50      1.00      0.67         4
         194       0.67      0.50      0.57         4
         195       0.70      0.78      0.74         9
         196       1.00      1.00      1.00         9
         197       0.64      0.78      0.70         9
         198       0.50      0.50      0.50         4
         199       0.88      0.78      0.82         9
         200       1.00      0.80      0.89         5
         201       0.83      1.00      0.91         5
         202       0.31      0.80      0.44         5
         203       0.13      0.50      0.21         4
         204       0.75      1.00      0.86         9
         205       1.00      1.00      1.00         4
         206       1.00      0.50      0.67         4
         207       0.88      0.78      0.82         9
         208       0.83      1.00      0.91         5
         209       1.00      1.00      1.00         5
         210       0.08      0.56      0.14         9
         211       1.00      0.60      0.75         5
         212       0.25      0.25      0.25         4
         213       0.75      1.00      0.86         9
         214       0.67      0.80      0.73         5
         215       0.62      0.89      0.73         9
         216       0.00      0.00      0.00         4
         217       0.50      0.33      0.40         9
         218       0.73      0.89      0.80         9
         219       1.00      0.80      0.89         5
         220       1.00      1.00      1.00         4
         221       0.00      0.00      0.00         4
         222       0.00      0.00      0.00         4
         223       1.00      0.75      0.86         4
         224       0.90      1.00      0.95         9
         225       0.67      0.50      0.57         4
         226       0.75      0.75      0.75         4
         227       1.00      0.75      0.86         4
         228       0.00      0.00      0.00         4
         229       0.67      0.44      0.53         9
         230       0.80      1.00      0.89         4
         231       0.50      0.50      0.50         4
         232       1.00      0.75      0.86         4
         233       1.00      1.00      1.00         4
         234       1.00      1.00      1.00         5
         235       0.83      1.00      0.91         5
         236       0.00      0.00      0.00         4
         237       0.50      1.00      0.67         4
         238       1.00      1.00      1.00         9
         239       1.00      0.80      0.89         5
         240       0.80      1.00      0.89         4
         241       0.00      0.00      0.00         5
         242       0.56      0.56      0.56         9
         243       0.67      0.50      0.57         4
         244       0.80      0.80      0.80         5
         245       1.00      0.80      0.89         5
         246       1.00      0.75      0.86         4
         247       0.67      0.86      0.75         7
         248       0.00      0.00      0.00         4
         249       1.00      1.00      1.00         5
         250       1.00      0.75      0.86         4
         251       0.00      0.00      0.00         4
         252       0.67      1.00      0.80         4
         253       0.00      0.00      0.00         9
         254       0.00      0.00      0.00         4
         255       1.00      0.50      0.67         4
         256       0.33      0.20      0.25         5
         257       0.60      0.75      0.67         4
         258       0.80      0.89      0.84         9
         259       0.00      0.00      0.00         4
         260       0.00      0.00      0.00         4
         261       1.00      0.89      0.94         9
         262       0.75      1.00      0.86         9
         263       0.00      0.00      0.00         4
         264       0.80      1.00      0.89         4
         265       0.83      1.00      0.91         5
         266       1.00      0.40      0.57         5
         267       0.00      0.00      0.00         4
         268       0.00      0.00      0.00         4
         269       0.25      0.25      0.25         4
         270       1.00      0.25      0.40         4
         271       1.00      0.89      0.94         9
         272       1.00      1.00      1.00         9
         273       1.00      0.50      0.67         4
         274       1.00      1.00      1.00         9
         275       0.00      0.00      0.00         4
         276       1.00      1.00      1.00         5
         277       0.80      1.00      0.89         4
         278       0.83      1.00      0.91         5
         279       0.67      0.89      0.76         9
         280       0.75      1.00      0.86         9
         281       0.80      1.00      0.89         4
         282       0.50      0.75      0.60         4
         283       0.64      0.78      0.70         9
         284       0.00      0.00      0.00         9
         285       0.40      0.50      0.44         4
         286       0.00      0.00      0.00         4
         287       1.00      0.20      0.33         5
         288       1.00      0.50      0.67         4
         289       0.90      1.00      0.95         9
         290       0.75      0.75      0.75         4
         291       0.83      1.00      0.91         5
         292       1.00      0.60      0.75         5
         293       0.00      0.00      0.00         4
         294       0.80      1.00      0.89         4
         295       0.73      0.89      0.80         9
         296       0.57      1.00      0.73         4
         297       0.20      0.25      0.22         4
         298       1.00      0.80      0.89         5
         299       0.40      0.22      0.29         9
         300       0.38      0.75      0.50         4
         301       0.89      0.89      0.89         9
         302       0.83      1.00      0.91         5
         303       0.00      0.00      0.00         9
         304       1.00      1.00      1.00         9
         305       0.00      0.00      0.00         4
         306       1.00      1.00      1.00         4
         307       0.89      0.89      0.89         9
         308       0.80      1.00      0.89         4
         309       0.00      0.00      0.00         4
         310       0.50      1.00      0.67         4
         311       0.80      1.00      0.89         4
         312       1.00      1.00      1.00         9
         313       0.00      0.00      0.00         9
         314       0.78      0.78      0.78         9
         315       0.33      0.75      0.46         4
         316       0.67      1.00      0.80         4
         317       0.00      0.00      0.00         4
         318       1.00      0.89      0.94         9
         319       0.40      0.44      0.42         9
         320       0.75      0.75      0.75         4
         321       0.00      0.00      0.00         4
         322       0.50      0.20      0.29         5
         323       0.33      0.20      0.25         5
         324       1.00      1.00      1.00         5
         325       0.82      1.00      0.90         9
         326       0.60      0.75      0.67         4
         327       1.00      1.00      1.00         4
         328       0.20      0.50      0.29         4
         329       0.60      0.75      0.67         4
         330       0.00      0.00      0.00         9
         331       0.80      0.80      0.80         5
         332       0.55      0.67      0.60         9
         333       0.40      0.50      0.44         4
         334       0.78      0.78      0.78         9
         335       1.00      1.00      1.00         4
         336       0.56      0.56      0.56         9
         337       1.00      1.00      1.00         4
         338       0.00      0.00      0.00         4
         339       1.00      1.00      1.00         9
         340       0.80      1.00      0.89         4
         341       1.00      1.00      1.00         9
         342       0.00      0.00      0.00         4
         343       1.00      0.89      0.94         9
         344       0.00      0.00      0.00         4
         345       1.00      0.75      0.86         4
         346       0.57      1.00      0.73         4
         347       0.80      1.00      0.89         4
         348       0.43      0.75      0.55         4
         349       1.00      0.75      0.86         4
         350       0.80      1.00      0.89         4
         351       0.78      0.78      0.78         9
         352       1.00      0.75      0.86         4
         353       0.45      0.83      0.59         6
         354       1.00      0.78      0.88         9
         355       0.82      1.00      0.90         9
         356       1.00      0.75      0.86         4
         357       1.00      1.00      1.00         9
         358       0.29      0.50      0.36         4
         359       0.89      0.89      0.89         9
         360       0.00      0.00      0.00         9
         361       0.70      0.78      0.74         9
         362       0.00      0.00      0.00         4
         363       0.50      0.80      0.62         5
         364       0.83      1.00      0.91         5
         365       0.60      0.60      0.60         5
         366       1.00      1.00      1.00         4
         367       0.67      0.50      0.57         4
         368       1.00      0.89      0.94         9
         369       0.00      0.00      0.00         4
         370       0.67      1.00      0.80         4
         371       0.17      0.44      0.24         9
         372       0.86      0.67      0.75         9
         373       0.47      0.89      0.62         9
         374       1.00      1.00      1.00         4
         375       0.83      0.56      0.67         9
         376       0.88      0.78      0.82         9
         377       1.00      0.75      0.86         4
         378       1.00      1.00      1.00         4
         379       0.00      0.00      0.00         5
         380       0.57      0.80      0.67         5
         381       1.00      0.75      0.86         4
         382       0.80      1.00      0.89         4
         383       0.80      0.80      0.80         5
         384       0.83      1.00      0.91         5
         385       0.06      0.25      0.09         4
         386       1.00      0.75      0.86         4
         387       0.83      1.00      0.91         5
         388       0.80      1.00      0.89         4
         389       1.00      0.78      0.88         9
         390       1.00      0.60      0.75         5
         391       0.00      0.00      0.00         4
         392       0.00      0.00      0.00         4
         393       0.80      1.00      0.89         4
         394       1.00      0.50      0.67         4
         395       0.83      0.56      0.67         9
         396       1.00      1.00      1.00         4
         397       1.00      0.50      0.67         4
         398       0.62      1.00      0.77         5
         399       1.00      0.75      0.86         4
         400       0.50      0.89      0.64         9
         401       1.00      1.00      1.00         4
         402       0.75      0.75      0.75         4
         403       1.00      1.00      1.00         9
         404       0.69      1.00      0.82         9
         405       1.00      0.67      0.80         9
         406       1.00      1.00      1.00         5
         407       1.00      1.00      1.00         4
         408       1.00      0.20      0.33         5
         409       1.00      1.00      1.00         4
         410       0.00      0.00      0.00         9
         411       1.00      0.50      0.67         4
         412       0.50      0.25      0.33         4
         413       0.78      0.78      0.78         9
         414       1.00      1.00      1.00         4
         415       1.00      1.00      1.00         4
         416       1.00      0.75      0.86         4
         417       1.00      0.78      0.88         9
         418       0.67      1.00      0.80         4
         419       0.78      0.78      0.78         9
         420       0.80      0.80      0.80         5
         421       1.00      0.75      0.86         4
         422       0.67      1.00      0.80         4
         423       0.00      0.00      0.00         4
         424       0.80      0.80      0.80         5
         425       0.83      1.00      0.91         5
         426       1.00      0.75      0.86         4
         427       0.67      1.00      0.80         4
         428       0.50      0.75      0.60         4
         429       0.90      1.00      0.95         9
         430       1.00      0.22      0.36         9
         431       1.00      0.75      0.86         4
         432       1.00      0.75      0.86         4
         433       1.00      0.75      0.86         4
         434       0.00      0.00      0.00         4
         435       0.00      0.00      0.00         9
         436       0.44      1.00      0.62         4
         437       1.00      0.75      0.86         4
         438       1.00      0.80      0.89         5
         439       0.80      0.89      0.84         9
         440       1.00      1.00      1.00         4
         441       1.00      0.25      0.40         4
         442       0.75      0.75      0.75         4
         443       0.82      1.00      0.90         9
         444       1.00      0.75      0.86         4
         445       0.80      0.80      0.80         5
         446       1.00      1.00      1.00         4
         447       0.67      0.50      0.57         4
         448       0.90      1.00      0.95         9
         449       1.00      1.00      1.00         4
         450       1.00      0.80      0.89         5
         451       1.00      1.00      1.00         5
         452       0.50      0.25      0.33         4
         453       0.57      0.44      0.50         9
         454       0.80      1.00      0.89         4
         455       0.60      0.67      0.63         9
         456       0.83      0.56      0.67         9
         457       0.12      0.75      0.21         4
         458       1.00      0.50      0.67         4
         459       0.00      0.00      0.00         4
         460       1.00      1.00      1.00         4
         461       1.00      0.78      0.88         9
         462       0.80      1.00      0.89         4
         463       1.00      1.00      1.00         5
         464       0.00      0.00      0.00         9
         465       1.00      1.00      1.00         4
         466       0.00      0.00      0.00         4
         467       0.36      0.56      0.43         9
         468       1.00      0.25      0.40         4
         469       0.00      0.00      0.00         4
         470       1.00      0.75      0.86         4
         471       1.00      0.50      0.67         4
         472       1.00      0.80      0.89         5
         473       1.00      1.00      1.00         5
         474       0.40      0.40      0.40         5
         475       0.67      1.00      0.80         4
         476       1.00      1.00      1.00         4
         477       0.80      0.80      0.80         5
         478       0.90      1.00      0.95         9
         479       0.50      0.50      0.50         4
         480       0.80      1.00      0.89         4
         481       1.00      0.50      0.67         4
         482       0.80      1.00      0.89         4
         483       0.14      1.00      0.24         4
         484       0.50      0.25      0.33         4
         485       0.71      1.00      0.83         5
         486       0.75      0.60      0.67         5
         487       1.00      0.50      0.67         4
         488       0.80      1.00      0.89         4
         489       0.60      0.33      0.43         9
         490       1.00      0.50      0.67         4
         491       0.67      0.40      0.50         5
         492       1.00      1.00      1.00         4
         493       1.00      0.50      0.67         4
         494       1.00      1.00      1.00         9
         495       1.00      1.00      1.00         4
         496       1.00      0.50      0.67         4
         497       0.83      1.00      0.91         5
         498       0.80      1.00      0.89         4
         499       1.00      1.00      1.00         4
         500       0.50      0.22      0.31         9
         501       1.00      0.75      0.86         4
         502       0.09      0.25      0.13         4
         503       1.00      1.00      1.00         4
         504       1.00      0.75      0.86         4
         505       0.67      1.00      0.80         4
         506       1.00      1.00      1.00         4
         507       0.04      0.25      0.07         4
         508       0.00      0.00      0.00         4
         509       1.00      1.00      1.00         9
         510       0.33      0.25      0.29         4
         511       0.75      0.75      0.75         4
         512       1.00      0.25      0.40         4
         513       0.75      0.75      0.75         4
         514       0.75      0.75      0.75         4
         515       0.60      0.60      0.60         5
         516       1.00      1.00      1.00         9
         517       0.00      0.00      0.00         4
         518       0.75      0.60      0.67         5
         519       0.62      0.56      0.59         9
         520       0.50      0.75      0.60         4
         521       0.75      0.67      0.71         9
         522       0.00      0.00      0.00         5
         523       0.50      0.20      0.29         5
         524       0.50      0.50      0.50         4
         525       0.00      0.00      0.00         4
         526       0.60      0.75      0.67         4
         527       0.00      0.00      0.00         4
         528       0.00      0.00      0.00         4
         529       0.82      1.00      0.90         9
         530       0.50      0.50      0.50         4
         531       1.00      0.89      0.94         9
         532       0.80      1.00      0.89         4
         533       0.00      0.00      0.00         4
         534       0.80      0.89      0.84         9
         535       1.00      0.75      0.86         4
         536       0.50      0.50      0.50         4
         537       1.00      1.00      1.00         5
         538       1.00      1.00      1.00         4
         539       0.50      0.25      0.33         4
         540       1.00      0.80      0.89         5
         541       1.00      0.25      0.40         4
         542       0.50      0.40      0.44         5
         543       0.20      0.25      0.22         4
         544       1.00      0.75      0.86         4
         545       1.00      1.00      1.00         4
         546       1.00      1.00      1.00         9
         547       0.73      0.89      0.80         9
         548       0.00      0.00      0.00         4
         549       0.50      0.25      0.33         4
         550       0.80      1.00      0.89         4
         551       0.75      0.60      0.67         5
         552       0.40      0.50      0.44         4
         553       0.33      0.50      0.40         4
         554       0.31      0.89      0.46         9
         555       0.50      0.50      0.50         4
         556       1.00      0.25      0.40         4
         557       0.62      0.56      0.59         9
         558       0.90      1.00      0.95         9
         559       1.00      0.89      0.94         9
         560       0.67      0.40      0.50         5
         561       1.00      0.50      0.67         4
         562       0.80      1.00      0.89         4
         563       0.89      0.89      0.89         9
         564       1.00      1.00      1.00         4
         565       0.80      1.00      0.89         4
         566       1.00      0.25      0.40         4
         567       0.00      0.00      0.00         4
         568       1.00      1.00      1.00         4
         569       1.00      0.50      0.67         4
         570       0.00      0.00      0.00         9
         571       1.00      1.00      1.00         5
         572       0.90      1.00      0.95         9
         573       0.67      0.50      0.57         4
         574       0.50      1.00      0.67         4
         575       0.67      1.00      0.80         4
         576       1.00      1.00      1.00         4
         577       1.00      0.60      0.75         5
         578       1.00      0.67      0.80         9
         579       0.80      0.80      0.80         5
         580       0.00      0.00      0.00         4
         581       0.33      0.25      0.29         4
         582       0.75      0.75      0.75         4
         583       0.00      0.00      0.00         4
         584       0.80      0.44      0.57         9
         585       0.82      1.00      0.90         9
         586       0.40      1.00      0.57         4
         587       1.00      0.50      0.67         4
         588       0.80      1.00      0.89         4
         589       1.00      1.00      1.00         4
         590       1.00      1.00      1.00         4
         591       0.89      0.89      0.89         9
         592       0.00      0.00      0.00         9
         593       0.67      1.00      0.80         8
         594       1.00      0.22      0.36         9
         595       0.00      0.00      0.00         4
         596       0.80      0.89      0.84         9
         597       1.00      0.75      0.86         4
         598       1.00      0.20      0.33         5
         599       0.09      0.11      0.10         9
         600       1.00      1.00      1.00         4
         601       0.83      0.56      0.67         9
         602       1.00      0.89      0.94         9
         603       0.78      0.78      0.78         9
         604       0.75      1.00      0.86         9
         605       0.00      0.00      0.00         4
         606       0.40      0.50      0.44         4
         607       0.00      0.00      0.00         4
         608       0.86      0.67      0.75         9
         609       1.00      1.00      1.00         5
         610       1.00      1.00      1.00         4
         611       0.75      0.75      0.75         4
         612       1.00      0.80      0.89         5
         613       1.00      1.00      1.00         5
         614       0.00      0.00      0.00         5
         615       0.44      1.00      0.62         4
         616       0.67      0.50      0.57         4
         617       0.75      0.60      0.67         5
         618       1.00      0.50      0.67         4
         619       0.75      0.75      0.75         4
         620       1.00      1.00      1.00         4
         621       0.75      0.75      0.75         4
         622       0.50      0.75      0.60         4
         623       0.47      1.00      0.64         9
         624       1.00      0.50      0.67         4
         625       0.14      0.75      0.23         4
         626       1.00      0.22      0.36         9
         627       1.00      0.80      0.89         5
         628       0.00      0.00      0.00         4
         629       0.00      0.00      0.00         9
         630       0.50      1.00      0.67         4
         631       1.00      0.78      0.88         9
         632       1.00      0.80      0.89         5
         633       1.00      1.00      1.00         9
         634       0.50      0.40      0.44         5
         635       0.67      0.50      0.57         4
         636       0.00      0.00      0.00         4
         637       0.00      0.00      0.00         4
         638       1.00      0.50      0.67         8
         639       1.00      1.00      1.00         9
         640       1.00      0.50      0.67         4
         641       0.73      0.89      0.80         9
         642       0.83      0.56      0.67         9
         643       1.00      0.80      0.89         5
         644       1.00      0.75      0.86         4
         645       0.50      0.60      0.55         5
         646       0.60      0.75      0.67         4
         647       1.00      1.00      1.00         4
         648       1.00      1.00      1.00         5
         649       0.43      0.75      0.55         4
         650       0.71      0.56      0.63         9
         651       0.00      0.00      0.00         4
         652       0.50      0.50      0.50         4
         653       0.75      1.00      0.86         9
         654       1.00      0.80      0.89         5
         655       0.78      0.78      0.78         9
         656       0.00      0.00      0.00         4
         657       0.00      0.00      0.00         4
         658       1.00      0.75      0.86         4
         659       0.67      1.00      0.80         4
         660       0.00      0.00      0.00         4
         661       1.00      0.33      0.50         9
         662       1.00      1.00      1.00         9
         663       1.00      0.67      0.80         9
         664       0.14      0.20      0.17         5
         665       0.86      0.67      0.75         9
         666       1.00      0.75      0.86         4
         667       0.67      1.00      0.80         4
         668       1.00      1.00      1.00         9
         669       1.00      0.75      0.86         4
         670       1.00      1.00      1.00         5
         671       0.83      1.00      0.91         5
         672       1.00      0.89      0.94         9
         673       1.00      1.00      1.00         4
         674       0.70      0.78      0.74         9
         675       0.40      0.50      0.44         4
         676       0.70      0.78      0.74         9
         677       0.64      0.78      0.70         9
         678       0.25      0.25      0.25         4
         679       0.50      0.50      0.50         4
         680       1.00      0.75      0.86         4
         681       1.00      0.80      0.89         5
         682       1.00      0.25      0.40         4
         683       1.00      0.89      0.94         9
         684       1.00      0.89      0.94         9
         685       1.00      0.75      0.86         4
         686       1.00      1.00      1.00         5
         687       1.00      0.89      0.94         9
         688       0.82      1.00      0.90         9
         689       0.00      0.00      0.00         9
         690       0.80      1.00      0.89         4
         691       1.00      0.40      0.57         5
         692       0.00      0.00      0.00         4
         693       1.00      0.80      0.89         5
         694       0.57      0.80      0.67         5
         695       0.50      0.40      0.44         5
         696       1.00      1.00      1.00         4
         697       0.00      0.00      0.00         4
         698       0.80      1.00      0.89         4
         699       1.00      1.00      1.00         9
         700       1.00      1.00      1.00         5
         701       0.00      0.00      0.00         4
         702       0.67      0.89      0.76         9
         703       0.50      0.25      0.33         4
         704       0.67      1.00      0.80         4
         705       0.00      0.00      0.00         4
         706       1.00      1.00      1.00         5
         707       1.00      1.00      1.00         9
         708       0.80      0.89      0.84         9
         709       1.00      1.00      1.00         4
         710       0.67      0.80      0.73         5
         711       0.00      0.00      0.00         4
         712       1.00      0.75      0.86         4
         713       0.62      0.56      0.59         9
         714       0.00      0.00      0.00         4
         715       1.00      0.75      0.86         4
         716       0.67      1.00      0.80         4
         717       0.00      0.00      0.00         4
         718       1.00      1.00      1.00         4
         719       0.67      0.50      0.57         4
         720       0.80      0.80      0.80         5
         721       0.00      0.00      0.00         9
         722       0.80      0.89      0.84         9
         723       0.00      0.00      0.00         4
         724       1.00      0.75      0.86         4
         725       1.00      1.00      1.00         4
         726       1.00      1.00      1.00         4
         727       0.86      0.67      0.75         9
         728       0.10      0.25      0.14         4
         729       0.89      0.89      0.89         9
         730       0.50      0.89      0.64         9
         731       0.89      0.89      0.89         9
         732       1.00      0.89      0.94         9
         733       0.86      0.67      0.75         9
         734       0.25      0.25      0.25         4
         735       0.89      0.89      0.89         9
         736       0.00      0.00      0.00         4
         737       1.00      0.89      0.94         9
         738       0.82      1.00      0.90         9
         739       0.00      0.00      0.00         4
         740       0.71      1.00      0.83         5
         741       1.00      0.75      0.86         4
         742       1.00      0.75      0.86         4
         743       1.00      0.75      0.86         4
         744       0.33      0.80      0.47         5
         745       0.50      0.75      0.60         4
         746       1.00      1.00      1.00         4
         747       1.00      0.89      0.94         9
         748       0.80      0.89      0.84         9
         749       0.60      0.75      0.67         4
         750       0.00      0.00      0.00         4
         751       1.00      0.75      0.86         4
         752       0.00      0.00      0.00         4
         753       0.60      0.75      0.67         4
         754       0.90      1.00      0.95         9
         755       1.00      0.25      0.40         4
         756       0.75      0.75      0.75         4
         757       1.00      1.00      1.00         5
         758       1.00      0.80      0.89         5
         759       0.67      0.50      0.57         4
         760       0.75      1.00      0.86         9
         761       1.00      0.50      0.67         4
         762       0.00      0.00      0.00         4
         763       1.00      1.00      1.00         9
         764       0.00      0.00      0.00         4
         765       0.62      0.56      0.59         9
         766       0.75      1.00      0.86         9
         767       0.50      0.50      0.50         4
         768       1.00      0.50      0.67         4
         769       0.60      0.33      0.43         9
         770       0.80      1.00      0.89         4
         771       0.89      0.89      0.89         9
         772       0.38      0.75      0.50         4
         773       0.07      0.25      0.11         4
         774       1.00      0.75      0.86         4
         775       1.00      1.00      1.00         4
         776       0.67      0.80      0.73         5
         777       1.00      0.50      0.67         4
         778       0.33      0.25      0.29         4
         779       0.70      0.78      0.74         9
         780       0.57      1.00      0.73         4
         781       0.82      1.00      0.90         9
         782       1.00      0.75      0.86         4
         783       0.75      0.75      0.75         4
         784       0.83      1.00      0.91         5
         785       1.00      0.80      0.89         5
         786       0.55      0.67      0.60         9
         787       0.67      1.00      0.80         4
         788       0.00      0.00      0.00         4
         789       1.00      1.00      1.00         4
         790       0.75      0.75      0.75         4
         791       1.00      0.50      0.67         4
         792       0.83      1.00      0.91         5
         793       0.60      0.75      0.67         4
         794       1.00      0.50      0.67         4
         795       1.00      0.75      0.86         4
         796       0.00      0.00      0.00         4
         797       0.80      1.00      0.89         4
         798       0.00      0.00      0.00         4
         799       0.00      0.00      0.00         4
         800       1.00      0.50      0.67         4
         801       0.67      1.00      0.80         4
         802       1.00      1.00      1.00         5
         803       1.00      1.00      1.00         4
         804       1.00      0.67      0.80         9
         805       1.00      1.00      1.00         4
         806       1.00      0.67      0.80         9
         807       1.00      0.78      0.88         9
         808       0.50      0.50      0.50         4
         809       0.64      1.00      0.78         9
         810       0.00      0.00      0.00         4
         811       1.00      1.00      1.00         4
         812       0.00      0.00      0.00         4
         813       0.50      0.25      0.33         4
         814       0.00      0.00      0.00         5
         815       0.67      0.50      0.57         4
         816       1.00      0.60      0.75         5
         817       1.00      0.88      0.93         8
         818       0.89      0.89      0.89         9
         819       0.00      0.00      0.00         4
         820       1.00      0.75      0.86         4
         821       0.50      0.60      0.55         5
         822       0.00      0.00      0.00         4
         823       1.00      0.89      0.94         9
         824       0.14      1.00      0.24         4
         825       0.90      1.00      0.95         9
         826       0.00      0.00      0.00         4
         827       0.56      1.00      0.71         5
         828       0.75      0.75      0.75         4
         829       0.75      0.67      0.71         9
         830       1.00      0.50      0.67         4
         831       0.80      1.00      0.89         4
         832       1.00      0.60      0.75         5
         833       0.80      1.00      0.89         4
         834       0.00      0.00      0.00         4
         835       1.00      0.75      0.86         4
         836       0.00      0.00      0.00         4
         837       0.78      0.78      0.78         9
         838       1.00      1.00      1.00         4
         839       0.64      0.78      0.70         9
         840       0.23      0.60      0.33         5
         841       0.00      0.00      0.00         4
         842       0.33      0.25      0.29         4
         843       0.00      0.00      0.00         4
         844       1.00      0.75      0.86         4
         845       1.00      0.60      0.75         5
         846       0.80      0.80      0.80         5
         847       1.00      0.67      0.80         9
         848       0.00      0.00      0.00         4
         849       0.00      0.00      0.00         4
         850       0.00      0.00      0.00         4
         851       1.00      0.22      0.36         9
         852       0.54      0.78      0.64         9
         853       1.00      1.00      1.00         9
         854       0.00      0.00      0.00         4
         855       1.00      1.00      1.00         9
         856       1.00      0.50      0.67         4
         857       1.00      0.25      0.40         4
         858       1.00      0.25      0.40         4
         859       1.00      0.67      0.80         9
         860       0.57      1.00      0.73         4
         861       0.82      1.00      0.90         9
         862       0.50      0.60      0.55         5
         863       0.50      0.25      0.33         4
         864       0.00      0.00      0.00         4
         865       1.00      1.00      1.00         4
         866       0.83      0.56      0.67         9
         867       1.00      1.00      1.00         4
         868       0.33      0.25      0.29         4
         869       1.00      0.75      0.86         4
         870       0.20      0.25      0.22         4
         871       0.80      1.00      0.89         4
         872       0.67      1.00      0.80         4
         873       1.00      0.78      0.88         9
         874       1.00      1.00      1.00         4
         875       0.60      0.75      0.67         4
         876       0.67      0.22      0.33         9
         877       0.00      0.00      0.00         4
         878       0.89      0.89      0.89         9
         879       0.80      1.00      0.89         4
         880       0.71      0.56      0.63         9
         881       0.71      1.00      0.83         5
         882       0.71      1.00      0.83         5
         883       0.00      0.00      0.00         4
         884       0.25      0.25      0.25         4
         885       0.20      0.25      0.22         4
         886       0.12      0.25      0.17         4
         887       0.00      0.00      0.00         4
         888       0.00      0.00      0.00         4
         889       0.00      0.00      0.00         4
         890       0.00      0.00      0.00         9
         891       1.00      1.00      1.00         4
         892       0.40      0.80      0.53         5
         893       1.00      0.25      0.40         4

    accuracy                           0.67      4917
   macro avg       0.66      0.64      0.63      4917
weighted avg       0.68      0.67      0.66      4917

task_train_time: {0: 9.103292583000002, 1: 4.386084568000001, 2: 4.421774825, 3: 5.240873794000002, 4: 4.667099149000002, 5: 5.576868921000006, 6: 5.497317608000003, 7: 5.211722644000005, 8: 5.100258031000003, 9: 6.116205549000007, 10: 5.00340511200001, 11: 4.998662389000003, 12: 5.1838669539999955, 13: 5.481546096000002, 14: 6.135288398, 15: 5.321805468000008, 16: 5.164398777000002, 17: 6.3861485620000025, 18: 4.599026537, 19: 5.680113911999996, 20: 5.515688178999994, 21: 5.18190832099998, 22: 5.571286495999999, 23: 4.284967413000004, 24: 4.289556585999975, 25: 5.299668576000016, 26: 4.834246202000003, 27: 5.496337314000016, 28: 5.377533849000002, 29: 5.8925082080000095, 30: 5.18101758200001, 31: 5.434026485999993, 32: 5.874907264000001, 33: 6.291632117000006, 34: 5.489591899000004, 35: 6.163297685999993, 36: 5.223374279000012, 37: 5.948827075999986, 38: 4.872367278000013, 39: 4.872619525000005, 40: 5.5207019230000185, 41: 5.640284656999995, 42: 5.382247762999981, 43: 5.126796524000014}
prediction_time: 0.00028047500001093795
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
