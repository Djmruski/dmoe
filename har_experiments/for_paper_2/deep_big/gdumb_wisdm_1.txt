Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='be572de6-e0ec-493b-95ae-5fab422e1762', conf_timestamp='2023-08-09 12:53:10.888376', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 96.7 % 	 [Task-IL]: 54.4 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 56.13 % 	 [Task-IL]: 39.22 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 49.81 % 	 [Task-IL]: 36.92 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 36.42 % 	 [Task-IL]: 33.65 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 28.91 % 	 [Task-IL]: 33.08 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 24.37 % 	 [Task-IL]: 32.46 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.23 % 	 [Task-IL]: 33.1 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 16.49 % 	 [Task-IL]: 32.81 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 15.37 % 	 [Task-IL]: 32.89 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 14.62 % 	 [Task-IL]: 31.93 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 16.62 % 	 [Task-IL]: 31.01 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.55 % 	 [Task-IL]: 30.56 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 9.17 % 	 [Task-IL]: 30.89 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 10.63 % 	 [Task-IL]: 30.77 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 9.77 % 	 [Task-IL]: 30.53 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 10.02 % 	 [Task-IL]: 30.42 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 9.96 % 	 [Task-IL]: 30.61 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 10.87 % 	 [Task-IL]: 30.12 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 9.26 % 	 [Task-IL]: 29.83 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.76 % 	 [Task-IL]: 29.69 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 9.26 % 	 [Task-IL]: 29.64 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 5.99 % 	 [Task-IL]: 29.9 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 6.97 % 	 [Task-IL]: 29.65 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.64 % 	 [Task-IL]: 30.14 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.09 % 	 [Task-IL]: 30.41 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 5.82 % 	 [Task-IL]: 30.09 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 5.39 % 	 [Task-IL]: 30.2 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 5.43 % 	 [Task-IL]: 29.95 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.07 % 	 [Task-IL]: 29.81 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 5.53 % 	 [Task-IL]: 29.68 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.81 % 	 [Task-IL]: 29.51 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 5.14 % 	 [Task-IL]: 29.09 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 4.55 % 	 [Task-IL]: 28.94 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.48 % 	 [Task-IL]: 29.05 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.71 % 	 [Task-IL]: 28.78 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 4.54 % 	 [Task-IL]: 28.6 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.9 % 	 [Task-IL]: 28.79 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.47 % 	 [Task-IL]: 28.68 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 3.56 % 	 [Task-IL]: 28.73 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 3.78 % 	 [Task-IL]: 28.56 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.24 % 	 [Task-IL]: 28.5 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 3.79 % 	 [Task-IL]: 28.47 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.17 % 	 [Task-IL]: 28.17 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({567: 32, 876: 27, 544: 26, 122: 26, 604: 25, 447: 24, 327: 24, 150: 24, 3: 24, 462: 24, 170: 24, 684: 24, 220: 24, 532: 24, 31: 24, 256: 24, 669: 24, 871: 24, 259: 24, 84: 23, 777: 23, 534: 23, 625: 23, 50: 23, 443: 23, 495: 23, 587: 23, 552: 22, 238: 22, 39: 22, 498: 22, 531: 22, 14: 22, 597: 22, 473: 22, 427: 22, 154: 22, 861: 22, 194: 22, 81: 22, 361: 22, 134: 22, 822: 21, 32: 21, 856: 21, 367: 21, 438: 21, 440: 21, 432: 21, 201: 21, 803: 21, 105: 21, 693: 21, 528: 20, 83: 20, 610: 20, 169: 20, 379: 20, 529: 20, 872: 20, 411: 20, 556: 20, 652: 20, 148: 20, 294: 20, 727: 20, 772: 20, 733: 20, 106: 20, 553: 20, 650: 20, 314: 20, 55: 20, 252: 20, 543: 20, 280: 20, 780: 20, 589: 20, 337: 20, 732: 19, 819: 19, 284: 19, 113: 19, 368: 19, 451: 19, 172: 19, 644: 19, 851: 19, 680: 19, 319: 19, 526: 19, 21: 19, 46: 19, 613: 19, 349: 19, 629: 19, 403: 19, 712: 18, 879: 18, 137: 18, 151: 18, 298: 18, 0: 18, 168: 18, 836: 18, 475: 18, 880: 18, 273: 18, 397: 18, 147: 18, 773: 18, 2: 18, 78: 18, 728: 18, 890: 18, 740: 18, 430: 18, 541: 17, 439: 17, 812: 17, 706: 17, 497: 17, 831: 17, 153: 17, 588: 17, 165: 17, 205: 17, 756: 17, 802: 17, 862: 17, 163: 17, 248: 17, 735: 17, 229: 16, 320: 16, 682: 16, 94: 16, 743: 16, 499: 16, 761: 16, 524: 16, 114: 16, 276: 16, 196: 16, 385: 16, 747: 16, 267: 16, 734: 16, 225: 16, 96: 16, 869: 16, 174: 16, 254: 16, 343: 16, 624: 16, 809: 16, 672: 15, 825: 15, 264: 15, 192: 15, 533: 15, 85: 15, 656: 15, 178: 15, 678: 15, 813: 15, 407: 15, 90: 15, 386: 15, 308: 15, 140: 15, 643: 15, 607: 15, 373: 15, 305: 15, 710: 15, 716: 15, 56: 15, 464: 15, 670: 15, 465: 15, 487: 15, 700: 15, 454: 14, 345: 14, 666: 14, 874: 14, 805: 14, 139: 14, 309: 14, 730: 14, 428: 14, 517: 14, 657: 14, 844: 14, 608: 14, 671: 14, 95: 14, 233: 14, 286: 14, 886: 14, 123: 14, 355: 14, 828: 14, 384: 14, 88: 14, 136: 14, 146: 14, 702: 14, 249: 14, 406: 14, 591: 14, 240: 14, 630: 13, 389: 13, 80: 13, 520: 13, 770: 13, 784: 13, 779: 13, 804: 13, 615: 13, 509: 13, 435: 13, 570: 13, 63: 13, 893: 13, 37: 13, 452: 13, 328: 13, 200: 13, 568: 13, 162: 13, 459: 13, 416: 13, 161: 13, 184: 13, 477: 13, 210: 13, 179: 13, 763: 13, 191: 13, 302: 13, 241: 13, 503: 13, 711: 12, 87: 12, 30: 12, 855: 12, 217: 12, 265: 12, 502: 12, 781: 12, 360: 12, 714: 12, 376: 12, 458: 12, 442: 12, 574: 12, 617: 12, 218: 12, 429: 12, 635: 12, 414: 12, 585: 12, 539: 12, 310: 12, 762: 12, 564: 12, 648: 12, 595: 12, 413: 12, 300: 12, 398: 12, 628: 12, 230: 12, 129: 12, 239: 12, 77: 12, 234: 12, 99: 12, 645: 12, 253: 12, 159: 12, 798: 12, 651: 12, 697: 12, 126: 12, 668: 12, 820: 11, 423: 11, 810: 11, 559: 11, 634: 11, 339: 11, 764: 11, 44: 11, 489: 11, 409: 11, 115: 11, 515: 11, 392: 11, 857: 11, 834: 11, 600: 11, 418: 11, 16: 11, 548: 11, 41: 11, 410: 11, 538: 11, 312: 11, 866: 11, 444: 11, 289: 11, 707: 11, 293: 11, 653: 11, 511: 11, 420: 11, 546: 11, 510: 11, 57: 11, 207: 11, 457: 11, 704: 10, 590: 10, 47: 10, 616: 10, 97: 10, 849: 10, 203: 10, 402: 10, 287: 10, 778: 10, 748: 10, 195: 10, 19: 10, 292: 10, 288: 10, 737: 10, 363: 10, 324: 10, 530: 10, 467: 10, 889: 10, 745: 10, 649: 10, 282: 10, 13: 10, 8: 10, 639: 10, 326: 10, 352: 10, 156: 10, 482: 10, 132: 10, 408: 10, 676: 10, 1: 10, 719: 10, 560: 10, 393: 10, 598: 10, 715: 10, 481: 10, 365: 10, 833: 10, 291: 10, 350: 10, 675: 10, 873: 10, 12: 10, 208: 10, 223: 10, 175: 10, 120: 10, 694: 9, 830: 9, 390: 9, 793: 9, 396: 9, 48: 9, 647: 9, 796: 9, 687: 9, 221: 9, 580: 9, 573: 9, 701: 9, 677: 9, 7: 9, 870: 9, 788: 9, 236: 9, 726: 9, 315: 9, 476: 9, 124: 9, 863: 9, 323: 9, 577: 9, 29: 9, 227: 9, 848: 9, 460: 9, 145: 9, 75: 9, 404: 9, 11: 9, 185: 9, 142: 9, 850: 9, 351: 9, 769: 9, 843: 9, 347: 9, 268: 9, 348: 9, 490: 9, 472: 9, 868: 9, 266: 9, 110: 9, 231: 9, 621: 9, 622: 9, 492: 9, 446: 9, 307: 9, 569: 9, 374: 9, 766: 9, 103: 9, 437: 9, 144: 9, 5: 9, 768: 9, 338: 9, 177: 9, 513: 9, 882: 9, 774: 9, 742: 9, 82: 9, 486: 9, 118: 9, 359: 9, 400: 9, 642: 9, 674: 9, 795: 9, 198: 9, 104: 9, 321: 9, 713: 8, 61: 8, 173: 8, 261: 8, 859: 8, 466: 8, 791: 8, 562: 8, 799: 8, 620: 8, 35: 8, 612: 8, 258: 8, 353: 8, 561: 8, 746: 8, 801: 8, 448: 8, 892: 8, 383: 8, 25: 8, 222: 8, 214: 8, 623: 8, 111: 8, 759: 8, 523: 8, 70: 8, 257: 8, 160: 8, 456: 8, 606: 8, 468: 8, 183: 8, 369: 8, 875: 8, 441: 8, 434: 8, 789: 8, 603: 8, 100: 8, 838: 8, 372: 8, 823: 8, 42: 8, 330: 8, 776: 8, 251: 8, 817: 8, 638: 8, 841: 8, 6: 8, 811: 8, 507: 8, 846: 8, 213: 8, 27: 8, 877: 8, 417: 8, 775: 8, 341: 8, 93: 8, 313: 8, 665: 8, 366: 8, 141: 8, 566: 8, 66: 8, 853: 8, 493: 8, 157: 8, 24: 8, 699: 8, 878: 8, 204: 8, 752: 8, 884: 7, 808: 7, 275: 7, 816: 7, 212: 7, 633: 7, 211: 7, 181: 7, 187: 7, 478: 7, 232: 7, 852: 7, 579: 7, 826: 7, 52: 7, 69: 7, 436: 7, 504: 7, 334: 7, 387: 7, 186: 7, 626: 7, 512: 7, 758: 7, 117: 7, 54: 7, 705: 7, 845: 7, 522: 7, 664: 7, 67: 7, 724: 7, 494: 7, 370: 7, 279: 7, 281: 7, 412: 7, 619: 7, 751: 7, 188: 7, 17: 7, 357: 7, 661: 7, 112: 7, 641: 7, 837: 7, 58: 7, 301: 7, 786: 7, 582: 7, 199: 7, 128: 7, 224: 7, 518: 7, 26: 7, 219: 7, 121: 7, 640: 7, 496: 7, 658: 7, 449: 7, 739: 7, 542: 7, 131: 7, 572: 7, 631: 7, 749: 7, 4: 7, 471: 7, 558: 7, 547: 7, 155: 7, 425: 7, 692: 7, 865: 7, 304: 7, 107: 7, 525: 7, 190: 7, 483: 7, 753: 7, 250: 7, 824: 7, 881: 7, 271: 7, 242: 7, 637: 7, 867: 7, 431: 7, 15: 7, 189: 6, 22: 6, 79: 6, 91: 6, 576: 6, 395: 6, 272: 6, 86: 6, 527: 6, 765: 6, 847: 6, 23: 6, 246: 6, 461: 6, 514: 6, 228: 6, 445: 6, 698: 6, 340: 6, 74: 6, 28: 6, 500: 6, 401: 6, 378: 6, 832: 6, 62: 6, 783: 6, 555: 6, 306: 6, 578: 6, 599: 6, 68: 6, 662: 6, 618: 6, 109: 6, 235: 6, 614: 6, 794: 6, 296: 6, 433: 6, 519: 6, 422: 6, 835: 6, 72: 6, 785: 6, 488: 6, 596: 6, 540: 6, 394: 6, 549: 6, 270: 6, 303: 6, 750: 6, 344: 6, 646: 6, 176: 6, 135: 6, 243: 6, 602: 6, 64: 6, 318: 6, 501: 6, 667: 6, 364: 6, 424: 6, 149: 6, 33: 6, 679: 6, 247: 6, 545: 6, 659: 6, 636: 6, 354: 6, 325: 6, 814: 6, 563: 6, 127: 6, 592: 6, 43: 6, 581: 6, 362: 6, 627: 6, 317: 6, 356: 6, 71: 5, 829: 5, 485: 5, 358: 5, 660: 5, 888: 5, 605: 5, 792: 5, 725: 5, 554: 5, 883: 5, 470: 5, 688: 5, 821: 5, 695: 5, 479: 5, 709: 5, 133: 5, 469: 5, 329: 5, 864: 5, 49: 5, 332: 5, 818: 5, 89: 5, 741: 5, 683: 5, 722: 5, 76: 5, 38: 5, 754: 5, 594: 5, 274: 5, 255: 5, 738: 5, 744: 5, 377: 5, 708: 5, 125: 5, 60: 5, 815: 5, 388: 5, 290: 5, 721: 5, 767: 5, 584: 5, 723: 5, 322: 5, 138: 5, 92: 5, 283: 5, 382: 5, 381: 5, 152: 5, 854: 5, 20: 5, 790: 5, 696: 5, 73: 5, 887: 5, 371: 5, 760: 5, 65: 5, 206: 5, 691: 5, 237: 5, 654: 5, 593: 5, 755: 5, 399: 5, 450: 4, 583: 4, 297: 4, 842: 4, 331: 4, 703: 4, 36: 4, 98: 4, 571: 4, 263: 4, 484: 4, 102: 4, 346: 4, 717: 4, 295: 4, 685: 4, 245: 4, 202: 4, 535: 4, 673: 4, 720: 4, 53: 4, 335: 4, 663: 4, 40: 4, 601: 4, 736: 4, 480: 4, 277: 4, 59: 4, 474: 4, 285: 4, 108: 4, 278: 4, 45: 4, 197: 4, 299: 4, 193: 4, 405: 4, 262: 4, 9: 4, 419: 4, 689: 4, 839: 4, 536: 4, 10: 4, 521: 4, 415: 4, 505: 4, 860: 4, 209: 4, 226: 4, 18: 4, 260: 4, 731: 4, 491: 3, 182: 3, 333: 3, 455: 3, 807: 3, 632: 3, 686: 3, 51: 3, 690: 3, 516: 3, 216: 3, 453: 3, 611: 3, 244: 3, 609: 3, 143: 3, 167: 3, 797: 3, 840: 3, 782: 3, 806: 3, 171: 3, 551: 3, 158: 3, 34: 3, 426: 3, 180: 3, 316: 3, 269: 3, 757: 3, 508: 3, 342: 3, 336: 3, 164: 3, 463: 3, 891: 3, 787: 3, 101: 3, 391: 2, 116: 2, 215: 2, 421: 2, 166: 2, 858: 2, 550: 2, 130: 2, 885: 2, 771: 2, 655: 2, 557: 2, 718: 2, 375: 2, 119: 2, 800: 2, 506: 2, 729: 2, 311: 2, 537: 2, 586: 2, 827: 2, 575: 2, 565: 1, 380: 1})
fit_time: 28.467934162999967

Accuracy for 44 task(s): 	 [Class-IL]: 66.6 % 	 [Task-IL]: 29.41 %

CLASS_IL_ACC: 
	[71.97802197802197, 64.22018348623854, 63.0, 64.95726495726495, 66.05504587155964, 62.264150943396224, 69.40298507462687, 56.25, 61.61616161616161, 70.75471698113208, 70.37037037037037, 75.92592592592592, 71.7948717948718, 75.45454545454545, 77.87610619469027, 72.22222222222221, 71.9298245614035, 72.38095238095238, 46.0, 68.51851851851852, 77.88461538461539, 63.77952755905512, 61.73913043478261, 69.79166666666666, 72.56637168141593, 70.50359712230215, 58.82352941176471, 72.11538461538461, 62.37623762376238, 69.0909090909091, 60.37735849056604, 65.13761467889908, 63.20754716981132, 50.89285714285714, 59.79381443298969, 67.82608695652173, 67.56756756756756, 75.92592592592592, 76.92307692307693, 57.391304347826086, 56.730769230769226, 70.83333333333334, 61.94690265486725, 64.28571428571429]
TASK_IL_ACC: 
	[53.84615384615385, 22.018348623853214, 36.0, 22.22222222222222, 29.357798165137616, 29.245283018867923, 32.83582089552239, 28.90625, 34.34343434343434, 24.528301886792452, 18.51851851851852, 27.77777777777778, 38.46153846153847, 25.454545454545453, 27.43362831858407, 30.555555555555557, 28.07017543859649, 21.904761904761905, 28.999999999999996, 26.851851851851855, 26.923076923076923, 30.708661417322837, 26.956521739130434, 35.41666666666667, 37.16814159292036, 25.899280575539567, 27.73109243697479, 24.03846153846154, 24.752475247524753, 24.545454545454547, 26.41509433962264, 18.34862385321101, 28.30188679245283, 29.464285714285715, 21.649484536082475, 24.347826086956523, 29.72972972972973, 23.14814814814815, 31.73076923076923, 22.608695652173914, 27.884615384615387, 30.208333333333332, 24.778761061946902, 83.92857142857143]
f1_micro: 66.68700427089689
f1_macro: 62.04514063332629
              precision    recall  f1-score   support

           0       0.64      1.00      0.78         9
           1       0.83      1.00      0.91         5
           2       0.90      1.00      0.95         9
           3       0.60      1.00      0.75         9
           4       0.80      1.00      0.89         4
           5       0.67      0.50      0.57         4
           6       0.00      0.00      0.00         4
           7       0.00      0.00      0.00         4
           8       1.00      0.50      0.67         4
           9       1.00      1.00      1.00         4
          10       0.00      0.00      0.00         4
          11       0.00      0.00      0.00         4
          12       0.80      0.80      0.80         5
          13       1.00      0.75      0.86         4
          14       0.78      0.78      0.78         9
          15       0.67      0.50      0.57         4
          16       1.00      0.20      0.33         5
          17       0.80      1.00      0.89         4
          18       1.00      0.80      0.89         5
          19       0.29      0.50      0.36         4
          20       1.00      1.00      1.00         4
          21       0.46      0.67      0.55         9
          22       0.00      0.00      0.00         4
          23       0.83      1.00      0.91         5
          24       1.00      1.00      1.00         4
          25       0.12      0.25      0.17         4
          26       0.50      0.25      0.33         4
          27       0.80      1.00      0.89         4
          28       0.50      0.25      0.33         4
          29       1.00      1.00      1.00         5
          30       0.82      1.00      0.90         9
          31       1.00      1.00      1.00         9
          32       0.90      1.00      0.95         9
          33       0.33      0.50      0.40         4
          34       0.80      1.00      0.89         4
          35       0.00      0.00      0.00         4
          36       0.00      0.00      0.00         4
          37       0.71      1.00      0.83         5
          38       0.18      0.60      0.27         5
          39       0.73      0.89      0.80         9
          40       0.00      0.00      0.00         4
          41       1.00      0.44      0.62         9
          42       1.00      1.00      1.00         5
          43       0.56      1.00      0.71         5
          44       0.83      1.00      0.91         5
          45       0.67      0.50      0.57         4
          46       0.69      1.00      0.82         9
          47       0.56      0.62      0.59         8
          48       0.00      0.00      0.00         4
          49       1.00      1.00      1.00         4
          50       1.00      0.89      0.94         9
          51       0.33      0.25      0.29         4
          52       0.00      0.00      0.00         4
          53       0.29      0.50      0.36         4
          54       0.83      1.00      0.91         5
          55       0.67      0.89      0.76         9
          56       0.00      0.00      0.00         9
          57       0.57      0.80      0.67         5
          58       0.00      0.00      0.00         4
          59       0.80      1.00      0.89         4
          60       0.80      1.00      0.89         4
          61       0.90      1.00      0.95         9
          62       1.00      1.00      1.00         4
          63       1.00      0.50      0.67         4
          64       1.00      0.50      0.67         4
          65       0.80      1.00      0.89         4
          66       1.00      1.00      1.00         5
          67       0.00      0.00      0.00         5
          68       0.80      1.00      0.89         4
          69       0.67      0.50      0.57         4
          70       0.00      0.00      0.00         4
          71       1.00      1.00      1.00         4
          72       0.00      0.00      0.00         4
          73       0.40      0.40      0.40         5
          74       0.00      0.00      0.00         4
          75       0.80      1.00      0.89         4
          76       0.50      0.25      0.33         4
          77       1.00      1.00      1.00         5
          78       0.86      0.67      0.75         9
          79       0.00      0.00      0.00         4
          80       1.00      1.00      1.00         4
          81       0.86      0.67      0.75         9
          82       1.00      1.00      1.00         4
          83       0.80      0.89      0.84         9
          84       0.82      1.00      0.90         9
          85       0.67      0.89      0.76         9
          86       0.00      0.00      0.00         4
          87       0.75      0.67      0.71         9
          88       0.00      0.00      0.00         9
          89       1.00      0.75      0.86         4
          90       0.60      0.75      0.67         4
          91       1.00      1.00      1.00         4
          92       0.00      0.00      0.00         4
          93       1.00      1.00      1.00         5
          94       1.00      0.33      0.50         9
          95       0.50      0.75      0.60         4
          96       0.90      1.00      0.95         9
          97       0.44      1.00      0.62         4
          98       0.00      0.00      0.00         5
          99       0.67      0.50      0.57         4
         100       1.00      0.50      0.67         4
         101       0.00      0.00      0.00         4
         102       0.00      0.00      0.00         4
         103       0.21      1.00      0.35         4
         104       1.00      0.80      0.89         5
         105       0.82      1.00      0.90         9
         106       0.82      1.00      0.90         9
         107       0.75      0.75      0.75         4
         108       1.00      0.40      0.57         5
         109       0.50      0.75      0.60         4
         110       1.00      0.50      0.67         4
         111       0.60      0.75      0.67         4
         112       1.00      0.60      0.75         5
         113       0.78      0.78      0.78         9
         114       1.00      1.00      1.00         9
         115       0.83      1.00      0.91         5
         116       1.00      0.50      0.67         4
         117       1.00      0.40      0.57         5
         118       0.67      0.40      0.50         5
         119       0.00      0.00      0.00         4
         120       0.80      0.80      0.80         5
         121       0.00      0.00      0.00         4
         122       0.50      0.56      0.53         9
         123       1.00      0.78      0.88         9
         124       1.00      1.00      1.00         4
         125       0.00      0.00      0.00         4
         126       0.80      0.80      0.80         5
         127       0.33      0.25      0.29         4
         128       0.83      1.00      0.91         5
         129       1.00      0.89      0.94         9
         130       1.00      0.75      0.86         4
         131       0.00      0.00      0.00         4
         132       1.00      0.25      0.40         4
         133       1.00      1.00      1.00         4
         134       1.00      1.00      1.00         9
         135       1.00      0.40      0.57         5
         136       1.00      0.78      0.88         9
         137       0.90      1.00      0.95         9
         138       1.00      0.80      0.89         5
         139       0.67      0.44      0.53         9
         140       0.62      0.56      0.59         9
         141       1.00      1.00      1.00         5
         142       0.50      0.25      0.33         4
         143       1.00      0.50      0.67         4
         144       0.57      0.80      0.67         5
         145       0.09      0.50      0.15         4
         146       0.00      0.00      0.00         9
         147       0.75      1.00      0.86         9
         148       0.75      0.75      0.75         4
         149       1.00      0.75      0.86         4
         150       1.00      0.67      0.80         9
         151       0.90      1.00      0.95         9
         152       1.00      0.75      0.86         4
         153       0.75      0.67      0.71         9
         154       1.00      1.00      1.00         9
         155       1.00      1.00      1.00         5
         156       0.82      1.00      0.90         9
         157       1.00      0.80      0.89         5
         158       0.00      0.00      0.00         4
         159       0.40      0.57      0.47         7
         160       1.00      0.50      0.67         4
         161       1.00      0.20      0.33         5
         162       1.00      0.89      0.94         9
         163       0.07      0.11      0.09         9
         164       1.00      0.25      0.40         4
         165       0.64      0.78      0.70         9
         166       1.00      0.20      0.33         5
         167       0.00      0.00      0.00         4
         168       1.00      1.00      1.00         9
         169       0.67      0.67      0.67         9
         170       0.06      0.11      0.08         9
         171       0.00      0.00      0.00         4
         172       0.40      0.80      0.53         5
         173       0.00      0.00      0.00         4
         174       0.75      0.67      0.71         9
         175       0.57      0.80      0.67         5
         176       0.50      0.25      0.33         4
         177       1.00      0.75      0.86         4
         178       0.89      0.89      0.89         9
         179       0.67      1.00      0.80         4
         180       0.00      0.00      0.00         4
         181       0.60      0.75      0.67         4
         182       0.60      0.75      0.67         4
         183       0.08      0.50      0.13         4
         184       1.00      1.00      1.00         9
         185       0.50      0.40      0.44         5
         186       1.00      0.25      0.40         4
         187       0.00      0.00      0.00         4
         188       0.67      0.50      0.57         4
         189       0.67      0.50      0.57         4
         190       0.43      0.60      0.50         5
         191       0.38      0.60      0.46         5
         192       0.80      1.00      0.89         4
         193       0.50      0.25      0.33         4
         194       1.00      1.00      1.00         9
         195       0.75      0.60      0.67         5
         196       0.38      0.75      0.50         4
         197       0.33      0.50      0.40         4
         198       0.00      0.00      0.00         4
         199       1.00      1.00      1.00         4
         200       0.26      0.56      0.36         9
         201       0.80      0.89      0.84         9
         202       0.75      0.75      0.75         4
         203       0.06      0.25      0.10         4
         204       1.00      1.00      1.00         4
         205       1.00      1.00      1.00         9
         206       0.50      0.75      0.60         4
         207       0.21      1.00      0.35         4
         208       1.00      0.75      0.86         4
         209       0.00      0.00      0.00         4
         210       1.00      0.56      0.71         9
         211       0.60      0.75      0.67         4
         212       0.11      0.50      0.17         4
         213       0.80      1.00      0.89         4
         214       0.40      0.50      0.44         4
         215       0.00      0.00      0.00         4
         216       1.00      0.25      0.40         4
         217       0.00      0.00      0.00         4
         218       1.00      1.00      1.00         5
         219       1.00      1.00      1.00         4
         220       0.82      1.00      0.90         9
         221       1.00      1.00      1.00         9
         222       0.50      1.00      0.67         4
         223       0.57      0.80      0.67         5
         224       1.00      1.00      1.00         4
         225       1.00      0.56      0.71         9
         226       0.00      0.00      0.00         4
         227       1.00      0.89      0.94         9
         228       0.60      0.75      0.67         4
         229       0.71      1.00      0.83         5
         230       0.50      0.75      0.60         4
         231       0.00      0.00      0.00         4
         232       1.00      1.00      1.00         4
         233       0.75      0.67      0.71         9
         234       0.33      0.25      0.29         4
         235       1.00      0.80      0.89         5
         236       1.00      1.00      1.00         4
         237       0.00      0.00      0.00         4
         238       0.80      0.89      0.84         9
         239       0.00      0.00      0.00         4
         240       0.83      1.00      0.91         5
         241       0.60      0.75      0.67         4
         242       0.45      1.00      0.62         5
         243       1.00      0.75      0.86         4
         244       0.75      0.75      0.75         4
         245       1.00      0.75      0.86         4
         246       0.44      1.00      0.62         4
         247       1.00      1.00      1.00         4
         248       0.90      1.00      0.95         9
         249       1.00      1.00      1.00         9
         250       0.75      0.75      0.75         4
         251       0.67      1.00      0.80         4
         252       0.05      0.11      0.07         9
         253       0.90      1.00      0.95         9
         254       0.00      0.00      0.00         9
         255       0.00      0.00      0.00         4
         256       1.00      1.00      1.00         9
         257       0.71      1.00      0.83         5
         258       0.64      0.78      0.70         9
         259       1.00      1.00      1.00         9
         260       1.00      0.75      0.86         4
         261       0.17      0.50      0.25         4
         262       1.00      1.00      1.00         4
         263       0.75      0.75      0.75         4
         264       0.82      1.00      0.90         9
         265       0.83      1.00      0.91         5
         266       0.08      0.25      0.12         4
         267       0.88      0.78      0.82         9
         268       0.50      0.25      0.33         4
         269       1.00      0.50      0.67         4
         270       0.00      0.00      0.00         4
         271       1.00      1.00      1.00         4
         272       0.67      1.00      0.80         4
         273       0.90      1.00      0.95         9
         274       0.00      0.00      0.00         4
         275       0.71      1.00      0.83         5
         276       1.00      0.78      0.88         9
         277       1.00      0.75      0.86         4
         278       0.50      0.50      0.50         4
         279       0.67      1.00      0.80         4
         280       0.89      0.89      0.89         9
         281       0.50      0.25      0.33         4
         282       0.20      0.60      0.30         5
         283       0.00      0.00      0.00         4
         284       0.75      1.00      0.86         9
         285       1.00      0.75      0.86         4
         286       1.00      0.78      0.88         9
         287       1.00      0.40      0.57         5
         288       1.00      1.00      1.00         5
         289       1.00      0.89      0.94         9
         290       0.80      1.00      0.89         4
         291       0.83      1.00      0.91         5
         292       0.30      0.75      0.43         4
         293       1.00      1.00      1.00         4
         294       1.00      0.75      0.86         8
         295       1.00      0.40      0.57         5
         296       1.00      0.75      0.86         4
         297       0.50      0.75      0.60         4
         298       1.00      0.89      0.94         9
         299       1.00      1.00      1.00         4
         300       0.67      0.44      0.53         9
         301       0.50      0.60      0.55         5
         302       1.00      1.00      1.00         5
         303       1.00      0.50      0.67         4
         304       0.80      1.00      0.89         4
         305       0.56      1.00      0.71         5
         306       1.00      1.00      1.00         4
         307       0.80      1.00      0.89         4
         308       0.70      0.78      0.74         9
         309       0.64      0.78      0.70         9
         310       0.89      0.89      0.89         9
         311       1.00      0.25      0.40         4
         312       1.00      1.00      1.00         4
         313       0.67      1.00      0.80         4
         314       1.00      0.89      0.94         9
         315       1.00      1.00      1.00         5
         316       1.00      0.50      0.67         4
         317       0.00      0.00      0.00         5
         318       1.00      0.50      0.67         4
         319       0.90      1.00      0.95         9
         320       0.90      1.00      0.95         9
         321       0.75      0.75      0.75         4
         322       0.33      0.25      0.29         4
         323       0.50      1.00      0.67         4
         324       0.71      1.00      0.83         5
         325       1.00      1.00      1.00         4
         326       0.33      0.75      0.46         4
         327       0.73      0.89      0.80         9
         328       1.00      1.00      1.00         9
         329       0.00      0.00      0.00         4
         330       0.75      0.75      0.75         4
         331       1.00      0.25      0.40         4
         332       1.00      0.50      0.67         4
         333       0.00      0.00      0.00         4
         334       0.11      0.50      0.18         4
         335       1.00      0.75      0.86         4
         336       1.00      0.75      0.86         4
         337       1.00      1.00      1.00         9
         338       0.80      1.00      0.89         4
         339       0.86      0.67      0.75         9
         340       0.57      1.00      0.73         4
         341       0.57      1.00      0.73         4
         342       0.50      1.00      0.67         4
         343       0.29      0.22      0.25         9
         344       0.00      0.00      0.00         4
         345       0.75      1.00      0.86         9
         346       0.00      0.00      0.00         4
         347       1.00      1.00      1.00         4
         348       1.00      1.00      1.00         4
         349       1.00      0.78      0.88         9
         350       1.00      0.78      0.88         9
         351       1.00      1.00      1.00         5
         352       0.40      0.50      0.44         4
         353       0.75      0.43      0.55         7
         354       0.00      0.00      0.00         4
         355       1.00      0.75      0.86         4
         356       1.00      1.00      1.00         4
         357       0.60      0.75      0.67         4
         358       0.00      0.00      0.00         4
         359       0.60      0.75      0.67         4
         360       1.00      1.00      1.00         9
         361       0.89      0.89      0.89         9
         362       0.00      0.00      0.00         4
         363       0.60      0.75      0.67         4
         364       0.80      1.00      0.89         4
         365       0.00      0.00      0.00         4
         366       0.80      1.00      0.89         4
         367       0.86      0.67      0.75         9
         368       1.00      1.00      1.00         9
         369       1.00      1.00      1.00         4
         370       0.00      0.00      0.00         4
         371       0.80      1.00      0.89         4
         372       0.67      1.00      0.80         4
         373       0.89      0.89      0.89         9
         374       1.00      0.75      0.86         4
         375       1.00      0.75      0.86         4
         376       0.30      0.75      0.43         4
         377       0.50      0.75      0.60         4
         378       0.06      0.25      0.10         4
         379       1.00      0.11      0.20         9
         380       1.00      0.25      0.40         4
         381       0.00      0.00      0.00         4
         382       0.00      0.00      0.00         4
         383       0.75      0.75      0.75         4
         384       0.80      0.44      0.57         9
         385       0.89      0.89      0.89         9
         386       0.86      0.67      0.75         9
         387       0.33      0.25      0.29         4
         388       0.00      0.00      0.00         4
         389       0.57      1.00      0.73         4
         390       0.75      0.75      0.75         4
         391       0.00      0.00      0.00         4
         392       0.67      0.50      0.57         4
         393       0.00      0.00      0.00         4
         394       0.80      1.00      0.89         4
         395       1.00      0.25      0.40         4
         396       0.67      1.00      0.80         4
         397       0.67      0.89      0.76         9
         398       1.00      1.00      1.00         4
         399       1.00      0.75      0.86         4
         400       1.00      0.25      0.40         4
         401       0.60      0.75      0.67         4
         402       1.00      1.00      1.00         4
         403       0.45      1.00      0.62         9
         404       1.00      1.00      1.00         4
         405       0.80      1.00      0.89         4
         406       0.62      1.00      0.77         5
         407       1.00      0.11      0.20         9
         408       0.67      0.80      0.73         5
         409       0.71      1.00      0.83         5
         410       0.50      0.25      0.33         4
         411       0.50      0.67      0.57         9
         412       0.50      0.75      0.60         4
         413       0.00      0.00      0.00         9
         414       0.62      1.00      0.77         5
         415       1.00      1.00      1.00         4
         416       0.86      0.67      0.75         9
         417       0.80      1.00      0.89         4
         418       0.67      0.80      0.73         5
         419       0.00      0.00      0.00         4
         420       1.00      0.75      0.86         4
         421       0.00      0.00      0.00         4
         422       0.80      1.00      0.89         4
         423       1.00      0.80      0.89         5
         424       1.00      0.75      0.86         4
         425       0.80      1.00      0.89         4
         426       1.00      1.00      1.00         5
         427       0.67      0.67      0.67         9
         428       0.75      0.75      0.75         4
         429       1.00      1.00      1.00         4
         430       0.73      0.89      0.80         9
         431       1.00      0.50      0.67         4
         432       1.00      1.00      1.00         9
         433       0.75      0.75      0.75         4
         434       0.80      1.00      0.89         4
         435       0.80      0.89      0.84         9
         436       0.00      0.00      0.00         4
         437       0.14      0.25      0.18         4
         438       0.82      1.00      0.90         9
         439       0.69      1.00      0.82         9
         440       1.00      1.00      1.00         9
         441       0.00      0.00      0.00         4
         442       1.00      0.89      0.94         9
         443       1.00      1.00      1.00         9
         444       0.00      0.00      0.00         9
         445       0.00      0.00      0.00         4
         446       0.13      1.00      0.24         4
         447       0.12      0.11      0.12         9
         448       0.75      0.60      0.67         5
         449       0.00      0.00      0.00         4
         450       1.00      0.50      0.67         4
         451       1.00      0.89      0.94         9
         452       1.00      1.00      1.00         5
         453       1.00      0.25      0.40         4
         454       1.00      0.67      0.80         9
         455       1.00      0.25      0.40         4
         456       1.00      0.80      0.89         5
         457       0.62      1.00      0.77         5
         458       0.62      1.00      0.77         5
         459       0.83      1.00      0.91         5
         460       0.00      0.00      0.00         4
         461       0.00      0.00      0.00         4
         462       1.00      0.89      0.94         9
         463       0.00      0.00      0.00         4
         464       0.00      0.00      0.00         9
         465       0.64      0.78      0.70         9
         466       1.00      1.00      1.00         5
         467       1.00      0.75      0.86         4
         468       1.00      0.50      0.67         4
         469       0.00      0.00      0.00         4
         470       0.60      0.75      0.67         4
         471       0.38      0.75      0.50         4
         472       0.78      0.78      0.78         9
         473       1.00      0.78      0.88         9
         474       1.00      0.50      0.67         4
         475       1.00      0.89      0.94         9
         476       0.83      1.00      0.91         5
         477       0.88      0.78      0.82         9
         478       0.71      1.00      0.83         5
         479       0.67      1.00      0.80         4
         480       0.00      0.00      0.00         4
         481       0.33      0.50      0.40         4
         482       1.00      0.40      0.57         5
         483       1.00      0.75      0.86         4
         484       0.60      0.75      0.67         4
         485       0.50      0.50      0.50         4
         486       0.15      1.00      0.26         4
         487       0.75      0.75      0.75         4
         488       0.50      1.00      0.67         4
         489       0.67      0.80      0.73         5
         490       0.83      1.00      0.91         5
         491       0.00      0.00      0.00         4
         492       0.12      0.75      0.20         4
         493       0.50      0.20      0.29         5
         494       0.80      1.00      0.89         4
         495       0.80      0.89      0.84         9
         496       1.00      1.00      1.00         4
         497       0.57      0.89      0.70         9
         498       0.64      0.78      0.70         9
         499       0.67      0.67      0.67         9
         500       0.83      1.00      0.91         5
         501       0.75      0.75      0.75         4
         502       0.80      1.00      0.89         4
         503       0.60      0.67      0.63         9
         504       1.00      0.50      0.67         4
         505       0.12      0.25      0.17         4
         506       1.00      0.25      0.40         4
         507       1.00      0.80      0.89         5
         508       1.00      0.75      0.86         4
         509       0.60      0.60      0.60         5
         510       0.80      1.00      0.89         4
         511       1.00      0.75      0.86         4
         512       0.60      0.75      0.67         4
         513       0.38      0.33      0.35         9
         514       0.75      0.75      0.75         4
         515       0.80      0.89      0.84         9
         516       1.00      0.80      0.89         5
         517       1.00      0.56      0.71         9
         518       1.00      0.80      0.89         5
         519       1.00      0.80      0.89         5
         520       0.89      0.89      0.89         9
         521       1.00      0.75      0.86         4
         522       1.00      0.75      0.86         4
         523       0.20      0.25      0.22         4
         524       1.00      0.67      0.80         9
         525       1.00      1.00      1.00         4
         526       0.56      0.56      0.56         9
         527       0.83      1.00      0.91         5
         528       0.00      0.00      0.00         9
         529       0.89      0.89      0.89         9
         530       0.40      0.22      0.29         9
         531       0.82      1.00      0.90         9
         532       0.89      0.89      0.89         9
         533       1.00      0.89      0.94         9
         534       1.00      0.89      0.94         9
         535       0.75      0.75      0.75         4
         536       1.00      0.75      0.86         4
         537       0.00      0.00      0.00         4
         538       1.00      1.00      1.00         5
         539       0.78      0.78      0.78         9
         540       0.00      0.00      0.00         4
         541       0.57      0.44      0.50         9
         542       0.00      0.00      0.00         4
         543       1.00      0.67      0.80         9
         544       0.42      0.89      0.57         9
         545       0.60      0.75      0.67         4
         546       1.00      0.20      0.33         5
         547       0.57      1.00      0.73         4
         548       1.00      1.00      1.00         4
         549       0.67      0.40      0.50         5
         550       0.00      0.00      0.00         5
         551       0.00      0.00      0.00         4
         552       0.70      0.78      0.74         9
         553       0.56      0.56      0.56         9
         554       1.00      1.00      1.00         4
         555       0.75      0.75      0.75         4
         556       1.00      0.78      0.88         9
         557       0.00      0.00      0.00         4
         558       0.00      0.00      0.00         4
         559       1.00      1.00      1.00         5
         560       0.00      0.00      0.00         4
         561       0.80      0.80      0.80         5
         562       0.50      0.75      0.60         4
         563       1.00      1.00      1.00         4
         564       1.00      1.00      1.00         4
         565       1.00      0.60      0.75         5
         566       0.00      0.00      0.00         4
         567       0.57      0.89      0.70         9
         568       1.00      1.00      1.00         9
         569       0.75      0.75      0.75         4
         570       1.00      0.78      0.88         9
         571       0.50      0.50      0.50         4
         572       0.83      1.00      0.91         5
         573       1.00      1.00      1.00         4
         574       1.00      0.80      0.89         5
         575       0.00      0.00      0.00         4
         576       1.00      0.50      0.67         4
         577       1.00      1.00      1.00         4
         578       0.67      1.00      0.80         4
         579       1.00      1.00      1.00         4
         580       0.00      0.00      0.00         4
         581       0.00      0.00      0.00         4
         582       0.50      0.25      0.33         4
         583       1.00      1.00      1.00         4
         584       0.44      1.00      0.62         4
         585       0.80      1.00      0.89         4
         586       1.00      1.00      1.00         4
         587       0.73      0.89      0.80         9
         588       0.09      0.22      0.13         9
         589       1.00      1.00      1.00         9
         590       0.50      0.25      0.33         4
         591       0.88      0.78      0.82         9
         592       0.50      0.25      0.33         4
         593       0.00      0.00      0.00         4
         594       1.00      1.00      1.00         4
         595       1.00      0.80      0.89         5
         596       0.38      0.75      0.50         4
         597       1.00      0.67      0.80         9
         598       0.25      0.50      0.33         4
         599       0.67      0.40      0.50         5
         600       0.10      0.50      0.17         4
         601       0.00      0.00      0.00         5
         602       0.00      0.00      0.00         4
         603       0.00      0.00      0.00         4
         604       0.56      1.00      0.72         9
         605       1.00      0.75      0.86         4
         606       0.75      0.75      0.75         4
         607       1.00      1.00      1.00         5
         608       0.89      0.89      0.89         9
         609       0.80      1.00      0.89         4
         610       0.90      1.00      0.95         9
         611       1.00      1.00      1.00         5
         612       0.00      0.00      0.00         4
         613       0.88      0.78      0.82         9
         614       1.00      1.00      1.00         4
         615       0.27      0.60      0.37         5
         616       0.21      1.00      0.35         4
         617       0.67      0.33      0.44         6
         618       0.50      0.40      0.44         5
         619       1.00      1.00      1.00         5
         620       0.80      1.00      0.89         4
         621       0.75      0.60      0.67         5
         622       0.67      0.50      0.57         4
         623       1.00      0.75      0.86         4
         624       0.47      1.00      0.64         9
         625       0.00      0.00      0.00         9
         626       1.00      1.00      1.00         4
         627       1.00      0.75      0.86         4
         628       1.00      0.89      0.94         9
         629       0.06      0.11      0.07         9
         630       1.00      1.00      1.00         4
         631       0.60      0.75      0.67         4
         632       0.00      0.00      0.00         4
         633       0.00      0.00      0.00         4
         634       1.00      1.00      1.00         4
         635       1.00      0.75      0.86         4
         636       1.00      0.75      0.86         4
         637       0.00      0.00      0.00         4
         638       0.00      0.00      0.00         4
         639       0.67      1.00      0.80         4
         640       0.18      0.50      0.27         4
         641       1.00      0.50      0.67         4
         642       1.00      0.80      0.89         5
         643       0.40      0.44      0.42         9
         644       0.60      0.67      0.63         9
         645       0.33      0.40      0.36         5
         646       1.00      1.00      1.00         4
         647       0.60      0.60      0.60         5
         648       1.00      1.00      1.00         5
         649       0.00      0.00      0.00         4
         650       1.00      0.67      0.80         9
         651       1.00      0.78      0.88         9
         652       0.89      0.89      0.89         9
         653       0.57      1.00      0.73         4
         654       0.00      0.00      0.00         4
         655       1.00      0.25      0.40         4
         656       0.89      0.89      0.89         9
         657       0.67      0.86      0.75         7
         658       1.00      0.50      0.67         4
         659       0.00      0.00      0.00         4
         660       1.00      0.75      0.86         4
         661       0.38      0.75      0.50         4
         662       1.00      0.75      0.86         4
         663       0.50      0.75      0.60         4
         664       1.00      0.75      0.86         4
         665       0.40      0.50      0.44         4
         666       0.60      0.60      0.60         5
         667       0.75      0.75      0.75         4
         668       1.00      1.00      1.00         5
         669       1.00      0.67      0.80         9
         670       0.67      0.67      0.67         9
         671       0.71      1.00      0.83         5
         672       0.67      0.44      0.53         9
         673       0.50      0.25      0.33         4
         674       1.00      0.75      0.86         4
         675       1.00      0.60      0.75         5
         676       0.00      0.00      0.00         4
         677       1.00      0.56      0.71         9
         678       0.00      0.00      0.00         9
         679       0.00      0.00      0.00         4
         680       0.62      0.56      0.59         9
         681       0.00      0.00      0.00         4
         682       1.00      1.00      1.00         9
         683       0.33      0.20      0.25         5
         684       1.00      0.67      0.80         9
         685       1.00      0.50      0.67         4
         686       0.50      0.25      0.33         4
         687       1.00      0.50      0.67         4
         688       0.00      0.00      0.00         4
         689       0.67      1.00      0.80         4
         690       1.00      1.00      1.00         4
         691       0.50      0.25      0.33         4
         692       1.00      0.75      0.86         4
         693       0.89      0.89      0.89         9
         694       0.60      0.75      0.67         4
         695       0.80      1.00      0.89         4
         696       0.00      0.00      0.00         4
         697       0.00      0.00      0.00         4
         698       1.00      1.00      1.00         4
         699       1.00      1.00      1.00         4
         700       0.00      0.00      0.00         9
         701       0.00      0.00      0.00         4
         702       1.00      1.00      1.00         4
         703       1.00      0.75      0.86         4
         704       0.67      1.00      0.80         4
         705       1.00      0.50      0.67         4
         706       0.67      0.89      0.76         9
         707       1.00      1.00      1.00         4
         708       0.50      0.25      0.33         4
         709       1.00      0.50      0.67         4
         710       0.67      0.40      0.50         5
         711       0.33      0.40      0.36         5
         712       0.57      0.89      0.70         9
         713       1.00      0.75      0.86         4
         714       0.00      0.00      0.00         4
         715       1.00      0.75      0.86         4
         716       0.82      1.00      0.90         9
         717       0.00      0.00      0.00         4
         718       1.00      1.00      1.00         4
         719       0.43      0.60      0.50         5
         720       1.00      0.20      0.33         5
         721       0.00      0.00      0.00         4
         722       0.50      0.20      0.29         5
         723       1.00      0.50      0.67         4
         724       1.00      1.00      1.00         4
         725       0.67      0.50      0.57         4
         726       0.83      1.00      0.91         5
         727       0.73      0.89      0.80         9
         728       0.83      0.56      0.67         9
         729       1.00      0.60      0.75         5
         730       0.89      0.89      0.89         9
         731       1.00      0.50      0.67         4
         732       0.60      1.00      0.75         9
         733       1.00      1.00      1.00         9
         734       0.70      0.78      0.74         9
         735       0.90      1.00      0.95         9
         736       1.00      0.50      0.67         4
         737       1.00      0.56      0.71         9
         738       1.00      0.50      0.67         4
         739       0.67      0.50      0.57         4
         740       0.83      0.56      0.67         9
         741       0.75      0.75      0.75         4
         742       0.00      0.00      0.00         4
         743       0.80      0.89      0.84         9
         744       0.21      1.00      0.35         4
         745       0.80      1.00      0.89         4
         746       0.75      0.75      0.75         4
         747       1.00      1.00      1.00         9
         748       1.00      1.00      1.00         4
         749       1.00      0.25      0.40         4
         750       0.60      0.75      0.67         4
         751       0.00      0.00      0.00         4
         752       0.00      0.00      0.00         4
         753       1.00      0.80      0.89         5
         754       0.40      1.00      0.57         4
         755       0.00      0.00      0.00         4
         756       1.00      1.00      1.00         9
         757       0.00      0.00      0.00         4
         758       0.67      1.00      0.80         4
         759       1.00      1.00      1.00         4
         760       0.80      1.00      0.89         4
         761       0.75      0.60      0.67         5
         762       1.00      1.00      1.00         5
         763       0.88      0.78      0.82         9
         764       1.00      0.80      0.89         5
         765       0.50      0.25      0.33         4
         766       0.80      1.00      0.89         4
         767       1.00      1.00      1.00         4
         768       0.00      0.00      0.00         4
         769       1.00      0.75      0.86         4
         770       1.00      0.67      0.80         9
         771       1.00      0.50      0.67         4
         772       0.90      1.00      0.95         9
         773       0.75      1.00      0.86         9
         774       0.08      0.25      0.12         4
         775       0.43      0.60      0.50         5
         776       1.00      1.00      1.00         4
         777       0.82      1.00      0.90         9
         778       0.50      1.00      0.67         4
         779       1.00      0.78      0.88         9
         780       0.78      0.78      0.78         9
         781       0.67      1.00      0.80         4
         782       1.00      1.00      1.00         4
         783       0.00      0.00      0.00         4
         784       1.00      0.89      0.94         9
         785       1.00      1.00      1.00         4
         786       0.80      1.00      0.89         4
         787       0.60      0.75      0.67         4
         788       0.80      1.00      0.89         4
         789       0.80      0.80      0.80         5
         790       1.00      0.40      0.57         5
         791       0.60      0.75      0.67         4
         792       0.00      0.00      0.00         4
         793       0.83      1.00      0.91         5
         794       0.00      0.00      0.00         4
         795       1.00      1.00      1.00         5
         796       0.60      0.75      0.67         4
         797       1.00      0.75      0.86         4
         798       0.83      1.00      0.91         5
         799       0.80      0.80      0.80         5
         800       0.00      0.00      0.00         4
         801       0.67      0.80      0.73         5
         802       1.00      0.67      0.80         9
         803       0.86      0.67      0.75         9
         804       0.62      1.00      0.77         5
         805       1.00      0.78      0.88         9
         806       0.67      0.50      0.57         4
         807       1.00      0.50      0.67         4
         808       0.00      0.00      0.00         4
         809       0.00      0.00      0.00         9
         810       1.00      1.00      1.00         4
         811       0.50      0.75      0.60         4
         812       0.00      0.00      0.00         9
         813       0.64      0.78      0.70         9
         814       0.50      0.25      0.33         4
         815       1.00      0.40      0.57         5
         816       0.00      0.00      0.00         4
         817       0.80      0.80      0.80         5
         818       0.75      0.75      0.75         4
         819       0.83      0.56      0.67         9
         820       0.17      0.25      0.20         4
         821       0.00      0.00      0.00         4
         822       0.78      0.78      0.78         9
         823       0.67      1.00      0.80         4
         824       1.00      0.75      0.86         4
         825       0.40      1.00      0.57         4
         826       0.50      0.20      0.29         5
         827       0.00      0.00      0.00         4
         828       1.00      0.67      0.80         9
         829       0.00      0.00      0.00         4
         830       0.80      1.00      0.89         4
         831       0.89      0.89      0.89         9
         832       0.60      0.60      0.60         5
         833       0.75      0.75      0.75         4
         834       0.00      0.00      0.00         4
         835       1.00      1.00      1.00         4
         836       1.00      0.89      0.94         9
         837       0.75      0.75      0.75         4
         838       1.00      0.75      0.86         4
         839       1.00      0.75      0.86         4
         840       1.00      0.75      0.86         4
         841       0.50      0.50      0.50         4
         842       0.80      1.00      0.89         4
         843       0.80      1.00      0.89         4
         844       0.90      1.00      0.95         9
         845       0.75      0.75      0.75         4
         846       0.20      0.25      0.22         4
         847       0.80      0.80      0.80         5
         848       0.00      0.00      0.00         4
         849       0.00      0.00      0.00         4
         850       0.60      0.75      0.67         4
         851       0.58      0.78      0.67         9
         852       1.00      0.75      0.86         4
         853       0.80      1.00      0.89         4
         854       1.00      0.80      0.89         5
         855       0.67      1.00      0.80         4
         856       0.75      0.33      0.46         9
         857       0.80      1.00      0.89         4
         858       0.00      0.00      0.00         4
         859       0.00      0.00      0.00         4
         860       0.00      0.00      0.00         4
         861       0.82      1.00      0.90         9
         862       1.00      0.60      0.75         5
         863       0.71      1.00      0.83         5
         864       1.00      0.50      0.67         4
         865       0.33      0.75      0.46         4
         866       0.80      0.80      0.80         5
         867       0.80      1.00      0.89         4
         868       0.75      0.75      0.75         4
         869       0.08      0.44      0.14         9
         870       1.00      0.75      0.86         8
         871       0.00      0.00      0.00         9
         872       0.80      0.89      0.84         9
         873       0.80      1.00      0.89         4
         874       1.00      0.33      0.50         9
         875       0.00      0.00      0.00         4
         876       0.00      0.00      0.00         9
         877       0.80      1.00      0.89         4
         878       0.80      0.80      0.80         5
         879       0.67      0.89      0.76         9
         880       0.50      0.78      0.61         9
         881       0.60      0.75      0.67         4
         882       0.50      0.75      0.60         4
         883       0.00      0.00      0.00         4
         884       0.67      1.00      0.80         4
         885       0.33      0.25      0.29         4
         886       0.82      1.00      0.90         9
         887       0.75      0.75      0.75         4
         888       1.00      0.50      0.67         4
         889       1.00      1.00      1.00         5
         890       0.54      0.78      0.64         9
         891       0.80      1.00      0.89         4
         892       0.29      0.50      0.36         4
         893       0.75      0.75      0.75         4

    accuracy                           0.67      4917
   macro avg       0.65      0.64      0.62      4917
weighted avg       0.68      0.67      0.65      4917

task_train_time: {0: 8.951579836, 1: 5.170904124, 2: 4.970335027000001, 3: 5.721314832000001, 4: 4.888638224000005, 5: 4.994640171999997, 6: 6.449511896000004, 7: 6.1082038690000005, 8: 4.617584249000004, 9: 5.131708951999997, 10: 5.255809583000001, 11: 4.993895975000001, 12: 5.727526131999994, 13: 5.261105149000002, 14: 5.276177559000004, 15: 4.970344689000001, 16: 5.304871078000005, 17: 4.5707998400000065, 18: 4.708109362999991, 19: 5.192058450999994, 20: 4.960739062999991, 21: 6.150200091000002, 22: 5.528053932999995, 23: 4.3216900820000035, 24: 5.326346522000023, 25: 6.82205295899999, 26: 5.824296126999997, 27: 5.262909269999994, 28: 4.860772080000004, 29: 5.209331375000005, 30: 5.048184499000001, 31: 5.227384338000007, 32: 5.095540287000006, 33: 5.258778252000013, 34: 4.657123124999998, 35: 5.451492377999983, 36: 5.511130944000001, 37: 5.472384693999999, 38: 4.997139073, 39: 5.640362581000005, 40: 5.105279590999999, 41: 4.596072666999987, 42: 5.46503952499998, 43: 5.480715312000001}
prediction_time: 0.00025701200002004043
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
