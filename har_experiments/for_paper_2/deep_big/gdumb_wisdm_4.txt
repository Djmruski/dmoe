Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='59d40ca9-a1d7-4959-8720-3dd8c052cfe0', conf_timestamp='2023-08-09 13:07:42.316528', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 97.74 % 	 [Task-IL]: 57.06 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 56.23 % 	 [Task-IL]: 41.34 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 39.93 % 	 [Task-IL]: 38.76 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 35.31 % 	 [Task-IL]: 36.89 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 29.09 % 	 [Task-IL]: 35.45 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 24.18 % 	 [Task-IL]: 35.32 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 20.12 % 	 [Task-IL]: 35.08 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 19.65 % 	 [Task-IL]: 34.22 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.91 % 	 [Task-IL]: 32.77 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 14.9 % 	 [Task-IL]: 32.92 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 14.84 % 	 [Task-IL]: 32.28 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 14.69 % 	 [Task-IL]: 32.74 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 15.27 % 	 [Task-IL]: 31.93 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.5 % 	 [Task-IL]: 31.39 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.74 % 	 [Task-IL]: 31.53 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 13.28 % 	 [Task-IL]: 32.05 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 11.74 % 	 [Task-IL]: 32.05 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 10.45 % 	 [Task-IL]: 31.87 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 7.65 % 	 [Task-IL]: 31.66 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.33 % 	 [Task-IL]: 31.42 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 7.34 % 	 [Task-IL]: 31.11 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.74 % 	 [Task-IL]: 30.92 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 7.58 % 	 [Task-IL]: 30.66 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 6.58 % 	 [Task-IL]: 30.32 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 5.51 % 	 [Task-IL]: 30.16 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.06 % 	 [Task-IL]: 30.15 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 5.83 % 	 [Task-IL]: 30.47 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.21 % 	 [Task-IL]: 30.24 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 5.12 % 	 [Task-IL]: 30.36 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 5.66 % 	 [Task-IL]: 30.35 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.44 % 	 [Task-IL]: 29.86 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 4.92 % 	 [Task-IL]: 30.01 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.39 % 	 [Task-IL]: 30.02 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 5.44 % 	 [Task-IL]: 29.91 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.21 % 	 [Task-IL]: 30.01 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.05 % 	 [Task-IL]: 30.02 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.81 % 	 [Task-IL]: 29.61 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.71 % 	 [Task-IL]: 29.55 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.01 % 	 [Task-IL]: 29.49 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.45 % 	 [Task-IL]: 29.64 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 3.64 % 	 [Task-IL]: 29.51 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 3.6 % 	 [Task-IL]: 29.39 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 3.36 % 	 [Task-IL]: 29.55 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({40: 30, 300: 29, 238: 29, 201: 28, 371: 28, 762: 27, 517: 26, 615: 26, 863: 26, 374: 25, 731: 25, 557: 25, 106: 25, 130: 24, 840: 24, 520: 24, 460: 24, 843: 24, 341: 24, 95: 24, 118: 24, 579: 24, 566: 24, 296: 24, 749: 23, 284: 23, 462: 23, 805: 23, 793: 23, 811: 23, 631: 23, 509: 23, 54: 23, 422: 23, 363: 23, 716: 22, 108: 22, 410: 22, 692: 22, 83: 22, 730: 22, 699: 22, 68: 22, 529: 22, 763: 22, 195: 22, 219: 21, 297: 21, 646: 21, 232: 21, 32: 21, 14: 21, 134: 21, 378: 21, 588: 21, 689: 21, 448: 21, 515: 21, 424: 21, 496: 21, 791: 21, 93: 21, 373: 21, 477: 21, 20: 21, 575: 20, 756: 20, 679: 20, 770: 20, 695: 20, 772: 20, 853: 20, 468: 20, 328: 20, 698: 20, 164: 20, 273: 20, 431: 20, 315: 20, 286: 19, 813: 19, 362: 19, 291: 19, 817: 19, 262: 19, 443: 19, 635: 19, 114: 19, 446: 19, 124: 19, 760: 19, 818: 19, 287: 19, 77: 19, 212: 19, 757: 19, 812: 19, 629: 19, 891: 19, 85: 19, 503: 19, 117: 18, 31: 18, 75: 18, 653: 18, 3: 18, 823: 18, 357: 18, 260: 18, 283: 18, 592: 18, 549: 18, 361: 18, 327: 18, 293: 18, 38: 18, 355: 18, 508: 18, 655: 18, 568: 18, 441: 18, 233: 18, 524: 17, 317: 17, 746: 17, 560: 17, 804: 17, 827: 17, 511: 17, 476: 17, 502: 17, 197: 17, 498: 17, 234: 17, 884: 17, 235: 17, 519: 17, 747: 17, 717: 17, 705: 17, 157: 17, 186: 17, 525: 17, 198: 17, 693: 17, 776: 17, 4: 17, 187: 17, 320: 17, 137: 16, 224: 16, 125: 16, 854: 16, 176: 16, 205: 16, 673: 16, 821: 16, 457: 16, 535: 16, 119: 16, 657: 16, 499: 16, 221: 16, 872: 16, 206: 16, 544: 16, 406: 16, 210: 16, 228: 16, 173: 16, 647: 16, 710: 16, 316: 16, 741: 16, 806: 16, 856: 16, 11: 16, 586: 15, 426: 15, 835: 15, 512: 15, 559: 15, 153: 15, 303: 15, 774: 15, 596: 15, 445: 15, 624: 15, 556: 15, 113: 15, 385: 15, 781: 15, 649: 15, 274: 15, 353: 14, 56: 14, 697: 14, 834: 14, 192: 14, 491: 14, 43: 14, 864: 14, 182: 14, 613: 14, 810: 14, 67: 14, 794: 14, 240: 14, 654: 14, 438: 14, 828: 14, 132: 14, 379: 14, 239: 14, 822: 13, 59: 13, 72: 13, 721: 13, 193: 13, 522: 13, 421: 13, 218: 13, 883: 13, 879: 13, 528: 13, 553: 13, 861: 13, 567: 13, 314: 13, 150: 13, 202: 13, 620: 13, 160: 13, 367: 13, 199: 13, 700: 12, 728: 12, 591: 12, 681: 12, 281: 12, 190: 12, 159: 12, 37: 12, 200: 12, 384: 12, 420: 12, 35: 12, 21: 12, 338: 12, 185: 12, 769: 12, 213: 12, 565: 12, 833: 12, 86: 12, 637: 12, 191: 12, 890: 12, 803: 12, 456: 12, 678: 12, 623: 12, 194: 12, 259: 12, 648: 11, 800: 11, 350: 11, 345: 11, 97: 11, 347: 11, 354: 11, 735: 11, 667: 11, 485: 11, 475: 11, 675: 11, 542: 11, 839: 11, 777: 11, 708: 11, 860: 11, 513: 11, 129: 11, 101: 11, 658: 11, 482: 11, 8: 11, 824: 11, 715: 11, 222: 11, 393: 11, 548: 11, 767: 11, 887: 11, 788: 11, 64: 11, 81: 11, 370: 11, 820: 11, 342: 11, 851: 11, 139: 11, 98: 11, 203: 11, 23: 11, 70: 11, 447: 11, 798: 10, 62: 10, 66: 10, 266: 10, 561: 10, 247: 10, 248: 10, 701: 10, 650: 10, 633: 10, 99: 10, 880: 10, 147: 10, 141: 10, 676: 10, 570: 10, 868: 10, 471: 10, 179: 10, 334: 10, 27: 10, 484: 10, 611: 10, 889: 10, 599: 10, 455: 10, 57: 10, 82: 10, 430: 10, 78: 10, 481: 10, 408: 10, 339: 10, 415: 10, 223: 10, 847: 10, 738: 10, 208: 10, 726: 10, 836: 10, 537: 10, 434: 10, 704: 10, 848: 10, 459: 10, 790: 10, 870: 10, 211: 10, 598: 10, 576: 10, 377: 10, 882: 10, 333: 9, 144: 9, 411: 9, 527: 9, 178: 9, 61: 9, 258: 9, 429: 9, 55: 9, 808: 9, 751: 9, 109: 9, 669: 9, 892: 9, 759: 9, 140: 9, 782: 9, 10: 9, 215: 9, 638: 9, 563: 9, 665: 9, 76: 9, 96: 9, 396: 9, 16: 9, 875: 9, 534: 9, 376: 9, 256: 9, 51: 9, 814: 9, 253: 9, 336: 9, 47: 9, 6: 9, 121: 9, 859: 9, 227: 9, 360: 9, 419: 9, 666: 9, 874: 9, 538: 9, 729: 9, 590: 9, 405: 9, 748: 9, 551: 9, 580: 9, 326: 9, 826: 9, 510: 9, 703: 9, 183: 9, 290: 9, 663: 9, 250: 9, 440: 9, 470: 9, 366: 9, 718: 9, 321: 9, 152: 9, 453: 9, 226: 9, 94: 9, 564: 9, 356: 8, 540: 8, 569: 8, 289: 8, 634: 8, 745: 8, 661: 8, 252: 8, 323: 8, 63: 8, 245: 8, 251: 8, 490: 8, 594: 8, 52: 8, 340: 8, 414: 8, 307: 8, 670: 8, 412: 8, 711: 8, 832: 8, 643: 8, 687: 8, 505: 8, 279: 8, 682: 8, 601: 8, 302: 8, 452: 8, 84: 8, 12: 8, 74: 8, 351: 8, 143: 8, 487: 8, 618: 8, 523: 8, 400: 8, 131: 8, 158: 8, 849: 8, 831: 8, 837: 8, 465: 8, 562: 8, 743: 8, 50: 8, 546: 8, 304: 8, 165: 8, 593: 8, 581: 8, 799: 8, 572: 8, 292: 8, 436: 8, 641: 8, 816: 8, 479: 8, 543: 8, 254: 8, 842: 8, 740: 8, 280: 8, 331: 8, 582: 8, 640: 8, 269: 8, 397: 8, 617: 8, 516: 8, 375: 8, 399: 8, 346: 8, 451: 8, 395: 8, 454: 8, 494: 8, 308: 8, 778: 8, 625: 8, 387: 8, 893: 8, 127: 8, 636: 8, 602: 8, 732: 8, 780: 8, 473: 8, 750: 8, 386: 8, 48: 8, 126: 8, 364: 8, 606: 8, 855: 8, 236: 8, 102: 8, 651: 7, 437: 7, 627: 7, 690: 7, 684: 7, 39: 7, 672: 7, 585: 7, 278: 7, 365: 7, 497: 7, 276: 7, 604: 7, 225: 7, 768: 7, 418: 7, 163: 7, 288: 7, 450: 7, 577: 7, 866: 7, 545: 7, 428: 7, 727: 7, 668: 7, 398: 7, 852: 7, 196: 7, 877: 7, 474: 7, 433: 7, 142: 7, 754: 7, 427: 7, 785: 7, 309: 7, 702: 7, 621: 7, 204: 7, 723: 7, 573: 7, 313: 7, 802: 7, 809: 7, 449: 7, 825: 7, 136: 7, 174: 7, 466: 7, 630: 7, 530: 7, 685: 7, 674: 7, 531: 7, 115: 7, 154: 7, 616: 7, 390: 7, 58: 7, 2: 7, 642: 7, 369: 7, 656: 7, 161: 7, 622: 7, 518: 7, 628: 7, 786: 7, 242: 7, 172: 7, 348: 7, 597: 7, 264: 7, 423: 7, 680: 7, 683: 7, 45: 7, 305: 7, 486: 7, 358: 7, 188: 7, 857: 7, 214: 7, 319: 7, 469: 7, 815: 7, 500: 7, 382: 7, 216: 7, 552: 7, 388: 7, 547: 7, 753: 7, 255: 6, 120: 6, 145: 6, 402: 6, 829: 6, 714: 6, 761: 6, 435: 6, 737: 6, 217: 6, 521: 6, 60: 6, 229: 6, 122: 6, 271: 6, 885: 6, 171: 6, 404: 6, 807: 6, 589: 6, 742: 6, 439: 6, 709: 6, 332: 6, 169: 6, 571: 6, 261: 6, 325: 6, 862: 6, 244: 6, 844: 6, 135: 6, 765: 6, 845: 6, 766: 6, 464: 6, 869: 6, 344: 6, 312: 6, 773: 6, 167: 6, 24: 6, 504: 6, 796: 6, 123: 6, 608: 6, 871: 6, 65: 6, 189: 6, 299: 6, 15: 6, 318: 6, 444: 6, 514: 6, 736: 6, 170: 6, 138: 6, 49: 6, 784: 6, 349: 6, 17: 6, 425: 6, 22: 6, 607: 6, 368: 6, 838: 6, 92: 6, 249: 6, 391: 6, 44: 6, 706: 6, 275: 6, 662: 6, 696: 6, 403: 6, 587: 6, 789: 6, 688: 6, 389: 6, 795: 6, 380: 6, 90: 6, 41: 6, 409: 6, 100: 6, 744: 6, 13: 5, 282: 5, 886: 5, 220: 5, 270: 5, 237: 5, 489: 5, 609: 5, 89: 5, 867: 5, 677: 5, 876: 5, 324: 5, 478: 5, 330: 5, 578: 5, 394: 5, 155: 5, 105: 5, 463: 5, 272: 5, 53: 5, 660: 5, 442: 5, 148: 5, 28: 5, 243: 5, 301: 5, 9: 5, 722: 5, 46: 5, 263: 5, 644: 5, 413: 5, 36: 5, 652: 5, 111: 5, 207: 5, 277: 5, 686: 5, 69: 5, 755: 5, 614: 5, 539: 5, 329: 5, 558: 5, 639: 5, 294: 5, 416: 5, 603: 5, 472: 5, 554: 5, 541: 5, 268: 5, 713: 5, 493: 5, 231: 5, 480: 5, 107: 5, 779: 5, 407: 5, 758: 5, 311: 5, 873: 5, 752: 5, 501: 4, 1: 4, 128: 4, 846: 4, 180: 4, 801: 4, 26: 4, 30: 4, 151: 4, 335: 4, 88: 4, 343: 4, 359: 4, 664: 4, 691: 4, 168: 4, 467: 4, 417: 4, 712: 4, 322: 4, 19: 4, 783: 4, 865: 4, 133: 4, 103: 4, 310: 4, 285: 4, 830: 4, 605: 4, 619: 4, 550: 4, 162: 4, 533: 4, 25: 4, 392: 4, 574: 4, 492: 4, 775: 4, 0: 4, 337: 4, 87: 4, 306: 4, 383: 4, 506: 4, 600: 4, 29: 4, 461: 4, 583: 4, 739: 4, 149: 4, 734: 4, 257: 4, 645: 4, 458: 4, 401: 4, 79: 4, 381: 3, 483: 3, 841: 3, 888: 3, 352: 3, 495: 3, 878: 3, 797: 3, 819: 3, 720: 3, 175: 3, 719: 3, 146: 3, 507: 3, 694: 3, 707: 3, 116: 3, 91: 3, 7: 3, 177: 3, 771: 3, 265: 3, 432: 3, 33: 3, 584: 3, 626: 3, 488: 3, 209: 3, 858: 3, 733: 3, 792: 3, 241: 3, 110: 3, 536: 3, 34: 3, 5: 3, 610: 3, 166: 3, 230: 3, 555: 3, 42: 3, 612: 3, 104: 3, 632: 3, 671: 3, 80: 3, 526: 3, 267: 3, 298: 3, 659: 2, 881: 2, 184: 2, 71: 2, 295: 2, 850: 2, 725: 2, 532: 2, 73: 2, 764: 2, 595: 2, 18: 2, 724: 2, 112: 2, 156: 2, 181: 1, 246: 1, 372: 1, 787: 1})
fit_time: 27.549483117000023

Accuracy for 44 task(s): 	 [Class-IL]: 67.07 % 	 [Task-IL]: 30.93 %

CLASS_IL_ACC: 
	[64.97175141242938, 69.0, 72.03389830508475, 65.13761467889908, 68.26923076923077, 63.77952755905512, 74.0, 60.78431372549019, 55.44554455445545, 61.59420289855072, 72.64957264957265, 56.56565656565656, 64.28571428571429, 54.621848739495796, 65.71428571428571, 76.72413793103449, 80.3921568627451, 66.95652173913044, 70.58823529411765, 62.10526315789474, 66.05504587155964, 70.27027027027027, 70.0, 65.09433962264151, 68.25396825396825, 69.6, 63.10679611650486, 75.0, 69.23076923076923, 68.68686868686868, 63.46153846153846, 63.06306306306306, 69.47368421052632, 66.35514018691589, 71.9298245614035, 54.12844036697248, 66.3716814159292, 54.700854700854705, 61.53846153846154, 72.64957264957265, 66.38655462184873, 80.35714285714286, 77.87610619469027, 71.84466019417476]
TASK_IL_ACC: 
	[55.932203389830505, 28.999999999999996, 32.20338983050847, 32.11009174311927, 27.884615384615387, 33.85826771653544, 30.0, 23.52941176470588, 27.722772277227726, 34.05797101449276, 23.931623931623932, 35.35353535353536, 24.489795918367346, 22.689075630252102, 26.666666666666668, 37.93103448275862, 28.431372549019606, 27.82608695652174, 37.254901960784316, 25.263157894736842, 27.522935779816514, 21.62162162162162, 24.545454545454547, 31.132075471698112, 30.952380952380953, 31.2, 28.155339805825243, 31.896551724137932, 30.76923076923077, 30.303030303030305, 27.884615384615387, 23.423423423423422, 29.47368421052631, 26.168224299065418, 35.08771929824561, 30.275229357798167, 27.43362831858407, 24.786324786324787, 25.64102564102564, 24.786324786324787, 26.89075630252101, 29.464285714285715, 30.08849557522124, 95.14563106796116]
f1_micro: 67.05308114704088
f1_macro: 62.652600258072134
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       1.00      1.00      1.00         4
           2       0.29      0.50      0.36         4
           3       0.75      1.00      0.86         9
           4       0.80      0.44      0.57         9
           5       0.13      0.50      0.21         4
           6       0.43      0.60      0.50         5
           7       0.80      1.00      0.89         4
           8       0.43      0.75      0.55         4
           9       1.00      1.00      1.00         4
          10       0.00      0.00      0.00         4
          11       1.00      0.67      0.80         9
          12       0.43      0.60      0.50         5
          13       0.00      0.00      0.00         4
          14       0.57      0.89      0.70         9
          15       1.00      0.75      0.86         4
          16       1.00      0.80      0.89         5
          17       0.00      0.00      0.00         4
          18       0.00      0.00      0.00         4
          19       1.00      0.80      0.89         5
          20       0.56      0.56      0.56         9
          21       0.75      0.75      0.75         4
          22       0.60      0.75      0.67         4
          23       0.33      0.40      0.36         5
          24       0.00      0.00      0.00         5
          25       0.80      1.00      0.89         4
          26       0.57      1.00      0.73         4
          27       0.00      0.00      0.00         4
          28       0.57      1.00      0.73         4
          29       1.00      0.75      0.86         4
          30       1.00      0.75      0.86         4
          31       1.00      1.00      1.00         9
          32       1.00      0.89      0.94         9
          33       0.00      0.00      0.00         4
          34       0.00      0.00      0.00         4
          35       0.75      0.75      0.75         4
          36       1.00      0.75      0.86         4
          37       1.00      1.00      1.00         4
          38       0.50      0.67      0.57         9
          39       0.67      1.00      0.80         4
          40       0.69      1.00      0.82         9
          41       1.00      1.00      1.00         4
          42       0.00      0.00      0.00         4
          43       0.83      1.00      0.91         5
          44       1.00      0.50      0.67         4
          45       0.00      0.00      0.00         4
          46       0.00      0.00      0.00         4
          47       1.00      0.88      0.93         8
          48       1.00      1.00      1.00         4
          49       0.80      1.00      0.89         4
          50       0.80      0.89      0.84         9
          51       0.12      0.75      0.21         4
          52       0.20      0.25      0.22         4
          53       1.00      0.50      0.67         4
          54       1.00      1.00      1.00         9
          55       1.00      1.00      1.00         5
          56       0.90      1.00      0.95         9
          57       0.83      1.00      0.91         5
          58       1.00      0.17      0.29         6
          59       0.75      0.60      0.67         5
          60       1.00      0.75      0.86         4
          61       0.67      0.80      0.73         5
          62       0.00      0.00      0.00         4
          63       1.00      0.75      0.86         4
          64       1.00      0.80      0.89         5
          65       0.00      0.00      0.00         4
          66       0.71      1.00      0.83         5
          67       0.82      1.00      0.90         9
          68       0.47      1.00      0.64         9
          69       0.12      0.75      0.21         4
          70       0.89      0.89      0.89         9
          71       1.00      1.00      1.00         4
          72       0.00      0.00      0.00         9
          73       1.00      0.25      0.40         4
          74       1.00      0.75      0.86         4
          75       1.00      1.00      1.00         9
          76       0.50      0.50      0.50         4
          77       0.80      0.89      0.84         9
          78       1.00      1.00      1.00         5
          79       1.00      0.75      0.86         4
          80       1.00      0.75      0.86         4
          81       1.00      1.00      1.00         4
          82       0.67      0.80      0.73         5
          83       0.08      0.11      0.10         9
          84       1.00      0.75      0.86         4
          85       0.00      0.00      0.00         9
          86       1.00      0.80      0.89         5
          87       0.40      0.50      0.44         4
          88       0.00      0.00      0.00         4
          89       1.00      0.75      0.86         4
          90       0.67      1.00      0.80         4
          91       1.00      0.80      0.89         5
          92       0.00      0.00      0.00         4
          93       0.82      1.00      0.90         9
          94       0.67      1.00      0.80         4
          95       1.00      0.89      0.94         9
          96       0.00      0.00      0.00         4
          97       0.80      1.00      0.89         4
          98       0.80      0.80      0.80         5
          99       1.00      1.00      1.00         4
         100       0.00      0.00      0.00         4
         101       0.80      1.00      0.89         4
         102       0.00      0.00      0.00         4
         103       0.00      0.00      0.00         4
         104       1.00      0.20      0.33         5
         105       1.00      1.00      1.00         5
         106       1.00      1.00      1.00         9
         107       0.75      0.75      0.75         4
         108       0.80      0.89      0.84         9
         109       1.00      1.00      1.00         5
         110       0.00      0.00      0.00         4
         111       0.80      1.00      0.89         4
         112       1.00      0.25      0.40         4
         113       0.88      0.78      0.82         9
         114       0.89      0.89      0.89         9
         115       1.00      1.00      1.00         4
         116       1.00      0.75      0.86         4
         117       0.78      0.78      0.78         9
         118       0.33      0.11      0.17         9
         119       0.40      0.44      0.42         9
         120       0.00      0.00      0.00         4
         121       1.00      0.75      0.86         4
         122       0.80      1.00      0.89         4
         123       0.00      0.00      0.00         5
         124       0.00      0.00      0.00         9
         125       0.90      1.00      0.95         9
         126       1.00      0.40      0.57         5
         127       0.00      0.00      0.00         4
         128       1.00      0.75      0.86         4
         129       0.80      0.89      0.84         9
         130       1.00      1.00      1.00         9
         131       0.80      1.00      0.89         4
         132       1.00      1.00      1.00         9
         133       0.75      0.75      0.75         4
         134       0.44      0.78      0.56         9
         135       0.50      0.25      0.33         4
         136       0.67      1.00      0.80         4
         137       1.00      0.89      0.94         9
         138       1.00      0.75      0.86         4
         139       0.60      0.60      0.60         5
         140       1.00      1.00      1.00         5
         141       0.71      1.00      0.83         5
         142       0.33      0.25      0.29         4
         143       0.60      0.75      0.67         4
         144       0.44      1.00      0.62         4
         145       1.00      0.50      0.67         4
         146       0.80      1.00      0.89         4
         147       0.67      1.00      0.80         4
         148       0.57      0.80      0.67         5
         149       1.00      0.75      0.86         4
         150       0.47      0.78      0.58         9
         151       0.33      0.25      0.29         4
         152       0.50      0.20      0.29         5
         153       0.67      1.00      0.80         4
         154       1.00      0.75      0.86         4
         155       0.50      0.25      0.33         4
         156       0.07      0.25      0.11         4
         157       1.00      1.00      1.00         9
         158       0.57      1.00      0.73         4
         159       1.00      1.00      1.00         4
         160       0.00      0.00      0.00         9
         161       0.00      0.00      0.00         4
         162       1.00      1.00      1.00         4
         163       0.50      0.20      0.29         5
         164       0.89      0.89      0.89         9
         165       0.80      1.00      0.89         4
         166       0.00      0.00      0.00         4
         167       0.60      0.75      0.67         4
         168       1.00      0.60      0.75         5
         169       1.00      0.50      0.67         4
         170       1.00      0.50      0.67         4
         171       0.00      0.00      0.00         4
         172       0.80      1.00      0.89         4
         173       0.90      1.00      0.95         9
         174       1.00      0.25      0.40         4
         175       0.00      0.00      0.00         4
         176       0.67      0.67      0.67         9
         177       0.25      0.25      0.25         4
         178       0.08      0.50      0.14         4
         179       0.50      0.25      0.33         4
         180       0.80      1.00      0.89         4
         181       0.00      0.00      0.00         4
         182       1.00      1.00      1.00         5
         183       0.29      0.50      0.36         4
         184       1.00      0.75      0.86         4
         185       0.50      0.50      0.50         4
         186       0.70      0.78      0.74         9
         187       0.78      0.78      0.78         9
         188       0.00      0.00      0.00         4
         189       0.50      0.75      0.60         4
         190       0.17      0.25      0.20         4
         191       1.00      1.00      1.00         4
         192       0.00      0.00      0.00         4
         193       1.00      0.78      0.88         9
         194       0.67      0.44      0.53         9
         195       0.88      0.78      0.82         9
         196       0.00      0.00      0.00         4
         197       1.00      1.00      1.00         9
         198       1.00      0.78      0.88         9
         199       0.80      0.89      0.84         9
         200       1.00      1.00      1.00         5
         201       0.80      0.89      0.84         9
         202       0.00      0.00      0.00         9
         203       1.00      0.44      0.62         9
         204       0.80      1.00      0.89         4
         205       0.58      0.78      0.67         9
         206       0.88      0.78      0.82         9
         207       1.00      0.25      0.40         4
         208       1.00      1.00      1.00         4
         209       0.00      0.00      0.00         4
         210       1.00      1.00      1.00         4
         211       0.00      0.00      0.00         5
         212       0.07      0.11      0.09         9
         213       1.00      1.00      1.00         5
         214       0.33      0.40      0.36         5
         215       1.00      1.00      1.00         4
         216       1.00      1.00      1.00         4
         217       0.50      0.25      0.33         4
         218       0.44      1.00      0.62         4
         219       1.00      0.78      0.88         9
         220       0.00      0.00      0.00         4
         221       0.78      0.78      0.78         9
         222       0.89      0.89      0.89         9
         223       0.75      0.75      0.75         4
         224       1.00      0.89      0.94         9
         225       0.80      0.80      0.80         5
         226       0.50      0.25      0.33         4
         227       0.43      0.75      0.55         4
         228       0.38      0.33      0.35         9
         229       1.00      1.00      1.00         4
         230       1.00      1.00      1.00         4
         231       1.00      0.25      0.40         4
         232       0.90      1.00      0.95         9
         233       0.73      0.89      0.80         9
         234       0.89      0.89      0.89         9
         235       0.00      0.00      0.00         9
         236       0.33      0.75      0.46         4
         237       0.80      1.00      0.89         4
         238       0.00      0.00      0.00         9
         239       1.00      1.00      1.00         5
         240       0.80      1.00      0.89         4
         241       0.00      0.00      0.00         4
         242       1.00      1.00      1.00         4
         243       0.83      1.00      0.91         5
         244       1.00      1.00      1.00         4
         245       1.00      0.50      0.67         4
         246       1.00      0.25      0.40         4
         247       0.12      0.25      0.17         4
         248       1.00      1.00      1.00         4
         249       0.33      0.50      0.40         4
         250       0.83      1.00      0.91         5
         251       0.50      0.20      0.29         5
         252       0.33      0.25      0.29         4
         253       1.00      0.50      0.67         4
         254       0.00      0.00      0.00         4
         255       1.00      0.50      0.67         4
         256       0.80      1.00      0.89         4
         257       1.00      1.00      1.00         4
         258       1.00      1.00      1.00         5
         259       1.00      1.00      1.00         4
         260       0.06      0.11      0.08         9
         261       0.75      0.75      0.75         4
         262       0.82      1.00      0.90         9
         263       0.00      0.00      0.00         4
         264       1.00      0.80      0.89         5
         265       1.00      0.50      0.67         4
         266       0.00      0.00      0.00         4
         267       1.00      0.75      0.86         4
         268       0.00      0.00      0.00         4
         269       0.57      1.00      0.73         4
         270       0.67      0.50      0.57         4
         271       0.83      1.00      0.91         5
         272       1.00      0.50      0.67         4
         273       1.00      1.00      1.00         9
         274       0.00      0.00      0.00         9
         275       0.50      0.50      0.50         4
         276       0.80      0.80      0.80         5
         277       0.00      0.00      0.00         4
         278       0.83      1.00      0.91         5
         279       1.00      0.25      0.40         4
         280       0.00      0.00      0.00         4
         281       1.00      0.80      0.89         5
         282       1.00      1.00      1.00         4
         283       0.69      1.00      0.82         9
         284       0.09      0.11      0.10         9
         285       0.00      0.00      0.00         4
         286       0.73      0.89      0.80         9
         287       0.88      0.78      0.82         9
         288       0.00      0.00      0.00         4
         289       1.00      0.80      0.89         5
         290       0.00      0.00      0.00         4
         291       1.00      1.00      1.00         9
         292       0.40      0.50      0.44         4
         293       0.62      0.56      0.59         9
         294       0.67      0.50      0.57         4
         295       0.00      0.00      0.00         4
         296       0.90      1.00      0.95         9
         297       0.73      0.89      0.80         9
         298       0.00      0.00      0.00         4
         299       0.83      1.00      0.91         5
         300       0.08      0.11      0.10         9
         301       1.00      1.00      1.00         4
         302       0.80      1.00      0.89         4
         303       0.88      0.78      0.82         9
         304       1.00      0.75      0.86         4
         305       0.80      1.00      0.89         4
         306       1.00      0.25      0.40         4
         307       0.17      0.25      0.20         4
         308       0.50      0.60      0.55         5
         309       0.40      0.50      0.44         4
         310       0.80      0.80      0.80         5
         311       0.67      1.00      0.80         4
         312       0.67      0.40      0.50         5
         313       1.00      1.00      1.00         5
         314       0.83      1.00      0.91         5
         315       0.90      1.00      0.95         9
         316       1.00      1.00      1.00         9
         317       0.73      0.89      0.80         9
         318       0.00      0.00      0.00         4
         319       0.83      0.56      0.67         9
         320       1.00      0.78      0.88         9
         321       1.00      1.00      1.00         4
         322       0.50      0.25      0.33         4
         323       0.40      1.00      0.57         4
         324       1.00      0.25      0.40         4
         325       1.00      0.75      0.86         4
         326       0.75      0.75      0.75         4
         327       1.00      1.00      1.00         9
         328       0.71      0.56      0.63         9
         329       0.80      1.00      0.89         4
         330       0.50      1.00      0.67         4
         331       1.00      1.00      1.00         4
         332       1.00      1.00      1.00         4
         333       0.00      0.00      0.00         4
         334       0.50      1.00      0.67         4
         335       0.00      0.00      0.00         4
         336       0.71      1.00      0.83         5
         337       1.00      1.00      1.00         5
         338       0.80      0.89      0.84         9
         339       0.75      0.75      0.75         4
         340       1.00      1.00      1.00         4
         341       0.89      0.89      0.89         9
         342       0.80      1.00      0.89         4
         343       1.00      1.00      1.00         4
         344       1.00      0.40      0.57         5
         345       0.80      0.80      0.80         5
         346       0.00      0.00      0.00         4
         347       0.62      1.00      0.77         5
         348       1.00      1.00      1.00         5
         349       1.00      1.00      1.00         4
         350       0.75      1.00      0.86         9
         351       0.00      0.00      0.00         4
         352       1.00      1.00      1.00         4
         353       1.00      0.80      0.89         5
         354       1.00      0.50      0.67         4
         355       0.83      0.56      0.67         9
         356       0.00      0.00      0.00         4
         357       0.70      0.88      0.78         8
         358       0.75      0.75      0.75         4
         359       1.00      0.50      0.67         4
         360       0.67      1.00      0.80         4
         361       0.89      0.89      0.89         9
         362       0.90      1.00      0.95         9
         363       0.78      0.78      0.78         9
         364       0.00      0.00      0.00         4
         365       1.00      0.75      0.86         4
         366       1.00      0.75      0.86         4
         367       0.11      0.25      0.15         4
         368       0.33      0.50      0.40         4
         369       1.00      1.00      1.00         5
         370       0.00      0.00      0.00         4
         371       0.57      0.89      0.70         9
         372       0.00      0.00      0.00         4
         373       1.00      0.89      0.94         9
         374       0.73      0.89      0.80         9
         375       1.00      0.75      0.86         4
         376       0.33      0.75      0.46         4
         377       0.40      0.50      0.44         4
         378       0.80      0.89      0.84         9
         379       1.00      1.00      1.00         9
         380       1.00      0.75      0.86         4
         381       0.14      0.25      0.18         4
         382       1.00      0.80      0.89         5
         383       1.00      1.00      1.00         4
         384       1.00      1.00      1.00         4
         385       0.58      0.78      0.67         9
         386       0.08      0.25      0.12         4
         387       0.38      0.75      0.50         4
         388       0.00      0.00      0.00         4
         389       0.50      0.50      0.50         4
         390       0.67      0.50      0.57         4
         391       1.00      1.00      1.00         4
         392       0.00      0.00      0.00         5
         393       0.67      1.00      0.80         4
         394       1.00      0.50      0.67         4
         395       1.00      0.75      0.86         4
         396       0.00      0.00      0.00         4
         397       0.80      1.00      0.89         4
         398       0.67      1.00      0.80         4
         399       0.45      1.00      0.62         5
         400       0.00      0.00      0.00         4
         401       1.00      0.40      0.57         5
         402       1.00      0.75      0.86         4
         403       0.00      0.00      0.00         4
         404       0.33      0.25      0.29         4
         405       0.00      0.00      0.00         5
         406       0.90      1.00      0.95         9
         407       1.00      0.25      0.40         4
         408       1.00      1.00      1.00         5
         409       1.00      0.40      0.57         5
         410       1.00      1.00      1.00         9
         411       0.50      0.75      0.60         4
         412       1.00      0.50      0.67         4
         413       0.80      1.00      0.89         4
         414       0.82      1.00      0.90         9
         415       0.75      0.60      0.67         5
         416       1.00      1.00      1.00         4
         417       0.50      0.25      0.33         4
         418       0.50      0.75      0.60         4
         419       0.50      0.25      0.33         4
         420       1.00      0.80      0.89         5
         421       0.33      0.20      0.25         5
         422       1.00      0.78      0.88         9
         423       0.38      0.75      0.50         4
         424       1.00      1.00      1.00         9
         425       0.00      0.00      0.00         4
         426       0.80      0.44      0.57         9
         427       1.00      0.75      0.86         4
         428       1.00      0.50      0.67         4
         429       0.75      0.75      0.75         4
         430       0.75      0.60      0.67         5
         431       1.00      0.78      0.88         9
         432       0.67      0.50      0.57         4
         433       0.60      0.75      0.67         4
         434       1.00      0.20      0.33         5
         435       0.50      0.75      0.60         4
         436       1.00      1.00      1.00         5
         437       0.00      0.00      0.00         4
         438       0.67      1.00      0.80         4
         439       0.00      0.00      0.00         4
         440       0.67      1.00      0.80         4
         441       0.89      0.89      0.89         9
         442       1.00      0.80      0.89         5
         443       0.56      0.56      0.56         9
         444       1.00      0.80      0.89         5
         445       0.89      0.89      0.89         9
         446       0.89      0.89      0.89         9
         447       0.80      0.80      0.80         5
         448       1.00      0.89      0.94         9
         449       0.67      0.50      0.57         4
         450       0.29      0.50      0.36         4
         451       1.00      1.00      1.00         4
         452       0.80      0.80      0.80         5
         453       0.00      0.00      0.00         4
         454       0.83      1.00      0.91         5
         455       0.80      0.80      0.80         5
         456       0.43      0.75      0.55         4
         457       0.67      0.89      0.76         9
         458       0.00      0.00      0.00         4
         459       0.67      0.50      0.57         4
         460       0.90      1.00      0.95         9
         461       0.00      0.00      0.00         4
         462       0.80      0.89      0.84         9
         463       0.00      0.00      0.00         4
         464       0.38      1.00      0.56         5
         465       0.00      0.00      0.00         5
         466       1.00      1.00      1.00         5
         467       0.00      0.00      0.00         4
         468       0.55      0.67      0.60         9
         469       1.00      1.00      1.00         4
         470       0.80      1.00      0.89         4
         471       1.00      0.89      0.94         9
         472       0.50      0.50      0.50         4
         473       1.00      1.00      1.00         4
         474       0.80      1.00      0.89         4
         475       1.00      1.00      1.00         5
         476       1.00      0.44      0.62         9
         477       0.75      0.67      0.71         9
         478       0.80      1.00      0.89         4
         479       0.83      1.00      0.91         5
         480       0.67      0.50      0.57         4
         481       0.57      0.57      0.57         7
         482       1.00      1.00      1.00         4
         483       0.50      0.25      0.33         4
         484       0.89      0.89      0.89         9
         485       1.00      0.80      0.89         5
         486       0.00      0.00      0.00         4
         487       0.50      0.25      0.33         4
         488       0.00      0.00      0.00         4
         489       1.00      1.00      1.00         4
         490       0.00      0.00      0.00         4
         491       0.75      0.67      0.71         9
         492       1.00      1.00      1.00         4
         493       1.00      0.75      0.86         4
         494       0.30      0.60      0.40         5
         495       0.50      0.50      0.50         4
         496       0.69      1.00      0.82         9
         497       0.00      0.00      0.00         4
         498       0.06      0.11      0.07         9
         499       1.00      0.50      0.67         8
         500       0.75      0.75      0.75         4
         501       0.80      1.00      0.89         4
         502       0.89      0.89      0.89         9
         503       1.00      0.78      0.88         9
         504       0.75      0.75      0.75         4
         505       0.00      0.00      0.00         4
         506       0.40      0.50      0.44         4
         507       0.67      1.00      0.80         4
         508       1.00      0.78      0.88         9
         509       0.64      1.00      0.78         9
         510       0.00      0.00      0.00         4
         511       0.90      1.00      0.95         9
         512       1.00      0.67      0.80         9
         513       0.83      1.00      0.91         5
         514       0.50      0.20      0.29         5
         515       1.00      1.00      1.00         9
         516       0.33      0.50      0.40         4
         517       0.00      0.00      0.00         9
         518       0.00      0.00      0.00         4
         519       0.80      0.89      0.84         9
         520       0.45      1.00      0.62         9
         521       1.00      0.75      0.86         4
         522       0.40      0.50      0.44         4
         523       1.00      0.20      0.33         5
         524       0.83      0.56      0.67         9
         525       0.82      1.00      0.90         9
         526       1.00      1.00      1.00         4
         527       1.00      1.00      1.00         5
         528       1.00      1.00      1.00         9
         529       0.67      0.89      0.76         9
         530       1.00      0.80      0.89         5
         531       1.00      1.00      1.00         5
         532       0.00      0.00      0.00         4
         533       1.00      0.75      0.86         4
         534       1.00      1.00      1.00         4
         535       0.80      0.44      0.57         9
         536       1.00      0.25      0.40         4
         537       0.00      0.00      0.00         4
         538       0.40      0.80      0.53         5
         539       0.00      0.00      0.00         4
         540       1.00      0.75      0.86         4
         541       1.00      1.00      1.00         4
         542       0.80      1.00      0.89         4
         543       0.00      0.00      0.00         4
         544       0.73      0.89      0.80         9
         545       0.75      0.60      0.67         5
         546       0.11      0.25      0.15         4
         547       0.80      1.00      0.89         4
         548       0.80      0.80      0.80         5
         549       0.86      0.67      0.75         9
         550       1.00      0.50      0.67         4
         551       0.00      0.00      0.00         4
         552       1.00      1.00      1.00         4
         553       1.00      1.00      1.00         9
         554       1.00      1.00      1.00         4
         555       1.00      0.75      0.86         4
         556       0.89      0.89      0.89         9
         557       0.89      0.89      0.89         9
         558       1.00      0.75      0.86         4
         559       0.78      1.00      0.88         7
         560       0.83      0.56      0.67         9
         561       1.00      0.75      0.86         4
         562       0.38      0.75      0.50         4
         563       0.50      0.50      0.50         4
         564       0.60      0.75      0.67         4
         565       0.00      0.00      0.00         4
         566       1.00      0.89      0.94         9
         567       1.00      0.78      0.88         9
         568       0.50      0.44      0.47         9
         569       0.83      1.00      0.91         5
         570       0.00      0.00      0.00         4
         571       0.83      1.00      0.91         5
         572       0.71      1.00      0.83         5
         573       1.00      1.00      1.00         4
         574       1.00      1.00      1.00         4
         575       1.00      0.89      0.94         9
         576       0.83      0.56      0.67         9
         577       1.00      0.75      0.86         4
         578       0.17      0.50      0.25         4
         579       0.50      0.78      0.61         9
         580       1.00      0.75      0.86         4
         581       1.00      1.00      1.00         4
         582       1.00      1.00      1.00         4
         583       0.00      0.00      0.00         4
         584       1.00      1.00      1.00         5
         585       0.83      1.00      0.91         5
         586       0.64      0.78      0.70         9
         587       1.00      1.00      1.00         4
         588       0.75      1.00      0.86         9
         589       1.00      0.50      0.67         4
         590       0.33      0.50      0.40         4
         591       1.00      0.78      0.88         9
         592       0.00      0.00      0.00         9
         593       0.00      0.00      0.00         4
         594       0.57      0.80      0.67         5
         595       0.00      0.00      0.00         4
         596       0.38      0.56      0.45         9
         597       0.75      0.75      0.75         4
         598       0.83      1.00      0.91         5
         599       1.00      0.50      0.67         4
         600       0.60      0.60      0.60         5
         601       0.75      0.75      0.75         4
         602       1.00      1.00      1.00         4
         603       1.00      0.50      0.67         4
         604       0.67      1.00      0.80         4
         605       1.00      0.25      0.40         4
         606       0.44      1.00      0.62         4
         607       1.00      1.00      1.00         4
         608       1.00      1.00      1.00         4
         609       1.00      0.75      0.86         4
         610       0.00      0.00      0.00         4
         611       1.00      0.67      0.80         9
         612       1.00      0.40      0.57         5
         613       1.00      1.00      1.00         9
         614       0.67      0.50      0.57         4
         615       0.73      0.89      0.80         9
         616       0.00      0.00      0.00         4
         617       0.83      1.00      0.91         5
         618       1.00      0.50      0.67         4
         619       1.00      0.20      0.33         5
         620       0.43      0.60      0.50         5
         621       0.67      1.00      0.80         4
         622       1.00      0.50      0.67         4
         623       0.17      0.50      0.25         4
         624       1.00      0.78      0.88         9
         625       1.00      0.50      0.67         4
         626       1.00      0.50      0.67         4
         627       0.00      0.00      0.00         4
         628       0.75      0.75      0.75         4
         629       0.86      0.67      0.75         9
         630       1.00      0.80      0.89         5
         631       0.62      0.89      0.73         9
         632       0.67      0.50      0.57         4
         633       1.00      0.75      0.86         4
         634       1.00      1.00      1.00         4
         635       0.82      1.00      0.90         9
         636       1.00      0.75      0.86         4
         637       0.00      0.00      0.00         9
         638       1.00      0.60      0.75         5
         639       0.00      0.00      0.00         4
         640       0.60      0.75      0.67         4
         641       0.15      0.75      0.25         4
         642       0.20      0.25      0.22         4
         643       0.15      1.00      0.27         4
         644       0.00      0.00      0.00         4
         645       1.00      0.25      0.40         4
         646       0.67      0.89      0.76         9
         647       0.89      0.89      0.89         9
         648       0.33      0.50      0.40         4
         649       0.83      0.56      0.67         9
         650       0.57      1.00      0.73         4
         651       0.00      0.00      0.00         4
         652       1.00      0.75      0.86         4
         653       1.00      1.00      1.00         9
         654       1.00      0.78      0.88         9
         655       0.50      1.00      0.67         4
         656       0.43      0.75      0.55         4
         657       0.21      0.75      0.33         4
         658       1.00      1.00      1.00         5
         659       1.00      0.50      0.67         4
         660       1.00      1.00      1.00         4
         661       0.50      0.75      0.60         4
         662       1.00      0.80      0.89         5
         663       0.80      1.00      0.89         4
         664       1.00      1.00      1.00         4
         665       1.00      0.20      0.33         5
         666       0.67      0.80      0.73         5
         667       0.12      0.25      0.17         4
         668       1.00      0.40      0.57         5
         669       0.50      0.50      0.50         4
         670       0.00      0.00      0.00         4
         671       1.00      1.00      1.00         4
         672       0.00      0.00      0.00         4
         673       0.82      1.00      0.90         9
         674       0.00      0.00      0.00         4
         675       0.60      0.75      0.67         4
         676       1.00      0.50      0.67         4
         677       0.75      0.75      0.75         4
         678       1.00      1.00      1.00         5
         679       0.90      1.00      0.95         9
         680       0.15      1.00      0.26         4
         681       0.00      0.00      0.00         9
         682       0.17      0.25      0.20         4
         683       0.67      1.00      0.80         4
         684       1.00      0.20      0.33         5
         685       1.00      1.00      1.00         4
         686       1.00      0.75      0.86         4
         687       1.00      1.00      1.00         4
         688       0.00      0.00      0.00         4
         689       0.86      0.67      0.75         9
         690       1.00      1.00      1.00         4
         691       1.00      0.50      0.67         4
         692       0.82      1.00      0.90         9
         693       1.00      0.78      0.88         9
         694       0.00      0.00      0.00         4
         695       0.50      0.44      0.47         9
         696       1.00      0.40      0.57         5
         697       0.86      0.67      0.75         9
         698       1.00      1.00      1.00         9
         699       0.09      0.33      0.14         9
         700       0.40      0.50      0.44         4
         701       1.00      1.00      1.00         5
         702       1.00      0.80      0.89         5
         703       0.67      1.00      0.80         4
         704       0.67      1.00      0.80         4
         705       0.82      1.00      0.90         9
         706       0.00      0.00      0.00         4
         707       0.80      1.00      0.89         4
         708       0.75      0.60      0.67         5
         709       1.00      1.00      1.00         4
         710       0.89      0.89      0.89         9
         711       1.00      1.00      1.00         4
         712       1.00      0.75      0.86         4
         713       1.00      1.00      1.00         4
         714       0.33      0.50      0.40         4
         715       0.27      0.75      0.40         4
         716       0.73      0.89      0.80         9
         717       0.44      0.44      0.44         9
         718       0.75      0.75      0.75         4
         719       0.00      0.00      0.00         4
         720       1.00      0.80      0.89         5
         721       1.00      1.00      1.00         5
         722       0.12      0.25      0.17         4
         723       1.00      1.00      1.00         4
         724       1.00      0.25      0.40         4
         725       0.00      0.00      0.00         5
         726       0.14      0.75      0.24         4
         727       0.67      1.00      0.80         4
         728       0.67      0.22      0.33         9
         729       0.80      0.80      0.80         5
         730       0.50      0.33      0.40         9
         731       0.60      0.67      0.63         9
         732       0.00      0.00      0.00         4
         733       1.00      0.50      0.67         4
         734       1.00      1.00      1.00         4
         735       1.00      1.00      1.00         9
         736       1.00      1.00      1.00         4
         737       0.00      0.00      0.00         4
         738       0.80      0.89      0.84         9
         739       0.67      1.00      0.80         4
         740       0.00      0.00      0.00         4
         741       0.62      0.56      0.59         9
         742       0.80      1.00      0.89         4
         743       0.60      0.60      0.60         5
         744       0.80      1.00      0.89         4
         745       0.00      0.00      0.00         4
         746       0.82      1.00      0.90         9
         747       0.00      0.00      0.00         9
         748       0.57      1.00      0.73         4
         749       0.78      0.78      0.78         9
         750       0.57      0.80      0.67         5
         751       0.00      0.00      0.00         4
         752       0.67      0.80      0.73         5
         753       1.00      0.50      0.67         4
         754       0.00      0.00      0.00         4
         755       0.00      0.00      0.00         4
         756       1.00      0.89      0.94         9
         757       0.11      0.11      0.11         9
         758       1.00      0.25      0.40         4
         759       0.00      0.00      0.00         4
         760       1.00      0.78      0.88         9
         761       0.00      0.00      0.00         4
         762       1.00      1.00      1.00         9
         763       0.80      0.44      0.57         9
         764       1.00      0.25      0.40         4
         765       0.43      0.75      0.55         4
         766       0.43      0.75      0.55         4
         767       0.38      0.60      0.46         5
         768       0.83      1.00      0.91         5
         769       0.00      0.00      0.00         4
         770       1.00      1.00      1.00         9
         771       0.50      0.25      0.33         4
         772       0.86      0.67      0.75         9
         773       1.00      0.75      0.86         4
         774       0.90      1.00      0.95         9
         775       0.00      0.00      0.00         4
         776       0.50      0.67      0.57         9
         777       0.00      0.00      0.00         9
         778       1.00      0.50      0.67         4
         779       0.67      1.00      0.80         4
         780       1.00      0.75      0.86         4
         781       0.60      0.67      0.63         9
         782       0.50      0.40      0.44         5
         783       1.00      1.00      1.00         4
         784       1.00      0.60      0.75         5
         785       0.83      1.00      0.91         5
         786       0.00      0.00      0.00         4
         787       0.00      0.00      0.00         4
         788       1.00      0.71      0.83         7
         789       1.00      0.75      0.86         4
         790       1.00      0.60      0.75         5
         791       0.90      1.00      0.95         9
         792       0.00      0.00      0.00         4
         793       1.00      0.89      0.94         9
         794       0.69      1.00      0.82         9
         795       1.00      1.00      1.00         4
         796       1.00      0.75      0.86         4
         797       1.00      1.00      1.00         4
         798       0.50      1.00      0.67         5
         799       0.14      0.25      0.18         4
         800       0.50      0.25      0.33         4
         801       1.00      1.00      1.00         4
         802       0.40      0.50      0.44         4
         803       0.00      0.00      0.00         4
         804       0.00      0.00      0.00         9
         805       0.82      1.00      0.90         9
         806       0.67      0.89      0.76         9
         807       0.00      0.00      0.00         4
         808       0.83      1.00      0.91         5
         809       1.00      1.00      1.00         4
         810       0.17      0.25      0.20         4
         811       1.00      0.89      0.94         9
         812       1.00      1.00      1.00         9
         813       1.00      0.89      0.94         9
         814       0.50      0.40      0.44         5
         815       0.00      0.00      0.00         4
         816       0.80      1.00      0.89         4
         817       1.00      0.78      0.88         9
         818       1.00      1.00      1.00         9
         819       0.00      0.00      0.00         4
         820       0.60      0.75      0.67         4
         821       0.90      1.00      0.95         9
         822       0.57      0.44      0.50         9
         823       0.89      0.89      0.89         9
         824       0.42      1.00      0.59         5
         825       1.00      0.60      0.75         5
         826       0.75      0.75      0.75         4
         827       0.75      0.67      0.71         9
         828       0.56      0.56      0.56         9
         829       0.33      0.25      0.29         4
         830       0.60      0.75      0.67         4
         831       0.67      0.80      0.73         5
         832       0.50      0.25      0.33         4
         833       1.00      0.50      0.67         4
         834       0.82      1.00      0.90         9
         835       0.80      0.89      0.84         9
         836       0.43      0.75      0.55         4
         837       0.80      1.00      0.89         4
         838       0.57      0.80      0.67         5
         839       0.18      0.75      0.29         4
         840       0.60      0.67      0.63         9
         841       1.00      0.75      0.86         4
         842       1.00      0.75      0.86         4
         843       0.80      0.89      0.84         9
         844       1.00      1.00      1.00         4
         845       0.36      1.00      0.53         4
         846       0.50      0.50      0.50         4
         847       1.00      1.00      1.00         4
         848       0.88      0.78      0.82         9
         849       1.00      1.00      1.00         5
         850       0.80      1.00      0.89         4
         851       0.80      1.00      0.89         4
         852       0.00      0.00      0.00         4
         853       0.71      0.56      0.63         9
         854       1.00      0.89      0.94         9
         855       1.00      0.50      0.67         4
         856       0.69      1.00      0.82         9
         857       0.80      1.00      0.89         4
         858       1.00      0.50      0.67         4
         859       0.71      1.00      0.83         5
         860       0.50      0.25      0.33         4
         861       0.71      1.00      0.83         5
         862       1.00      0.75      0.86         4
         863       1.00      0.89      0.94         9
         864       0.54      0.78      0.64         9
         865       0.00      0.00      0.00         4
         866       0.57      1.00      0.73         4
         867       1.00      0.75      0.86         4
         868       0.62      1.00      0.77         5
         869       0.75      0.75      0.75         4
         870       0.60      0.67      0.63         9
         871       1.00      1.00      1.00         4
         872       0.75      0.67      0.71         9
         873       1.00      0.75      0.86         4
         874       0.67      0.80      0.73         5
         875       0.00      0.00      0.00         4
         876       0.50      0.25      0.33         4
         877       1.00      1.00      1.00         4
         878       1.00      0.75      0.86         4
         879       1.00      1.00      1.00         9
         880       0.80      1.00      0.89         4
         881       1.00      1.00      1.00         5
         882       1.00      0.80      0.89         5
         883       1.00      1.00      1.00         4
         884       0.07      0.33      0.12         9
         885       0.00      0.00      0.00         4
         886       0.25      0.25      0.25         4
         887       1.00      1.00      1.00         4
         888       1.00      0.50      0.67         4
         889       0.73      0.89      0.80         9
         890       1.00      1.00      1.00         4
         891       0.90      1.00      0.95         9
         892       1.00      0.75      0.86         4
         893       0.67      0.50      0.57         4

    accuracy                           0.67      4917
   macro avg       0.66      0.64      0.63      4917
weighted avg       0.68      0.67      0.66      4917

task_train_time: {0: 8.565943537999999, 1: 4.457758487000003, 2: 5.672507664000001, 3: 5.004568614, 4: 5.053414449999998, 5: 6.463952816999999, 6: 4.840839584000001, 7: 4.727411848999999, 8: 4.8222882479999996, 9: 6.915081806000003, 10: 5.65297769, 11: 4.680064082000001, 12: 4.86725799300001, 13: 5.774364697999999, 14: 5.0379951209999945, 15: 5.580923478999992, 16: 4.743620598999996, 17: 5.7115434910000005, 18: 4.785792121, 19: 4.3946602040000045, 20: 5.306675948999995, 21: 5.480167283, 22: 5.236670115999999, 23: 4.978997872999997, 24: 6.005470390999989, 25: 6.151092137000006, 26: 4.662670474999999, 27: 5.697073805999992, 28: 5.739216732999978, 29: 4.772568299, 30: 5.208352171999991, 31: 5.42110072600002, 32: 4.5429215530000135, 33: 5.185018774000014, 34: 5.4364013959999795, 35: 5.505533500000013, 36: 5.517979715999985, 37: 5.846678558999997, 38: 5.678963300999982, 39: 5.81213489999999, 40: 5.960879210999991, 41: 5.481052482999985, 42: 5.6476262390000045, 43: 4.915755877000009}
prediction_time: 0.00042284299996708796
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
