Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='355ad033-5b4d-4089-b265-26575cf71d84', conf_timestamp='2023-08-13 15:35:47.499897', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 68.34 % 	 [Task-IL]: 42.71 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 54.14 % 	 [Task-IL]: 39.1 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 43.45 % 	 [Task-IL]: 34.98 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 39.33 % 	 [Task-IL]: 33.19 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 34.94 % 	 [Task-IL]: 33.88 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 26.49 % 	 [Task-IL]: 32.66 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.62 % 	 [Task-IL]: 31.15 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 17.98 % 	 [Task-IL]: 30.4 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 17.71 % 	 [Task-IL]: 29.86 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.28 % 	 [Task-IL]: 30.07 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 22.71 % 	 [Task-IL]: 29.45 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 14.11 % 	 [Task-IL]: 29.5 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 16.49 % 	 [Task-IL]: 29.81 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 19.59 % 	 [Task-IL]: 29.43 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.14 % 	 [Task-IL]: 29.16 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 10.11 % 	 [Task-IL]: 28.44 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 11.0 % 	 [Task-IL]: 28.08 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 11.39 % 	 [Task-IL]: 27.42 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.43 % 	 [Task-IL]: 27.98 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 11.7 % 	 [Task-IL]: 27.61 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.62 % 	 [Task-IL]: 27.75 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.45 % 	 [Task-IL]: 27.92 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.74 % 	 [Task-IL]: 27.31 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.59 % 	 [Task-IL]: 27.36 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.45 % 	 [Task-IL]: 27.6 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.02 % 	 [Task-IL]: 27.55 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.58 % 	 [Task-IL]: 28.04 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.15 % 	 [Task-IL]: 27.63 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.4 % 	 [Task-IL]: 27.88 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.03 % 	 [Task-IL]: 28.14 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.22 % 	 [Task-IL]: 28.15 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.18 % 	 [Task-IL]: 28.05 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.5 % 	 [Task-IL]: 28.29 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.71 % 	 [Task-IL]: 27.78 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.74 % 	 [Task-IL]: 28.23 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.5 % 	 [Task-IL]: 27.99 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.79 % 	 [Task-IL]: 27.64 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.72 % 	 [Task-IL]: 28.2 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.98 % 	 [Task-IL]: 27.82 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.85 % 	 [Task-IL]: 28.07 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.98 % 	 [Task-IL]: 28.1 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.56 % 	 [Task-IL]: 28.08 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.5 % 	 [Task-IL]: 27.64 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({443: 28, 798: 24, 828: 24, 574: 24, 162: 24, 457: 24, 624: 23, 792: 23, 850: 23, 869: 23, 93: 23, 867: 22, 846: 22, 541: 22, 125: 22, 131: 22, 263: 22, 434: 22, 677: 21, 620: 21, 872: 21, 844: 21, 666: 21, 564: 21, 634: 21, 819: 21, 540: 21, 615: 21, 236: 21, 266: 21, 312: 21, 401: 21, 419: 21, 442: 21, 463: 21, 468: 21, 483: 21, 478: 21, 9: 20, 26: 20, 537: 20, 825: 20, 669: 20, 637: 20, 770: 20, 797: 20, 870: 20, 68: 20, 69: 20, 58: 20, 177: 20, 244: 20, 252: 20, 426: 20, 473: 20, 471: 20, 498: 20, 501: 20, 527: 20, 528: 20, 25: 19, 24: 19, 545: 19, 16: 19, 722: 19, 589: 19, 834: 19, 882: 19, 789: 19, 43: 19, 727: 19, 78: 19, 719: 19, 118: 19, 154: 19, 186: 19, 270: 19, 353: 19, 347: 19, 391: 19, 421: 19, 424: 19, 439: 19, 444: 19, 438: 19, 499: 19, 520: 19, 21: 18, 23: 18, 862: 18, 755: 18, 781: 18, 890: 18, 635: 18, 884: 18, 680: 18, 759: 18, 871: 18, 614: 18, 746: 18, 734: 18, 709: 18, 659: 18, 95: 18, 539: 18, 201: 18, 303: 18, 328: 18, 341: 18, 386: 18, 392: 18, 407: 18, 411: 18, 441: 18, 484: 18, 496: 18, 568: 17, 0: 17, 13: 17, 805: 17, 716: 17, 656: 17, 784: 17, 845: 17, 582: 17, 550: 17, 49: 17, 45: 17, 42: 17, 44: 17, 651: 17, 816: 17, 693: 17, 595: 17, 62: 17, 555: 17, 747: 17, 80: 17, 76: 17, 608: 17, 100: 17, 94: 17, 140: 17, 167: 17, 168: 17, 191: 17, 194: 17, 228: 17, 218: 17, 240: 17, 294: 17, 343: 17, 364: 17, 374: 17, 436: 17, 671: 16, 1: 16, 645: 16, 697: 16, 20: 16, 730: 16, 642: 16, 810: 16, 679: 16, 604: 16, 34: 16, 38: 16, 813: 16, 691: 16, 853: 16, 89: 16, 657: 16, 97: 16, 152: 16, 143: 16, 179: 16, 181: 16, 206: 16, 284: 16, 350: 16, 376: 16, 489: 16, 512: 16, 531: 16, 594: 15, 567: 15, 799: 15, 788: 15, 740: 15, 782: 15, 886: 15, 112: 15, 597: 15, 138: 15, 170: 15, 176: 15, 213: 15, 331: 15, 359: 15, 371: 15, 408: 15, 414: 15, 491: 15, 15: 14, 729: 14, 787: 14, 65: 14, 70: 14, 649: 14, 96: 14, 119: 14, 123: 14, 153: 14, 163: 14, 255: 14, 267: 14, 257: 14, 495: 14, 4: 13, 771: 13, 561: 13, 579: 13, 534: 13, 889: 13, 82: 13, 108: 13, 148: 13, 241: 13, 361: 13, 366: 13, 431: 13, 451: 13, 466: 13, 475: 13, 700: 12, 665: 12, 855: 12, 663: 12, 807: 12, 41: 12, 821: 12, 35: 12, 72: 12, 714: 12, 683: 12, 160: 12, 211: 12, 202: 12, 237: 12, 300: 12, 448: 12, 526: 12, 28: 11, 686: 11, 891: 11, 840: 11, 873: 11, 757: 11, 606: 11, 701: 11, 39: 11, 694: 11, 573: 11, 806: 11, 60: 11, 61: 11, 664: 11, 79: 11, 75: 11, 866: 11, 102: 11, 231: 11, 767: 11, 288: 11, 329: 11, 344: 11, 413: 11, 412: 11, 530: 11, 733: 10, 577: 10, 721: 10, 12: 10, 7: 10, 818: 10, 831: 10, 743: 10, 749: 10, 742: 10, 646: 10, 580: 10, 37: 10, 776: 10, 880: 10, 59: 10, 885: 10, 631: 10, 84: 10, 636: 10, 720: 10, 619: 10, 575: 10, 151: 10, 196: 10, 210: 10, 222: 10, 230: 10, 246: 10, 235: 10, 256: 10, 285: 10, 282: 10, 304: 10, 310: 10, 320: 10, 315: 10, 317: 10, 348: 10, 367: 10, 370: 10, 389: 10, 388: 10, 454: 10, 488: 10, 513: 10, 515: 10, 517: 10, 522: 10, 14: 9, 17: 9, 848: 9, 570: 9, 737: 9, 879: 9, 835: 9, 578: 9, 591: 9, 654: 9, 725: 9, 883: 9, 738: 9, 710: 9, 678: 9, 712: 9, 644: 9, 596: 9, 40: 9, 586: 9, 607: 9, 51: 9, 638: 9, 773: 9, 830: 9, 66: 9, 543: 9, 64: 9, 785: 9, 87: 9, 629: 9, 106: 9, 98: 9, 109: 9, 668: 9, 814: 9, 115: 9, 132: 9, 149: 9, 147: 9, 145: 9, 178: 9, 185: 9, 203: 9, 229: 9, 227: 9, 216: 9, 272: 9, 262: 9, 261: 9, 260: 9, 308: 9, 297: 9, 295: 9, 302: 9, 323: 9, 318: 9, 335: 9, 337: 9, 369: 9, 355: 9, 387: 9, 379: 9, 405: 9, 400: 9, 399: 9, 410: 9, 430: 9, 432: 9, 453: 9, 440: 9, 445: 9, 464: 9, 458: 9, 469: 9, 476: 9, 492: 9, 487: 9, 509: 9, 516: 9, 519: 9, 5: 8, 31: 8, 803: 8, 804: 8, 708: 8, 824: 8, 29: 8, 22: 8, 692: 8, 809: 8, 571: 8, 698: 8, 622: 8, 603: 8, 558: 8, 611: 8, 52: 8, 744: 8, 48: 8, 50: 8, 684: 8, 581: 8, 625: 8, 562: 8, 585: 8, 690: 8, 641: 8, 765: 8, 672: 8, 67: 8, 688: 8, 827: 8, 726: 8, 865: 8, 538: 8, 660: 8, 847: 8, 706: 8, 795: 8, 560: 8, 104: 8, 110: 8, 101: 8, 99: 8, 832: 8, 107: 8, 630: 8, 605: 8, 674: 8, 860: 8, 128: 8, 122: 8, 127: 8, 593: 8, 546: 8, 142: 8, 150: 8, 169: 8, 535: 8, 161: 8, 157: 8, 854: 8, 192: 8, 551: 8, 180: 8, 195: 8, 199: 8, 223: 8, 219: 8, 232: 8, 754: 8, 251: 8, 245: 8, 249: 8, 238: 8, 549: 8, 259: 8, 258: 8, 273: 8, 276: 8, 306: 8, 321: 8, 326: 8, 325: 8, 322: 8, 324: 8, 338: 8, 372: 8, 357: 8, 360: 8, 362: 8, 384: 8, 380: 8, 378: 8, 381: 8, 406: 8, 425: 8, 433: 8, 423: 8, 428: 8, 420: 8, 450: 8, 462: 8, 485: 8, 493: 8, 481: 8, 510: 8, 511: 8, 532: 8, 524: 8, 514: 8, 544: 8, 30: 7, 639: 7, 856: 7, 745: 7, 736: 7, 3: 7, 601: 7, 6: 7, 841: 7, 762: 7, 769: 7, 822: 7, 599: 7, 888: 7, 829: 7, 718: 7, 623: 7, 741: 7, 800: 7, 777: 7, 758: 7, 653: 7, 46: 7, 838: 7, 877: 7, 753: 7, 794: 7, 647: 7, 681: 7, 812: 7, 643: 7, 811: 7, 572: 7, 73: 7, 780: 7, 715: 7, 63: 7, 71: 7, 583: 7, 633: 7, 858: 7, 554: 7, 592: 7, 802: 7, 849: 7, 791: 7, 627: 7, 881: 7, 739: 7, 598: 7, 103: 7, 113: 7, 111: 7, 703: 7, 892: 7, 618: 7, 576: 7, 116: 7, 121: 7, 114: 7, 129: 7, 130: 7, 120: 7, 139: 7, 135: 7, 146: 7, 136: 7, 587: 7, 141: 7, 837: 7, 158: 7, 164: 7, 155: 7, 165: 7, 863: 7, 166: 7, 632: 7, 779: 7, 193: 7, 174: 7, 183: 7, 198: 7, 204: 7, 207: 7, 200: 7, 793: 7, 220: 7, 215: 7, 214: 7, 233: 7, 556: 7, 253: 7, 247: 7, 239: 7, 248: 7, 269: 7, 275: 7, 289: 7, 293: 7, 291: 7, 292: 7, 278: 7, 279: 7, 299: 7, 314: 7, 327: 7, 319: 7, 346: 7, 345: 7, 368: 7, 365: 7, 363: 7, 358: 7, 390: 7, 382: 7, 385: 7, 415: 7, 416: 7, 418: 7, 553: 7, 460: 7, 477: 7, 479: 7, 486: 7, 480: 7, 507: 7, 503: 7, 497: 7, 529: 7, 525: 7, 518: 7, 10: 6, 18: 6, 852: 6, 732: 6, 602: 6, 751: 6, 8: 6, 878: 6, 27: 6, 717: 6, 2: 6, 687: 6, 859: 6, 650: 6, 761: 6, 728: 6, 33: 6, 705: 6, 839: 6, 796: 6, 655: 6, 552: 6, 588: 6, 563: 6, 843: 6, 857: 6, 536: 6, 47: 6, 764: 6, 820: 6, 609: 6, 713: 6, 756: 6, 768: 6, 612: 6, 801: 6, 54: 6, 56: 6, 868: 6, 696: 6, 778: 6, 90: 6, 88: 6, 667: 6, 77: 6, 83: 6, 748: 6, 86: 6, 91: 6, 887: 6, 566: 6, 658: 6, 752: 6, 105: 6, 542: 6, 760: 6, 117: 6, 124: 6, 137: 6, 159: 6, 156: 6, 172: 6, 750: 6, 189: 6, 184: 6, 190: 6, 188: 6, 874: 6, 662: 6, 208: 6, 209: 6, 205: 6, 685: 6, 224: 6, 648: 6, 250: 6, 242: 6, 268: 6, 264: 6, 254: 6, 704: 6, 274: 6, 290: 6, 286: 6, 296: 6, 307: 6, 301: 6, 313: 6, 332: 6, 557: 6, 339: 6, 342: 6, 336: 6, 340: 6, 373: 6, 377: 6, 383: 6, 375: 6, 394: 6, 396: 6, 397: 6, 409: 6, 417: 6, 429: 6, 447: 6, 446: 6, 435: 6, 452: 6, 459: 6, 465: 6, 490: 6, 474: 6, 482: 6, 502: 6, 506: 6, 494: 6, 505: 6, 548: 6, 19: 5, 32: 5, 826: 5, 675: 5, 11: 5, 695: 5, 851: 5, 817: 5, 774: 5, 783: 5, 723: 5, 600: 5, 610: 5, 53: 5, 628: 5, 36: 5, 565: 5, 616: 5, 763: 5, 836: 5, 590: 5, 735: 5, 57: 5, 55: 5, 864: 5, 772: 5, 673: 5, 893: 5, 833: 5, 731: 5, 661: 5, 133: 5, 126: 5, 652: 5, 670: 5, 559: 5, 144: 5, 766: 5, 173: 5, 175: 5, 187: 5, 182: 5, 790: 5, 626: 5, 212: 5, 724: 5, 226: 5, 217: 5, 584: 5, 271: 5, 281: 5, 280: 5, 277: 5, 702: 5, 305: 5, 333: 5, 330: 5, 351: 5, 707: 5, 354: 5, 395: 5, 402: 5, 403: 5, 422: 5, 437: 5, 449: 5, 467: 5, 470: 5, 461: 5, 521: 5, 523: 5, 823: 4, 689: 4, 808: 4, 861: 4, 682: 4, 81: 4, 74: 4, 92: 4, 569: 4, 640: 4, 617: 4, 613: 4, 134: 4, 875: 4, 815: 4, 676: 4, 699: 4, 221: 4, 225: 4, 711: 4, 234: 4, 243: 4, 265: 4, 298: 4, 311: 4, 775: 4, 349: 4, 334: 4, 356: 4, 393: 4, 404: 4, 398: 4, 472: 4, 456: 4, 504: 4, 500: 4, 508: 4, 547: 4, 876: 3, 171: 3, 842: 3, 621: 3, 197: 3, 287: 3, 309: 3, 352: 3, 85: 2, 786: 2, 283: 2, 316: 2, 427: 2, 455: 2, 533: 2})
Total buffer: 8940
fit_time: 77.612362509

Accuracy for 44 task(s): 	 [Class-IL]: 71.43 % 	 [Task-IL]: 31.45 %

CLASS_IL_ACC: 
	[67.33668341708542, 82.03125, 63.1578947368421, 74.33628318584071, 75.86206896551724, 67.88990825688074, 54.12844036697248, 74.10714285714286, 79.27927927927928, 70.75471698113208, 61.224489795918366, 78.18181818181819, 78.99159663865547, 66.66666666666666, 61.0, 58.16326530612245, 69.72477064220183, 79.8076923076923, 74.31192660550458, 75.72815533980582, 60.526315789473685, 74.24242424242425, 72.32142857142857, 66.96428571428571, 70.27027027027027, 74.54545454545455, 72.17391304347827, 73.33333333333333, 74.75728155339806, 71.29629629629629, 76.19047619047619, 70.6896551724138, 62.39316239316239, 84.25925925925925, 65.0, 79.82456140350878, 62.5, 79.8076923076923, 77.58620689655173, 65.48672566371681, 68.57142857142857, 81.98198198198197, 63.24786324786324, 82.4074074074074]
TASK_IL_ACC: 
	[57.286432160804026, 30.46875, 24.561403508771928, 31.858407079646017, 37.06896551724138, 31.19266055045872, 24.770642201834864, 25.892857142857146, 35.13513513513514, 27.358490566037734, 32.6530612244898, 29.09090909090909, 29.411764705882355, 26.666666666666668, 27.0, 26.53061224489796, 16.51376146788991, 27.884615384615387, 32.11009174311927, 22.330097087378643, 28.947368421052634, 34.090909090909086, 25.0, 30.357142857142854, 38.73873873873874, 27.27272727272727, 33.04347826086956, 24.761904761904763, 33.980582524271846, 36.11111111111111, 29.523809523809526, 33.62068965517241, 33.33333333333333, 31.48148148148148, 28.000000000000004, 30.701754385964914, 25.961538461538463, 31.73076923076923, 19.82758620689655, 32.743362831858406, 34.285714285714285, 25.225225225225223, 23.931623931623932, 95.37037037037037]
f1_micro: 71.48667886922921
f1_macro: 68.6429378964212
              precision    recall  f1-score   support

           0       1.00      0.89      0.94         9
           1       0.89      0.89      0.89         9
           2       1.00      1.00      1.00         4
           3       0.00      0.00      0.00         4
           4       1.00      0.80      0.89         5
           5       0.00      0.00      0.00         4
           6       0.50      0.75      0.60         4
           7       0.38      0.60      0.46         5
           8       0.00      0.00      0.00         4
           9       1.00      1.00      1.00         9
          10       0.80      1.00      0.89         4
          11       0.80      1.00      0.89         4
          12       0.80      0.80      0.80         5
          13       1.00      0.44      0.62         9
          14       1.00      0.80      0.89         5
          15       1.00      1.00      1.00         9
          16       0.64      0.78      0.70         9
          17       1.00      1.00      1.00         4
          18       0.80      1.00      0.89         4
          19       1.00      1.00      1.00         5
          20       0.00      0.00      0.00         9
          21       1.00      1.00      1.00         9
          22       0.08      0.25      0.12         4
          23       0.78      1.00      0.88         7
          24       0.88      0.78      0.82         9
          25       0.78      0.78      0.78         9
          26       0.00      0.00      0.00         9
          27       0.67      0.50      0.57         4
          28       0.75      0.75      0.75         4
          29       0.80      1.00      0.89         4
          30       0.00      0.00      0.00         4
          31       0.00      0.00      0.00         4
          32       0.50      0.75      0.60         4
          33       0.75      0.75      0.75         4
          34       1.00      1.00      1.00         9
          35       1.00      0.78      0.88         9
          36       0.00      0.00      0.00         4
          37       1.00      1.00      1.00         5
          38       0.88      0.78      0.82         9
          39       1.00      0.80      0.89         5
          40       0.62      1.00      0.77         5
          41       1.00      1.00      1.00         9
          42       0.80      0.89      0.84         9
          43       1.00      0.67      0.80         9
          44       0.70      0.78      0.74         9
          45       0.89      0.89      0.89         9
          46       1.00      1.00      1.00         4
          47       0.25      0.25      0.25         4
          48       1.00      1.00      1.00         4
          49       0.90      1.00      0.95         9
          50       1.00      1.00      1.00         4
          51       0.44      1.00      0.62         4
          52       0.00      0.00      0.00         4
          53       1.00      1.00      1.00         4
          54       1.00      1.00      1.00         4
          55       0.00      0.00      0.00         4
          56       1.00      1.00      1.00         4
          57       0.00      0.00      0.00         4
          58       0.00      0.00      0.00         9
          59       0.75      0.60      0.67         5
          60       0.50      0.50      0.50         4
          61       1.00      1.00      1.00         5
          62       0.56      0.56      0.56         9
          63       0.67      1.00      0.80         4
          64       1.00      1.00      1.00         4
          65       0.90      1.00      0.95         9
          66       0.67      1.00      0.80         4
          67       0.00      0.00      0.00         5
          68       0.88      0.78      0.82         9
          69       0.70      0.78      0.74         9
          70       0.67      0.67      0.67         9
          71       1.00      1.00      1.00         4
          72       1.00      0.80      0.89         5
          73       0.00      0.00      0.00         4
          74       1.00      1.00      1.00         4
          75       1.00      0.80      0.89         5
          76       0.90      1.00      0.95         9
          77       0.75      0.75      0.75         4
          78       0.50      0.33      0.40         9
          79       0.67      0.80      0.73         5
          80       1.00      0.89      0.94         9
          81       1.00      1.00      1.00         4
          82       1.00      0.67      0.80         9
          83       1.00      0.50      0.67         4
          84       0.80      1.00      0.89         4
          85       1.00      0.25      0.40         4
          86       1.00      0.75      0.86         4
          87       1.00      1.00      1.00         5
          88       1.00      0.50      0.67         4
          89       1.00      1.00      1.00         9
          90       0.00      0.00      0.00         4
          91       1.00      0.75      0.86         4
          92       0.50      0.50      0.50         4
          93       0.89      0.89      0.89         9
          94       0.75      0.67      0.71         9
          95       1.00      0.56      0.71         9
          96       0.82      1.00      0.90         9
          97       0.50      0.67      0.57         9
          98       0.50      1.00      0.67         4
          99       1.00      0.50      0.67         4
         100       1.00      1.00      1.00         9
         101       1.00      0.75      0.86         4
         102       0.44      1.00      0.62         4
         103       0.80      1.00      0.89         4
         104       0.00      0.00      0.00         4
         105       0.50      0.50      0.50         4
         106       0.00      0.00      0.00         4
         107       1.00      1.00      1.00         4
         108       1.00      0.89      0.94         9
         109       0.45      1.00      0.62         5
         110       0.11      0.25      0.15         4
         111       1.00      1.00      1.00         4
         112       0.82      1.00      0.90         9
         113       0.75      0.75      0.75         4
         114       0.57      0.80      0.67         5
         115       1.00      0.80      0.89         5
         116       1.00      1.00      1.00         4
         117       1.00      1.00      1.00         4
         118       0.00      0.00      0.00         9
         119       0.89      0.89      0.89         9
         120       0.67      1.00      0.80         4
         121       0.00      0.00      0.00         4
         122       0.00      0.00      0.00         4
         123       0.86      0.67      0.75         9
         124       0.67      0.50      0.57         4
         125       1.00      1.00      1.00         9
         126       1.00      1.00      1.00         5
         127       1.00      1.00      1.00         5
         128       1.00      1.00      1.00         4
         129       1.00      1.00      1.00         4
         130       1.00      0.25      0.40         4
         131       1.00      0.33      0.50         9
         132       1.00      1.00      1.00         4
         133       0.75      0.75      0.75         4
         134       1.00      0.75      0.86         4
         135       0.00      0.00      0.00         4
         136       1.00      1.00      1.00         4
         137       0.60      0.75      0.67         4
         138       0.90      1.00      0.95         9
         139       0.00      0.00      0.00         4
         140       1.00      1.00      1.00         9
         141       1.00      0.75      0.86         4
         142       0.00      0.00      0.00         4
         143       0.00      0.00      0.00         9
         144       0.14      0.25      0.18         4
         145       0.80      1.00      0.89         4
         146       0.75      0.60      0.67         5
         147       1.00      0.75      0.86         4
         148       0.40      0.80      0.53         5
         149       1.00      1.00      1.00         5
         150       1.00      0.75      0.86         4
         151       0.50      0.20      0.29         5
         152       0.50      0.11      0.18         9
         153       0.60      0.33      0.43         9
         154       1.00      1.00      1.00         9
         155       0.00      0.00      0.00         4
         156       0.80      1.00      0.89         4
         157       1.00      0.75      0.86         4
         158       1.00      0.75      0.86         4
         159       0.50      0.75      0.60         4
         160       0.83      1.00      0.91         5
         161       1.00      0.50      0.67         4
         162       1.00      1.00      1.00         9
         163       0.00      0.00      0.00         9
         164       0.80      1.00      0.89         4
         165       0.00      0.00      0.00         4
         166       0.75      0.75      0.75         4
         167       0.67      0.89      0.76         9
         168       1.00      0.89      0.94         9
         169       0.83      1.00      0.91         5
         170       0.80      0.89      0.84         9
         171       1.00      1.00      1.00         4
         172       1.00      1.00      1.00         4
         173       0.33      0.25      0.29         4
         174       1.00      0.75      0.86         4
         175       1.00      1.00      1.00         4
         176       1.00      0.89      0.94         9
         177       1.00      0.78      0.88         9
         178       0.80      1.00      0.89         4
         179       0.82      1.00      0.90         9
         180       0.00      0.00      0.00         4
         181       0.89      0.89      0.89         9
         182       1.00      1.00      1.00         4
         183       0.80      1.00      0.89         4
         184       1.00      0.80      0.89         5
         185       0.67      0.50      0.57         4
         186       0.73      0.89      0.80         9
         187       1.00      1.00      1.00         4
         188       0.00      0.00      0.00         4
         189       1.00      1.00      1.00         4
         190       1.00      1.00      1.00         4
         191       1.00      0.56      0.71         9
         192       1.00      0.50      0.67         4
         193       1.00      1.00      1.00         4
         194       0.78      0.78      0.78         9
         195       1.00      1.00      1.00         4
         196       1.00      1.00      1.00         4
         197       0.00      0.00      0.00         4
         198       0.75      0.60      0.67         5
         199       0.33      0.50      0.40         4
         200       0.60      0.60      0.60         5
         201       0.64      0.78      0.70         9
         202       0.67      0.67      0.67         6
         203       0.67      1.00      0.80         4
         204       1.00      1.00      1.00         4
         205       1.00      0.75      0.86         4
         206       1.00      0.78      0.88         9
         207       0.12      0.25      0.17         4
         208       1.00      1.00      1.00         4
         209       0.00      0.00      0.00         4
         210       1.00      0.80      0.89         5
         211       1.00      1.00      1.00         9
         212       0.00      0.00      0.00         4
         213       1.00      1.00      1.00         5
         214       1.00      1.00      1.00         5
         215       1.00      1.00      1.00         4
         216       1.00      1.00      1.00         5
         217       1.00      0.50      0.67         4
         218       0.50      0.33      0.40         9
         219       0.83      1.00      0.91         5
         220       0.00      0.00      0.00         4
         221       0.00      0.00      0.00         4
         222       0.50      0.60      0.55         5
         223       0.50      0.75      0.60         4
         224       0.00      0.00      0.00         4
         225       0.00      0.00      0.00         4
         226       1.00      0.50      0.67         4
         227       0.50      0.20      0.29         5
         228       0.75      1.00      0.86         9
         229       0.83      1.00      0.91         5
         230       0.83      1.00      0.91         5
         231       0.67      0.80      0.73         5
         232       0.00      0.00      0.00         4
         233       1.00      1.00      1.00         4
         234       0.00      0.00      0.00         4
         235       0.80      1.00      0.89         4
         236       1.00      1.00      1.00         9
         237       0.50      1.00      0.67         5
         238       0.83      1.00      0.91         5
         239       1.00      1.00      1.00         5
         240       0.70      0.78      0.74         9
         241       1.00      0.89      0.94         9
         242       0.00      0.00      0.00         4
         243       0.00      0.00      0.00         4
         244       0.54      0.78      0.64         9
         245       0.80      0.80      0.80         5
         246       0.83      1.00      0.91         5
         247       1.00      1.00      1.00         4
         248       1.00      1.00      1.00         4
         249       1.00      0.50      0.67         4
         250       0.80      1.00      0.89         4
         251       0.80      1.00      0.89         4
         252       0.82      1.00      0.90         9
         253       0.00      0.00      0.00         4
         254       0.00      0.00      0.00         4
         255       0.88      0.78      0.82         9
         256       0.78      0.88      0.82         8
         257       0.88      0.78      0.82         9
         258       1.00      1.00      1.00         5
         259       0.71      1.00      0.83         5
         260       0.17      0.25      0.20         4
         261       1.00      1.00      1.00         4
         262       0.00      0.00      0.00         4
         263       0.89      0.89      0.89         9
         264       0.50      0.50      0.50         4
         265       1.00      1.00      1.00         4
         266       1.00      1.00      1.00         9
         267       1.00      1.00      1.00         9
         268       1.00      0.50      0.67         4
         269       1.00      1.00      1.00         5
         270       1.00      0.89      0.94         9
         271       1.00      0.50      0.67         4
         272       0.83      1.00      0.91         5
         273       1.00      0.80      0.89         5
         274       0.75      0.75      0.75         4
         275       1.00      1.00      1.00         4
         276       0.67      0.50      0.57         4
         277       0.00      0.00      0.00         4
         278       1.00      1.00      1.00         4
         279       0.67      0.50      0.57         4
         280       1.00      1.00      1.00         4
         281       1.00      1.00      1.00         4
         282       0.60      0.75      0.67         4
         283       0.00      0.00      0.00         4
         284       1.00      1.00      1.00         9
         285       0.60      0.60      0.60         5
         286       0.00      0.00      0.00         4
         287       0.00      0.00      0.00         4
         288       0.86      0.86      0.86         7
         289       1.00      1.00      1.00         4
         290       0.50      0.50      0.50         4
         291       1.00      1.00      1.00         4
         292       1.00      1.00      1.00         4
         293       0.40      0.40      0.40         5
         294       0.00      0.00      0.00         9
         295       0.50      0.50      0.50         4
         296       0.00      0.00      0.00         4
         297       1.00      0.60      0.75         5
         298       1.00      0.80      0.89         5
         299       0.67      0.80      0.73         5
         300       0.60      0.75      0.67         4
         301       0.00      0.00      0.00         4
         302       0.75      0.75      0.75         4
         303       0.60      1.00      0.75         9
         304       1.00      1.00      1.00         5
         305       0.75      0.75      0.75         4
         306       0.67      0.50      0.57         4
         307       0.80      1.00      0.89         4
         308       0.00      0.00      0.00         4
         309       0.00      0.00      0.00         4
         310       0.80      0.80      0.80         5
         311       1.00      1.00      1.00         4
         312       0.62      0.89      0.73         9
         313       0.75      0.75      0.75         4
         314       0.75      0.60      0.67         5
         315       0.57      1.00      0.73         4
         316       1.00      0.25      0.40         4
         317       0.80      1.00      0.89         4
         318       0.00      0.00      0.00         4
         319       1.00      0.80      0.89         5
         320       0.57      1.00      0.73         4
         321       1.00      0.75      0.86         4
         322       0.00      0.00      0.00         4
         323       0.25      0.25      0.25         4
         324       0.00      0.00      0.00         4
         325       1.00      0.60      0.75         5
         326       0.57      1.00      0.73         4
         327       1.00      1.00      1.00         4
         328       0.78      0.78      0.78         9
         329       0.73      0.89      0.80         9
         330       1.00      0.50      0.67         4
         331       0.00      0.00      0.00         9
         332       0.67      0.50      0.57         4
         333       0.60      0.75      0.67         4
         334       1.00      0.50      0.67         4
         335       0.60      0.75      0.67         4
         336       1.00      0.75      0.86         4
         337       0.00      0.00      0.00         4
         338       0.83      1.00      0.91         5
         339       0.00      0.00      0.00         4
         340       0.00      0.00      0.00         4
         341       0.86      0.67      0.75         9
         342       0.40      0.50      0.44         4
         343       0.75      1.00      0.86         9
         344       0.62      1.00      0.77         5
         345       0.50      1.00      0.67         4
         346       1.00      1.00      1.00         4
         347       0.82      1.00      0.90         9
         348       0.71      1.00      0.83         5
         349       0.50      0.50      0.50         4
         350       0.62      0.56      0.59         9
         351       1.00      0.80      0.89         5
         352       0.00      0.00      0.00         4
         353       1.00      0.89      0.94         9
         354       1.00      0.75      0.86         4
         355       0.50      0.50      0.50         4
         356       1.00      1.00      1.00         4
         357       0.00      0.00      0.00         4
         358       0.80      0.80      0.80         5
         359       1.00      0.89      0.94         9
         360       0.67      1.00      0.80         4
         361       1.00      1.00      1.00         8
         362       1.00      0.25      0.40         4
         363       0.67      0.40      0.50         5
         364       0.89      0.89      0.89         9
         365       1.00      1.00      1.00         4
         366       0.67      0.80      0.73         5
         367       1.00      1.00      1.00         4
         368       0.80      1.00      0.89         4
         369       1.00      1.00      1.00         4
         370       0.38      0.75      0.50         4
         371       0.80      0.89      0.84         9
         372       0.80      0.80      0.80         5
         373       0.67      0.80      0.73         5
         374       0.90      1.00      0.95         9
         375       0.00      0.00      0.00         4
         376       1.00      0.89      0.94         9
         377       1.00      1.00      1.00         4
         378       1.00      1.00      1.00         5
         379       1.00      1.00      1.00         5
         380       0.00      0.00      0.00         4
         381       0.50      0.25      0.33         4
         382       0.33      0.20      0.25         5
         383       1.00      0.75      0.86         4
         384       0.17      0.25      0.20         4
         385       0.10      0.25      0.14         4
         386       1.00      0.67      0.80         9
         387       1.00      0.75      0.86         4
         388       0.67      1.00      0.80         4
         389       1.00      1.00      1.00         5
         390       0.80      1.00      0.89         4
         391       0.80      0.89      0.84         9
         392       1.00      1.00      1.00         9
         393       1.00      1.00      1.00         4
         394       0.00      0.00      0.00         4
         395       1.00      1.00      1.00         4
         396       1.00      0.50      0.67         4
         397       0.08      0.25      0.12         4
         398       0.80      1.00      0.89         4
         399       0.50      0.25      0.33         4
         400       1.00      1.00      1.00         4
         401       1.00      0.89      0.94         9
         402       1.00      1.00      1.00         4
         403       0.50      0.75      0.60         4
         404       0.00      0.00      0.00         4
         405       0.50      0.20      0.29         5
         406       1.00      0.75      0.86         4
         407       1.00      1.00      1.00         9
         408       0.90      1.00      0.95         9
         409       0.67      1.00      0.80         4
         410       0.71      1.00      0.83         5
         411       0.90      1.00      0.95         9
         412       0.75      0.60      0.67         5
         413       0.80      1.00      0.89         4
         414       0.00      0.00      0.00         9
         415       1.00      0.80      0.89         5
         416       0.50      0.50      0.50         4
         417       1.00      0.50      0.67         4
         418       1.00      0.75      0.86         4
         419       0.89      0.89      0.89         9
         420       1.00      0.60      0.75         5
         421       1.00      0.89      0.94         9
         422       1.00      1.00      1.00         4
         423       0.75      0.75      0.75         4
         424       0.00      0.00      0.00         9
         425       0.67      1.00      0.80         4
         426       1.00      0.78      0.88         9
         427       0.00      0.00      0.00         4
         428       0.80      1.00      0.89         4
         429       0.75      0.75      0.75         4
         430       0.67      0.80      0.73         5
         431       0.83      0.56      0.67         9
         432       0.50      0.40      0.44         5
         433       1.00      0.75      0.86         4
         434       0.57      0.44      0.50         9
         435       1.00      1.00      1.00         5
         436       0.47      0.89      0.62         9
         437       0.00      0.00      0.00         4
         438       0.89      0.89      0.89         9
         439       0.82      1.00      0.90         9
         440       0.67      0.50      0.57         4
         441       0.75      1.00      0.86         9
         442       1.00      0.89      0.94         9
         443       0.00      0.00      0.00         9
         444       0.75      0.67      0.71         9
         445       0.67      1.00      0.80         4
         446       0.80      1.00      0.89         4
         447       0.60      0.60      0.60         5
         448       0.78      0.78      0.78         9
         449       1.00      1.00      1.00         4
         450       0.00      0.00      0.00         4
         451       1.00      1.00      1.00         9
         452       1.00      1.00      1.00         4
         453       0.67      1.00      0.80         4
         454       0.80      1.00      0.89         4
         455       0.00      0.00      0.00         4
         456       0.67      0.50      0.57         4
         457       1.00      0.89      0.94         9
         458       1.00      0.75      0.86         4
         459       0.00      0.00      0.00         4
         460       0.00      0.00      0.00         4
         461       1.00      0.75      0.86         4
         462       1.00      0.75      0.86         4
         463       1.00      1.00      1.00         9
         464       0.60      0.60      0.60         5
         465       0.43      0.75      0.55         4
         466       0.83      0.56      0.67         9
         467       0.67      1.00      0.80         4
         468       0.75      1.00      0.86         9
         469       1.00      0.80      0.89         5
         470       1.00      0.75      0.86         4
         471       0.67      0.89      0.76         9
         472       0.67      1.00      0.80         4
         473       0.86      0.67      0.75         9
         474       0.67      0.50      0.57         4
         475       0.86      0.67      0.75         9
         476       1.00      0.25      0.40         4
         477       1.00      1.00      1.00         4
         478       0.88      0.78      0.82         9
         479       1.00      0.80      0.89         5
         480       1.00      1.00      1.00         4
         481       1.00      0.50      0.67         4
         482       0.75      0.75      0.75         4
         483       1.00      1.00      1.00         9
         484       0.67      0.89      0.76         9
         485       0.00      0.00      0.00         4
         486       0.60      0.75      0.67         4
         487       0.00      0.00      0.00         4
         488       0.60      0.60      0.60         5
         489       0.80      0.89      0.84         9
         490       1.00      1.00      1.00         4
         491       0.57      0.44      0.50         9
         492       0.00      0.00      0.00         4
         493       0.75      0.75      0.75         4
         494       0.67      1.00      0.80         4
         495       0.89      0.89      0.89         9
         496       0.80      0.44      0.57         9
         497       0.10      0.25      0.14         4
         498       0.75      1.00      0.86         9
         499       0.88      0.78      0.82         9
         500       1.00      0.50      0.67         4
         501       0.50      0.89      0.64         9
         502       1.00      0.75      0.86         4
         503       0.00      0.00      0.00         4
         504       0.50      0.25      0.33         4
         505       0.00      0.00      0.00         4
         506       0.00      0.00      0.00         4
         507       0.67      1.00      0.80         4
         508       1.00      1.00      1.00         4
         509       1.00      1.00      1.00         4
         510       1.00      1.00      1.00         5
         511       0.80      1.00      0.89         4
         512       0.58      0.78      0.67         9
         513       0.75      0.75      0.75         4
         514       1.00      0.25      0.40         4
         515       0.10      0.50      0.16         4
         516       0.71      1.00      0.83         5
         517       1.00      0.67      0.80         9
         518       1.00      1.00      1.00         4
         519       0.57      1.00      0.73         4
         520       0.55      0.67      0.60         9
         521       0.75      0.75      0.75         4
         522       0.67      0.80      0.73         5
         523       0.25      0.25      0.25         4
         524       0.60      0.75      0.67         4
         525       1.00      1.00      1.00         5
         526       1.00      1.00      1.00         5
         527       1.00      0.89      0.94         9
         528       0.60      0.67      0.63         9
         529       0.60      0.75      0.67         4
         530       0.80      0.80      0.80         5
         531       1.00      1.00      1.00         9
         532       0.00      0.00      0.00         4
         533       0.75      0.75      0.75         4
         534       0.88      0.78      0.82         9
         535       1.00      1.00      1.00         4
         536       1.00      1.00      1.00         4
         537       0.73      0.89      0.80         9
         538       1.00      1.00      1.00         4
         539       0.69      1.00      0.82         9
         540       1.00      0.89      0.94         9
         541       0.00      0.00      0.00         9
         542       0.50      0.75      0.60         4
         543       0.80      1.00      0.89         4
         544       0.67      0.50      0.57         4
         545       1.00      0.89      0.94         9
         546       0.00      0.00      0.00         4
         547       0.00      0.00      0.00         4
         548       0.80      1.00      0.89         4
         549       0.67      1.00      0.80         4
         550       0.80      0.89      0.84         9
         551       0.80      1.00      0.89         4
         552       0.50      0.50      0.50         4
         553       0.00      0.00      0.00         4
         554       1.00      0.75      0.86         4
         555       0.75      0.67      0.71         9
         556       1.00      0.20      0.33         5
         557       1.00      1.00      1.00         4
         558       0.80      1.00      0.89         4
         559       1.00      0.75      0.86         4
         560       0.80      1.00      0.89         4
         561       1.00      0.80      0.89         5
         562       0.80      1.00      0.89         4
         563       0.00      0.00      0.00         4
         564       1.00      0.89      0.94         9
         565       0.80      1.00      0.89         4
         566       1.00      0.80      0.89         5
         567       0.78      0.78      0.78         9
         568       0.75      0.67      0.71         9
         569       0.00      0.00      0.00         4
         570       0.62      1.00      0.77         5
         571       0.33      0.40      0.36         5
         572       1.00      1.00      1.00         4
         573       0.80      1.00      0.89         4
         574       0.75      0.67      0.71         9
         575       0.80      1.00      0.89         4
         576       0.83      1.00      0.91         5
         577       0.80      1.00      0.89         4
         578       0.57      1.00      0.73         4
         579       0.00      0.00      0.00         9
         580       0.67      1.00      0.80         4
         581       0.80      1.00      0.89         4
         582       1.00      0.89      0.94         9
         583       0.67      1.00      0.80         4
         584       1.00      0.75      0.86         4
         585       0.67      1.00      0.80         4
         586       0.00      0.00      0.00         4
         587       0.75      0.75      0.75         4
         588       0.83      1.00      0.91         5
         589       0.50      0.78      0.61         9
         590       1.00      1.00      1.00         4
         591       0.00      0.00      0.00         4
         592       0.71      1.00      0.83         5
         593       1.00      0.75      0.86         4
         594       0.90      1.00      0.95         9
         595       0.80      0.89      0.84         9
         596       0.80      1.00      0.89         4
         597       0.78      0.78      0.78         9
         598       1.00      1.00      1.00         4
         599       0.00      0.00      0.00         4
         600       1.00      1.00      1.00         4
         601       1.00      0.75      0.86         4
         602       0.67      0.50      0.57         4
         603       0.60      0.75      0.67         4
         604       1.00      1.00      1.00         9
         605       0.80      1.00      0.89         4
         606       0.75      0.60      0.67         5
         607       0.29      0.40      0.33         5
         608       1.00      0.89      0.94         9
         609       0.00      0.00      0.00         4
         610       0.00      0.00      0.00         4
         611       1.00      0.75      0.86         4
         612       0.00      0.00      0.00         4
         613       1.00      0.80      0.89         5
         614       0.90      1.00      0.95         9
         615       0.78      0.78      0.78         9
         616       0.50      0.75      0.60         4
         617       0.00      0.00      0.00         4
         618       1.00      1.00      1.00         4
         619       0.07      0.25      0.11         4
         620       0.89      0.89      0.89         9
         621       1.00      0.80      0.89         5
         622       1.00      0.75      0.86         4
         623       1.00      1.00      1.00         4
         624       1.00      0.78      0.88         9
         625       0.08      0.25      0.12         4
         626       0.57      1.00      0.73         4
         627       0.80      1.00      0.89         4
         628       0.00      0.00      0.00         4
         629       1.00      0.80      0.89         5
         630       1.00      1.00      1.00         5
         631       1.00      1.00      1.00         5
         632       1.00      0.75      0.86         4
         633       0.80      0.80      0.80         5
         634       0.50      0.56      0.53         9
         635       1.00      1.00      1.00         9
         636       1.00      1.00      1.00         4
         637       1.00      0.67      0.80         9
         638       0.00      0.00      0.00         4
         639       0.75      0.60      0.67         5
         640       1.00      1.00      1.00         4
         641       0.75      0.75      0.75         4
         642       0.88      0.78      0.82         9
         643       0.50      0.50      0.50         4
         644       1.00      0.80      0.89         5
         645       0.88      0.78      0.82         9
         646       0.50      0.50      0.50         4
         647       1.00      1.00      1.00         5
         648       1.00      1.00      1.00         4
         649       0.57      0.57      0.57         7
         650       0.75      0.75      0.75         4
         651       1.00      0.67      0.80         9
         652       1.00      1.00      1.00         4
         653       0.00      0.00      0.00         4
         654       0.67      0.80      0.73         5
         655       0.00      0.00      0.00         4
         656       0.78      0.78      0.78         9
         657       0.30      0.33      0.32         9
         658       0.60      0.75      0.67         4
         659       1.00      1.00      1.00         8
         660       0.75      0.75      0.75         4
         661       0.00      0.00      0.00         4
         662       1.00      1.00      1.00         4
         663       0.73      0.89      0.80         9
         664       1.00      0.20      0.33         5
         665       1.00      1.00      1.00         4
         666       1.00      0.33      0.50         9
         667       1.00      0.80      0.89         5
         668       1.00      1.00      1.00         4
         669       1.00      1.00      1.00         9
         670       1.00      1.00      1.00         4
         671       0.00      0.00      0.00         9
         672       0.00      0.00      0.00         4
         673       0.80      1.00      0.89         4
         674       0.67      1.00      0.80         4
         675       1.00      1.00      1.00         4
         676       0.75      0.75      0.75         4
         677       0.89      0.89      0.89         9
         678       1.00      1.00      1.00         5
         679       0.82      1.00      0.90         9
         680       0.75      0.67      0.71         9
         681       1.00      1.00      1.00         4
         682       0.00      0.00      0.00         4
         683       0.80      0.80      0.80         5
         684       1.00      0.75      0.86         4
         685       0.67      0.80      0.73         5
         686       1.00      1.00      1.00         4
         687       0.57      1.00      0.73         4
         688       0.60      0.75      0.67         4
         689       1.00      0.50      0.67         4
         690       1.00      0.75      0.86         4
         691       1.00      1.00      1.00         9
         692       0.75      0.75      0.75         4
         693       0.82      1.00      0.90         9
         694       0.67      0.80      0.73         5
         695       1.00      0.75      0.86         4
         696       1.00      1.00      1.00         5
         697       0.00      0.00      0.00         9
         698       1.00      1.00      1.00         4
         699       1.00      0.75      0.86         4
         700       1.00      1.00      1.00         9
         701       1.00      1.00      1.00         4
         702       0.00      0.00      0.00         4
         703       0.80      1.00      0.89         4
         704       1.00      0.80      0.89         5
         705       0.80      1.00      0.89         4
         706       0.50      0.50      0.50         4
         707       1.00      0.60      0.75         5
         708       1.00      1.00      1.00         5
         709       0.00      0.00      0.00         9
         710       1.00      0.50      0.67         4
         711       1.00      1.00      1.00         4
         712       1.00      0.75      0.86         4
         713       0.50      0.50      0.50         4
         714       0.83      1.00      0.91         5
         715       0.00      0.00      0.00         4
         716       0.89      0.89      0.89         9
         717       0.80      1.00      0.89         4
         718       0.40      0.50      0.44         4
         719       0.90      1.00      0.95         9
         720       0.00      0.00      0.00         4
         721       0.75      0.75      0.75         4
         722       1.00      0.89      0.94         9
         723       1.00      0.75      0.86         4
         724       0.50      0.50      0.50         4
         725       0.83      1.00      0.91         5
         726       1.00      1.00      1.00         5
         727       0.90      1.00      0.95         9
         728       1.00      1.00      1.00         4
         729       0.90      1.00      0.95         9
         730       1.00      1.00      1.00         9
         731       0.00      0.00      0.00         4
         732       1.00      0.50      0.67         4
         733       0.80      0.80      0.80         5
         734       0.73      0.89      0.80         9
         735       0.00      0.00      0.00         4
         736       1.00      1.00      1.00         4
         737       1.00      1.00      1.00         4
         738       0.50      0.75      0.60         4
         739       1.00      0.75      0.86         4
         740       0.00      0.00      0.00         9
         741       0.75      0.75      0.75         4
         742       1.00      1.00      1.00         5
         743       0.60      0.60      0.60         5
         744       0.80      1.00      0.89         4
         745       0.75      0.60      0.67         5
         746       0.00      0.00      0.00         9
         747       0.90      1.00      0.95         9
         748       1.00      1.00      1.00         5
         749       1.00      1.00      1.00         4
         750       0.00      0.00      0.00         4
         751       0.00      0.00      0.00         4
         752       1.00      0.75      0.86         4
         753       1.00      1.00      1.00         4
         754       0.50      0.75      0.60         4
         755       0.78      0.78      0.78         9
         756       1.00      1.00      1.00         4
         757       0.67      0.80      0.73         5
         758       0.50      0.25      0.33         4
         759       1.00      0.89      0.94         9
         760       1.00      1.00      1.00         4
         761       1.00      1.00      1.00         4
         762       1.00      1.00      1.00         5
         763       0.00      0.00      0.00         4
         764       1.00      1.00      1.00         4
         765       1.00      0.80      0.89         5
         766       1.00      1.00      1.00         4
         767       0.75      0.75      0.75         4
         768       1.00      1.00      1.00         4
         769       0.80      1.00      0.89         4
         770       1.00      0.67      0.80         9
         771       1.00      0.78      0.88         9
         772       0.60      0.75      0.67         4
         773       0.50      0.80      0.62         5
         774       1.00      0.25      0.40         4
         775       1.00      1.00      1.00         5
         776       1.00      0.75      0.86         4
         777       1.00      0.75      0.86         4
         778       0.75      0.75      0.75         4
         779       0.67      1.00      0.80         4
         780       0.80      1.00      0.89         4
         781       1.00      0.78      0.88         9
         782       1.00      0.89      0.94         9
         783       1.00      1.00      1.00         4
         784       1.00      1.00      1.00         9
         785       0.60      0.75      0.67         4
         786       0.00      0.00      0.00         4
         787       1.00      1.00      1.00         9
         788       0.89      0.89      0.89         9
         789       0.70      0.78      0.74         9
         790       1.00      0.75      0.86         4
         791       1.00      0.75      0.86         4
         792       0.75      0.67      0.71         9
         793       0.00      0.00      0.00         4
         794       1.00      0.75      0.86         4
         795       0.00      0.00      0.00         4
         796       0.25      0.25      0.25         4
         797       0.70      0.78      0.74         9
         798       1.00      0.89      0.94         9
         799       0.89      0.89      0.89         9
         800       0.00      0.00      0.00         4
         801       0.75      0.60      0.67         5
         802       0.00      0.00      0.00         4
         803       0.00      0.00      0.00         4
         804       1.00      1.00      1.00         4
         805       0.88      0.78      0.82         9
         806       0.83      1.00      0.91         5
         807       0.60      0.60      0.60         5
         808       1.00      1.00      1.00         4
         809       0.00      0.00      0.00         4
         810       0.86      0.67      0.75         9
         811       1.00      1.00      1.00         4
         812       0.80      1.00      0.89         4
         813       0.88      0.78      0.82         9
         814       0.50      0.80      0.62         5
         815       0.00      0.00      0.00         4
         816       0.89      0.89      0.89         9
         817       1.00      0.50      0.67         4
         818       1.00      1.00      1.00         5
         819       0.64      0.78      0.70         9
         820       0.00      0.00      0.00         4
         821       0.83      1.00      0.91         5
         822       0.17      0.25      0.20         4
         823       1.00      1.00      1.00         4
         824       0.00      0.00      0.00         4
         825       0.00      0.00      0.00         9
         826       1.00      1.00      1.00         4
         827       0.75      0.75      0.75         4
         828       0.82      1.00      0.90         9
         829       0.83      1.00      0.91         5
         830       0.75      0.75      0.75         4
         831       1.00      1.00      1.00         5
         832       1.00      1.00      1.00         4
         833       1.00      0.75      0.86         4
         834       0.80      0.89      0.84         9
         835       1.00      1.00      1.00         5
         836       1.00      0.50      0.67         4
         837       0.80      1.00      0.89         4
         838       0.67      0.50      0.57         4
         839       1.00      1.00      1.00         4
         840       0.75      0.75      0.75         4
         841       0.00      0.00      0.00         4
         842       1.00      0.75      0.86         4
         843       1.00      1.00      1.00         4
         844       0.80      0.89      0.84         9
         845       1.00      0.67      0.80         9
         846       0.90      1.00      0.95         9
         847       1.00      0.75      0.86         4
         848       1.00      1.00      1.00         4
         849       0.75      0.75      0.75         4
         850       0.90      1.00      0.95         9
         851       1.00      0.25      0.40         4
         852       1.00      1.00      1.00         4
         853       0.82      1.00      0.90         9
         854       0.50      0.25      0.33         4
         855       0.33      0.11      0.17         9
         856       1.00      1.00      1.00         4
         857       1.00      0.50      0.67         4
         858       0.75      0.75      0.75         4
         859       1.00      1.00      1.00         4
         860       1.00      1.00      1.00         4
         861       1.00      0.75      0.86         4
         862       0.75      0.67      0.71         9
         863       0.09      0.25      0.13         4
         864       1.00      0.75      0.86         4
         865       1.00      0.75      0.86         4
         866       0.00      0.00      0.00         5
         867       0.58      0.78      0.67         9
         868       0.00      0.00      0.00         4
         869       0.06      0.11      0.08         9
         870       0.82      1.00      0.90         9
         871       0.82      1.00      0.90         9
         872       1.00      0.89      0.94         9
         873       1.00      1.00      1.00         5
         874       1.00      1.00      1.00         4
         875       1.00      1.00      1.00         4
         876       1.00      0.25      0.40         4
         877       0.80      1.00      0.89         4
         878       1.00      0.75      0.86         4
         879       1.00      0.80      0.89         5
         880       0.75      0.75      0.75         4
         881       1.00      1.00      1.00         4
         882       0.90      1.00      0.95         9
         883       1.00      1.00      1.00         4
         884       1.00      0.89      0.94         9
         885       1.00      1.00      1.00         5
         886       1.00      0.89      0.94         9
         887       0.00      0.00      0.00         4
         888       0.80      1.00      0.89         4
         889       0.78      0.78      0.78         9
         890       1.00      0.89      0.94         9
         891       0.80      0.80      0.80         5
         892       1.00      0.50      0.67         4
         893       0.75      0.75      0.75         4

    accuracy                           0.71      4917
   macro avg       0.71      0.69      0.69      4917
weighted avg       0.73      0.71      0.71      4917

task_train_time: {0: 0.12587652200000043, 1: 0.03768572299999917, 2: 0.0352778899999997, 3: 0.03334651899999841, 4: 0.03214612699999897, 5: 0.03137534800000097, 6: 0.028973261999999167, 7: 0.030456042999999156, 8: 0.034403138000000055, 9: 0.02992161299999907, 10: 0.025211048999999264, 11: 0.026006963000000383, 12: 0.029475142000000787, 13: 0.02138111700000067, 14: 0.02637811799999845, 15: 0.028360437999999988, 16: 0.035466221000000075, 17: 0.03223315600000021, 18: 0.032538864000001055, 19: 0.029078743999999546, 20: 0.03428760499999939, 21: 0.04264844699999948, 22: 0.033032478000000864, 23: 0.03290162000000052, 24: 0.03648837099999902, 25: 0.03473150299999972, 26: 0.03463184000000119, 27: 0.0345007319999997, 28: 0.03235000700000157, 29: 0.032781815999999964, 30: 0.0316159099999993, 31: 0.03821895399999953, 32: 0.03853044999999966, 33: 0.03210365800000048, 34: 0.03203563799999998, 35: 0.03582131799999999, 36: 0.03203222100000147, 37: 0.03125135800000223, 38: 0.03508816000000081, 39: 0.03264985000000209, 40: 0.03167870399999728, 41: 0.032690884000000864, 42: 0.03817951099999917, 43: 0.03545710499999899}
prediction_time: 0.00041670099999180366
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
