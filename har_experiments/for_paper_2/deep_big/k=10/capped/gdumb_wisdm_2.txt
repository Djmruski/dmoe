Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='e35523b4-509e-49b6-95f1-5e80e9a08e4a', conf_timestamp='2023-08-14 11:28:06.891554', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 73.22 % 	 [Task-IL]: 47.54 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 59.66 % 	 [Task-IL]: 35.89 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 46.17 % 	 [Task-IL]: 32.3 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 40.56 % 	 [Task-IL]: 28.31 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 35.83 % 	 [Task-IL]: 28.61 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 27.79 % 	 [Task-IL]: 29.36 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 28.58 % 	 [Task-IL]: 27.88 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 22.7 % 	 [Task-IL]: 26.36 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.08 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.57 % 	 [Task-IL]: 26.75 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 15.13 % 	 [Task-IL]: 26.08 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.78 % 	 [Task-IL]: 26.23 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 12.15 % 	 [Task-IL]: 26.3 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.8 % 	 [Task-IL]: 25.81 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.59 % 	 [Task-IL]: 26.04 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.53 % 	 [Task-IL]: 25.85 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.42 % 	 [Task-IL]: 25.09 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.74 % 	 [Task-IL]: 25.21 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 9.31 % 	 [Task-IL]: 25.04 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.09 % 	 [Task-IL]: 24.97 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.43 % 	 [Task-IL]: 24.88 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 9.2 % 	 [Task-IL]: 24.51 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.94 % 	 [Task-IL]: 24.61 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.28 % 	 [Task-IL]: 24.41 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.82 % 	 [Task-IL]: 24.64 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.46 % 	 [Task-IL]: 24.28 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.23 % 	 [Task-IL]: 23.88 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 8.4 % 	 [Task-IL]: 23.91 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.81 % 	 [Task-IL]: 24.22 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.47 % 	 [Task-IL]: 24.43 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 8.8 % 	 [Task-IL]: 24.15 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.06 % 	 [Task-IL]: 23.9 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 7.11 % 	 [Task-IL]: 23.74 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.62 % 	 [Task-IL]: 24.66 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.12 % 	 [Task-IL]: 24.81 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.54 % 	 [Task-IL]: 24.96 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.08 % 	 [Task-IL]: 24.56 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.64 % 	 [Task-IL]: 24.87 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.46 % 	 [Task-IL]: 24.86 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.61 % 	 [Task-IL]: 25.17 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.77 % 	 [Task-IL]: 25.04 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.13 % 	 [Task-IL]: 24.98 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.77 % 	 [Task-IL]: 24.98 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({107: 28, 489: 25, 479: 25, 795: 24, 253: 24, 520: 24, 581: 23, 148: 23, 330: 23, 317: 23, 859: 22, 51: 22, 550: 22, 293: 22, 292: 22, 304: 22, 319: 22, 777: 21, 608: 21, 863: 21, 676: 21, 89: 21, 784: 21, 119: 21, 193: 21, 183: 21, 307: 21, 469: 21, 491: 21, 504: 21, 4: 20, 747: 20, 623: 20, 702: 20, 585: 20, 823: 20, 203: 20, 227: 20, 264: 20, 272: 20, 298: 20, 325: 20, 322: 20, 442: 20, 435: 20, 471: 20, 529: 20, 625: 19, 841: 19, 622: 19, 866: 19, 821: 19, 640: 19, 806: 19, 754: 19, 61: 19, 787: 19, 117: 19, 744: 19, 172: 19, 175: 19, 191: 19, 199: 19, 299: 19, 349: 19, 385: 19, 393: 19, 480: 19, 487: 19, 521: 19, 5: 18, 27: 18, 853: 18, 570: 18, 648: 18, 567: 18, 707: 18, 598: 18, 781: 18, 818: 18, 642: 18, 41: 18, 852: 18, 834: 18, 53: 18, 534: 18, 759: 18, 750: 18, 60: 18, 65: 18, 67: 18, 83: 18, 561: 18, 735: 18, 96: 18, 121: 18, 162: 18, 159: 18, 176: 18, 192: 18, 201: 18, 211: 18, 198: 18, 223: 18, 222: 18, 266: 18, 311: 18, 308: 18, 327: 18, 346: 18, 362: 18, 388: 18, 396: 18, 410: 18, 415: 18, 430: 18, 448: 18, 446: 18, 486: 18, 493: 18, 24: 17, 0: 17, 745: 17, 624: 17, 832: 17, 609: 17, 772: 17, 749: 17, 862: 17, 726: 17, 811: 17, 92: 17, 108: 17, 133: 17, 125: 17, 128: 17, 877: 17, 213: 17, 228: 17, 256: 17, 261: 17, 288: 17, 391: 17, 389: 17, 394: 17, 405: 17, 403: 17, 419: 17, 439: 17, 503: 17, 526: 17, 548: 16, 677: 16, 751: 16, 682: 16, 647: 16, 878: 16, 605: 16, 678: 16, 612: 16, 140: 16, 182: 16, 200: 16, 250: 16, 302: 16, 306: 16, 352: 16, 371: 16, 365: 16, 374: 16, 404: 16, 422: 16, 452: 16, 457: 16, 680: 15, 539: 15, 30: 15, 669: 15, 741: 15, 736: 15, 48: 15, 46: 15, 641: 15, 543: 15, 91: 15, 84: 15, 763: 15, 94: 15, 98: 15, 110: 15, 857: 15, 848: 15, 248: 15, 242: 15, 255: 15, 305: 15, 351: 15, 373: 15, 401: 15, 417: 15, 424: 15, 444: 15, 510: 15, 496: 15, 633: 14, 2: 14, 723: 14, 826: 14, 666: 14, 594: 14, 733: 14, 820: 14, 238: 14, 359: 14, 466: 14, 527: 14, 44: 13, 752: 13, 774: 13, 127: 13, 230: 13, 268: 13, 277: 13, 294: 13, 338: 13, 367: 13, 440: 13, 458: 13, 483: 13, 484: 13, 6: 12, 839: 12, 556: 12, 675: 12, 684: 12, 694: 12, 584: 12, 547: 12, 78: 12, 540: 12, 95: 12, 130: 12, 178: 12, 220: 12, 287: 12, 326: 12, 363: 12, 375: 12, 383: 12, 691: 11, 649: 11, 864: 11, 861: 11, 840: 11, 589: 11, 845: 11, 615: 11, 568: 11, 54: 11, 101: 11, 111: 11, 132: 11, 150: 11, 245: 11, 868: 11, 246: 11, 350: 11, 344: 11, 360: 11, 382: 11, 407: 11, 416: 11, 443: 11, 462: 11, 497: 11, 517: 11, 701: 10, 23: 10, 541: 10, 727: 10, 791: 10, 835: 10, 731: 10, 814: 10, 757: 10, 715: 10, 644: 10, 776: 10, 798: 10, 724: 10, 695: 10, 773: 10, 815: 10, 703: 10, 766: 10, 667: 10, 73: 10, 55: 10, 552: 10, 616: 10, 586: 10, 729: 10, 721: 10, 579: 10, 97: 10, 689: 10, 768: 10, 802: 10, 149: 10, 160: 10, 650: 10, 185: 10, 196: 10, 208: 10, 195: 10, 194: 10, 229: 10, 257: 10, 262: 10, 290: 10, 284: 10, 296: 10, 321: 10, 316: 10, 353: 10, 341: 10, 347: 10, 427: 10, 465: 10, 470: 10, 482: 10, 514: 10, 883: 9, 15: 9, 9: 9, 32: 9, 725: 9, 10: 9, 18: 9, 7: 9, 31: 9, 33: 9, 28: 9, 670: 9, 17: 9, 590: 9, 782: 9, 693: 9, 587: 9, 732: 9, 661: 9, 789: 9, 569: 9, 673: 9, 575: 9, 535: 9, 836: 9, 45: 9, 578: 9, 881: 9, 837: 9, 686: 9, 59: 9, 537: 9, 68: 9, 603: 9, 692: 9, 817: 9, 88: 9, 80: 9, 76: 9, 746: 9, 728: 9, 572: 9, 112: 9, 803: 9, 893: 9, 631: 9, 120: 9, 833: 9, 710: 9, 891: 9, 885: 9, 651: 9, 137: 9, 145: 9, 142: 9, 151: 9, 171: 9, 166: 9, 169: 9, 187: 9, 792: 9, 844: 9, 215: 9, 218: 9, 219: 9, 247: 9, 289: 9, 283: 9, 297: 9, 310: 9, 320: 9, 329: 9, 318: 9, 331: 9, 345: 9, 348: 9, 357: 9, 387: 9, 380: 9, 411: 9, 414: 9, 436: 9, 451: 9, 449: 9, 463: 9, 456: 9, 472: 9, 485: 9, 500: 9, 502: 9, 16: 8, 3: 8, 809: 8, 582: 8, 824: 8, 21: 8, 11: 8, 657: 8, 671: 8, 635: 8, 875: 8, 573: 8, 830: 8, 688: 8, 577: 8, 708: 8, 829: 8, 611: 8, 838: 8, 799: 8, 851: 8, 655: 8, 718: 8, 740: 8, 884: 8, 619: 8, 846: 8, 697: 8, 767: 8, 808: 8, 668: 8, 49: 8, 47: 8, 36: 8, 37: 8, 34: 8, 536: 8, 35: 8, 42: 8, 600: 8, 576: 8, 665: 8, 737: 8, 716: 8, 785: 8, 66: 8, 63: 8, 630: 8, 58: 8, 871: 8, 617: 8, 867: 8, 69: 8, 653: 8, 843: 8, 742: 8, 613: 8, 734: 8, 93: 8, 77: 8, 90: 8, 627: 8, 748: 8, 870: 8, 629: 8, 557: 8, 104: 8, 654: 8, 115: 8, 558: 8, 136: 8, 860: 8, 161: 8, 155: 8, 173: 8, 163: 8, 551: 8, 720: 8, 188: 8, 190: 8, 559: 8, 206: 8, 207: 8, 712: 8, 719: 8, 233: 8, 217: 8, 800: 8, 231: 8, 555: 8, 243: 8, 241: 8, 236: 8, 270: 8, 263: 8, 282: 8, 279: 8, 278: 8, 291: 8, 276: 8, 295: 8, 300: 8, 314: 8, 355: 8, 366: 8, 372: 8, 354: 8, 409: 8, 413: 8, 408: 8, 420: 8, 418: 8, 432: 8, 450: 8, 438: 8, 441: 8, 437: 8, 434: 8, 445: 8, 454: 8, 455: 8, 492: 8, 477: 8, 481: 8, 488: 8, 513: 8, 511: 8, 494: 8, 507: 8, 531: 8, 522: 8, 659: 7, 758: 7, 704: 7, 610: 7, 637: 7, 1: 7, 765: 7, 819: 7, 714: 7, 22: 7, 593: 7, 664: 7, 690: 7, 872: 7, 639: 7, 831: 7, 544: 7, 679: 7, 713: 7, 825: 7, 779: 7, 756: 7, 705: 7, 812: 7, 645: 7, 620: 7, 755: 7, 554: 7, 599: 7, 761: 7, 604: 7, 681: 7, 753: 7, 890: 7, 804: 7, 542: 7, 70: 7, 56: 7, 62: 7, 738: 7, 75: 7, 85: 7, 876: 7, 81: 7, 775: 7, 564: 7, 618: 7, 699: 7, 796: 7, 717: 7, 879: 7, 109: 7, 102: 7, 99: 7, 103: 7, 638: 7, 652: 7, 129: 7, 114: 7, 131: 7, 770: 7, 706: 7, 118: 7, 822: 7, 147: 7, 135: 7, 146: 7, 134: 7, 141: 7, 828: 7, 873: 7, 562: 7, 165: 7, 154: 7, 813: 7, 696: 7, 602: 7, 769: 7, 810: 7, 181: 7, 184: 7, 186: 7, 797: 7, 858: 7, 212: 7, 197: 7, 214: 7, 221: 7, 234: 7, 254: 7, 273: 7, 260: 7, 309: 7, 313: 7, 324: 7, 328: 7, 334: 7, 342: 7, 337: 7, 340: 7, 343: 7, 339: 7, 364: 7, 356: 7, 377: 7, 386: 7, 384: 7, 400: 7, 426: 7, 429: 7, 428: 7, 423: 7, 464: 7, 468: 7, 490: 7, 499: 7, 509: 7, 512: 7, 533: 7, 530: 7, 516: 7, 528: 7, 524: 7, 8: 6, 12: 6, 816: 6, 29: 6, 722: 6, 672: 6, 887: 6, 711: 6, 565: 6, 545: 6, 783: 6, 643: 6, 43: 6, 621: 6, 889: 6, 888: 6, 778: 6, 52: 6, 764: 6, 743: 6, 614: 6, 592: 6, 72: 6, 57: 6, 64: 6, 807: 6, 549: 6, 771: 6, 674: 6, 79: 6, 698: 6, 87: 6, 607: 6, 538: 6, 106: 6, 113: 6, 553: 6, 663: 6, 646: 6, 786: 6, 123: 6, 662: 6, 788: 6, 139: 6, 143: 6, 869: 6, 170: 6, 158: 6, 157: 6, 739: 6, 632: 6, 174: 6, 189: 6, 179: 6, 177: 6, 596: 6, 202: 6, 205: 6, 226: 6, 237: 6, 249: 6, 235: 6, 251: 6, 240: 6, 794: 6, 265: 6, 258: 6, 259: 6, 271: 6, 267: 6, 274: 6, 285: 6, 280: 6, 760: 6, 333: 6, 323: 6, 370: 6, 361: 6, 376: 6, 378: 6, 412: 6, 399: 6, 406: 6, 421: 6, 478: 6, 474: 6, 498: 6, 505: 6, 515: 6, 519: 6, 523: 6, 518: 6, 13: 5, 19: 5, 20: 5, 14: 5, 762: 5, 571: 5, 874: 5, 805: 5, 574: 5, 882: 5, 38: 5, 50: 5, 39: 5, 685: 5, 71: 5, 801: 5, 628: 5, 583: 5, 601: 5, 892: 5, 660: 5, 580: 5, 886: 5, 855: 5, 842: 5, 124: 5, 138: 5, 152: 5, 168: 5, 156: 5, 167: 5, 597: 5, 180: 5, 827: 5, 210: 5, 209: 5, 626: 5, 225: 5, 252: 5, 239: 5, 244: 5, 281: 5, 546: 5, 275: 5, 286: 5, 301: 5, 312: 5, 591: 5, 336: 5, 358: 5, 390: 5, 381: 5, 392: 5, 397: 5, 395: 5, 402: 5, 433: 5, 425: 5, 453: 5, 473: 5, 459: 5, 461: 5, 476: 5, 501: 5, 508: 5, 506: 5, 495: 5, 532: 5, 25: 4, 687: 4, 566: 4, 40: 4, 854: 4, 847: 4, 700: 4, 849: 4, 86: 4, 683: 4, 74: 4, 850: 4, 105: 4, 100: 4, 856: 4, 606: 4, 116: 4, 122: 4, 144: 4, 153: 4, 164: 4, 595: 4, 588: 4, 790: 4, 232: 4, 224: 4, 216: 4, 269: 4, 315: 4, 332: 4, 730: 4, 368: 4, 780: 4, 379: 4, 431: 4, 447: 4, 467: 4, 26: 3, 880: 3, 636: 3, 563: 3, 793: 3, 560: 3, 865: 3, 709: 3, 658: 3, 204: 3, 303: 3, 335: 3, 460: 3, 475: 3, 525: 3, 634: 2, 82: 2, 126: 2, 656: 2, 398: 2})
Total buffer: 8940
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 10, 2: 10, 4: 10, 5: 10, 6: 10, 23: 10, 24: 10, 27: 10, 30: 10, 41: 10, 44: 10, 46: 10, 48: 10, 51: 10, 53: 10, 54: 10, 55: 10, 60: 10, 61: 10, 65: 10, 67: 10, 73: 10, 78: 10, 83: 10, 84: 10, 89: 10, 91: 10, 92: 10, 94: 10, 95: 10, 96: 10, 97: 10, 98: 10, 101: 10, 107: 10, 108: 10, 110: 10, 111: 10, 117: 10, 119: 10, 121: 10, 125: 10, 127: 10, 128: 10, 130: 10, 132: 10, 133: 10, 140: 10, 148: 10, 149: 10, 150: 10, 159: 10, 160: 10, 162: 10, 172: 10, 175: 10, 176: 10, 178: 10, 182: 10, 183: 10, 185: 10, 191: 10, 192: 10, 193: 10, 194: 10, 195: 10, 196: 10, 198: 10, 199: 10, 200: 10, 201: 10, 203: 10, 208: 10, 211: 10, 213: 10, 220: 10, 222: 10, 223: 10, 227: 10, 228: 10, 229: 10, 230: 10, 238: 10, 242: 10, 245: 10, 246: 10, 248: 10, 250: 10, 253: 10, 255: 10, 256: 10, 257: 10, 261: 10, 262: 10, 264: 10, 266: 10, 268: 10, 272: 10, 277: 10, 284: 10, 287: 10, 288: 10, 290: 10, 292: 10, 293: 10, 294: 10, 296: 10, 298: 10, 299: 10, 302: 10, 304: 10, 305: 10, 306: 10, 307: 10, 308: 10, 311: 10, 316: 10, 317: 10, 319: 10, 321: 10, 322: 10, 325: 10, 326: 10, 327: 10, 330: 10, 338: 10, 341: 10, 344: 10, 346: 10, 347: 10, 349: 10, 350: 10, 351: 10, 352: 10, 353: 10, 359: 10, 360: 10, 362: 10, 363: 10, 365: 10, 367: 10, 371: 10, 373: 10, 374: 10, 375: 10, 382: 10, 383: 10, 385: 10, 388: 10, 389: 10, 391: 10, 393: 10, 394: 10, 396: 10, 401: 10, 403: 10, 404: 10, 405: 10, 407: 10, 410: 10, 415: 10, 416: 10, 417: 10, 419: 10, 422: 10, 424: 10, 427: 10, 430: 10, 435: 10, 439: 10, 440: 10, 442: 10, 443: 10, 444: 10, 446: 10, 448: 10, 452: 10, 457: 10, 458: 10, 462: 10, 465: 10, 466: 10, 469: 10, 470: 10, 471: 10, 479: 10, 480: 10, 482: 10, 483: 10, 484: 10, 486: 10, 487: 10, 489: 10, 491: 10, 493: 10, 496: 10, 497: 10, 503: 10, 504: 10, 510: 10, 514: 10, 517: 10, 520: 10, 521: 10, 526: 10, 527: 10, 529: 10, 534: 10, 539: 10, 540: 10, 541: 10, 543: 10, 547: 10, 548: 10, 550: 10, 552: 10, 556: 10, 561: 10, 567: 10, 568: 10, 570: 10, 579: 10, 581: 10, 584: 10, 585: 10, 586: 10, 589: 10, 594: 10, 598: 10, 605: 10, 608: 10, 609: 10, 612: 10, 615: 10, 616: 10, 622: 10, 623: 10, 624: 10, 625: 10, 633: 10, 640: 10, 641: 10, 642: 10, 644: 10, 647: 10, 648: 10, 649: 10, 650: 10, 666: 10, 667: 10, 669: 10, 675: 10, 676: 10, 677: 10, 678: 10, 680: 10, 682: 10, 684: 10, 689: 10, 691: 10, 694: 10, 695: 10, 701: 10, 702: 10, 703: 10, 707: 10, 715: 10, 721: 10, 723: 10, 724: 10, 726: 10, 727: 10, 729: 10, 731: 10, 733: 10, 735: 10, 736: 10, 741: 10, 744: 10, 745: 10, 747: 10, 749: 10, 750: 10, 751: 10, 752: 10, 754: 10, 757: 10, 759: 10, 763: 10, 766: 10, 768: 10, 772: 10, 773: 10, 774: 10, 776: 10, 777: 10, 781: 10, 784: 10, 787: 10, 791: 10, 795: 10, 798: 10, 802: 10, 806: 10, 811: 10, 814: 10, 815: 10, 818: 10, 820: 10, 821: 10, 823: 10, 826: 10, 832: 10, 834: 10, 835: 10, 839: 10, 840: 10, 841: 10, 845: 10, 848: 10, 852: 10, 853: 10, 857: 10, 859: 10, 861: 10, 862: 10, 863: 10, 864: 10, 866: 10, 868: 10, 877: 10, 878: 10, 7: 9, 9: 9, 10: 9, 15: 9, 17: 9, 18: 9, 28: 9, 31: 9, 32: 9, 33: 9, 45: 9, 59: 9, 68: 9, 76: 9, 80: 9, 88: 9, 112: 9, 120: 9, 137: 9, 142: 9, 145: 9, 151: 9, 166: 9, 169: 9, 171: 9, 187: 9, 215: 9, 218: 9, 219: 9, 247: 9, 283: 9, 289: 9, 297: 9, 310: 9, 318: 9, 320: 9, 329: 9, 331: 9, 345: 9, 348: 9, 357: 9, 380: 9, 387: 9, 411: 9, 414: 9, 436: 9, 449: 9, 451: 9, 456: 9, 463: 9, 472: 9, 485: 9, 500: 9, 502: 9, 535: 9, 537: 9, 569: 9, 572: 9, 575: 9, 578: 9, 587: 9, 590: 9, 603: 9, 631: 9, 651: 9, 661: 9, 670: 9, 673: 9, 686: 9, 692: 9, 693: 9, 710: 9, 725: 9, 728: 9, 732: 9, 746: 9, 782: 9, 789: 9, 792: 9, 803: 9, 817: 9, 833: 9, 836: 9, 837: 9, 844: 9, 881: 9, 883: 9, 885: 9, 891: 9, 893: 9, 3: 8, 11: 8, 16: 8, 21: 8, 34: 8, 35: 8, 36: 8, 37: 8, 42: 8, 47: 8, 49: 8, 58: 8, 63: 8, 66: 8, 69: 8, 77: 8, 90: 8, 93: 8, 104: 8, 115: 8, 136: 8, 155: 8, 161: 8, 163: 8, 173: 8, 188: 8, 190: 8, 206: 8, 207: 8, 217: 8, 231: 8, 233: 8, 236: 8, 241: 8, 243: 8, 263: 8, 270: 8, 276: 8, 278: 8, 279: 8, 282: 8, 291: 8, 295: 8, 300: 8, 314: 8, 354: 8, 355: 8, 366: 8, 372: 8, 408: 8, 409: 8, 413: 8, 418: 8, 420: 8, 432: 8, 434: 8, 437: 8, 438: 8, 441: 8, 445: 8, 450: 8, 454: 8, 455: 8, 477: 8, 481: 8, 488: 8, 492: 8, 494: 8, 507: 8, 511: 8, 513: 8, 522: 8, 531: 8, 536: 8, 551: 8, 555: 8, 557: 8, 558: 8, 559: 8, 573: 8, 576: 8, 577: 8, 582: 8, 600: 8, 611: 8, 613: 8, 617: 8, 619: 8, 627: 8, 629: 8, 630: 8, 635: 8, 653: 8, 654: 8, 655: 8, 657: 8, 665: 8, 668: 8, 671: 8, 688: 8, 697: 8, 708: 8, 712: 8, 716: 8, 718: 8, 719: 8, 720: 8, 734: 8, 737: 8, 740: 8, 742: 8, 748: 8, 767: 8, 785: 8, 799: 8, 800: 8, 808: 8, 809: 8, 824: 8, 829: 8, 830: 8, 838: 8, 843: 8, 846: 8, 851: 8, 860: 8, 867: 8, 870: 8, 871: 8, 875: 8, 884: 8, 1: 7, 22: 7, 56: 7, 62: 7, 70: 7, 75: 7, 81: 7, 85: 7, 99: 7, 102: 7, 103: 7, 109: 7, 114: 7, 118: 7, 129: 7, 131: 7, 134: 7, 135: 7, 141: 7, 146: 7, 147: 7, 154: 7, 165: 7, 181: 7, 184: 7, 186: 7, 197: 7, 212: 7, 214: 7, 221: 7, 234: 7, 254: 7, 260: 7, 273: 7, 309: 7, 313: 7, 324: 7, 328: 7, 334: 7, 337: 7, 339: 7, 340: 7, 342: 7, 343: 7, 356: 7, 364: 7, 377: 7, 384: 7, 386: 7, 400: 7, 423: 7, 426: 7, 428: 7, 429: 7, 464: 7, 468: 7, 490: 7, 499: 7, 509: 7, 512: 7, 516: 7, 524: 7, 528: 7, 530: 7, 533: 7, 542: 7, 544: 7, 554: 7, 562: 7, 564: 7, 593: 7, 599: 7, 602: 7, 604: 7, 610: 7, 618: 7, 620: 7, 637: 7, 638: 7, 639: 7, 645: 7, 652: 7, 659: 7, 664: 7, 679: 7, 681: 7, 690: 7, 696: 7, 699: 7, 704: 7, 705: 7, 706: 7, 713: 7, 714: 7, 717: 7, 738: 7, 753: 7, 755: 7, 756: 7, 758: 7, 761: 7, 765: 7, 769: 7, 770: 7, 775: 7, 779: 7, 796: 7, 797: 7, 804: 7, 810: 7, 812: 7, 813: 7, 819: 7, 822: 7, 825: 7, 828: 7, 831: 7, 858: 7, 872: 7, 873: 7, 876: 7, 879: 7, 890: 7, 8: 6, 12: 6, 29: 6, 43: 6, 52: 6, 57: 6, 64: 6, 72: 6, 79: 6, 87: 6, 106: 6, 113: 6, 123: 6, 139: 6, 143: 6, 157: 6, 158: 6, 170: 6, 174: 6, 177: 6, 179: 6, 189: 6, 202: 6, 205: 6, 226: 6, 235: 6, 237: 6, 240: 6, 249: 6, 251: 6, 258: 6, 259: 6, 265: 6, 267: 6, 271: 6, 274: 6, 280: 6, 285: 6, 323: 6, 333: 6, 361: 6, 370: 6, 376: 6, 378: 6, 399: 6, 406: 6, 412: 6, 421: 6, 474: 6, 478: 6, 498: 6, 505: 6, 515: 6, 518: 6, 519: 6, 523: 6, 538: 6, 545: 6, 549: 6, 553: 6, 565: 6, 592: 6, 596: 6, 607: 6, 614: 6, 621: 6, 632: 6, 643: 6, 646: 6, 662: 6, 663: 6, 672: 6, 674: 6, 698: 6, 711: 6, 722: 6, 739: 6, 743: 6, 760: 6, 764: 6, 771: 6, 778: 6, 783: 6, 786: 6, 788: 6, 794: 6, 807: 6, 816: 6, 869: 6, 887: 6, 888: 6, 889: 6, 13: 5, 14: 5, 19: 5, 20: 5, 38: 5, 39: 5, 50: 5, 71: 5, 124: 5, 138: 5, 152: 5, 156: 5, 167: 5, 168: 5, 180: 5, 209: 5, 210: 5, 225: 5, 239: 5, 244: 5, 252: 5, 275: 5, 281: 5, 286: 5, 301: 5, 312: 5, 336: 5, 358: 5, 381: 5, 390: 5, 392: 5, 395: 5, 397: 5, 402: 5, 425: 5, 433: 5, 453: 5, 459: 5, 461: 5, 473: 5, 476: 5, 495: 5, 501: 5, 506: 5, 508: 5, 532: 5, 546: 5, 571: 5, 574: 5, 580: 5, 583: 5, 591: 5, 597: 5, 601: 5, 626: 5, 628: 5, 660: 5, 685: 5, 762: 5, 801: 5, 805: 5, 827: 5, 842: 5, 855: 5, 874: 5, 882: 5, 886: 5, 892: 5, 25: 4, 40: 4, 74: 4, 86: 4, 100: 4, 105: 4, 116: 4, 122: 4, 144: 4, 153: 4, 164: 4, 216: 4, 224: 4, 232: 4, 269: 4, 315: 4, 332: 4, 368: 4, 379: 4, 431: 4, 447: 4, 467: 4, 566: 4, 588: 4, 595: 4, 606: 4, 683: 4, 687: 4, 700: 4, 730: 4, 780: 4, 790: 4, 847: 4, 849: 4, 850: 4, 854: 4, 856: 4, 26: 3, 204: 3, 303: 3, 335: 3, 460: 3, 475: 3, 525: 3, 560: 3, 563: 3, 636: 3, 658: 3, 709: 3, 793: 3, 865: 3, 880: 3, 82: 2, 126: 2, 398: 2, 634: 2, 656: 2})
Total buffer: 7134
fit_time: 59.696884556

Accuracy for 44 task(s): 	 [Class-IL]: 70.08 % 	 [Task-IL]: 28.86 %

CLASS_IL_ACC: 
	[71.58469945355192, 71.29629629629629, 75.96153846153845, 60.18518518518518, 74.56140350877193, 52.10084033613446, 64.94845360824742, 67.0103092783505, 80.83333333333333, 68.64406779661016, 73.39449541284404, 69.56521739130434, 76.22950819672131, 75.23809523809524, 71.42857142857143, 68.10344827586206, 74.54545454545455, 62.06896551724138, 63.02521008403361, 69.82758620689656, 66.3716814159292, 71.31147540983606, 71.02803738317756, 79.52755905511812, 82.52427184466019, 72.89719626168224, 75.22123893805309, 68.04123711340206, 62.0, 66.66666666666666, 63.55140186915887, 66.36363636363637, 71.27659574468085, 69.2982456140351, 59.183673469387756, 70.0, 83.33333333333334, 73.58490566037736, 67.28971962616822, 73.46938775510205, 74.33628318584071, 65.74074074074075, 75.65217391304347, 64.51612903225806]
TASK_IL_ACC: 
	[57.377049180327866, 23.14814814814815, 24.03846153846154, 18.51851851851852, 32.45614035087719, 28.57142857142857, 24.742268041237114, 30.927835051546392, 30.0, 27.966101694915253, 22.018348623853214, 20.869565217391305, 31.147540983606557, 27.61904761904762, 25.396825396825395, 29.310344827586203, 24.545454545454547, 21.551724137931032, 27.73109243697479, 23.275862068965516, 28.31858407079646, 27.86885245901639, 27.102803738317753, 19.68503937007874, 28.155339805825243, 23.364485981308412, 29.20353982300885, 25.773195876288657, 30.0, 27.927927927927925, 22.429906542056074, 21.818181818181817, 27.659574468085108, 35.96491228070175, 29.591836734693878, 26.0, 25.757575757575758, 33.0188679245283, 28.037383177570092, 29.591836734693878, 28.31858407079646, 24.074074074074073, 29.565217391304348, 89.24731182795699]
f1_micro: 70.24608501118567
f1_macro: 67.30350206330426
              precision    recall  f1-score   support

           0       0.44      0.44      0.44         9
           1       1.00      0.75      0.86         4
           2       0.78      0.78      0.78         9
           3       0.40      0.50      0.44         4
           4       0.42      0.56      0.48         9
           5       1.00      0.89      0.94         9
           6       0.88      0.78      0.82         9
           7       0.38      0.75      0.50         4
           8       1.00      0.50      0.67         4
           9       1.00      1.00      1.00         4
          10       0.83      1.00      0.91         5
          11       1.00      0.50      0.67         4
          12       0.12      0.25      0.17         4
          13       1.00      0.50      0.67         4
          14       0.71      1.00      0.83         5
          15       0.71      1.00      0.83         5
          16       0.67      0.40      0.50         5
          17       0.00      0.00      0.00         4
          18       1.00      1.00      1.00         4
          19       0.20      0.25      0.22         4
          20       1.00      1.00      1.00         5
          21       1.00      1.00      1.00         4
          22       0.80      1.00      0.89         4
          23       1.00      0.75      0.86         4
          24       0.78      0.78      0.78         9
          25       0.50      0.60      0.55         5
          26       0.67      1.00      0.80         4
          27       0.89      0.89      0.89         9
          28       0.67      1.00      0.80         4
          29       0.80      1.00      0.89         4
          30       1.00      0.56      0.71         9
          31       1.00      0.75      0.86         4
          32       0.67      0.80      0.73         5
          33       1.00      0.25      0.40         4
          34       0.67      1.00      0.80         4
          35       0.67      0.50      0.57         4
          36       0.67      0.50      0.57         4
          37       0.83      1.00      0.91         5
          38       0.67      1.00      0.80         4
          39       1.00      1.00      1.00         4
          40       0.67      1.00      0.80         4
          41       1.00      0.89      0.94         9
          42       0.80      1.00      0.89         4
          43       0.75      0.75      0.75         4
          44       1.00      0.78      0.88         9
          45       0.50      0.50      0.50         4
          46       0.00      0.00      0.00         9
          47       0.00      0.00      0.00         4
          48       0.56      1.00      0.71         5
          49       0.80      1.00      0.89         4
          50       0.00      0.00      0.00         4
          51       0.89      0.89      0.89         9
          52       1.00      0.80      0.89         5
          53       1.00      0.78      0.88         9
          54       0.50      0.25      0.33         4
          55       0.00      0.00      0.00         4
          56       1.00      1.00      1.00         4
          57       0.80      0.80      0.80         5
          58       0.75      0.75      0.75         4
          59       0.80      0.80      0.80         5
          60       1.00      0.89      0.94         9
          61       0.90      1.00      0.95         9
          62       0.80      1.00      0.89         4
          63       0.75      0.75      0.75         4
          64       1.00      0.50      0.67         4
          65       0.67      0.89      0.76         9
          66       0.20      0.75      0.32         4
          67       0.89      0.89      0.89         9
          68       1.00      0.60      0.75         5
          69       0.67      0.80      0.73         5
          70       1.00      0.50      0.67         4
          71       1.00      0.75      0.86         4
          72       0.67      0.50      0.57         4
          73       0.57      1.00      0.73         4
          74       0.00      0.00      0.00         4
          75       1.00      0.75      0.86         4
          76       0.80      1.00      0.89         4
          77       0.40      1.00      0.57         4
          78       0.83      1.00      0.91         5
          79       0.33      0.50      0.40         4
          80       1.00      0.60      0.75         5
          81       1.00      1.00      1.00         4
          82       1.00      0.25      0.40         4
          83       0.86      0.67      0.75         9
          84       0.08      0.11      0.09         9
          85       0.60      0.75      0.67         4
          86       1.00      0.50      0.67         4
          87       0.25      0.25      0.25         4
          88       0.67      1.00      0.80         4
          89       0.86      0.67      0.75         9
          90       0.80      0.80      0.80         5
          91       0.07      0.11      0.08         9
          92       1.00      0.89      0.94         9
          93       0.75      0.75      0.75         4
          94       0.90      1.00      0.95         9
          95       1.00      0.75      0.86         4
          96       0.82      1.00      0.90         9
          97       0.50      0.50      0.50         4
          98       1.00      1.00      1.00         9
          99       1.00      0.75      0.86         4
         100       0.75      0.75      0.75         4
         101       0.67      0.29      0.40         7
         102       1.00      1.00      1.00         4
         103       0.75      0.75      0.75         4
         104       1.00      0.75      0.86         4
         105       0.40      0.50      0.44         4
         106       0.00      0.00      0.00         4
         107       0.88      0.78      0.82         9
         108       0.45      0.56      0.50         9
         109       0.50      0.60      0.55         5
         110       0.62      1.00      0.76         8
         111       1.00      1.00      1.00         4
         112       1.00      0.40      0.57         5
         113       0.80      1.00      0.89         4
         114       1.00      0.80      0.89         5
         115       0.00      0.00      0.00         4
         116       1.00      0.60      0.75         5
         117       0.75      0.67      0.71         9
         118       1.00      0.75      0.86         4
         119       0.80      0.89      0.84         9
         120       0.07      0.25      0.11         4
         121       0.00      0.00      0.00         9
         122       1.00      1.00      1.00         4
         123       0.50      0.50      0.50         4
         124       0.00      0.00      0.00         4
         125       0.25      0.11      0.15         9
         126       1.00      0.25      0.40         4
         127       0.89      0.89      0.89         9
         128       0.86      0.67      0.75         9
         129       0.00      0.00      0.00         4
         130       0.67      0.80      0.73         5
         131       0.00      0.00      0.00         4
         132       1.00      0.80      0.89         5
         133       1.00      0.78      0.88         9
         134       0.80      1.00      0.89         4
         135       0.75      0.60      0.67         5
         136       0.67      1.00      0.80         4
         137       1.00      1.00      1.00         4
         138       0.50      0.25      0.33         4
         139       0.60      0.75      0.67         4
         140       0.67      0.44      0.53         9
         141       1.00      0.75      0.86         4
         142       1.00      1.00      1.00         4
         143       1.00      1.00      1.00         5
         144       1.00      0.20      0.33         5
         145       0.83      1.00      0.91         5
         146       0.50      0.50      0.50         4
         147       1.00      0.75      0.86         4
         148       0.00      0.00      0.00         9
         149       1.00      1.00      1.00         5
         150       1.00      1.00      1.00         5
         151       0.75      0.60      0.67         5
         152       0.00      0.00      0.00         4
         153       0.80      1.00      0.89         4
         154       0.75      0.75      0.75         4
         155       0.83      1.00      0.91         5
         156       0.00      0.00      0.00         4
         157       1.00      1.00      1.00         4
         158       1.00      0.75      0.86         4
         159       1.00      0.78      0.88         9
         160       0.00      0.00      0.00         4
         161       0.50      1.00      0.67         4
         162       0.89      0.89      0.89         9
         163       0.80      1.00      0.89         4
         164       0.00      0.00      0.00         4
         165       0.80      1.00      0.89         4
         166       0.75      0.75      0.75         4
         167       0.80      1.00      0.89         4
         168       1.00      0.50      0.67         4
         169       0.75      0.75      0.75         4
         170       0.40      0.50      0.44         4
         171       0.67      0.80      0.73         5
         172       0.50      0.33      0.40         9
         173       1.00      0.50      0.67         4
         174       1.00      1.00      1.00         4
         175       1.00      0.89      0.94         9
         176       1.00      0.89      0.94         9
         177       1.00      1.00      1.00         4
         178       1.00      1.00      1.00         5
         179       0.83      1.00      0.91         5
         180       1.00      0.75      0.86         4
         181       0.83      1.00      0.91         5
         182       1.00      0.44      0.62         9
         183       0.71      0.56      0.63         9
         184       0.83      1.00      0.91         5
         185       1.00      1.00      1.00         4
         186       0.67      1.00      0.80         4
         187       0.60      0.60      0.60         5
         188       1.00      0.75      0.86         4
         189       0.67      0.50      0.57         4
         190       1.00      0.75      0.86         4
         191       1.00      1.00      1.00         9
         192       0.83      0.56      0.67         9
         193       0.89      0.89      0.89         9
         194       1.00      1.00      1.00         5
         195       0.80      1.00      0.89         4
         196       1.00      0.75      0.86         4
         197       0.80      1.00      0.89         4
         198       0.00      0.00      0.00         9
         199       0.88      0.78      0.82         9
         200       0.78      0.78      0.78         9
         201       0.80      0.89      0.84         9
         202       0.00      0.00      0.00         4
         203       1.00      0.78      0.88         9
         204       1.00      1.00      1.00         4
         205       0.00      0.00      0.00         4
         206       1.00      0.75      0.86         4
         207       1.00      0.75      0.86         4
         208       1.00      0.80      0.89         5
         209       1.00      0.50      0.67         4
         210       0.71      1.00      0.83         5
         211       1.00      1.00      1.00         9
         212       0.00      0.00      0.00         4
         213       0.60      0.67      0.63         9
         214       0.80      1.00      0.89         4
         215       0.57      1.00      0.73         4
         216       0.67      0.50      0.57         4
         217       0.75      0.75      0.75         4
         218       0.67      0.50      0.57         4
         219       1.00      1.00      1.00         4
         220       0.67      0.89      0.76         9
         221       1.00      0.80      0.89         5
         222       1.00      1.00      1.00         9
         223       0.83      0.56      0.67         9
         224       0.50      0.25      0.33         4
         225       1.00      0.25      0.40         4
         226       0.60      0.60      0.60         5
         227       0.89      0.89      0.89         9
         228       1.00      1.00      1.00         9
         229       0.67      0.80      0.73         5
         230       0.75      0.60      0.67         5
         231       0.80      1.00      0.89         4
         232       0.00      0.00      0.00         4
         233       0.33      0.50      0.40         4
         234       0.00      0.00      0.00         4
         235       1.00      1.00      1.00         4
         236       1.00      1.00      1.00         5
         237       0.75      0.75      0.75         4
         238       1.00      0.56      0.71         9
         239       0.67      0.50      0.57         4
         240       0.00      0.00      0.00         4
         241       0.67      0.40      0.50         5
         242       1.00      0.89      0.94         9
         243       0.67      0.80      0.73         5
         244       1.00      1.00      1.00         4
         245       0.67      1.00      0.80         4
         246       1.00      1.00      1.00         9
         247       1.00      0.75      0.86         4
         248       1.00      0.89      0.94         9
         249       1.00      1.00      1.00         5
         250       0.90      1.00      0.95         9
         251       1.00      0.50      0.67         4
         252       0.75      0.60      0.67         5
         253       0.00      0.00      0.00         9
         254       0.50      0.25      0.33         4
         255       1.00      1.00      1.00         9
         256       0.90      1.00      0.95         9
         257       1.00      1.00      1.00         9
         258       1.00      0.75      0.86         4
         259       1.00      1.00      1.00         5
         260       1.00      1.00      1.00         5
         261       0.89      0.89      0.89         9
         262       0.00      0.00      0.00         4
         263       0.50      0.20      0.29         5
         264       0.80      0.44      0.57         9
         265       0.80      1.00      0.89         4
         266       0.75      1.00      0.86         9
         267       0.00      0.00      0.00         4
         268       0.78      1.00      0.88         7
         269       0.67      0.50      0.57         4
         270       1.00      1.00      1.00         4
         271       1.00      0.75      0.86         4
         272       1.00      0.67      0.80         9
         273       0.67      0.80      0.73         5
         274       0.33      0.50      0.40         4
         275       0.00      0.00      0.00         4
         276       0.40      0.40      0.40         5
         277       0.82      1.00      0.90         9
         278       1.00      1.00      1.00         4
         279       0.43      0.60      0.50         5
         280       1.00      0.75      0.86         4
         281       1.00      1.00      1.00         4
         282       0.00      0.00      0.00         4
         283       1.00      1.00      1.00         5
         284       1.00      1.00      1.00         4
         285       1.00      1.00      1.00         4
         286       1.00      0.50      0.67         4
         287       0.44      0.80      0.57         5
         288       0.75      1.00      0.86         9
         289       1.00      0.75      0.86         4
         290       0.33      0.50      0.40         4
         291       1.00      0.80      0.89         5
         292       1.00      0.67      0.80         9
         293       0.82      1.00      0.90         9
         294       0.50      1.00      0.67         4
         295       1.00      1.00      1.00         4
         296       0.00      0.00      0.00         4
         297       0.43      0.75      0.55         4
         298       0.00      0.00      0.00         9
         299       1.00      0.67      0.80         9
         300       0.75      0.75      0.75         4
         301       0.80      1.00      0.89         4
         302       0.90      1.00      0.95         9
         303       0.75      0.75      0.75         4
         304       1.00      0.67      0.80         9
         305       0.80      0.89      0.84         9
         306       0.89      0.89      0.89         9
         307       1.00      0.78      0.88         9
         308       1.00      0.78      0.88         9
         309       0.40      0.50      0.44         4
         310       0.60      0.75      0.67         4
         311       1.00      0.67      0.80         9
         312       0.75      0.75      0.75         4
         313       0.50      0.80      0.62         5
         314       0.60      0.75      0.67         4
         315       0.33      0.20      0.25         5
         316       1.00      1.00      1.00         5
         317       1.00      0.89      0.94         9
         318       1.00      0.50      0.67         4
         319       0.73      0.89      0.80         9
         320       0.50      0.50      0.50         4
         321       1.00      1.00      1.00         4
         322       0.50      0.44      0.47         9
         323       1.00      1.00      1.00         4
         324       1.00      1.00      1.00         5
         325       0.00      0.00      0.00         9
         326       0.67      0.80      0.73         5
         327       1.00      1.00      1.00         9
         328       1.00      1.00      1.00         5
         329       1.00      0.80      0.89         5
         330       0.50      0.22      0.31         9
         331       0.50      0.50      0.50         4
         332       1.00      0.75      0.86         4
         333       1.00      1.00      1.00         4
         334       1.00      0.20      0.33         5
         335       1.00      0.25      0.40         4
         336       0.83      1.00      0.91         5
         337       0.80      1.00      0.89         4
         338       0.50      0.20      0.29         5
         339       1.00      0.50      0.67         4
         340       0.00      0.00      0.00         4
         341       0.00      0.00      0.00         4
         342       0.33      1.00      0.50         4
         343       0.83      1.00      0.91         5
         344       0.90      1.00      0.95         9
         345       0.57      1.00      0.73         4
         346       0.70      0.78      0.74         9
         347       0.50      0.75      0.60         4
         348       1.00      1.00      1.00         4
         349       0.75      1.00      0.86         9
         350       0.25      0.40      0.31         5
         351       0.80      0.89      0.84         9
         352       0.90      1.00      0.95         9
         353       0.67      1.00      0.80         4
         354       0.75      0.75      0.75         4
         355       0.80      1.00      0.89         4
         356       0.00      0.00      0.00         4
         357       0.00      0.00      0.00         4
         358       0.00      0.00      0.00         4
         359       1.00      0.60      0.75         5
         360       0.00      0.00      0.00         9
         361       0.75      0.75      0.75         4
         362       0.78      0.78      0.78         9
         363       1.00      0.78      0.88         9
         364       0.80      1.00      0.89         4
         365       0.78      0.78      0.78         9
         366       1.00      1.00      1.00         4
         367       1.00      1.00      1.00         9
         368       0.67      0.50      0.57         4
         369       0.00      0.00      0.00         4
         370       1.00      0.75      0.86         4
         371       0.78      0.78      0.78         9
         372       0.50      0.25      0.33         4
         373       0.80      0.89      0.84         9
         374       0.88      0.78      0.82         9
         375       1.00      1.00      1.00         9
         376       0.43      0.75      0.55         4
         377       0.75      0.75      0.75         4
         378       1.00      0.75      0.86         4
         379       1.00      0.50      0.67         4
         380       1.00      1.00      1.00         4
         381       0.80      1.00      0.89         4
         382       0.00      0.00      0.00         9
         383       0.11      0.50      0.18         4
         384       0.50      0.50      0.50         4
         385       0.83      0.56      0.67         9
         386       0.75      0.60      0.67         5
         387       0.14      0.25      0.18         4
         388       0.69      1.00      0.82         9
         389       0.00      0.00      0.00         9
         390       0.00      0.00      0.00         4
         391       0.83      0.71      0.77         7
         392       0.80      1.00      0.89         4
         393       1.00      1.00      1.00         9
         394       0.00      0.00      0.00         9
         395       1.00      0.75      0.86         4
         396       0.82      1.00      0.90         9
         397       0.67      0.50      0.57         4
         398       1.00      1.00      1.00         4
         399       0.80      1.00      0.89         4
         400       0.00      0.00      0.00         4
         401       1.00      0.67      0.80         9
         402       0.80      1.00      0.89         4
         403       0.89      0.89      0.89         9
         404       0.78      0.78      0.78         9
         405       1.00      1.00      1.00         9
         406       1.00      0.25      0.40         4
         407       0.80      0.80      0.80         5
         408       1.00      1.00      1.00         4
         409       0.80      1.00      0.89         4
         410       0.89      0.89      0.89         9
         411       0.33      0.25      0.29         4
         412       1.00      0.75      0.86         4
         413       0.00      0.00      0.00         4
         414       0.00      0.00      0.00         4
         415       1.00      0.56      0.71         9
         416       0.40      0.40      0.40         5
         417       0.89      0.89      0.89         9
         418       0.00      0.00      0.00         4
         419       1.00      0.56      0.71         9
         420       1.00      0.75      0.86         4
         421       1.00      0.25      0.40         4
         422       0.89      0.89      0.89         9
         423       1.00      0.80      0.89         5
         424       0.89      0.89      0.89         9
         425       1.00      1.00      1.00         4
         426       1.00      0.75      0.86         4
         427       1.00      0.25      0.40         4
         428       0.75      0.60      0.67         5
         429       1.00      1.00      1.00         4
         430       1.00      1.00      1.00         9
         431       0.75      0.75      0.75         4
         432       0.60      0.75      0.67         4
         433       1.00      0.25      0.40         4
         434       0.57      0.80      0.67         5
         435       0.75      1.00      0.86         9
         436       0.57      1.00      0.73         4
         437       0.67      1.00      0.80         4
         438       0.60      0.75      0.67         4
         439       0.00      0.00      0.00         9
         440       1.00      1.00      1.00         9
         441       1.00      1.00      1.00         4
         442       0.58      0.78      0.67         9
         443       0.83      1.00      0.91         5
         444       0.75      1.00      0.86         9
         445       0.67      1.00      0.80         4
         446       0.89      0.89      0.89         9
         447       0.75      0.75      0.75         4
         448       0.00      0.00      0.00         9
         449       0.33      0.25      0.29         4
         450       0.80      1.00      0.89         4
         451       0.80      1.00      0.89         4
         452       0.10      0.11      0.11         9
         453       1.00      1.00      1.00         4
         454       0.50      0.25      0.33         4
         455       0.00      0.00      0.00         4
         456       0.33      0.50      0.40         4
         457       0.73      0.89      0.80         9
         458       1.00      0.89      0.94         9
         459       0.60      0.75      0.67         4
         460       0.75      0.75      0.75         4
         461       0.00      0.00      0.00         4
         462       1.00      1.00      1.00         4
         463       1.00      1.00      1.00         4
         464       0.00      0.00      0.00         4
         465       1.00      1.00      1.00         5
         466       1.00      0.89      0.94         9
         467       0.00      0.00      0.00         4
         468       0.67      1.00      0.80         4
         469       1.00      1.00      1.00         9
         470       0.67      0.40      0.50         5
         471       0.78      0.78      0.78         9
         472       1.00      1.00      1.00         4
         473       0.80      1.00      0.89         4
         474       1.00      1.00      1.00         5
         475       0.50      0.25      0.33         4
         476       0.00      0.00      0.00         4
         477       0.67      0.50      0.57         4
         478       0.75      0.75      0.75         4
         479       1.00      1.00      1.00         9
         480       0.64      0.78      0.70         9
         481       0.50      0.50      0.50         4
         482       1.00      1.00      1.00         4
         483       1.00      0.67      0.80         9
         484       1.00      0.89      0.94         9
         485       1.00      1.00      1.00         5
         486       0.82      1.00      0.90         9
         487       0.67      0.89      0.76         9
         488       1.00      0.50      0.67         4
         489       1.00      0.89      0.94         9
         490       1.00      0.75      0.86         4
         491       1.00      1.00      1.00         9
         492       0.67      1.00      0.80         4
         493       0.67      0.67      0.67         9
         494       0.38      0.75      0.50         4
         495       1.00      0.75      0.86         4
         496       0.67      0.67      0.67         9
         497       1.00      1.00      1.00         4
         498       1.00      1.00      1.00         4
         499       1.00      0.75      0.86         4
         500       1.00      1.00      1.00         4
         501       1.00      1.00      1.00         5
         502       0.80      1.00      0.89         4
         503       0.62      0.89      0.73         9
         504       1.00      1.00      1.00         9
         505       0.00      0.00      0.00         4
         506       0.80      1.00      0.89         4
         507       0.67      1.00      0.80         4
         508       1.00      1.00      1.00         4
         509       0.08      0.25      0.12         4
         510       0.70      0.78      0.74         9
         511       0.71      1.00      0.83         5
         512       0.67      0.50      0.57         4
         513       0.83      1.00      0.91         5
         514       1.00      0.80      0.89         5
         515       1.00      1.00      1.00         4
         516       0.50      0.75      0.60         4
         517       0.00      0.00      0.00         4
         518       1.00      1.00      1.00         4
         519       1.00      1.00      1.00         4
         520       0.89      0.89      0.89         9
         521       0.82      1.00      0.90         9
         522       0.75      0.75      0.75         4
         523       0.00      0.00      0.00         4
         524       1.00      1.00      1.00         5
         525       0.80      1.00      0.89         4
         526       0.80      0.89      0.84         9
         527       0.64      0.78      0.70         9
         528       1.00      1.00      1.00         4
         529       1.00      0.56      0.71         9
         530       0.00      0.00      0.00         4
         531       0.67      0.50      0.57         4
         532       0.67      1.00      0.80         4
         533       0.00      0.00      0.00         4
         534       0.86      0.67      0.75         9
         535       1.00      1.00      1.00         4
         536       1.00      1.00      1.00         4
         537       1.00      0.40      0.57         5
         538       0.60      0.60      0.60         5
         539       0.73      0.89      0.80         9
         540       0.60      0.67      0.63         9
         541       0.83      1.00      0.91         5
         542       0.67      1.00      0.80         4
         543       0.90      1.00      0.95         9
         544       0.80      1.00      0.89         4
         545       0.00      0.00      0.00         4
         546       0.00      0.00      0.00         4
         547       1.00      1.00      1.00         4
         548       0.71      0.56      0.63         9
         549       0.00      0.00      0.00         4
         550       1.00      1.00      1.00         9
         551       0.67      1.00      0.80         4
         552       0.80      1.00      0.89         4
         553       1.00      1.00      1.00         4
         554       0.50      1.00      0.67         4
         555       0.67      1.00      0.80         4
         556       1.00      1.00      1.00         4
         557       1.00      0.75      0.86         4
         558       0.83      1.00      0.91         5
         559       0.00      0.00      0.00         4
         560       0.40      0.50      0.44         4
         561       0.09      0.11      0.10         9
         562       1.00      1.00      1.00         5
         563       1.00      0.75      0.86         4
         564       1.00      1.00      1.00         4
         565       0.00      0.00      0.00         4
         566       1.00      1.00      1.00         4
         567       0.67      0.89      0.76         9
         568       0.67      1.00      0.80         4
         569       0.17      0.25      0.20         4
         570       1.00      0.78      0.88         9
         571       0.00      0.00      0.00         4
         572       1.00      1.00      1.00         4
         573       0.43      0.75      0.55         4
         574       0.50      0.25      0.33         4
         575       1.00      0.75      0.86         4
         576       1.00      0.50      0.67         4
         577       0.50      0.75      0.60         4
         578       1.00      1.00      1.00         5
         579       0.90      1.00      0.95         9
         580       0.50      0.25      0.33         4
         581       0.82      1.00      0.90         9
         582       0.67      0.50      0.57         4
         583       0.67      1.00      0.80         4
         584       0.00      0.00      0.00         4
         585       0.67      0.44      0.53         9
         586       1.00      0.60      0.75         5
         587       1.00      1.00      1.00         5
         588       0.00      0.00      0.00         4
         589       0.25      0.20      0.22         5
         590       1.00      1.00      1.00         5
         591       0.00      0.00      0.00         4
         592       0.50      0.25      0.33         4
         593       0.57      1.00      0.73         4
         594       1.00      1.00      1.00         9
         595       0.00      0.00      0.00         4
         596       0.00      0.00      0.00         4
         597       0.00      0.00      0.00         4
         598       0.00      0.00      0.00         9
         599       0.12      0.25      0.17         4
         600       0.80      1.00      0.89         4
         601       1.00      1.00      1.00         4
         602       0.80      1.00      0.89         4
         603       0.80      1.00      0.89         4
         604       1.00      0.75      0.86         4
         605       0.83      0.56      0.67         9
         606       0.80      1.00      0.89         4
         607       1.00      1.00      1.00         4
         608       0.80      0.89      0.84         9
         609       0.88      0.78      0.82         9
         610       0.00      0.00      0.00         4
         611       1.00      0.80      0.89         5
         612       1.00      1.00      1.00         8
         613       0.62      1.00      0.77         5
         614       0.20      0.50      0.29         4
         615       0.83      1.00      0.91         5
         616       1.00      1.00      1.00         4
         617       0.00      0.00      0.00         4
         618       0.50      1.00      0.67         4
         619       0.00      0.00      0.00         4
         620       0.57      1.00      0.73         4
         621       0.00      0.00      0.00         4
         622       0.43      0.33      0.38         9
         623       1.00      1.00      1.00         9
         624       0.71      0.56      0.63         9
         625       0.70      0.78      0.74         9
         626       0.00      0.00      0.00         4
         627       0.57      1.00      0.73         4
         628       1.00      1.00      1.00         5
         629       0.00      0.00      0.00         4
         630       1.00      0.25      0.40         4
         631       0.75      0.75      0.75         4
         632       1.00      0.75      0.86         4
         633       1.00      1.00      1.00         9
         634       0.75      0.75      0.75         4
         635       1.00      0.80      0.89         5
         636       1.00      0.75      0.86         4
         637       0.75      0.75      0.75         4
         638       1.00      0.40      0.57         5
         639       0.00      0.00      0.00         4
         640       1.00      1.00      1.00         9
         641       0.86      0.67      0.75         9
         642       0.08      0.11      0.09         9
         643       0.50      0.50      0.50         4
         644       0.80      1.00      0.89         4
         645       0.00      0.00      0.00         4
         646       1.00      1.00      1.00         4
         647       0.89      0.89      0.89         9
         648       1.00      0.67      0.80         9
         649       0.60      0.60      0.60         5
         650       0.75      0.75      0.75         4
         651       0.80      0.80      0.80         5
         652       0.45      1.00      0.62         5
         653       1.00      0.75      0.86         4
         654       0.80      0.80      0.80         5
         655       0.83      1.00      0.91         5
         656       1.00      1.00      1.00         4
         657       1.00      1.00      1.00         4
         658       1.00      0.50      0.67         4
         659       0.75      0.75      0.75         4
         660       1.00      1.00      1.00         4
         661       0.67      1.00      0.80         4
         662       1.00      0.80      0.89         5
         663       0.00      0.00      0.00         4
         664       0.00      0.00      0.00         4
         665       0.00      0.00      0.00         4
         666       0.57      0.44      0.50         9
         667       0.75      0.75      0.75         4
         668       0.67      0.80      0.73         5
         669       0.88      0.78      0.82         9
         670       1.00      1.00      1.00         4
         671       0.50      0.75      0.60         4
         672       1.00      1.00      1.00         4
         673       1.00      1.00      1.00         4
         674       0.00      0.00      0.00         4
         675       1.00      0.78      0.88         9
         676       0.67      0.89      0.76         9
         677       1.00      1.00      1.00         9
         678       0.00      0.00      0.00         9
         679       0.75      0.75      0.75         4
         680       1.00      1.00      1.00         9
         681       1.00      0.75      0.86         4
         682       0.69      1.00      0.82         9
         683       1.00      0.75      0.86         4
         684       0.71      1.00      0.83         5
         685       1.00      0.40      0.57         5
         686       1.00      0.75      0.86         4
         687       0.00      0.00      0.00         4
         688       0.83      1.00      0.91         5
         689       0.50      1.00      0.67         4
         690       0.00      0.00      0.00         4
         691       0.75      0.60      0.67         5
         692       0.40      0.50      0.44         4
         693       1.00      1.00      1.00         4
         694       0.00      0.00      0.00         9
         695       0.38      0.75      0.50         4
         696       1.00      1.00      1.00         4
         697       1.00      1.00      1.00         4
         698       0.00      0.00      0.00         4
         699       0.00      0.00      0.00         4
         700       0.50      0.25      0.33         4
         701       0.80      1.00      0.89         4
         702       0.36      0.44      0.40         9
         703       0.71      1.00      0.83         5
         704       0.80      1.00      0.89         4
         705       1.00      0.80      0.89         5
         706       1.00      0.75      0.86         4
         707       0.90      1.00      0.95         9
         708       1.00      1.00      1.00         4
         709       0.00      0.00      0.00         4
         710       1.00      0.40      0.57         5
         711       0.00      0.00      0.00         4
         712       1.00      0.75      0.86         4
         713       1.00      1.00      1.00         4
         714       0.00      0.00      0.00         4
         715       0.80      1.00      0.89         4
         716       0.50      0.25      0.33         4
         717       1.00      1.00      1.00         5
         718       0.67      1.00      0.80         4
         719       0.50      0.80      0.62         5
         720       0.00      0.00      0.00         4
         721       1.00      0.75      0.86         4
         722       0.00      0.00      0.00         4
         723       1.00      0.89      0.94         9
         724       0.80      0.80      0.80         5
         725       1.00      1.00      1.00         4
         726       1.00      0.89      0.94         9
         727       0.71      1.00      0.83         5
         728       0.33      0.25      0.29         4
         729       0.40      0.50      0.44         4
         730       0.50      0.25      0.33         4
         731       1.00      0.60      0.75         5
         732       1.00      1.00      1.00         4
         733       0.90      1.00      0.95         9
         734       0.80      1.00      0.89         4
         735       1.00      0.89      0.94         9
         736       0.75      0.67      0.71         9
         737       1.00      1.00      1.00         4
         738       0.50      0.25      0.33         4
         739       1.00      1.00      1.00         4
         740       0.00      0.00      0.00         4
         741       0.78      0.78      0.78         9
         742       1.00      1.00      1.00         4
         743       1.00      0.50      0.67         4
         744       0.90      1.00      0.95         9
         745       1.00      0.78      0.88         9
         746       1.00      0.80      0.89         5
         747       1.00      1.00      1.00         9
         748       1.00      1.00      1.00         5
         749       1.00      0.89      0.94         9
         750       0.60      0.67      0.63         9
         751       1.00      1.00      1.00         9
         752       0.90      1.00      0.95         9
         753       1.00      1.00      1.00         4
         754       1.00      1.00      1.00         9
         755       0.80      1.00      0.89         4
         756       1.00      0.40      0.57         5
         757       0.67      0.80      0.73         5
         758       0.67      1.00      0.80         4
         759       0.90      1.00      0.95         9
         760       1.00      1.00      1.00         4
         761       0.67      0.50      0.57         4
         762       1.00      0.75      0.86         4
         763       0.89      0.89      0.89         9
         764       0.00      0.00      0.00         4
         765       0.00      0.00      0.00         4
         766       1.00      0.80      0.89         5
         767       1.00      0.50      0.67         4
         768       0.50      1.00      0.67         4
         769       1.00      0.80      0.89         5
         770       0.00      0.00      0.00         4
         771       1.00      0.75      0.86         4
         772       0.82      1.00      0.90         9
         773       0.75      0.50      0.60         6
         774       1.00      1.00      1.00         9
         775       1.00      0.80      0.89         5
         776       1.00      0.25      0.40         4
         777       1.00      1.00      1.00         9
         778       0.80      1.00      0.89         4
         779       0.20      0.25      0.22         4
         780       1.00      0.50      0.67         4
         781       0.67      0.67      0.67         9
         782       1.00      0.75      0.86         4
         783       0.00      0.00      0.00         4
         784       0.58      0.78      0.67         9
         785       0.75      0.75      0.75         4
         786       0.75      0.75      0.75         4
         787       0.82      1.00      0.90         9
         788       1.00      1.00      1.00         4
         789       0.00      0.00      0.00         4
         790       0.67      0.50      0.57         4
         791       1.00      0.75      0.86         4
         792       0.67      0.40      0.50         5
         793       0.00      0.00      0.00         4
         794       0.60      0.75      0.67         4
         795       1.00      0.89      0.94         9
         796       0.80      0.80      0.80         5
         797       0.67      1.00      0.80         4
         798       0.00      0.00      0.00         4
         799       0.67      0.40      0.50         5
         800       0.80      1.00      0.89         4
         801       0.67      0.50      0.57         4
         802       1.00      0.80      0.89         5
         803       0.80      1.00      0.89         4
         804       1.00      0.50      0.67         4
         805       0.00      0.00      0.00         4
         806       1.00      1.00      1.00         9
         807       1.00      1.00      1.00         4
         808       0.00      0.00      0.00         4
         809       0.75      0.75      0.75         4
         810       0.44      1.00      0.62         4
         811       0.90      1.00      0.95         9
         812       1.00      0.75      0.86         4
         813       0.60      0.75      0.67         4
         814       1.00      0.75      0.86         4
         815       0.89      0.89      0.89         9
         816       0.80      1.00      0.89         4
         817       1.00      0.50      0.67         4
         818       1.00      1.00      1.00         9
         819       0.75      0.75      0.75         4
         820       0.83      1.00      0.91         5
         821       0.78      0.78      0.78         9
         822       0.80      0.80      0.80         5
         823       0.88      0.78      0.82         9
         824       1.00      0.75      0.86         4
         825       0.75      0.60      0.67         5
         826       0.89      1.00      0.94         8
         827       0.67      0.50      0.57         4
         828       0.00      0.00      0.00         4
         829       1.00      1.00      1.00         4
         830       0.00      0.00      0.00         4
         831       1.00      0.75      0.86         4
         832       0.67      0.44      0.53         9
         833       0.83      1.00      0.91         5
         834       0.90      1.00      0.95         9
         835       0.67      1.00      0.80         4
         836       0.40      1.00      0.57         4
         837       0.29      0.50      0.36         4
         838       0.00      0.00      0.00         4
         839       0.43      0.60      0.50         5
         840       1.00      0.80      0.89         5
         841       0.88      0.78      0.82         9
         842       0.00      0.00      0.00         4
         843       1.00      0.75      0.86         4
         844       0.83      1.00      0.91         5
         845       0.75      0.75      0.75         4
         846       0.50      0.50      0.50         4
         847       0.67      0.50      0.57         4
         848       0.78      0.78      0.78         9
         849       0.57      1.00      0.73         4
         850       0.25      0.25      0.25         4
         851       1.00      0.50      0.67         4
         852       0.75      0.33      0.46         9
         853       0.67      0.67      0.67         9
         854       1.00      0.25      0.40         4
         855       1.00      0.60      0.75         5
         856       0.67      1.00      0.80         4
         857       0.90      1.00      0.95         9
         858       0.00      0.00      0.00         4
         859       0.80      0.89      0.84         9
         860       0.80      0.80      0.80         5
         861       1.00      1.00      1.00         5
         862       0.82      1.00      0.90         9
         863       0.70      0.78      0.74         9
         864       0.89      0.89      0.89         9
         865       0.00      0.00      0.00         4
         866       1.00      0.89      0.94         9
         867       1.00      1.00      1.00         4
         868       0.71      1.00      0.83         5
         869       1.00      0.75      0.86         4
         870       0.00      0.00      0.00         4
         871       0.83      1.00      0.91         5
         872       0.00      0.00      0.00         4
         873       1.00      1.00      1.00         4
         874       1.00      0.75      0.86         4
         875       0.00      0.00      0.00         4
         876       0.75      0.75      0.75         4
         877       0.64      0.78      0.70         9
         878       0.75      0.67      0.71         9
         879       1.00      1.00      1.00         4
         880       1.00      0.50      0.67         4
         881       0.40      0.40      0.40         5
         882       0.00      0.00      0.00         4
         883       1.00      0.75      0.86         4
         884       1.00      0.80      0.89         5
         885       0.80      1.00      0.89         4
         886       0.00      0.00      0.00         4
         887       0.11      0.25      0.15         4
         888       0.75      0.75      0.75         4
         889       0.80      1.00      0.89         4
         890       0.20      0.25      0.22         4
         891       0.67      1.00      0.80         4
         892       0.80      1.00      0.89         4
         893       0.62      1.00      0.77         5

    accuracy                           0.70      4917
   macro avg       0.70      0.68      0.67      4917
weighted avg       0.72      0.70      0.70      4917

task_train_time: {0: 0.12494014199999981, 1: 0.03283116999999969, 2: 0.03419269399999969, 3: 0.031653459999999356, 4: 0.035613369000000006, 5: 0.03781824200000017, 6: 0.027501967999999266, 7: 0.029016123999999976, 8: 0.038396993999999296, 9: 0.03504657599999916, 10: 0.031173485000000056, 11: 0.03335223899999917, 12: 0.03583291200000005, 13: 0.0317804490000011, 14: 0.039814691000000124, 15: 0.0359656820000005, 16: 0.034443203000000366, 17: 0.037299556999998984, 18: 0.03724834800000032, 19: 0.03701891699999926, 20: 0.033972756000000714, 21: 0.03759638500000051, 22: 0.031999171000000715, 23: 0.04056947000000122, 24: 0.03133190500000005, 25: 0.033842951000000454, 26: 0.03577434299999993, 27: 0.031168800999999746, 28: 0.031084823000000483, 29: 0.03319806400000047, 30: 0.03271511099999991, 31: 0.03372804099999982, 32: 0.029477547999999132, 33: 0.03407427399999996, 34: 0.029982476999999008, 35: 0.030485783999999683, 36: 0.04148684399999958, 37: 0.030764622999999602, 38: 0.03364800400000334, 39: 0.03190922099999938, 40: 0.03770443100000165, 41: 0.028281655999997213, 42: 0.03457881900000004, 43: 0.02895064300000172}
prediction_time: 0.0003076269999979786
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
