Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.01, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='e8940822-cb89-46d2-8fcd-b7b4a1bc4136', conf_timestamp='2023-08-14 11:25:55.167716', cutmix_alpha=None, dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.01, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=12, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=12, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=12, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 8.33 % 	 [Task-IL]: 8.33 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=22, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=22, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=22, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 5.0 % 	 [Task-IL]: 27.22 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=32, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=32, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=32, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 13.89 % 	 [Task-IL]: 49.72 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=42, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=42, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=42, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 2.71 % 	 [Task-IL]: 41.81 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=52, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=52, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=52, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 7.67 % 	 [Task-IL]: 52.25 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=62, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=62, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=62, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 8.89 % 	 [Task-IL]: 49.7 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=72, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=72, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=72, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 4.29 % 	 [Task-IL]: 51.31 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=82, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=82, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=82, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 2.4 % 	 [Task-IL]: 47.45 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=92, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=92, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=92, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 4.91 % 	 [Task-IL]: 49.04 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=102, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=102, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=102, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 3.25 % 	 [Task-IL]: 42.67 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=112, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=112, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=112, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 4.55 % 	 [Task-IL]: 45.61 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=122, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=122, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=122, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 4.03 % 	 [Task-IL]: 49.76 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=132, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=132, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=132, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 1.54 % 	 [Task-IL]: 42.91 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=142, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=142, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=142, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 2.68 % 	 [Task-IL]: 44.24 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)
torch.Size([1520, 405])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151]	Counter({97: 21, 130: 20, 22: 17, 135: 16, 150: 16, 103: 15, 149: 15, 28: 15, 23: 15, 26: 15, 51: 14, 0: 14, 36: 14, 86: 14, 141: 14, 78: 14, 89: 13, 96: 13, 5: 13, 101: 13, 93: 13, 79: 13, 53: 13, 47: 13, 94: 13, 69: 13, 107: 13, 19: 13, 14: 13, 38: 13, 102: 12, 32: 12, 104: 12, 125: 12, 126: 12, 74: 12, 2: 12, 56: 12, 108: 12, 76: 12, 68: 12, 75: 12, 12: 12, 29: 12, 147: 11, 42: 11, 142: 11, 148: 11, 6: 11, 120: 11, 80: 11, 67: 11, 124: 11, 40: 11, 73: 11, 45: 11, 63: 11, 65: 11, 16: 11, 20: 11, 33: 11, 70: 10, 10: 10, 4: 10, 106: 10, 145: 10, 118: 10, 111: 10, 43: 10, 98: 10, 87: 10, 84: 10, 99: 10, 127: 10, 59: 10, 151: 10, 88: 10, 92: 10, 39: 10, 27: 10, 132: 9, 49: 9, 1: 9, 112: 9, 7: 9, 143: 9, 58: 9, 90: 9, 139: 9, 95: 9, 137: 9, 82: 9, 128: 9, 83: 9, 136: 9, 41: 9, 114: 9, 119: 9, 46: 9, 54: 9, 72: 9, 57: 9, 110: 9, 21: 9, 15: 9, 35: 9, 121: 8, 55: 8, 66: 8, 85: 8, 11: 8, 113: 8, 52: 8, 91: 8, 44: 8, 100: 8, 146: 8, 61: 8, 144: 8, 77: 8, 133: 8, 18: 8, 25: 8, 129: 7, 122: 7, 8: 7, 109: 7, 3: 7, 50: 7, 123: 7, 48: 7, 131: 7, 34: 7, 37: 7, 115: 6, 116: 6, 134: 6, 138: 6, 140: 6, 81: 6, 64: 6, 117: 6, 62: 6, 31: 6, 24: 6, 9: 5, 105: 5, 71: 5, 17: 5, 13: 5, 30: 4, 60: 2})
Total buffer: 1520
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151]	Counter({0: 10, 2: 10, 4: 10, 5: 10, 6: 10, 10: 10, 12: 10, 14: 10, 16: 10, 19: 10, 20: 10, 22: 10, 23: 10, 26: 10, 27: 10, 28: 10, 29: 10, 32: 10, 33: 10, 36: 10, 38: 10, 39: 10, 40: 10, 42: 10, 43: 10, 45: 10, 47: 10, 51: 10, 53: 10, 56: 10, 59: 10, 63: 10, 65: 10, 67: 10, 68: 10, 69: 10, 70: 10, 73: 10, 74: 10, 75: 10, 76: 10, 78: 10, 79: 10, 80: 10, 84: 10, 86: 10, 87: 10, 88: 10, 89: 10, 92: 10, 93: 10, 94: 10, 96: 10, 97: 10, 98: 10, 99: 10, 101: 10, 102: 10, 103: 10, 104: 10, 106: 10, 107: 10, 108: 10, 111: 10, 118: 10, 120: 10, 124: 10, 125: 10, 126: 10, 127: 10, 130: 10, 135: 10, 141: 10, 142: 10, 145: 10, 147: 10, 148: 10, 149: 10, 150: 10, 151: 10, 1: 9, 7: 9, 15: 9, 21: 9, 35: 9, 41: 9, 46: 9, 49: 9, 54: 9, 57: 9, 58: 9, 72: 9, 82: 9, 83: 9, 90: 9, 95: 9, 110: 9, 112: 9, 114: 9, 119: 9, 128: 9, 132: 9, 136: 9, 137: 9, 139: 9, 143: 9, 11: 8, 18: 8, 25: 8, 44: 8, 52: 8, 55: 8, 61: 8, 66: 8, 77: 8, 85: 8, 91: 8, 100: 8, 113: 8, 121: 8, 133: 8, 144: 8, 146: 8, 3: 7, 8: 7, 34: 7, 37: 7, 48: 7, 50: 7, 109: 7, 122: 7, 123: 7, 129: 7, 131: 7, 24: 6, 31: 6, 62: 6, 64: 6, 81: 6, 115: 6, 116: 6, 117: 6, 134: 6, 138: 6, 140: 6, 9: 5, 13: 5, 17: 5, 71: 5, 105: 5, 30: 4, 60: 2})
Total buffer: 1344
fit_time: 11.509580208

Accuracy for 15 task(s): 	 [Class-IL]: 81.31 % 	 [Task-IL]: 79.0 %

CLASS_IL_ACC: 
	[80.55555555555556, 84.16666666666667, 73.33333333333333, 78.33333333333333, 74.16666666666667, 76.66666666666667, 87.5, 92.5, 88.33333333333333, 85.83333333333333, 78.33333333333333, 74.16666666666667, 87.5, 66.66666666666666, 91.66666666666666]
TASK_IL_ACC: 
	[79.16666666666666, 77.5, 80.0, 78.33333333333333, 74.16666666666667, 80.0, 79.16666666666666, 79.16666666666666, 79.16666666666666, 79.16666666666666, 71.66666666666667, 76.66666666666667, 77.5, 73.33333333333333, 100.0]
f1_micro: 81.3048245614035
f1_macro: 80.60238914792232
              precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       1.00      1.00      1.00        12
           2       0.77      0.83      0.80        12
           3       0.48      1.00      0.65        12
           4       0.45      0.42      0.43        12
           5       1.00      0.83      0.91        12
           6       0.67      0.33      0.44        12
           7       0.55      0.50      0.52        12
           8       0.73      0.92      0.81        12
           9       1.00      1.00      1.00        12
          10       1.00      1.00      1.00        12
          11       1.00      1.00      1.00        12
          12       1.00      0.92      0.96        12
          13       0.75      1.00      0.86        12
          14       0.92      1.00      0.96        12
          15       1.00      0.92      0.96        12
          16       1.00      1.00      1.00        12
          17       0.33      0.33      0.33        12
          18       0.92      0.92      0.92        12
          19       0.56      0.42      0.48        12
          20       0.92      1.00      0.96        12
          21       1.00      0.92      0.96        12
          22       1.00      1.00      1.00        12
          23       1.00      1.00      1.00        12
          24       0.78      0.58      0.67        12
          25       0.42      0.67      0.52        12
          26       0.92      1.00      0.96        12
          27       0.56      0.42      0.48        12
          28       0.91      0.83      0.87        12
          29       0.71      1.00      0.83        12
          30       0.40      0.17      0.24        12
          31       0.50      0.67      0.57        12
          32       0.92      0.92      0.92        12
          33       0.44      0.58      0.50        12
          34       1.00      1.00      1.00        12
          35       0.85      0.92      0.88        12
          36       1.00      0.92      0.96        12
          37       0.67      0.50      0.57        12
          38       1.00      0.75      0.86        12
          39       0.67      0.67      0.67        12
          40       0.57      0.67      0.62        12
          41       1.00      0.92      0.96        12
          42       1.00      1.00      1.00        12
          43       0.65      0.92      0.76        12
          44       0.86      0.50      0.63        12
          45       0.31      0.33      0.32        12
          46       1.00      1.00      1.00        12
          47       1.00      1.00      1.00        12
          48       0.50      0.92      0.65        12
          49       0.40      0.33      0.36        12
          50       0.62      0.42      0.50        12
          51       0.92      1.00      0.96        12
          52       0.00      0.00      0.00        12
          53       1.00      1.00      1.00        12
          54       0.50      0.67      0.57        12
          55       1.00      0.83      0.91        12
          56       1.00      1.00      1.00        12
          57       1.00      0.92      0.96        12
          58       0.92      1.00      0.96        12
          59       1.00      1.00      1.00        12
          60       1.00      0.50      0.67        12
          61       1.00      0.75      0.86        12
          62       1.00      0.58      0.74        12
          63       1.00      1.00      1.00        12
          64       1.00      1.00      1.00        12
          65       1.00      1.00      1.00        12
          66       1.00      0.75      0.86        12
          67       1.00      1.00      1.00        12
          68       0.79      0.92      0.85        12
          69       0.83      0.83      0.83        12
          70       0.69      0.92      0.79        12
          71       1.00      0.75      0.86        12
          72       1.00      0.83      0.91        12
          73       0.80      0.67      0.73        12
          74       1.00      1.00      1.00        12
          75       0.62      0.83      0.71        12
          76       0.92      1.00      0.96        12
          77       0.86      1.00      0.92        12
          78       1.00      1.00      1.00        12
          79       1.00      0.92      0.96        12
          80       0.67      1.00      0.80        12
          81       1.00      1.00      1.00        12
          82       1.00      1.00      1.00        12
          83       0.17      0.17      0.17        12
          84       1.00      0.92      0.96        12
          85       1.00      1.00      1.00        12
          86       0.92      1.00      0.96        12
          87       1.00      1.00      1.00        12
          88       1.00      1.00      1.00        12
          89       1.00      1.00      1.00        12
          90       1.00      1.00      1.00        12
          91       1.00      0.75      0.86        12
          92       1.00      1.00      1.00        12
          93       1.00      1.00      1.00        12
          94       0.82      0.75      0.78        12
          95       0.86      1.00      0.92        12
          96       0.82      0.75      0.78        12
          97       0.85      0.92      0.88        12
          98       0.50      0.25      0.33        12
          99       0.73      0.92      0.81        12
         100       1.00      1.00      1.00        12
         101       0.92      1.00      0.96        12
         102       1.00      1.00      1.00        12
         103       0.82      0.75      0.78        12
         104       0.64      0.75      0.69        12
         105       0.00      0.00      0.00        12
         106       0.92      1.00      0.96        12
         107       1.00      1.00      1.00        12
         108       0.50      0.33      0.40        12
         109       0.92      1.00      0.96        12
         110       1.00      1.00      1.00        12
         111       1.00      1.00      1.00        12
         112       1.00      1.00      1.00        12
         113       1.00      1.00      1.00        12
         114       0.44      0.33      0.38        12
         115       0.86      0.50      0.63        12
         116       1.00      1.00      1.00        12
         117       0.53      0.67      0.59        12
         118       0.77      0.83      0.80        12
         119       0.83      0.42      0.56        12
         120       0.71      0.83      0.77        12
         121       0.77      0.83      0.80        12
         122       0.58      0.58      0.58        12
         123       0.91      0.83      0.87        12
         124       0.73      0.92      0.81        12
         125       0.92      1.00      0.96        12
         126       0.60      0.75      0.67        12
         127       0.64      0.75      0.69        12
         128       1.00      1.00      1.00        12
         129       1.00      0.92      0.96        12
         130       0.92      1.00      0.96        12
         131       0.86      1.00      0.92        12
         132       0.38      0.42      0.40        12
         133       0.90      0.75      0.82        12
         134       0.62      0.42      0.50        12
         135       1.00      1.00      1.00        12
         136       0.92      1.00      0.96        12
         137       0.38      0.25      0.30        12
         138       0.25      0.33      0.29        12
         139       0.71      0.83      0.77        12
         140       1.00      0.67      0.80        12
         141       1.00      1.00      1.00        12
         142       0.92      0.92      0.92        12
         143       0.82      0.75      0.78        12
         144       0.92      0.92      0.92        12
         145       1.00      1.00      1.00        12
         146       0.92      1.00      0.96        12
         147       0.44      0.67      0.53        12
         148       1.00      1.00      1.00        12
         149       0.52      0.92      0.67        12
         150       1.00      1.00      1.00        12
         151       1.00      1.00      1.00        12

    accuracy                           0.81      1824
   macro avg       0.82      0.81      0.81      1824
weighted avg       0.82      0.81      0.81      1824

task_train_time: {0: 0.1156007429999999, 1: 0.040908573999999476, 2: 0.03887274200000057, 3: 0.0403311869999996, 4: 0.040561526999999487, 5: 0.03794423899999977, 6: 0.039387375000000446, 7: 0.03834855000000026, 8: 0.03661555799999938, 9: 0.035652240000001, 10: 0.03600530599999985, 11: 0.03656508399999936, 12: 0.03777353199999922, 13: 0.037043346999999116, 14: 0.03702833600000055}
prediction_time: 0.00025397599999976705
Parameters: 558152
Task parameters: {0: 418012, 1: 428022, 2: 438032, 3: 448042, 4: 458052, 5: 468062, 6: 478072, 7: 488082, 8: 498092, 9: 508102, 10: 518112, 11: 528122, 12: 538132, 13: 548142, 14: 558152}
