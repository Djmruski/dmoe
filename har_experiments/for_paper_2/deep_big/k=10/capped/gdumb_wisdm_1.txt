Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='9d16879d-6888-4620-baff-2105a0fc445f', conf_timestamp='2023-08-14 11:26:46.168116', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 68.78 % 	 [Task-IL]: 44.44 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 58.44 % 	 [Task-IL]: 34.26 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 38.86 % 	 [Task-IL]: 30.57 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 37.34 % 	 [Task-IL]: 30.09 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 38.63 % 	 [Task-IL]: 30.49 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 29.75 % 	 [Task-IL]: 30.11 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.39 % 	 [Task-IL]: 28.09 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 15.53 % 	 [Task-IL]: 28.48 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 16.98 % 	 [Task-IL]: 28.43 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 16.03 % 	 [Task-IL]: 28.48 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.9 % 	 [Task-IL]: 28.14 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 18.14 % 	 [Task-IL]: 28.94 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 14.55 % 	 [Task-IL]: 28.95 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 13.23 % 	 [Task-IL]: 28.62 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 10.75 % 	 [Task-IL]: 29.08 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.73 % 	 [Task-IL]: 28.88 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.26 % 	 [Task-IL]: 28.82 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 12.46 % 	 [Task-IL]: 28.56 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.92 % 	 [Task-IL]: 28.47 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 11.02 % 	 [Task-IL]: 28.41 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 11.22 % 	 [Task-IL]: 27.5 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 9.45 % 	 [Task-IL]: 27.6 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.79 % 	 [Task-IL]: 27.71 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.62 % 	 [Task-IL]: 27.11 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 6.71 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.6 % 	 [Task-IL]: 28.17 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.64 % 	 [Task-IL]: 27.67 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.53 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.78 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.82 % 	 [Task-IL]: 27.08 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.31 % 	 [Task-IL]: 26.78 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.44 % 	 [Task-IL]: 26.78 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 4.96 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.66 % 	 [Task-IL]: 26.95 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.36 % 	 [Task-IL]: 26.72 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.86 % 	 [Task-IL]: 26.6 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.69 % 	 [Task-IL]: 26.44 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.91 % 	 [Task-IL]: 26.03 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.57 % 	 [Task-IL]: 26.12 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.1 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.46 % 	 [Task-IL]: 25.84 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.91 % 	 [Task-IL]: 26.24 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 5.76 % 	 [Task-IL]: 26.46 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({632: 26, 540: 26, 558: 25, 426: 25, 796: 24, 264: 24, 384: 24, 761: 23, 573: 23, 187: 23, 218: 23, 239: 23, 252: 23, 416: 23, 527: 23, 3: 22, 651: 22, 883: 22, 689: 22, 535: 22, 710: 22, 834: 22, 151: 22, 255: 22, 366: 22, 501: 22, 549: 21, 29: 21, 23: 21, 784: 21, 713: 21, 542: 21, 560: 21, 882: 21, 844: 21, 714: 21, 71: 21, 169: 21, 191: 21, 251: 21, 293: 21, 405: 21, 615: 20, 19: 20, 10: 20, 703: 20, 720: 20, 545: 20, 893: 20, 667: 20, 50: 20, 41: 20, 82: 20, 173: 20, 238: 20, 262: 20, 309: 20, 314: 20, 370: 20, 371: 20, 381: 20, 410: 20, 469: 20, 30: 19, 801: 19, 831: 19, 580: 19, 695: 19, 571: 19, 705: 19, 49: 19, 39: 19, 569: 19, 543: 19, 810: 19, 552: 19, 168: 19, 195: 19, 203: 19, 248: 19, 271: 19, 340: 19, 367: 19, 388: 19, 489: 19, 510: 19, 822: 18, 4: 18, 789: 18, 642: 18, 799: 18, 629: 18, 669: 18, 643: 18, 553: 18, 674: 18, 675: 18, 110: 18, 537: 18, 165: 18, 213: 18, 194: 18, 297: 18, 324: 18, 337: 18, 375: 18, 427: 18, 439: 18, 453: 18, 516: 18, 776: 17, 718: 17, 707: 17, 785: 17, 738: 17, 848: 17, 613: 17, 877: 17, 786: 17, 566: 17, 636: 17, 48: 17, 762: 17, 676: 17, 708: 17, 98: 17, 141: 17, 626: 17, 154: 17, 159: 17, 157: 17, 192: 17, 197: 17, 279: 17, 312: 17, 315: 17, 329: 17, 445: 17, 435: 17, 449: 17, 444: 17, 467: 17, 460: 17, 490: 17, 518: 17, 763: 16, 760: 16, 774: 16, 640: 16, 773: 16, 795: 16, 881: 16, 625: 16, 65: 16, 60: 16, 722: 16, 132: 16, 118: 16, 131: 16, 133: 16, 158: 16, 167: 16, 175: 16, 176: 16, 227: 16, 223: 16, 236: 16, 275: 16, 346: 16, 361: 16, 374: 16, 378: 16, 411: 16, 397: 16, 431: 16, 418: 16, 468: 16, 455: 16, 493: 16, 499: 16, 508: 16, 495: 16, 515: 16, 5: 15, 8: 15, 17: 15, 706: 15, 563: 15, 536: 15, 691: 15, 653: 15, 769: 15, 63: 15, 741: 15, 77: 15, 172: 15, 170: 15, 161: 15, 225: 15, 334: 15, 372: 15, 385: 15, 436: 15, 491: 15, 478: 15, 509: 15, 876: 14, 782: 14, 588: 14, 818: 14, 570: 14, 56: 14, 655: 14, 699: 14, 113: 14, 575: 14, 683: 14, 155: 14, 258: 14, 270: 14, 287: 14, 313: 14, 369: 14, 406: 14, 464: 14, 517: 14, 751: 13, 620: 13, 52: 13, 679: 13, 67: 13, 825: 13, 671: 13, 541: 13, 856: 13, 285: 13, 274: 13, 349: 13, 471: 13, 654: 12, 791: 12, 36: 12, 823: 12, 658: 12, 87: 12, 90: 12, 211: 12, 292: 12, 350: 12, 450: 12, 16: 11, 696: 11, 686: 11, 672: 11, 715: 11, 583: 11, 34: 11, 619: 11, 66: 11, 108: 11, 135: 11, 137: 11, 202: 11, 219: 11, 221: 11, 229: 11, 282: 11, 380: 11, 456: 11, 487: 11, 506: 11, 519: 11, 533: 11, 532: 11, 809: 10, 22: 10, 590: 10, 693: 10, 874: 10, 797: 10, 746: 10, 892: 10, 614: 10, 802: 10, 627: 10, 561: 10, 794: 10, 737: 10, 666: 10, 772: 10, 826: 10, 58: 10, 61: 10, 59: 10, 605: 10, 79: 10, 83: 10, 92: 10, 80: 10, 105: 10, 122: 10, 116: 10, 582: 10, 891: 10, 149: 10, 171: 10, 677: 10, 220: 10, 230: 10, 226: 10, 319: 10, 323: 10, 341: 10, 393: 10, 390: 10, 404: 10, 430: 10, 473: 10, 520: 10, 7: 9, 6: 9, 11: 9, 829: 9, 25: 9, 811: 9, 534: 9, 0: 9, 885: 9, 28: 9, 868: 9, 598: 9, 819: 9, 764: 9, 757: 9, 742: 9, 47: 9, 556: 9, 719: 9, 539: 9, 858: 9, 577: 9, 574: 9, 759: 9, 749: 9, 576: 9, 702: 9, 879: 9, 630: 9, 736: 9, 76: 9, 75: 9, 78: 9, 723: 9, 864: 9, 800: 9, 74: 9, 628: 9, 790: 9, 660: 9, 611: 9, 95: 9, 568: 9, 889: 9, 639: 9, 820: 9, 130: 9, 119: 9, 121: 9, 748: 9, 148: 9, 143: 9, 624: 9, 140: 9, 873: 9, 160: 9, 163: 9, 604: 9, 182: 9, 188: 9, 659: 9, 196: 9, 231: 9, 250: 9, 246: 9, 240: 9, 243: 9, 269: 9, 277: 9, 288: 9, 290: 9, 299: 9, 295: 9, 317: 9, 363: 9, 386: 9, 412: 9, 413: 9, 472: 9, 462: 9, 480: 9, 484: 9, 511: 9, 512: 9, 504: 9, 529: 9, 528: 9, 531: 9, 701: 8, 27: 8, 14: 8, 2: 8, 779: 8, 792: 8, 840: 8, 730: 8, 740: 8, 599: 8, 803: 8, 853: 8, 838: 8, 847: 8, 584: 8, 594: 8, 830: 8, 622: 8, 648: 8, 734: 8, 700: 8, 612: 8, 816: 8, 756: 8, 35: 8, 38: 8, 53: 8, 51: 8, 729: 8, 45: 8, 42: 8, 813: 8, 716: 8, 688: 8, 68: 8, 694: 8, 70: 8, 767: 8, 69: 8, 631: 8, 637: 8, 712: 8, 645: 8, 89: 8, 652: 8, 845: 8, 721: 8, 100: 8, 115: 8, 120: 8, 129: 8, 851: 8, 704: 8, 798: 8, 142: 8, 152: 8, 134: 8, 681: 8, 866: 8, 739: 8, 601: 8, 544: 8, 156: 8, 608: 8, 842: 8, 649: 8, 828: 8, 177: 8, 189: 8, 861: 8, 711: 8, 833: 8, 200: 8, 198: 8, 209: 8, 210: 8, 207: 8, 805: 8, 806: 8, 641: 8, 217: 8, 242: 8, 244: 8, 237: 8, 256: 8, 266: 8, 268: 8, 273: 8, 276: 8, 283: 8, 302: 8, 308: 8, 294: 8, 311: 8, 306: 8, 328: 8, 344: 8, 336: 8, 345: 8, 354: 8, 391: 8, 382: 8, 396: 8, 403: 8, 425: 8, 433: 8, 420: 8, 437: 8, 434: 8, 461: 8, 465: 8, 477: 8, 485: 8, 486: 8, 497: 8, 507: 8, 502: 8, 498: 8, 505: 8, 521: 8, 15: 7, 562: 7, 644: 7, 18: 7, 768: 7, 20: 7, 647: 7, 31: 7, 33: 7, 9: 7, 849: 7, 593: 7, 824: 7, 538: 7, 617: 7, 855: 7, 680: 7, 865: 7, 668: 7, 728: 7, 780: 7, 618: 7, 744: 7, 564: 7, 579: 7, 557: 7, 887: 7, 44: 7, 550: 7, 733: 7, 670: 7, 73: 7, 687: 7, 804: 7, 57: 7, 771: 7, 72: 7, 755: 7, 732: 7, 663: 7, 821: 7, 698: 7, 106: 7, 104: 7, 97: 7, 109: 7, 107: 7, 99: 7, 111: 7, 745: 7, 787: 7, 128: 7, 123: 7, 664: 7, 808: 7, 843: 7, 880: 7, 783: 7, 144: 7, 827: 7, 567: 7, 836: 7, 697: 7, 138: 7, 692: 7, 166: 7, 162: 7, 878: 7, 657: 7, 193: 7, 180: 7, 178: 7, 190: 7, 181: 7, 208: 7, 201: 7, 232: 7, 228: 7, 216: 7, 547: 7, 253: 7, 272: 7, 260: 7, 257: 7, 857: 7, 254: 7, 263: 7, 596: 7, 286: 7, 289: 7, 280: 7, 307: 7, 300: 7, 318: 7, 326: 7, 316: 7, 353: 7, 338: 7, 347: 7, 352: 7, 356: 7, 408: 7, 394: 7, 400: 7, 402: 7, 409: 7, 415: 7, 432: 7, 429: 7, 414: 7, 419: 7, 423: 7, 470: 7, 463: 7, 482: 7, 488: 7, 481: 7, 483: 7, 476: 7, 475: 7, 513: 7, 500: 7, 496: 7, 523: 7, 526: 7, 12: 6, 13: 6, 24: 6, 752: 6, 603: 6, 607: 6, 1: 6, 684: 6, 788: 6, 753: 6, 662: 6, 623: 6, 859: 6, 43: 6, 638: 6, 37: 6, 872: 6, 863: 6, 40: 6, 781: 6, 747: 6, 815: 6, 572: 6, 852: 6, 55: 6, 875: 6, 661: 6, 807: 6, 867: 6, 592: 6, 85: 6, 86: 6, 81: 6, 91: 6, 88: 6, 727: 6, 589: 6, 793: 6, 585: 6, 600: 6, 650: 6, 646: 6, 114: 6, 117: 6, 127: 6, 758: 6, 673: 6, 743: 6, 150: 6, 146: 6, 136: 6, 870: 6, 621: 6, 595: 6, 812: 6, 183: 6, 735: 6, 186: 6, 884: 6, 841: 6, 656: 6, 212: 6, 199: 6, 206: 6, 205: 6, 215: 6, 850: 6, 241: 6, 249: 6, 247: 6, 265: 6, 754: 6, 259: 6, 886: 6, 291: 6, 303: 6, 304: 6, 305: 6, 331: 6, 322: 6, 320: 6, 330: 6, 327: 6, 339: 6, 348: 6, 342: 6, 368: 6, 362: 6, 358: 6, 355: 6, 373: 6, 383: 6, 376: 6, 377: 6, 387: 6, 407: 6, 398: 6, 399: 6, 422: 6, 417: 6, 428: 6, 442: 6, 443: 6, 446: 6, 441: 6, 451: 6, 452: 6, 438: 6, 448: 6, 466: 6, 479: 6, 494: 6, 503: 6, 525: 6, 514: 6, 524: 6, 21: 5, 750: 5, 717: 5, 682: 5, 766: 5, 832: 5, 602: 5, 814: 5, 586: 5, 616: 5, 817: 5, 46: 5, 554: 5, 62: 5, 54: 5, 591: 5, 835: 5, 665: 5, 685: 5, 725: 5, 839: 5, 93: 5, 862: 5, 103: 5, 102: 5, 726: 5, 96: 5, 94: 5, 678: 5, 125: 5, 709: 5, 888: 5, 597: 5, 153: 5, 869: 5, 139: 5, 164: 5, 185: 5, 184: 5, 179: 5, 724: 5, 224: 5, 233: 5, 581: 5, 633: 5, 235: 5, 635: 5, 267: 5, 284: 5, 281: 5, 310: 5, 298: 5, 301: 5, 333: 5, 332: 5, 609: 5, 321: 5, 871: 5, 335: 5, 606: 5, 359: 5, 365: 5, 357: 5, 392: 5, 389: 5, 424: 5, 440: 5, 447: 5, 458: 5, 459: 5, 454: 5, 530: 5, 522: 5, 778: 4, 32: 4, 555: 4, 634: 4, 565: 4, 770: 4, 860: 4, 690: 4, 559: 4, 551: 4, 124: 4, 846: 4, 147: 4, 174: 4, 548: 4, 890: 4, 222: 4, 214: 4, 610: 4, 854: 4, 234: 4, 245: 4, 777: 4, 296: 4, 343: 4, 364: 4, 546: 4, 395: 4, 421: 4, 578: 4, 457: 4, 492: 4, 474: 4, 587: 3, 64: 3, 84: 3, 101: 3, 126: 3, 145: 3, 731: 3, 204: 3, 278: 3, 351: 3, 360: 3, 379: 3, 401: 3, 837: 3, 26: 2, 112: 2, 775: 2, 765: 2, 261: 2})
Total buffer: 8940
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({3: 10, 4: 10, 5: 10, 8: 10, 10: 10, 16: 10, 17: 10, 19: 10, 22: 10, 23: 10, 29: 10, 30: 10, 34: 10, 36: 10, 39: 10, 41: 10, 48: 10, 49: 10, 50: 10, 52: 10, 56: 10, 58: 10, 59: 10, 60: 10, 61: 10, 63: 10, 65: 10, 66: 10, 67: 10, 71: 10, 77: 10, 79: 10, 80: 10, 82: 10, 83: 10, 87: 10, 90: 10, 92: 10, 98: 10, 105: 10, 108: 10, 110: 10, 113: 10, 116: 10, 118: 10, 122: 10, 131: 10, 132: 10, 133: 10, 135: 10, 137: 10, 141: 10, 149: 10, 151: 10, 154: 10, 155: 10, 157: 10, 158: 10, 159: 10, 161: 10, 165: 10, 167: 10, 168: 10, 169: 10, 170: 10, 171: 10, 172: 10, 173: 10, 175: 10, 176: 10, 187: 10, 191: 10, 192: 10, 194: 10, 195: 10, 197: 10, 202: 10, 203: 10, 211: 10, 213: 10, 218: 10, 219: 10, 220: 10, 221: 10, 223: 10, 225: 10, 226: 10, 227: 10, 229: 10, 230: 10, 236: 10, 238: 10, 239: 10, 248: 10, 251: 10, 252: 10, 255: 10, 258: 10, 262: 10, 264: 10, 270: 10, 271: 10, 274: 10, 275: 10, 279: 10, 282: 10, 285: 10, 287: 10, 292: 10, 293: 10, 297: 10, 309: 10, 312: 10, 313: 10, 314: 10, 315: 10, 319: 10, 323: 10, 324: 10, 329: 10, 334: 10, 337: 10, 340: 10, 341: 10, 346: 10, 349: 10, 350: 10, 361: 10, 366: 10, 367: 10, 369: 10, 370: 10, 371: 10, 372: 10, 374: 10, 375: 10, 378: 10, 380: 10, 381: 10, 384: 10, 385: 10, 388: 10, 390: 10, 393: 10, 397: 10, 404: 10, 405: 10, 406: 10, 410: 10, 411: 10, 416: 10, 418: 10, 426: 10, 427: 10, 430: 10, 431: 10, 435: 10, 436: 10, 439: 10, 444: 10, 445: 10, 449: 10, 450: 10, 453: 10, 455: 10, 456: 10, 460: 10, 464: 10, 467: 10, 468: 10, 469: 10, 471: 10, 473: 10, 478: 10, 487: 10, 489: 10, 490: 10, 491: 10, 493: 10, 495: 10, 499: 10, 501: 10, 506: 10, 508: 10, 509: 10, 510: 10, 515: 10, 516: 10, 517: 10, 518: 10, 519: 10, 520: 10, 527: 10, 532: 10, 533: 10, 535: 10, 536: 10, 537: 10, 540: 10, 541: 10, 542: 10, 543: 10, 545: 10, 549: 10, 552: 10, 553: 10, 558: 10, 560: 10, 561: 10, 563: 10, 566: 10, 569: 10, 570: 10, 571: 10, 573: 10, 575: 10, 580: 10, 582: 10, 583: 10, 588: 10, 590: 10, 605: 10, 613: 10, 614: 10, 615: 10, 619: 10, 620: 10, 625: 10, 626: 10, 627: 10, 629: 10, 632: 10, 636: 10, 640: 10, 642: 10, 643: 10, 651: 10, 653: 10, 654: 10, 655: 10, 658: 10, 666: 10, 667: 10, 669: 10, 671: 10, 672: 10, 674: 10, 675: 10, 676: 10, 677: 10, 679: 10, 683: 10, 686: 10, 689: 10, 691: 10, 693: 10, 695: 10, 696: 10, 699: 10, 703: 10, 705: 10, 706: 10, 707: 10, 708: 10, 710: 10, 713: 10, 714: 10, 715: 10, 718: 10, 720: 10, 722: 10, 737: 10, 738: 10, 741: 10, 746: 10, 751: 10, 760: 10, 761: 10, 762: 10, 763: 10, 769: 10, 772: 10, 773: 10, 774: 10, 776: 10, 782: 10, 784: 10, 785: 10, 786: 10, 789: 10, 791: 10, 794: 10, 795: 10, 796: 10, 797: 10, 799: 10, 801: 10, 802: 10, 809: 10, 810: 10, 818: 10, 822: 10, 823: 10, 825: 10, 826: 10, 831: 10, 834: 10, 844: 10, 848: 10, 856: 10, 874: 10, 876: 10, 877: 10, 881: 10, 882: 10, 883: 10, 891: 10, 892: 10, 893: 10, 0: 9, 6: 9, 7: 9, 11: 9, 25: 9, 28: 9, 47: 9, 74: 9, 75: 9, 76: 9, 78: 9, 95: 9, 119: 9, 121: 9, 130: 9, 140: 9, 143: 9, 148: 9, 160: 9, 163: 9, 182: 9, 188: 9, 196: 9, 231: 9, 240: 9, 243: 9, 246: 9, 250: 9, 269: 9, 277: 9, 288: 9, 290: 9, 295: 9, 299: 9, 317: 9, 363: 9, 386: 9, 412: 9, 413: 9, 462: 9, 472: 9, 480: 9, 484: 9, 504: 9, 511: 9, 512: 9, 528: 9, 529: 9, 531: 9, 534: 9, 539: 9, 556: 9, 568: 9, 574: 9, 576: 9, 577: 9, 598: 9, 604: 9, 611: 9, 624: 9, 628: 9, 630: 9, 639: 9, 659: 9, 660: 9, 702: 9, 719: 9, 723: 9, 736: 9, 742: 9, 748: 9, 749: 9, 757: 9, 759: 9, 764: 9, 790: 9, 800: 9, 811: 9, 819: 9, 820: 9, 829: 9, 858: 9, 864: 9, 868: 9, 873: 9, 879: 9, 885: 9, 889: 9, 2: 8, 14: 8, 27: 8, 35: 8, 38: 8, 42: 8, 45: 8, 51: 8, 53: 8, 68: 8, 69: 8, 70: 8, 89: 8, 100: 8, 115: 8, 120: 8, 129: 8, 134: 8, 142: 8, 152: 8, 156: 8, 177: 8, 189: 8, 198: 8, 200: 8, 207: 8, 209: 8, 210: 8, 217: 8, 237: 8, 242: 8, 244: 8, 256: 8, 266: 8, 268: 8, 273: 8, 276: 8, 283: 8, 294: 8, 302: 8, 306: 8, 308: 8, 311: 8, 328: 8, 336: 8, 344: 8, 345: 8, 354: 8, 382: 8, 391: 8, 396: 8, 403: 8, 420: 8, 425: 8, 433: 8, 434: 8, 437: 8, 461: 8, 465: 8, 477: 8, 485: 8, 486: 8, 497: 8, 498: 8, 502: 8, 505: 8, 507: 8, 521: 8, 544: 8, 584: 8, 594: 8, 599: 8, 601: 8, 608: 8, 612: 8, 622: 8, 631: 8, 637: 8, 641: 8, 645: 8, 648: 8, 649: 8, 652: 8, 681: 8, 688: 8, 694: 8, 700: 8, 701: 8, 704: 8, 711: 8, 712: 8, 716: 8, 721: 8, 729: 8, 730: 8, 734: 8, 739: 8, 740: 8, 756: 8, 767: 8, 779: 8, 792: 8, 798: 8, 803: 8, 805: 8, 806: 8, 813: 8, 816: 8, 828: 8, 830: 8, 833: 8, 838: 8, 840: 8, 842: 8, 845: 8, 847: 8, 851: 8, 853: 8, 861: 8, 866: 8, 9: 7, 15: 7, 18: 7, 20: 7, 31: 7, 33: 7, 44: 7, 57: 7, 72: 7, 73: 7, 97: 7, 99: 7, 104: 7, 106: 7, 107: 7, 109: 7, 111: 7, 123: 7, 128: 7, 138: 7, 144: 7, 162: 7, 166: 7, 178: 7, 180: 7, 181: 7, 190: 7, 193: 7, 201: 7, 208: 7, 216: 7, 228: 7, 232: 7, 253: 7, 254: 7, 257: 7, 260: 7, 263: 7, 272: 7, 280: 7, 286: 7, 289: 7, 300: 7, 307: 7, 316: 7, 318: 7, 326: 7, 338: 7, 347: 7, 352: 7, 353: 7, 356: 7, 394: 7, 400: 7, 402: 7, 408: 7, 409: 7, 414: 7, 415: 7, 419: 7, 423: 7, 429: 7, 432: 7, 463: 7, 470: 7, 475: 7, 476: 7, 481: 7, 482: 7, 483: 7, 488: 7, 496: 7, 500: 7, 513: 7, 523: 7, 526: 7, 538: 7, 547: 7, 550: 7, 557: 7, 562: 7, 564: 7, 567: 7, 579: 7, 593: 7, 596: 7, 617: 7, 618: 7, 644: 7, 647: 7, 657: 7, 663: 7, 664: 7, 668: 7, 670: 7, 680: 7, 687: 7, 692: 7, 697: 7, 698: 7, 728: 7, 732: 7, 733: 7, 744: 7, 745: 7, 755: 7, 768: 7, 771: 7, 780: 7, 783: 7, 787: 7, 804: 7, 808: 7, 821: 7, 824: 7, 827: 7, 836: 7, 843: 7, 849: 7, 855: 7, 857: 7, 865: 7, 878: 7, 880: 7, 887: 7, 1: 6, 12: 6, 13: 6, 24: 6, 37: 6, 40: 6, 43: 6, 55: 6, 81: 6, 85: 6, 86: 6, 88: 6, 91: 6, 114: 6, 117: 6, 127: 6, 136: 6, 146: 6, 150: 6, 183: 6, 186: 6, 199: 6, 205: 6, 206: 6, 212: 6, 215: 6, 241: 6, 247: 6, 249: 6, 259: 6, 265: 6, 291: 6, 303: 6, 304: 6, 305: 6, 320: 6, 322: 6, 327: 6, 330: 6, 331: 6, 339: 6, 342: 6, 348: 6, 355: 6, 358: 6, 362: 6, 368: 6, 373: 6, 376: 6, 377: 6, 383: 6, 387: 6, 398: 6, 399: 6, 407: 6, 417: 6, 422: 6, 428: 6, 438: 6, 441: 6, 442: 6, 443: 6, 446: 6, 448: 6, 451: 6, 452: 6, 466: 6, 479: 6, 494: 6, 503: 6, 514: 6, 524: 6, 525: 6, 572: 6, 585: 6, 589: 6, 592: 6, 595: 6, 600: 6, 603: 6, 607: 6, 621: 6, 623: 6, 638: 6, 646: 6, 650: 6, 656: 6, 661: 6, 662: 6, 673: 6, 684: 6, 727: 6, 735: 6, 743: 6, 747: 6, 752: 6, 753: 6, 754: 6, 758: 6, 781: 6, 788: 6, 793: 6, 807: 6, 812: 6, 815: 6, 841: 6, 850: 6, 852: 6, 859: 6, 863: 6, 867: 6, 870: 6, 872: 6, 875: 6, 884: 6, 886: 6, 21: 5, 46: 5, 54: 5, 62: 5, 93: 5, 94: 5, 96: 5, 102: 5, 103: 5, 125: 5, 139: 5, 153: 5, 164: 5, 179: 5, 184: 5, 185: 5, 224: 5, 233: 5, 235: 5, 267: 5, 281: 5, 284: 5, 298: 5, 301: 5, 310: 5, 321: 5, 332: 5, 333: 5, 335: 5, 357: 5, 359: 5, 365: 5, 389: 5, 392: 5, 424: 5, 440: 5, 447: 5, 454: 5, 458: 5, 459: 5, 522: 5, 530: 5, 554: 5, 581: 5, 586: 5, 591: 5, 597: 5, 602: 5, 606: 5, 609: 5, 616: 5, 633: 5, 635: 5, 665: 5, 678: 5, 682: 5, 685: 5, 709: 5, 717: 5, 724: 5, 725: 5, 726: 5, 750: 5, 766: 5, 814: 5, 817: 5, 832: 5, 835: 5, 839: 5, 862: 5, 869: 5, 871: 5, 888: 5, 32: 4, 124: 4, 147: 4, 174: 4, 214: 4, 222: 4, 234: 4, 245: 4, 296: 4, 343: 4, 364: 4, 395: 4, 421: 4, 457: 4, 474: 4, 492: 4, 546: 4, 548: 4, 551: 4, 555: 4, 559: 4, 565: 4, 578: 4, 610: 4, 634: 4, 690: 4, 770: 4, 777: 4, 778: 4, 846: 4, 854: 4, 860: 4, 890: 4, 64: 3, 84: 3, 101: 3, 126: 3, 145: 3, 204: 3, 278: 3, 351: 3, 360: 3, 379: 3, 401: 3, 587: 3, 731: 3, 837: 3, 26: 2, 112: 2, 261: 2, 765: 2, 775: 2})
Total buffer: 7062
fit_time: 59.17879737599999

Accuracy for 44 task(s): 	 [Class-IL]: 69.8 % 	 [Task-IL]: 30.27 %

CLASS_IL_ACC: 
	[78.83597883597884, 76.99115044247787, 67.27272727272727, 71.42857142857143, 46.875, 75.23809523809524, 77.0, 74.30555555555556, 65.76576576576578, 79.46428571428571, 83.33333333333334, 61.40350877192983, 75.89285714285714, 66.95652173913044, 60.952380952380956, 72.54901960784314, 82.2429906542056, 71.42857142857143, 79.83193277310924, 65.74074074074075, 63.888888888888886, 57.49999999999999, 75.63025210084034, 75.45454545454545, 69.23076923076923, 77.27272727272727, 70.37037037037037, 57.377049180327866, 64.64646464646465, 72.41379310344827, 57.391304347826086, 79.46428571428571, 63.10679611650486, 74.33628318584071, 66.92913385826772, 76.69902912621359, 67.0103092783505, 75.0, 67.24137931034483, 75.65217391304347, 81.44329896907216, 51.041666666666664, 53.48837209302325, 65.2542372881356]
TASK_IL_ACC: 
	[58.201058201058196, 26.548672566371685, 25.454545454545453, 27.55102040816326, 28.125, 29.523809523809526, 28.000000000000004, 30.555555555555557, 28.82882882882883, 34.82142857142857, 27.77777777777778, 34.21052631578947, 31.25, 25.217391304347824, 30.476190476190478, 32.35294117647059, 31.775700934579437, 21.428571428571427, 32.773109243697476, 23.14814814814815, 30.555555555555557, 26.666666666666668, 23.52941176470588, 25.454545454545453, 29.914529914529915, 40.0, 28.888888888888886, 22.131147540983605, 29.292929292929294, 26.436781609195403, 24.347826086956523, 23.214285714285715, 31.06796116504854, 35.39823008849557, 27.559055118110237, 33.00970873786408, 22.68041237113402, 17.857142857142858, 28.448275862068968, 36.52173913043478, 26.804123711340207, 22.916666666666664, 27.906976744186046, 83.05084745762711]
f1_micro: 70.08338417734392
f1_macro: 67.60979639669807
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       1.00      1.00      1.00         4
           2       1.00      1.00      1.00         4
           3       1.00      1.00      1.00         9
           4       0.67      0.67      0.67         9
           5       0.80      0.89      0.84         9
           6       1.00      1.00      1.00         4
           7       1.00      0.75      0.86         4
           8       0.55      0.67      0.60         9
           9       0.00      0.00      0.00         4
          10       1.00      1.00      1.00         9
          11       0.80      1.00      0.89         4
          12       1.00      0.25      0.40         4
          13       1.00      1.00      1.00         5
          14       1.00      0.75      0.86         4
          15       0.67      0.50      0.57         4
          16       1.00      0.60      0.75         5
          17       1.00      1.00      1.00         9
          18       0.50      0.50      0.50         4
          19       1.00      0.89      0.94         9
          20       1.00      0.75      0.86         4
          21       1.00      0.75      0.86         4
          22       1.00      1.00      1.00         5
          23       0.80      0.89      0.84         9
          24       1.00      0.75      0.86         4
          25       1.00      1.00      1.00         4
          26       0.00      0.00      0.00         4
          27       0.00      0.00      0.00         4
          28       0.40      0.50      0.44         4
          29       0.82      1.00      0.90         9
          30       1.00      1.00      1.00         9
          31       0.80      1.00      0.89         4
          32       1.00      0.25      0.40         4
          33       1.00      1.00      1.00         4
          34       0.75      0.75      0.75         4
          35       0.75      0.75      0.75         4
          36       0.80      0.80      0.80         5
          37       0.38      0.75      0.50         4
          38       0.80      1.00      0.89         4
          39       1.00      0.89      0.94         9
          40       1.00      1.00      1.00         4
          41       0.38      0.56      0.45         9
          42       0.00      0.00      0.00         4
          43       0.60      0.75      0.67         4
          44       0.00      0.00      0.00         4
          45       1.00      0.80      0.89         5
          46       0.80      1.00      0.89         4
          47       0.56      1.00      0.71         5
          48       0.75      1.00      0.86         9
          49       0.75      0.67      0.71         9
          50       1.00      1.00      1.00         9
          51       0.00      0.00      0.00         4
          52       1.00      1.00      1.00         9
          53       0.80      1.00      0.89         4
          54       0.80      1.00      0.89         4
          55       0.00      0.00      0.00         4
          56       1.00      0.75      0.86         8
          57       0.00      0.00      0.00         4
          58       0.75      0.75      0.75         4
          59       1.00      0.80      0.89         5
          60       0.07      0.11      0.09         9
          61       0.50      0.60      0.55         5
          62       1.00      1.00      1.00         5
          63       0.88      0.78      0.82         9
          64       0.50      0.25      0.33         4
          65       0.86      0.67      0.75         9
          66       0.83      1.00      0.91         5
          67       0.83      1.00      0.91         5
          68       1.00      0.75      0.86         4
          69       1.00      1.00      1.00         4
          70       0.80      0.80      0.80         5
          71       0.82      1.00      0.90         9
          72       0.67      0.50      0.57         4
          73       0.29      0.50      0.36         4
          74       0.80      0.80      0.80         5
          75       0.80      1.00      0.89         4
          76       0.67      1.00      0.80         4
          77       1.00      0.67      0.80         9
          78       0.67      0.50      0.57         4
          79       0.57      1.00      0.73         4
          80       0.80      0.80      0.80         5
          81       1.00      0.50      0.67         4
          82       0.80      0.89      0.84         9
          83       0.80      1.00      0.89         4
          84       1.00      0.50      0.67         4
          85       0.00      0.00      0.00         4
          86       0.00      0.00      0.00         4
          87       0.90      1.00      0.95         9
          88       0.75      0.75      0.75         4
          89       1.00      1.00      1.00         4
          90       0.50      0.60      0.55         5
          91       0.00      0.00      0.00         4
          92       1.00      0.75      0.86         4
          93       0.80      1.00      0.89         4
          94       1.00      1.00      1.00         4
          95       1.00      1.00      1.00         4
          96       0.75      0.75      0.75         4
          97       0.00      0.00      0.00         4
          98       0.89      0.89      0.89         9
          99       0.80      1.00      0.89         4
         100       0.00      0.00      0.00         4
         101       0.00      0.00      0.00         4
         102       1.00      1.00      1.00         4
         103       0.40      0.50      0.44         4
         104       1.00      0.80      0.89         5
         105       0.00      0.00      0.00         4
         106       1.00      0.50      0.67         4
         107       0.25      0.25      0.25         4
         108       0.07      0.25      0.11         4
         109       0.50      0.50      0.50         4
         110       0.38      0.33      0.35         9
         111       1.00      0.75      0.86         4
         112       0.00      0.00      0.00         4
         113       0.00      0.00      0.00         9
         114       0.83      1.00      0.91         5
         115       0.50      0.75      0.60         4
         116       1.00      0.80      0.89         5
         117       0.80      1.00      0.89         4
         118       0.90      1.00      0.95         9
         119       0.75      0.75      0.75         4
         120       0.83      1.00      0.91         5
         121       0.50      0.50      0.50         4
         122       0.00      0.00      0.00         4
         123       0.00      0.00      0.00         4
         124       1.00      0.75      0.86         4
         125       0.00      0.00      0.00         4
         126       1.00      0.75      0.86         4
         127       0.80      1.00      0.89         4
         128       0.60      0.75      0.67         4
         129       1.00      0.80      0.89         5
         130       0.83      1.00      0.91         5
         131       0.89      0.89      0.89         9
         132       0.75      0.67      0.71         9
         133       1.00      0.89      0.94         9
         134       0.71      1.00      0.83         5
         135       1.00      0.80      0.89         5
         136       0.67      0.40      0.50         5
         137       0.50      0.60      0.55         5
         138       0.80      0.80      0.80         5
         139       0.00      0.00      0.00         4
         140       1.00      0.75      0.86         4
         141       0.90      1.00      0.95         9
         142       0.80      1.00      0.89         4
         143       1.00      1.00      1.00         4
         144       1.00      0.75      0.86         4
         145       1.00      0.25      0.40         4
         146       1.00      1.00      1.00         5
         147       1.00      0.50      0.67         4
         148       1.00      0.60      0.75         5
         149       0.67      0.80      0.73         5
         150       1.00      1.00      1.00         5
         151       1.00      0.89      0.94         9
         152       0.67      0.80      0.73         5
         153       1.00      1.00      1.00         4
         154       0.88      0.78      0.82         9
         155       0.88      1.00      0.93         7
         156       1.00      0.75      0.86         4
         157       0.00      0.00      0.00         9
         158       0.67      0.67      0.67         9
         159       0.90      1.00      0.95         9
         160       0.60      0.75      0.67         4
         161       0.89      0.89      0.89         9
         162       0.75      0.75      0.75         4
         163       0.80      1.00      0.89         4
         164       1.00      1.00      1.00         4
         165       0.50      0.44      0.47         9
         166       1.00      0.75      0.86         4
         167       0.88      0.78      0.82         9
         168       0.75      0.67      0.71         9
         169       0.73      0.89      0.80         9
         170       0.80      0.89      0.84         9
         171       1.00      1.00      1.00         5
         172       0.55      0.67      0.60         9
         173       0.55      0.67      0.60         9
         174       0.80      1.00      0.89         4
         175       0.00      0.00      0.00         9
         176       0.80      0.89      0.84         9
         177       0.75      0.60      0.67         5
         178       0.57      1.00      0.73         4
         179       1.00      0.60      0.75         5
         180       1.00      0.80      0.89         5
         181       1.00      0.80      0.89         5
         182       0.67      1.00      0.80         4
         183       1.00      0.50      0.67         4
         184       1.00      0.20      0.33         5
         185       1.00      0.75      0.86         4
         186       0.50      0.75      0.60         4
         187       0.64      0.78      0.70         9
         188       0.00      0.00      0.00         4
         189       0.75      0.60      0.67         5
         190       1.00      1.00      1.00         4
         191       0.70      0.78      0.74         9
         192       0.90      1.00      0.95         9
         193       0.00      0.00      0.00         4
         194       0.73      0.89      0.80         9
         195       0.83      0.56      0.67         9
         196       0.67      1.00      0.80         4
         197       0.89      0.89      0.89         9
         198       0.57      1.00      0.73         4
         199       1.00      0.80      0.89         5
         200       1.00      1.00      1.00         4
         201       0.50      0.75      0.60         4
         202       0.67      1.00      0.80         8
         203       0.90      1.00      0.95         9
         204       0.50      0.25      0.33         4
         205       1.00      0.75      0.86         4
         206       0.00      0.00      0.00         4
         207       0.00      0.00      0.00         4
         208       1.00      1.00      1.00         4
         209       0.57      1.00      0.73         4
         210       0.71      1.00      0.83         5
         211       1.00      1.00      1.00         5
         212       0.75      0.75      0.75         4
         213       0.70      0.78      0.74         9
         214       0.00      0.00      0.00         4
         215       1.00      1.00      1.00         4
         216       1.00      1.00      1.00         5
         217       1.00      1.00      1.00         4
         218       1.00      0.89      0.94         9
         219       0.67      1.00      0.80         4
         220       1.00      1.00      1.00         5
         221       0.50      1.00      0.67         4
         222       0.00      0.00      0.00         4
         223       1.00      1.00      1.00         9
         224       1.00      0.75      0.86         4
         225       0.90      1.00      0.95         9
         226       0.83      0.71      0.77         7
         227       1.00      0.89      0.94         9
         228       1.00      1.00      1.00         4
         229       0.50      0.80      0.62         5
         230       0.50      0.50      0.50         4
         231       0.83      1.00      0.91         5
         232       0.75      0.60      0.67         5
         233       1.00      1.00      1.00         4
         234       0.67      0.40      0.50         5
         235       1.00      1.00      1.00         4
         236       1.00      0.89      0.94         9
         237       1.00      1.00      1.00         4
         238       0.82      1.00      0.90         9
         239       0.22      0.22      0.22         9
         240       0.80      1.00      0.89         4
         241       0.80      1.00      0.89         4
         242       0.80      1.00      0.89         4
         243       0.17      0.20      0.18         5
         244       0.80      0.80      0.80         5
         245       0.00      0.00      0.00         4
         246       0.67      0.50      0.57         4
         247       1.00      1.00      1.00         4
         248       1.00      1.00      1.00         9
         249       0.00      0.00      0.00         5
         250       0.00      0.00      0.00         4
         251       1.00      1.00      1.00         9
         252       0.00      0.00      0.00         9
         253       0.00      0.00      0.00         4
         254       0.00      0.00      0.00         4
         255       0.90      1.00      0.95         9
         256       1.00      0.80      0.89         5
         257       0.80      1.00      0.89         4
         258       0.90      1.00      0.95         9
         259       1.00      0.75      0.86         4
         260       0.57      1.00      0.73         4
         261       1.00      0.75      0.86         4
         262       0.89      0.89      0.89         9
         263       0.10      0.25      0.14         4
         264       0.38      0.33      0.35         9
         265       1.00      0.75      0.86         4
         266       1.00      1.00      1.00         5
         267       0.00      0.00      0.00         4
         268       0.67      1.00      0.80         4
         269       0.75      0.75      0.75         4
         270       0.88      0.78      0.82         9
         271       1.00      1.00      1.00         9
         272       1.00      1.00      1.00         4
         273       0.29      0.50      0.36         4
         274       1.00      1.00      1.00         5
         275       0.00      0.00      0.00         9
         276       0.12      0.25      0.17         4
         277       0.75      0.75      0.75         4
         278       1.00      0.25      0.40         4
         279       0.64      0.78      0.70         9
         280       0.83      1.00      0.91         5
         281       0.50      0.25      0.33         4
         282       1.00      1.00      1.00         5
         283       0.83      1.00      0.91         5
         284       0.57      1.00      0.73         4
         285       0.40      0.57      0.47         7
         286       0.75      0.75      0.75         4
         287       0.56      0.56      0.56         9
         288       1.00      0.75      0.86         4
         289       0.80      0.80      0.80         5
         290       0.57      0.80      0.67         5
         291       1.00      0.80      0.89         5
         292       0.83      0.56      0.67         9
         293       0.89      0.89      0.89         9
         294       0.00      0.00      0.00         5
         295       0.83      1.00      0.91         5
         296       0.67      0.50      0.57         4
         297       0.90      1.00      0.95         9
         298       1.00      1.00      1.00         4
         299       1.00      0.80      0.89         5
         300       1.00      1.00      1.00         5
         301       1.00      0.75      0.86         4
         302       0.50      0.25      0.33         4
         303       0.00      0.00      0.00         4
         304       0.00      0.00      0.00         4
         305       1.00      0.75      0.86         4
         306       0.11      0.25      0.15         4
         307       1.00      1.00      1.00         4
         308       0.00      0.00      0.00         4
         309       0.50      0.22      0.31         9
         310       1.00      0.75      0.86         4
         311       0.83      1.00      0.91         5
         312       0.86      0.67      0.75         9
         313       1.00      0.78      0.88         9
         314       0.40      0.44      0.42         9
         315       0.86      0.67      0.75         9
         316       1.00      1.00      1.00         4
         317       1.00      1.00      1.00         4
         318       0.50      1.00      0.67         4
         319       0.31      0.80      0.44         5
         320       1.00      1.00      1.00         4
         321       0.00      0.00      0.00         4
         322       0.33      0.50      0.40         4
         323       1.00      0.80      0.89         5
         324       0.58      0.78      0.67         9
         325       0.00      0.00      0.00         4
         326       0.75      0.75      0.75         4
         327       1.00      1.00      1.00         4
         328       1.00      0.50      0.67         4
         329       0.90      1.00      0.95         9
         330       1.00      1.00      1.00         4
         331       1.00      0.75      0.86         4
         332       1.00      0.75      0.86         4
         333       0.75      0.75      0.75         4
         334       0.90      1.00      0.95         9
         335       1.00      1.00      1.00         4
         336       0.60      0.75      0.67         4
         337       1.00      0.78      0.88         9
         338       1.00      1.00      1.00         4
         339       0.50      0.25      0.33         4
         340       0.44      0.78      0.56         9
         341       0.57      1.00      0.73         4
         342       0.83      1.00      0.91         5
         343       1.00      0.75      0.86         4
         344       0.00      0.00      0.00         4
         345       1.00      1.00      1.00         5
         346       1.00      1.00      1.00         9
         347       1.00      0.50      0.67         4
         348       0.67      1.00      0.80         4
         349       0.82      1.00      0.90         9
         350       0.50      0.50      0.50         4
         351       1.00      1.00      1.00         4
         352       0.40      0.50      0.44         4
         353       0.67      1.00      0.80         4
         354       0.10      0.25      0.14         4
         355       0.80      1.00      0.89         4
         356       0.00      0.00      0.00         4
         357       0.50      0.75      0.60         4
         358       0.67      0.50      0.57         4
         359       0.60      0.75      0.67         4
         360       0.00      0.00      0.00         4
         361       1.00      1.00      1.00         9
         362       1.00      1.00      1.00         5
         363       1.00      1.00      1.00         4
         364       0.50      1.00      0.67         4
         365       1.00      0.75      0.86         4
         366       0.89      0.89      0.89         9
         367       0.73      0.89      0.80         9
         368       0.00      0.00      0.00         4
         369       1.00      1.00      1.00         5
         370       0.62      0.56      0.59         9
         371       0.71      0.56      0.63         9
         372       1.00      1.00      1.00         9
         373       0.67      0.50      0.57         4
         374       0.60      0.67      0.63         9
         375       0.64      0.78      0.70         9
         376       0.75      0.75      0.75         4
         377       1.00      1.00      1.00         5
         378       0.80      0.89      0.84         9
         379       0.67      0.50      0.57         4
         380       0.80      1.00      0.89         4
         381       0.89      0.89      0.89         9
         382       1.00      0.75      0.86         4
         383       0.20      0.20      0.20         5
         384       1.00      0.89      0.94         9
         385       1.00      1.00      1.00         9
         386       0.67      0.80      0.73         5
         387       1.00      1.00      1.00         4
         388       1.00      0.89      0.94         9
         389       0.67      0.50      0.57         4
         390       0.44      1.00      0.62         4
         391       1.00      1.00      1.00         4
         392       1.00      0.80      0.89         5
         393       0.05      0.25      0.09         4
         394       1.00      1.00      1.00         4
         395       1.00      1.00      1.00         4
         396       1.00      1.00      1.00         4
         397       0.89      0.89      0.89         9
         398       0.00      0.00      0.00         4
         399       1.00      1.00      1.00         4
         400       0.00      0.00      0.00         4
         401       0.00      0.00      0.00         4
         402       1.00      0.75      0.86         4
         403       0.67      0.50      0.57         4
         404       0.67      0.40      0.50         5
         405       0.50      0.33      0.40         9
         406       0.83      0.56      0.67         9
         407       0.83      1.00      0.91         5
         408       1.00      0.50      0.67         4
         409       0.50      0.75      0.60         4
         410       0.67      0.67      0.67         9
         411       1.00      0.89      0.94         9
         412       0.75      0.75      0.75         4
         413       0.71      1.00      0.83         5
         414       0.57      0.80      0.67         5
         415       1.00      0.75      0.86         4
         416       0.08      0.11      0.10         9
         417       0.75      0.75      0.75         4
         418       0.89      0.89      0.89         9
         419       0.60      0.75      0.67         4
         420       1.00      0.50      0.67         4
         421       0.00      0.00      0.00         4
         422       0.67      0.50      0.57         4
         423       0.80      1.00      0.89         4
         424       1.00      1.00      1.00         4
         425       1.00      0.75      0.86         4
         426       0.89      0.89      0.89         9
         427       1.00      0.89      0.94         9
         428       0.83      1.00      0.91         5
         429       1.00      0.75      0.86         4
         430       1.00      1.00      1.00         4
         431       0.00      0.00      0.00         9
         432       1.00      0.40      0.57         5
         433       0.50      0.50      0.50         4
         434       0.00      0.00      0.00         4
         435       1.00      0.89      0.94         9
         436       0.64      0.78      0.70         9
         437       0.00      0.00      0.00         4
         438       0.67      0.50      0.57         4
         439       0.05      0.11      0.07         9
         440       1.00      1.00      1.00         4
         441       1.00      1.00      1.00         4
         442       0.75      0.75      0.75         4
         443       1.00      1.00      1.00         4
         444       1.00      0.56      0.71         9
         445       0.00      0.00      0.00         9
         446       0.80      1.00      0.89         4
         447       0.00      0.00      0.00         4
         448       0.80      1.00      0.89         4
         449       1.00      1.00      1.00         9
         450       0.58      0.78      0.67         9
         451       0.75      0.75      0.75         4
         452       0.25      0.25      0.25         4
         453       0.27      0.33      0.30         9
         454       0.67      1.00      0.80         4
         455       0.50      0.78      0.61         9
         456       1.00      1.00      1.00         5
         457       1.00      0.75      0.86         4
         458       0.00      0.00      0.00         4
         459       0.00      0.00      0.00         4
         460       0.78      0.78      0.78         9
         461       0.50      0.50      0.50         4
         462       0.50      0.75      0.60         4
         463       0.83      1.00      0.91         5
         464       0.75      1.00      0.86         9
         465       0.67      0.50      0.57         4
         466       1.00      0.60      0.75         5
         467       1.00      0.89      0.94         9
         468       1.00      0.67      0.80         9
         469       0.80      0.89      0.84         9
         470       1.00      1.00      1.00         4
         471       1.00      0.78      0.88         9
         472       1.00      1.00      1.00         4
         473       0.75      0.60      0.67         5
         474       0.67      0.50      0.57         4
         475       1.00      1.00      1.00         5
         476       1.00      1.00      1.00         4
         477       0.33      0.25      0.29         4
         478       1.00      0.78      0.88         9
         479       0.00      0.00      0.00         4
         480       0.67      1.00      0.80         4
         481       1.00      0.75      0.86         4
         482       1.00      0.50      0.67         4
         483       1.00      1.00      1.00         4
         484       1.00      0.80      0.89         5
         485       0.71      1.00      0.83         5
         486       1.00      1.00      1.00         4
         487       1.00      1.00      1.00         5
         488       0.80      0.80      0.80         5
         489       0.86      0.67      0.75         9
         490       0.73      0.89      0.80         9
         491       1.00      0.89      0.94         9
         492       1.00      0.75      0.86         4
         493       0.50      0.44      0.47         9
         494       1.00      0.75      0.86         4
         495       1.00      1.00      1.00         9
         496       0.60      0.75      0.67         4
         497       0.83      1.00      0.91         5
         498       1.00      0.75      0.86         4
         499       0.90      1.00      0.95         9
         500       0.50      0.50      0.50         4
         501       0.11      0.11      0.11         9
         502       0.67      0.50      0.57         4
         503       1.00      0.60      0.75         5
         504       0.00      0.00      0.00         4
         505       1.00      1.00      1.00         4
         506       0.70      0.78      0.74         9
         507       0.00      0.00      0.00         4
         508       1.00      0.89      0.94         9
         509       1.00      0.89      0.94         9
         510       0.86      0.67      0.75         9
         511       1.00      0.25      0.40         4
         512       0.67      1.00      0.80         4
         513       0.60      0.75      0.67         4
         514       1.00      1.00      1.00         5
         515       1.00      1.00      1.00         9
         516       0.67      0.67      0.67         9
         517       0.90      1.00      0.95         9
         518       0.88      0.78      0.82         9
         519       0.67      1.00      0.80         4
         520       1.00      1.00      1.00         5
         521       0.00      0.00      0.00         4
         522       0.67      0.50      0.57         4
         523       0.67      0.50      0.57         4
         524       0.33      0.25      0.29         4
         525       0.33      0.25      0.29         4
         526       1.00      1.00      1.00         4
         527       1.00      0.89      0.94         9
         528       0.00      0.00      0.00         4
         529       1.00      1.00      1.00         5
         530       0.43      0.75      0.55         4
         531       0.80      1.00      0.89         4
         532       1.00      1.00      1.00         5
         533       1.00      1.00      1.00         5
         534       0.75      0.75      0.75         4
         535       0.00      0.00      0.00         9
         536       1.00      1.00      1.00         9
         537       0.90      1.00      0.95         9
         538       0.00      0.00      0.00         4
         539       1.00      1.00      1.00         5
         540       1.00      0.67      0.80         9
         541       0.83      1.00      0.91         5
         542       1.00      0.89      0.94         9
         543       0.75      0.67      0.71         9
         544       0.83      1.00      0.91         5
         545       0.50      0.33      0.40         9
         546       0.80      1.00      0.89         4
         547       0.83      1.00      0.91         5
         548       0.00      0.00      0.00         4
         549       0.50      0.67      0.57         9
         550       0.80      0.80      0.80         5
         551       0.67      0.50      0.57         4
         552       0.90      1.00      0.95         9
         553       0.60      0.67      0.63         9
         554       0.33      0.40      0.36         5
         555       0.00      0.00      0.00         4
         556       1.00      1.00      1.00         4
         557       1.00      0.75      0.86         4
         558       0.78      0.78      0.78         9
         559       1.00      1.00      1.00         4
         560       0.50      0.22      0.31         9
         561       1.00      0.80      0.89         5
         562       0.80      1.00      0.89         4
         563       0.78      0.78      0.78         9
         564       1.00      1.00      1.00         4
         565       0.00      0.00      0.00         4
         566       1.00      1.00      1.00         9
         567       0.14      0.25      0.18         4
         568       0.50      1.00      0.67         4
         569       0.00      0.00      0.00         9
         570       0.78      0.78      0.78         9
         571       1.00      0.89      0.94         9
         572       0.00      0.00      0.00         4
         573       0.00      0.00      0.00         9
         574       1.00      0.75      0.86         4
         575       1.00      1.00      1.00         9
         576       0.50      0.40      0.44         5
         577       1.00      1.00      1.00         4
         578       1.00      1.00      1.00         4
         579       0.67      0.40      0.50         5
         580       1.00      0.44      0.62         9
         581       0.00      0.00      0.00         4
         582       1.00      0.80      0.89         5
         583       0.83      1.00      0.91         5
         584       0.00      0.00      0.00         4
         585       0.00      0.00      0.00         4
         586       1.00      0.75      0.86         4
         587       1.00      1.00      1.00         4
         588       0.60      0.67      0.63         9
         589       0.67      0.50      0.57         4
         590       0.80      1.00      0.89         4
         591       0.00      0.00      0.00         4
         592       0.80      1.00      0.89         4
         593       1.00      1.00      1.00         4
         594       1.00      0.75      0.86         4
         595       1.00      0.50      0.67         4
         596       1.00      0.50      0.67         4
         597       0.75      0.75      0.75         4
         598       1.00      1.00      1.00         4
         599       0.80      1.00      0.89         4
         600       1.00      0.75      0.86         4
         601       0.67      0.50      0.57         4
         602       1.00      1.00      1.00         4
         603       1.00      1.00      1.00         4
         604       0.80      0.80      0.80         5
         605       0.57      1.00      0.73         4
         606       0.50      0.75      0.60         4
         607       0.00      0.00      0.00         4
         608       1.00      0.60      0.75         5
         609       0.75      0.75      0.75         4
         610       0.75      0.75      0.75         4
         611       0.80      1.00      0.89         4
         612       0.00      0.00      0.00         4
         613       0.89      0.89      0.89         9
         614       0.50      0.75      0.60         4
         615       0.78      0.78      0.78         9
         616       0.00      0.00      0.00         4
         617       0.00      0.00      0.00         4
         618       1.00      1.00      1.00         4
         619       0.12      0.20      0.15         5
         620       1.00      1.00      1.00         9
         621       1.00      0.50      0.67         4
         622       0.83      1.00      0.91         5
         623       0.67      0.40      0.50         5
         624       0.00      0.00      0.00         4
         625       1.00      0.89      0.94         9
         626       1.00      0.22      0.36         9
         627       0.67      0.40      0.50         5
         628       0.00      0.00      0.00         4
         629       0.88      0.78      0.82         9
         630       0.83      1.00      0.91         5
         631       0.67      0.50      0.57         4
         632       1.00      0.78      0.88         9
         633       0.00      0.00      0.00         4
         634       1.00      0.75      0.86         4
         635       0.00      0.00      0.00         4
         636       0.62      0.89      0.73         9
         637       1.00      1.00      1.00         4
         638       0.75      0.75      0.75         4
         639       0.80      1.00      0.89         4
         640       0.82      1.00      0.90         9
         641       0.80      1.00      0.89         4
         642       1.00      1.00      1.00         9
         643       0.80      0.89      0.84         9
         644       1.00      1.00      1.00         4
         645       1.00      0.75      0.86         4
         646       0.00      0.00      0.00         4
         647       0.33      0.20      0.25         5
         648       0.80      1.00      0.89         4
         649       1.00      0.75      0.86         4
         650       1.00      1.00      1.00         5
         651       0.80      0.89      0.84         9
         652       0.80      1.00      0.89         4
         653       0.56      0.56      0.56         9
         654       0.80      0.67      0.73         6
         655       1.00      0.89      0.94         9
         656       1.00      0.50      0.67         4
         657       0.67      1.00      0.80         4
         658       0.62      1.00      0.77         5
         659       0.80      1.00      0.89         4
         660       1.00      1.00      1.00         4
         661       0.67      0.50      0.57         4
         662       1.00      1.00      1.00         4
         663       0.67      1.00      0.80         4
         664       0.67      0.50      0.57         4
         665       1.00      0.75      0.86         4
         666       0.67      1.00      0.80         4
         667       0.54      0.78      0.64         9
         668       0.75      0.75      0.75         4
         669       0.12      0.11      0.12         9
         670       1.00      0.25      0.40         4
         671       0.00      0.00      0.00         9
         672       0.29      0.50      0.36         4
         673       0.33      0.25      0.29         4
         674       1.00      0.89      0.94         9
         675       1.00      1.00      1.00         9
         676       1.00      1.00      1.00         9
         677       1.00      1.00      1.00         4
         678       0.60      0.75      0.67         4
         679       1.00      1.00      1.00         5
         680       0.80      1.00      0.89         4
         681       0.67      0.50      0.57         4
         682       0.00      0.00      0.00         4
         683       0.78      0.88      0.82         8
         684       0.00      0.00      0.00         4
         685       0.75      0.75      0.75         4
         686       1.00      0.80      0.89         5
         687       0.00      0.00      0.00         4
         688       1.00      1.00      1.00         5
         689       1.00      0.89      0.94         9
         690       0.00      0.00      0.00         4
         691       1.00      0.78      0.88         9
         692       0.60      0.75      0.67         4
         693       1.00      0.60      0.75         5
         694       1.00      1.00      1.00         4
         695       1.00      0.56      0.71         9
         696       0.67      0.80      0.73         5
         697       1.00      0.75      0.86         4
         698       1.00      1.00      1.00         4
         699       0.78      0.78      0.78         9
         700       0.00      0.00      0.00         4
         701       0.80      1.00      0.89         4
         702       0.83      1.00      0.91         5
         703       0.78      0.78      0.78         9
         704       0.80      1.00      0.89         4
         705       1.00      0.78      0.88         9
         706       0.78      0.78      0.78         9
         707       0.00      0.00      0.00         9
         708       1.00      0.78      0.88         9
         709       1.00      0.25      0.40         4
         710       0.67      0.44      0.53         9
         711       0.50      0.25      0.33         4
         712       0.80      1.00      0.89         4
         713       0.78      0.78      0.78         9
         714       1.00      1.00      1.00         9
         715       1.00      0.80      0.89         5
         716       0.17      0.25      0.20         4
         717       1.00      1.00      1.00         4
         718       1.00      1.00      1.00         9
         719       1.00      0.75      0.86         4
         720       0.55      0.67      0.60         9
         721       0.80      0.80      0.80         5
         722       0.90      1.00      0.95         9
         723       0.83      1.00      0.91         5
         724       0.67      1.00      0.80         4
         725       0.75      0.75      0.75         4
         726       0.67      1.00      0.80         4
         727       1.00      1.00      1.00         4
         728       0.00      0.00      0.00         4
         729       0.50      0.25      0.33         4
         730       0.07      0.25      0.11         4
         731       0.00      0.00      0.00         4
         732       1.00      1.00      1.00         4
         733       1.00      1.00      1.00         4
         734       0.00      0.00      0.00         4
         735       0.75      0.75      0.75         4
         736       0.75      0.60      0.67         5
         737       1.00      1.00      1.00         4
         738       0.83      0.56      0.67         9
         739       1.00      0.75      0.86         4
         740       0.75      0.75      0.75         4
         741       1.00      0.44      0.62         9
         742       0.75      0.75      0.75         4
         743       0.00      0.00      0.00         4
         744       1.00      1.00      1.00         4
         745       0.00      0.00      0.00         4
         746       1.00      0.75      0.86         4
         747       0.67      1.00      0.80         4
         748       1.00      1.00      1.00         4
         749       1.00      1.00      1.00         5
         750       0.80      1.00      0.89         4
         751       0.86      0.67      0.75         9
         752       1.00      0.75      0.86         4
         753       0.67      1.00      0.80         4
         754       0.80      1.00      0.89         4
         755       0.00      0.00      0.00         4
         756       0.00      0.00      0.00         4
         757       0.83      1.00      0.91         5
         758       0.50      0.25      0.33         4
         759       0.40      0.50      0.44         4
         760       0.88      0.78      0.82         9
         761       0.82      1.00      0.90         9
         762       1.00      0.78      0.88         9
         763       0.67      0.89      0.76         9
         764       0.44      1.00      0.62         4
         765       1.00      0.50      0.67         4
         766       1.00      1.00      1.00         4
         767       0.00      0.00      0.00         4
         768       1.00      0.80      0.89         5
         769       1.00      1.00      1.00         9
         770       1.00      0.75      0.86         4
         771       0.50      0.75      0.60         4
         772       0.75      0.75      0.75         4
         773       1.00      1.00      1.00         9
         774       1.00      0.89      0.94         9
         775       0.00      0.00      0.00         4
         776       0.89      0.89      0.89         9
         777       0.75      0.75      0.75         4
         778       0.00      0.00      0.00         4
         779       1.00      0.50      0.67         4
         780       0.00      0.00      0.00         4
         781       0.80      1.00      0.89         4
         782       0.89      0.89      0.89         9
         783       1.00      0.50      0.67         4
         784       0.56      0.56      0.56         9
         785       0.75      1.00      0.86         9
         786       1.00      0.89      0.94         9
         787       1.00      0.75      0.86         4
         788       0.80      1.00      0.89         4
         789       0.70      0.78      0.74         9
         790       0.38      0.60      0.46         5
         791       0.80      1.00      0.89         4
         792       0.00      0.00      0.00         4
         793       0.00      0.00      0.00         4
         794       0.56      1.00      0.71         5
         795       0.89      0.89      0.89         9
         796       0.83      0.56      0.67         9
         797       0.67      0.67      0.67         9
         798       1.00      1.00      1.00         4
         799       1.00      0.67      0.80         9
         800       1.00      1.00      1.00         4
         801       0.90      1.00      0.95         9
         802       0.80      1.00      0.89         4
         803       1.00      1.00      1.00         5
         804       0.00      0.00      0.00         4
         805       1.00      0.20      0.33         5
         806       1.00      1.00      1.00         4
         807       1.00      1.00      1.00         4
         808       0.50      0.40      0.44         5
         809       1.00      1.00      1.00         5
         810       0.78      0.78      0.78         9
         811       0.33      0.50      0.40         4
         812       0.75      0.75      0.75         4
         813       1.00      0.75      0.86         4
         814       1.00      0.80      0.89         5
         815       1.00      0.75      0.86         4
         816       1.00      1.00      1.00         5
         817       1.00      1.00      1.00         4
         818       0.80      0.80      0.80         5
         819       0.75      0.75      0.75         4
         820       1.00      0.80      0.89         5
         821       0.75      0.75      0.75         4
         822       1.00      0.67      0.80         9
         823       0.83      1.00      0.91         5
         824       0.75      0.75      0.75         4
         825       0.00      0.00      0.00         4
         826       1.00      1.00      1.00         5
         827       0.83      1.00      0.91         5
         828       0.75      0.75      0.75         4
         829       0.57      1.00      0.73         4
         830       0.80      1.00      0.89         4
         831       1.00      0.67      0.80         9
         832       0.80      1.00      0.89         4
         833       0.80      1.00      0.89         4
         834       0.08      0.11      0.10         9
         835       0.33      0.25      0.29         4
         836       0.33      0.25      0.29         4
         837       0.00      0.00      0.00         4
         838       0.67      1.00      0.80         4
         839       0.50      0.50      0.50         4
         840       1.00      1.00      1.00         4
         841       0.00      0.00      0.00         4
         842       0.67      1.00      0.80         4
         843       1.00      0.50      0.67         4
         844       0.73      0.89      0.80         9
         845       1.00      1.00      1.00         5
         846       0.00      0.00      0.00         4
         847       0.00      0.00      0.00         4
         848       0.50      0.56      0.53         9
         849       0.80      1.00      0.89         4
         850       0.75      0.75      0.75         4
         851       0.14      0.25      0.18         4
         852       0.75      0.75      0.75         4
         853       0.20      0.25      0.22         4
         854       0.00      0.00      0.00         4
         855       0.80      1.00      0.89         4
         856       0.00      0.00      0.00         9
         857       0.00      0.00      0.00         4
         858       1.00      1.00      1.00         4
         859       0.60      0.75      0.67         4
         860       1.00      1.00      1.00         4
         861       0.00      0.00      0.00         4
         862       1.00      0.75      0.86         4
         863       0.00      0.00      0.00         4
         864       0.60      0.75      0.67         4
         865       0.83      1.00      0.91         5
         866       1.00      0.25      0.40         4
         867       0.00      0.00      0.00         4
         868       0.75      0.75      0.75         4
         869       0.80      1.00      0.89         4
         870       0.80      1.00      0.89         4
         871       0.25      0.25      0.25         4
         872       1.00      1.00      1.00         4
         873       1.00      0.75      0.86         4
         874       0.00      0.00      0.00         9
         875       0.80      1.00      0.89         4
         876       0.90      1.00      0.95         9
         877       0.82      1.00      0.90         9
         878       1.00      0.50      0.67         4
         879       1.00      0.75      0.86         4
         880       1.00      1.00      1.00         5
         881       0.78      0.78      0.78         9
         882       0.08      0.11      0.09         9
         883       1.00      1.00      1.00         9
         884       0.00      0.00      0.00         4
         885       1.00      1.00      1.00         4
         886       1.00      0.75      0.86         4
         887       1.00      1.00      1.00         4
         888       1.00      0.50      0.67         4
         889       0.12      0.25      0.17         4
         890       0.00      0.00      0.00         4
         891       0.50      0.60      0.55         5
         892       0.67      0.40      0.50         5
         893       0.82      1.00      0.90         9

    accuracy                           0.70      4917
   macro avg       0.70      0.68      0.68      4917
weighted avg       0.72      0.70      0.70      4917

task_train_time: {0: 0.12035475000000062, 1: 0.032583024000000904, 2: 0.03367120000000057, 3: 0.02830443999999943, 4: 0.026798368999999767, 5: 0.030550912999999014, 6: 0.02762972300000044, 7: 0.04540109500000078, 8: 0.03275921400000037, 9: 0.032400854999998785, 10: 0.02978521800000067, 11: 0.03361848599999995, 12: 0.033640143999999594, 13: 0.034393989999999874, 14: 0.03110959099999988, 15: 0.029294636999999568, 16: 0.03151108399999991, 17: 0.0332459759999999, 18: 0.03541302900000076, 19: 0.0325031340000006, 20: 0.0328341769999998, 21: 0.03656506999999998, 22: 0.036714101000001165, 23: 0.0355447489999996, 24: 0.03553508000000072, 25: 0.03361499000000023, 26: 0.04445116099999957, 27: 0.04260792400000035, 28: 0.03222296200000052, 29: 0.028982332, 30: 0.03562357000000027, 31: 0.03681524099999933, 32: 0.03607243899999979, 33: 0.035834541999999914, 34: 0.041653505999999396, 35: 0.03466356400000059, 36: 0.03258085900000118, 37: 0.03664507899999947, 38: 0.03638633599999963, 39: 0.03826036299999913, 40: 0.030662923000001285, 41: 0.030693277999997548, 42: 0.024670146000001836, 43: 0.03755849599999905}
prediction_time: 0.0003190280000069379
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
