Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='b0e149bb-7b0f-4d87-bb53-b4d49c4c168e', conf_timestamp='2023-08-14 11:30:54.781089', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 82.47 % 	 [Task-IL]: 51.03 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 54.36 % 	 [Task-IL]: 38.39 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 43.24 % 	 [Task-IL]: 32.89 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 39.45 % 	 [Task-IL]: 32.13 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 27.58 % 	 [Task-IL]: 31.53 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 27.59 % 	 [Task-IL]: 31.84 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.35 % 	 [Task-IL]: 31.56 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 22.97 % 	 [Task-IL]: 30.71 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 19.23 % 	 [Task-IL]: 31.46 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 18.36 % 	 [Task-IL]: 31.28 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 15.8 % 	 [Task-IL]: 30.29 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.8 % 	 [Task-IL]: 29.51 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 14.07 % 	 [Task-IL]: 27.98 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 15.4 % 	 [Task-IL]: 28.55 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.45 % 	 [Task-IL]: 28.03 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 11.22 % 	 [Task-IL]: 28.52 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.24 % 	 [Task-IL]: 28.94 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 12.4 % 	 [Task-IL]: 28.58 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.76 % 	 [Task-IL]: 28.2 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.77 % 	 [Task-IL]: 27.85 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.39 % 	 [Task-IL]: 27.74 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.74 % 	 [Task-IL]: 27.44 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.47 % 	 [Task-IL]: 27.11 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.14 % 	 [Task-IL]: 27.26 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.78 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.58 % 	 [Task-IL]: 27.28 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.2 % 	 [Task-IL]: 27.28 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 8.14 % 	 [Task-IL]: 27.26 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.69 % 	 [Task-IL]: 26.98 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.68 % 	 [Task-IL]: 27.09 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.59 % 	 [Task-IL]: 27.04 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.27 % 	 [Task-IL]: 26.74 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.69 % 	 [Task-IL]: 26.34 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.28 % 	 [Task-IL]: 26.22 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.95 % 	 [Task-IL]: 26.22 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.09 % 	 [Task-IL]: 26.34 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.36 % 	 [Task-IL]: 26.18 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.51 % 	 [Task-IL]: 26.65 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.17 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.97 % 	 [Task-IL]: 26.31 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 6.52 % 	 [Task-IL]: 26.42 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.18 % 	 [Task-IL]: 26.85 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 6.03 % 	 [Task-IL]: 26.75 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({371: 26, 555: 25, 668: 25, 478: 25, 871: 24, 426: 24, 10: 23, 673: 23, 127: 23, 549: 23, 143: 23, 451: 23, 6: 22, 847: 22, 883: 22, 592: 22, 47: 22, 49: 22, 175: 22, 236: 22, 288: 22, 342: 22, 416: 22, 441: 22, 463: 22, 557: 21, 841: 21, 637: 21, 85: 21, 882: 21, 534: 21, 166: 21, 222: 21, 271: 21, 413: 21, 466: 21, 527: 21, 3: 20, 691: 20, 568: 20, 558: 20, 585: 20, 863: 20, 631: 20, 703: 20, 649: 20, 672: 20, 757: 20, 48: 20, 53: 20, 617: 20, 564: 20, 55: 20, 151: 20, 154: 20, 186: 20, 179: 20, 200: 20, 247: 20, 241: 20, 256: 20, 348: 20, 345: 20, 411: 20, 412: 20, 446: 20, 469: 20, 524: 20, 27: 19, 801: 19, 765: 19, 793: 19, 777: 19, 741: 19, 640: 19, 563: 19, 540: 19, 835: 19, 605: 19, 535: 19, 580: 19, 772: 19, 116: 19, 149: 19, 144: 19, 233: 19, 261: 19, 284: 19, 323: 19, 424: 19, 421: 19, 622: 18, 856: 18, 711: 18, 775: 18, 797: 18, 559: 18, 810: 18, 767: 18, 612: 18, 813: 18, 700: 18, 796: 18, 51: 18, 63: 18, 66: 18, 172: 18, 184: 18, 187: 18, 281: 18, 338: 18, 334: 18, 391: 18, 382: 18, 378: 18, 387: 18, 404: 18, 423: 18, 417: 18, 462: 18, 461: 18, 497: 18, 501: 18, 533: 18, 19: 17, 16: 17, 659: 17, 723: 17, 837: 17, 583: 17, 861: 17, 35: 17, 759: 17, 799: 17, 791: 17, 169: 17, 158: 17, 174: 17, 212: 17, 228: 17, 267: 17, 295: 17, 306: 17, 361: 17, 362: 17, 443: 17, 467: 17, 475: 17, 486: 17, 507: 17, 519: 17, 514: 17, 737: 16, 31: 16, 7: 16, 26: 16, 834: 16, 652: 16, 768: 16, 818: 16, 719: 16, 596: 16, 725: 16, 821: 16, 826: 16, 682: 16, 876: 16, 597: 16, 37: 16, 695: 16, 101: 16, 666: 16, 147: 16, 177: 16, 196: 16, 263: 16, 317: 16, 355: 16, 427: 16, 494: 16, 500: 16, 745: 15, 636: 15, 539: 15, 567: 15, 814: 15, 553: 15, 97: 15, 95: 15, 546: 15, 153: 15, 265: 15, 293: 15, 331: 15, 437: 15, 457: 15, 24: 14, 614: 14, 644: 14, 0: 14, 638: 14, 589: 14, 853: 14, 704: 14, 50: 14, 578: 14, 65: 14, 98: 14, 107: 14, 687: 14, 115: 14, 193: 14, 210: 14, 235: 14, 260: 14, 279: 14, 313: 14, 439: 14, 641: 13, 770: 13, 836: 13, 80: 13, 111: 13, 138: 13, 248: 13, 294: 13, 395: 13, 449: 13, 518: 13, 531: 13, 22: 12, 591: 12, 676: 12, 653: 12, 753: 12, 808: 12, 868: 12, 787: 12, 783: 12, 642: 12, 628: 12, 755: 12, 805: 12, 720: 12, 693: 12, 862: 12, 709: 12, 560: 12, 117: 12, 609: 12, 654: 12, 547: 12, 269: 12, 307: 12, 350: 12, 356: 12, 365: 12, 392: 12, 479: 12, 766: 11, 685: 11, 42: 11, 570: 11, 785: 11, 869: 11, 744: 11, 81: 11, 96: 11, 627: 11, 120: 11, 831: 11, 148: 11, 159: 11, 165: 11, 164: 11, 191: 11, 237: 11, 273: 11, 272: 11, 292: 11, 287: 11, 291: 11, 300: 11, 309: 11, 367: 11, 385: 11, 389: 11, 394: 11, 470: 11, 503: 11, 529: 11, 526: 11, 516: 11, 532: 11, 14: 10, 888: 10, 879: 10, 820: 10, 713: 10, 724: 10, 616: 10, 761: 10, 62: 10, 87: 10, 754: 10, 104: 10, 113: 10, 100: 10, 715: 10, 171: 10, 157: 10, 167: 10, 176: 10, 224: 10, 221: 10, 217: 10, 215: 10, 264: 10, 285: 10, 296: 10, 332: 10, 316: 10, 337: 10, 368: 10, 384: 10, 377: 10, 407: 10, 455: 10, 498: 10, 502: 10, 651: 9, 13: 9, 15: 9, 619: 9, 17: 9, 663: 9, 699: 9, 748: 9, 891: 9, 571: 9, 587: 9, 730: 9, 878: 9, 852: 9, 867: 9, 740: 9, 604: 9, 38: 9, 52: 9, 46: 9, 893: 9, 832: 9, 646: 9, 707: 9, 70: 9, 67: 9, 59: 9, 621: 9, 798: 9, 82: 9, 613: 9, 706: 9, 694: 9, 108: 9, 103: 9, 106: 9, 577: 9, 667: 9, 132: 9, 795: 9, 134: 9, 140: 9, 680: 9, 161: 9, 562: 9, 189: 9, 182: 9, 185: 9, 178: 9, 188: 9, 633: 9, 201: 9, 249: 9, 266: 9, 255: 9, 278: 9, 301: 9, 302: 9, 330: 9, 333: 9, 340: 9, 364: 9, 543: 9, 406: 9, 399: 9, 401: 9, 430: 9, 431: 9, 419: 9, 420: 9, 444: 9, 436: 9, 438: 9, 472: 9, 492: 9, 485: 9, 496: 9, 511: 9, 8: 8, 830: 8, 542: 8, 769: 8, 2: 8, 12: 8, 620: 8, 689: 8, 675: 8, 665: 8, 561: 8, 782: 8, 674: 8, 855: 8, 20: 8, 21: 8, 643: 8, 773: 8, 877: 8, 749: 8, 684: 8, 840: 8, 771: 8, 731: 8, 579: 8, 626: 8, 710: 8, 789: 8, 786: 8, 575: 8, 816: 8, 815: 8, 812: 8, 718: 8, 72: 8, 779: 8, 64: 8, 69: 8, 594: 8, 683: 8, 790: 8, 849: 8, 860: 8, 91: 8, 74: 8, 77: 8, 83: 8, 846: 8, 84: 8, 698: 8, 692: 8, 110: 8, 112: 8, 747: 8, 566: 8, 129: 8, 122: 8, 119: 8, 145: 8, 139: 8, 137: 8, 629: 8, 593: 8, 163: 8, 203: 8, 206: 8, 211: 8, 209: 8, 776: 8, 662: 8, 216: 8, 231: 8, 223: 8, 238: 8, 253: 8, 268: 8, 258: 8, 270: 8, 872: 8, 289: 8, 310: 8, 304: 8, 318: 8, 329: 8, 320: 8, 353: 8, 336: 8, 344: 8, 351: 8, 381: 8, 383: 8, 408: 8, 403: 8, 397: 8, 405: 8, 432: 8, 435: 8, 460: 8, 465: 8, 473: 8, 480: 8, 490: 8, 506: 8, 515: 8, 4: 7, 677: 7, 610: 7, 29: 7, 32: 7, 1: 7, 18: 7, 664: 7, 743: 7, 28: 7, 25: 7, 829: 7, 33: 7, 890: 7, 697: 7, 864: 7, 827: 7, 650: 7, 807: 7, 556: 7, 34: 7, 41: 7, 857: 7, 733: 7, 794: 7, 804: 7, 44: 7, 599: 7, 751: 7, 884: 7, 565: 7, 538: 7, 850: 7, 739: 7, 655: 7, 806: 7, 828: 7, 68: 7, 858: 7, 61: 7, 71: 7, 60: 7, 886: 7, 56: 7, 859: 7, 624: 7, 842: 7, 598: 7, 803: 7, 79: 7, 661: 7, 89: 7, 866: 7, 763: 7, 109: 7, 758: 7, 865: 7, 678: 7, 114: 7, 123: 7, 133: 7, 784: 7, 848: 7, 825: 7, 746: 7, 738: 7, 606: 7, 152: 7, 141: 7, 135: 7, 136: 7, 173: 7, 160: 7, 162: 7, 843: 7, 800: 7, 190: 7, 716: 7, 889: 7, 630: 7, 194: 7, 202: 7, 734: 7, 195: 7, 197: 7, 618: 7, 220: 7, 214: 7, 219: 7, 252: 7, 245: 7, 239: 7, 750: 7, 242: 7, 752: 7, 254: 7, 280: 7, 282: 7, 283: 7, 311: 7, 298: 7, 305: 7, 544: 7, 319: 7, 322: 7, 328: 7, 327: 7, 352: 7, 349: 7, 372: 7, 366: 7, 369: 7, 360: 7, 373: 7, 358: 7, 379: 7, 388: 7, 380: 7, 396: 7, 398: 7, 541: 7, 433: 7, 415: 7, 418: 7, 429: 7, 445: 7, 453: 7, 450: 7, 452: 7, 464: 7, 454: 7, 456: 7, 474: 7, 481: 7, 491: 7, 476: 7, 510: 7, 525: 7, 517: 7, 552: 7, 550: 7, 11: 6, 781: 6, 732: 6, 30: 6, 647: 6, 590: 6, 584: 6, 581: 6, 839: 6, 742: 6, 696: 6, 873: 6, 756: 6, 625: 6, 635: 6, 681: 6, 844: 6, 43: 6, 39: 6, 712: 6, 608: 6, 595: 6, 726: 6, 833: 6, 645: 6, 701: 6, 582: 6, 880: 6, 671: 6, 90: 6, 92: 6, 93: 6, 76: 6, 574: 6, 75: 6, 822: 6, 780: 6, 679: 6, 788: 6, 722: 6, 121: 6, 881: 6, 128: 6, 126: 6, 658: 6, 142: 6, 146: 6, 601: 6, 823: 6, 156: 6, 168: 6, 155: 6, 170: 6, 536: 6, 845: 6, 192: 6, 183: 6, 811: 6, 207: 6, 208: 6, 213: 6, 198: 6, 688: 6, 226: 6, 218: 6, 225: 6, 234: 6, 244: 6, 240: 6, 251: 6, 243: 6, 257: 6, 551: 6, 274: 6, 290: 6, 277: 6, 554: 6, 303: 6, 312: 6, 299: 6, 326: 6, 325: 6, 324: 6, 314: 6, 321: 6, 315: 6, 339: 6, 335: 6, 343: 6, 393: 6, 375: 6, 390: 6, 386: 6, 410: 6, 409: 6, 425: 6, 471: 6, 493: 6, 477: 6, 483: 6, 495: 6, 505: 6, 508: 6, 521: 6, 530: 6, 5: 5, 9: 5, 632: 5, 648: 5, 623: 5, 600: 5, 885: 5, 660: 5, 36: 5, 774: 5, 573: 5, 669: 5, 721: 5, 760: 5, 73: 5, 764: 5, 58: 5, 702: 5, 602: 5, 78: 5, 736: 5, 887: 5, 572: 5, 105: 5, 94: 5, 670: 5, 639: 5, 548: 5, 131: 5, 611: 5, 819: 5, 537: 5, 150: 5, 735: 5, 870: 5, 727: 5, 708: 5, 181: 5, 705: 5, 180: 5, 854: 5, 205: 5, 778: 5, 230: 5, 227: 5, 229: 5, 246: 5, 588: 5, 607: 5, 259: 5, 714: 5, 308: 5, 297: 5, 347: 5, 346: 5, 354: 5, 357: 5, 359: 5, 363: 5, 376: 5, 402: 5, 400: 5, 414: 5, 440: 5, 434: 5, 458: 5, 488: 5, 484: 5, 513: 5, 499: 5, 509: 5, 504: 5, 512: 5, 520: 5, 615: 4, 656: 4, 728: 4, 817: 4, 45: 4, 802: 4, 40: 4, 569: 4, 57: 4, 809: 4, 729: 4, 892: 4, 102: 4, 657: 4, 118: 4, 130: 4, 576: 4, 762: 4, 838: 4, 874: 4, 232: 4, 824: 4, 690: 4, 262: 4, 276: 4, 603: 4, 851: 4, 341: 4, 370: 4, 374: 4, 422: 4, 442: 4, 459: 4, 487: 4, 482: 4, 489: 4, 522: 4, 23: 3, 54: 3, 86: 3, 88: 3, 634: 3, 99: 3, 125: 3, 124: 3, 875: 3, 545: 3, 792: 3, 586: 3, 204: 3, 199: 3, 250: 3, 717: 3, 275: 3, 286: 3, 428: 3, 448: 3, 447: 3, 528: 3, 523: 3, 686: 2, 468: 2})
Total buffer: 8940
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 10, 3: 10, 6: 10, 7: 10, 10: 10, 14: 10, 16: 10, 19: 10, 22: 10, 24: 10, 26: 10, 27: 10, 31: 10, 35: 10, 37: 10, 42: 10, 47: 10, 48: 10, 49: 10, 50: 10, 51: 10, 53: 10, 55: 10, 62: 10, 63: 10, 65: 10, 66: 10, 80: 10, 81: 10, 85: 10, 87: 10, 95: 10, 96: 10, 97: 10, 98: 10, 100: 10, 101: 10, 104: 10, 107: 10, 111: 10, 113: 10, 115: 10, 116: 10, 117: 10, 120: 10, 127: 10, 138: 10, 143: 10, 144: 10, 147: 10, 148: 10, 149: 10, 151: 10, 153: 10, 154: 10, 157: 10, 158: 10, 159: 10, 164: 10, 165: 10, 166: 10, 167: 10, 169: 10, 171: 10, 172: 10, 174: 10, 175: 10, 176: 10, 177: 10, 179: 10, 184: 10, 186: 10, 187: 10, 191: 10, 193: 10, 196: 10, 200: 10, 210: 10, 212: 10, 215: 10, 217: 10, 221: 10, 222: 10, 224: 10, 228: 10, 233: 10, 235: 10, 236: 10, 237: 10, 241: 10, 247: 10, 248: 10, 256: 10, 260: 10, 261: 10, 263: 10, 264: 10, 265: 10, 267: 10, 269: 10, 271: 10, 272: 10, 273: 10, 279: 10, 281: 10, 284: 10, 285: 10, 287: 10, 288: 10, 291: 10, 292: 10, 293: 10, 294: 10, 295: 10, 296: 10, 300: 10, 306: 10, 307: 10, 309: 10, 313: 10, 316: 10, 317: 10, 323: 10, 331: 10, 332: 10, 334: 10, 337: 10, 338: 10, 342: 10, 345: 10, 348: 10, 350: 10, 355: 10, 356: 10, 361: 10, 362: 10, 365: 10, 367: 10, 368: 10, 371: 10, 377: 10, 378: 10, 382: 10, 384: 10, 385: 10, 387: 10, 389: 10, 391: 10, 392: 10, 394: 10, 395: 10, 404: 10, 407: 10, 411: 10, 412: 10, 413: 10, 416: 10, 417: 10, 421: 10, 423: 10, 424: 10, 426: 10, 427: 10, 437: 10, 439: 10, 441: 10, 443: 10, 446: 10, 449: 10, 451: 10, 455: 10, 457: 10, 461: 10, 462: 10, 463: 10, 466: 10, 467: 10, 469: 10, 470: 10, 475: 10, 478: 10, 479: 10, 486: 10, 494: 10, 497: 10, 498: 10, 500: 10, 501: 10, 502: 10, 503: 10, 507: 10, 514: 10, 516: 10, 518: 10, 519: 10, 524: 10, 526: 10, 527: 10, 529: 10, 531: 10, 532: 10, 533: 10, 534: 10, 535: 10, 539: 10, 540: 10, 546: 10, 547: 10, 549: 10, 553: 10, 555: 10, 557: 10, 558: 10, 559: 10, 560: 10, 563: 10, 564: 10, 567: 10, 568: 10, 570: 10, 578: 10, 580: 10, 583: 10, 585: 10, 589: 10, 591: 10, 592: 10, 596: 10, 597: 10, 605: 10, 609: 10, 612: 10, 614: 10, 616: 10, 617: 10, 622: 10, 627: 10, 628: 10, 631: 10, 636: 10, 637: 10, 638: 10, 640: 10, 641: 10, 642: 10, 644: 10, 649: 10, 652: 10, 653: 10, 654: 10, 659: 10, 666: 10, 668: 10, 672: 10, 673: 10, 676: 10, 682: 10, 685: 10, 687: 10, 691: 10, 693: 10, 695: 10, 700: 10, 703: 10, 704: 10, 709: 10, 711: 10, 713: 10, 715: 10, 719: 10, 720: 10, 723: 10, 724: 10, 725: 10, 737: 10, 741: 10, 744: 10, 745: 10, 753: 10, 754: 10, 755: 10, 757: 10, 759: 10, 761: 10, 765: 10, 766: 10, 767: 10, 768: 10, 770: 10, 772: 10, 775: 10, 777: 10, 783: 10, 785: 10, 787: 10, 791: 10, 793: 10, 796: 10, 797: 10, 799: 10, 801: 10, 805: 10, 808: 10, 810: 10, 813: 10, 814: 10, 818: 10, 820: 10, 821: 10, 826: 10, 831: 10, 834: 10, 835: 10, 836: 10, 837: 10, 841: 10, 847: 10, 853: 10, 856: 10, 861: 10, 862: 10, 863: 10, 868: 10, 869: 10, 871: 10, 876: 10, 879: 10, 882: 10, 883: 10, 888: 10, 13: 9, 15: 9, 17: 9, 38: 9, 46: 9, 52: 9, 59: 9, 67: 9, 70: 9, 82: 9, 103: 9, 106: 9, 108: 9, 132: 9, 134: 9, 140: 9, 161: 9, 178: 9, 182: 9, 185: 9, 188: 9, 189: 9, 201: 9, 249: 9, 255: 9, 266: 9, 278: 9, 301: 9, 302: 9, 330: 9, 333: 9, 340: 9, 364: 9, 399: 9, 401: 9, 406: 9, 419: 9, 420: 9, 430: 9, 431: 9, 436: 9, 438: 9, 444: 9, 472: 9, 485: 9, 492: 9, 496: 9, 511: 9, 543: 9, 562: 9, 571: 9, 577: 9, 587: 9, 604: 9, 613: 9, 619: 9, 621: 9, 633: 9, 646: 9, 651: 9, 663: 9, 667: 9, 680: 9, 694: 9, 699: 9, 706: 9, 707: 9, 730: 9, 740: 9, 748: 9, 795: 9, 798: 9, 832: 9, 852: 9, 867: 9, 878: 9, 891: 9, 893: 9, 2: 8, 8: 8, 12: 8, 20: 8, 21: 8, 64: 8, 69: 8, 72: 8, 74: 8, 77: 8, 83: 8, 84: 8, 91: 8, 110: 8, 112: 8, 119: 8, 122: 8, 129: 8, 137: 8, 139: 8, 145: 8, 163: 8, 203: 8, 206: 8, 209: 8, 211: 8, 216: 8, 223: 8, 231: 8, 238: 8, 253: 8, 258: 8, 268: 8, 270: 8, 289: 8, 304: 8, 310: 8, 318: 8, 320: 8, 329: 8, 336: 8, 344: 8, 351: 8, 353: 8, 381: 8, 383: 8, 397: 8, 403: 8, 405: 8, 408: 8, 432: 8, 435: 8, 460: 8, 465: 8, 473: 8, 480: 8, 490: 8, 506: 8, 515: 8, 542: 8, 561: 8, 566: 8, 575: 8, 579: 8, 593: 8, 594: 8, 620: 8, 626: 8, 629: 8, 643: 8, 662: 8, 665: 8, 674: 8, 675: 8, 683: 8, 684: 8, 689: 8, 692: 8, 698: 8, 710: 8, 718: 8, 731: 8, 747: 8, 749: 8, 769: 8, 771: 8, 773: 8, 776: 8, 779: 8, 782: 8, 786: 8, 789: 8, 790: 8, 812: 8, 815: 8, 816: 8, 830: 8, 840: 8, 846: 8, 849: 8, 855: 8, 860: 8, 872: 8, 877: 8, 1: 7, 4: 7, 18: 7, 25: 7, 28: 7, 29: 7, 32: 7, 33: 7, 34: 7, 41: 7, 44: 7, 56: 7, 60: 7, 61: 7, 68: 7, 71: 7, 79: 7, 89: 7, 109: 7, 114: 7, 123: 7, 133: 7, 135: 7, 136: 7, 141: 7, 152: 7, 160: 7, 162: 7, 173: 7, 190: 7, 194: 7, 195: 7, 197: 7, 202: 7, 214: 7, 219: 7, 220: 7, 239: 7, 242: 7, 245: 7, 252: 7, 254: 7, 280: 7, 282: 7, 283: 7, 298: 7, 305: 7, 311: 7, 319: 7, 322: 7, 327: 7, 328: 7, 349: 7, 352: 7, 358: 7, 360: 7, 366: 7, 369: 7, 372: 7, 373: 7, 379: 7, 380: 7, 388: 7, 396: 7, 398: 7, 415: 7, 418: 7, 429: 7, 433: 7, 445: 7, 450: 7, 452: 7, 453: 7, 454: 7, 456: 7, 464: 7, 474: 7, 476: 7, 481: 7, 491: 7, 510: 7, 517: 7, 525: 7, 538: 7, 541: 7, 544: 7, 550: 7, 552: 7, 556: 7, 565: 7, 598: 7, 599: 7, 606: 7, 610: 7, 618: 7, 624: 7, 630: 7, 650: 7, 655: 7, 661: 7, 664: 7, 677: 7, 678: 7, 697: 7, 716: 7, 733: 7, 734: 7, 738: 7, 739: 7, 743: 7, 746: 7, 750: 7, 751: 7, 752: 7, 758: 7, 763: 7, 784: 7, 794: 7, 800: 7, 803: 7, 804: 7, 806: 7, 807: 7, 825: 7, 827: 7, 828: 7, 829: 7, 842: 7, 843: 7, 848: 7, 850: 7, 857: 7, 858: 7, 859: 7, 864: 7, 865: 7, 866: 7, 884: 7, 886: 7, 889: 7, 890: 7, 11: 6, 30: 6, 39: 6, 43: 6, 75: 6, 76: 6, 90: 6, 92: 6, 93: 6, 121: 6, 126: 6, 128: 6, 142: 6, 146: 6, 155: 6, 156: 6, 168: 6, 170: 6, 183: 6, 192: 6, 198: 6, 207: 6, 208: 6, 213: 6, 218: 6, 225: 6, 226: 6, 234: 6, 240: 6, 243: 6, 244: 6, 251: 6, 257: 6, 274: 6, 277: 6, 290: 6, 299: 6, 303: 6, 312: 6, 314: 6, 315: 6, 321: 6, 324: 6, 325: 6, 326: 6, 335: 6, 339: 6, 343: 6, 375: 6, 386: 6, 390: 6, 393: 6, 409: 6, 410: 6, 425: 6, 471: 6, 477: 6, 483: 6, 493: 6, 495: 6, 505: 6, 508: 6, 521: 6, 530: 6, 536: 6, 551: 6, 554: 6, 574: 6, 581: 6, 582: 6, 584: 6, 590: 6, 595: 6, 601: 6, 608: 6, 625: 6, 635: 6, 645: 6, 647: 6, 658: 6, 671: 6, 679: 6, 681: 6, 688: 6, 696: 6, 701: 6, 712: 6, 722: 6, 726: 6, 732: 6, 742: 6, 756: 6, 780: 6, 781: 6, 788: 6, 811: 6, 822: 6, 823: 6, 833: 6, 839: 6, 844: 6, 845: 6, 873: 6, 880: 6, 881: 6, 5: 5, 9: 5, 36: 5, 58: 5, 73: 5, 78: 5, 94: 5, 105: 5, 131: 5, 150: 5, 180: 5, 181: 5, 205: 5, 227: 5, 229: 5, 230: 5, 246: 5, 259: 5, 297: 5, 308: 5, 346: 5, 347: 5, 354: 5, 357: 5, 359: 5, 363: 5, 376: 5, 400: 5, 402: 5, 414: 5, 434: 5, 440: 5, 458: 5, 484: 5, 488: 5, 499: 5, 504: 5, 509: 5, 512: 5, 513: 5, 520: 5, 537: 5, 548: 5, 572: 5, 573: 5, 588: 5, 600: 5, 602: 5, 607: 5, 611: 5, 623: 5, 632: 5, 639: 5, 648: 5, 660: 5, 669: 5, 670: 5, 702: 5, 705: 5, 708: 5, 714: 5, 721: 5, 727: 5, 735: 5, 736: 5, 760: 5, 764: 5, 774: 5, 778: 5, 819: 5, 854: 5, 870: 5, 885: 5, 887: 5, 40: 4, 45: 4, 57: 4, 102: 4, 118: 4, 130: 4, 232: 4, 262: 4, 276: 4, 341: 4, 370: 4, 374: 4, 422: 4, 442: 4, 459: 4, 482: 4, 487: 4, 489: 4, 522: 4, 569: 4, 576: 4, 603: 4, 615: 4, 656: 4, 657: 4, 690: 4, 728: 4, 729: 4, 762: 4, 802: 4, 809: 4, 817: 4, 824: 4, 838: 4, 851: 4, 874: 4, 892: 4, 23: 3, 54: 3, 86: 3, 88: 3, 99: 3, 124: 3, 125: 3, 199: 3, 204: 3, 250: 3, 275: 3, 286: 3, 428: 3, 447: 3, 448: 3, 523: 3, 528: 3, 545: 3, 586: 3, 634: 3, 717: 3, 792: 3, 875: 3, 468: 2, 686: 2})
Total buffer: 7042
fit_time: 60.490506334

Accuracy for 44 task(s): 	 [Class-IL]: 69.41 % 	 [Task-IL]: 30.62 %

CLASS_IL_ACC: 
	[77.83505154639175, 75.0, 76.69902912621359, 65.21739130434783, 58.4070796460177, 68.68686868686868, 56.41025641025641, 78.18181818181819, 76.15384615384615, 59.61538461538461, 58.16326530612245, 80.0, 72.95081967213115, 61.94690265486725, 67.67676767676768, 67.3469387755102, 76.14678899082568, 76.99115044247787, 67.85714285714286, 69.44444444444444, 78.8135593220339, 75.89285714285714, 51.28205128205128, 68.68686868686868, 71.55963302752293, 58.119658119658126, 70.24793388429752, 76.22950819672131, 77.06422018348624, 81.55339805825243, 66.35514018691589, 59.055118110236215, 68.51851851851852, 62.745098039215684, 67.88990825688074, 67.96116504854369, 69.6969696969697, 67.47967479674797, 69.72477064220183, 70.17543859649122, 54.45544554455446, 75.21367521367522, 84.25925925925925, 70.52631578947368]
TASK_IL_ACC: 
	[57.21649484536082, 27.419354838709676, 28.155339805825243, 27.173913043478258, 32.743362831858406, 33.33333333333333, 23.076923076923077, 27.27272727272727, 33.84615384615385, 29.807692307692307, 26.53061224489796, 30.0, 23.770491803278688, 23.893805309734514, 30.303030303030305, 28.57142857142857, 30.275229357798167, 27.43362831858407, 25.0, 17.59259259259259, 28.8135593220339, 29.464285714285715, 21.367521367521366, 33.33333333333333, 30.275229357798167, 32.47863247863248, 32.231404958677686, 33.60655737704918, 22.93577981651376, 32.038834951456316, 30.8411214953271, 28.346456692913385, 25.0, 22.54901960784314, 26.605504587155966, 25.24271844660194, 28.28282828282828, 30.081300813008134, 30.275229357798167, 30.701754385964914, 32.67326732673268, 35.8974358974359, 25.0, 95.78947368421052]
f1_micro: 69.61561928004882
f1_macro: 66.87327543745708
              precision    recall  f1-score   support

           0       1.00      0.89      0.94         9
           1       1.00      0.75      0.86         4
           2       1.00      0.75      0.86         4
           3       1.00      0.89      0.94         9
           4       1.00      0.75      0.86         4
           5       1.00      0.75      0.86         4
           6       0.89      0.89      0.89         9
           7       1.00      0.67      0.80         9
           8       0.80      1.00      0.89         4
           9       1.00      1.00      1.00         4
          10       0.75      1.00      0.86         9
          11       0.00      0.00      0.00         4
          12       0.80      1.00      0.89         4
          13       0.50      0.25      0.33         4
          14       1.00      1.00      1.00         4
          15       1.00      1.00      1.00         4
          16       0.75      0.67      0.71         9
          17       0.80      1.00      0.89         4
          18       0.08      0.25      0.12         4
          19       0.90      1.00      0.95         9
          20       1.00      1.00      1.00         4
          21       0.00      0.00      0.00         4
          22       1.00      0.80      0.89         5
          23       0.67      0.50      0.57         4
          24       0.00      0.00      0.00         9
          25       0.83      1.00      0.91         5
          26       1.00      1.00      1.00         9
          27       1.00      1.00      1.00         9
          28       1.00      1.00      1.00         4
          29       0.67      1.00      0.80         4
          30       0.00      0.00      0.00         4
          31       1.00      1.00      1.00         9
          32       1.00      1.00      1.00         4
          33       1.00      1.00      1.00         5
          34       0.67      1.00      0.80         4
          35       1.00      0.89      0.94         9
          36       0.33      0.25      0.29         4
          37       0.80      0.89      0.84         9
          38       0.80      0.80      0.80         5
          39       0.50      0.25      0.33         4
          40       1.00      1.00      1.00         5
          41       1.00      0.25      0.40         4
          42       0.67      1.00      0.80         4
          43       0.60      0.75      0.67         4
          44       1.00      1.00      1.00         5
          45       0.80      1.00      0.89         4
          46       0.44      1.00      0.62         4
          47       0.00      0.00      0.00         9
          48       1.00      0.89      0.94         9
          49       1.00      1.00      1.00         9
          50       1.00      1.00      1.00         9
          51       0.67      0.67      0.67         9
          52       1.00      0.20      0.33         5
          53       0.89      0.89      0.89         9
          54       1.00      0.75      0.86         4
          55       1.00      1.00      1.00         9
          56       1.00      1.00      1.00         4
          57       0.00      0.00      0.00         4
          58       0.00      0.00      0.00         4
          59       1.00      1.00      1.00         4
          60       1.00      1.00      1.00         4
          61       1.00      1.00      1.00         4
          62       0.80      0.80      0.80         5
          63       0.75      1.00      0.86         9
          64       0.00      0.00      0.00         4
          65       0.73      0.89      0.80         9
          66       0.75      0.67      0.71         9
          67       0.75      0.60      0.67         5
          68       0.50      0.50      0.50         4
          69       1.00      1.00      1.00         4
          70       0.80      1.00      0.89         4
          71       0.67      0.50      0.57         4
          72       0.80      1.00      0.89         4
          73       1.00      1.00      1.00         5
          74       0.80      1.00      0.89         4
          75       0.50      0.25      0.33         4
          76       0.00      0.00      0.00         4
          77       1.00      0.60      0.75         5
          78       1.00      0.75      0.86         4
          79       0.80      1.00      0.89         4
          80       0.60      0.33      0.43         9
          81       0.62      1.00      0.77         5
          82       1.00      1.00      1.00         4
          83       0.00      0.00      0.00         4
          84       1.00      1.00      1.00         4
          85       0.80      0.89      0.84         9
          86       1.00      1.00      1.00         4
          87       0.00      0.00      0.00         4
          88       0.60      0.75      0.67         4
          89       0.75      0.75      0.75         4
          90       0.00      0.00      0.00         4
          91       0.80      1.00      0.89         4
          92       1.00      0.75      0.86         4
          93       1.00      1.00      1.00         4
          94       1.00      0.50      0.67         4
          95       0.88      0.78      0.82         9
          96       1.00      0.80      0.89         5
          97       1.00      0.89      0.94         9
          98       0.29      0.22      0.25         9
          99       1.00      0.25      0.40         4
         100       1.00      0.40      0.57         5
         101       0.00      0.00      0.00         9
         102       0.67      1.00      0.80         4
         103       0.33      0.20      0.25         5
         104       0.75      0.60      0.67         5
         105       0.67      0.50      0.57         4
         106       1.00      0.60      0.75         5
         107       1.00      0.89      0.94         9
         108       0.43      0.75      0.55         4
         109       0.75      0.75      0.75         4
         110       1.00      1.00      1.00         4
         111       1.00      0.60      0.75         5
         112       0.80      0.80      0.80         5
         113       0.50      0.40      0.44         5
         114       0.75      0.75      0.75         4
         115       1.00      0.89      0.94         9
         116       1.00      0.78      0.88         9
         117       0.50      0.60      0.55         5
         118       0.75      0.75      0.75         4
         119       0.00      0.00      0.00         4
         120       0.80      1.00      0.89         4
         121       1.00      1.00      1.00         4
         122       0.50      0.60      0.55         5
         123       1.00      1.00      1.00         4
         124       1.00      0.50      0.67         4
         125       1.00      1.00      1.00         4
         126       0.00      0.00      0.00         4
         127       0.64      0.78      0.70         9
         128       0.50      0.40      0.44         5
         129       0.75      0.75      0.75         4
         130       0.20      0.25      0.22         4
         131       0.80      1.00      0.89         4
         132       1.00      0.60      0.75         5
         133       1.00      0.75      0.86         4
         134       0.00      0.00      0.00         4
         135       0.00      0.00      0.00         4
         136       0.00      0.00      0.00         4
         137       1.00      0.50      0.67         4
         138       0.89      0.89      0.89         9
         139       0.80      0.80      0.80         5
         140       1.00      0.80      0.89         5
         141       0.67      1.00      0.80         4
         142       1.00      0.50      0.67         4
         143       0.73      0.89      0.80         9
         144       0.00      0.00      0.00         9
         145       0.50      0.50      0.50         4
         146       0.25      0.25      0.25         4
         147       0.80      0.89      0.84         9
         148       1.00      1.00      1.00         4
         149       0.80      0.89      0.84         9
         150       0.00      0.00      0.00         4
         151       0.14      0.22      0.17         9
         152       0.00      0.00      0.00         4
         153       1.00      1.00      1.00         9
         154       0.57      0.89      0.70         9
         155       0.50      0.50      0.50         4
         156       0.00      0.00      0.00         4
         157       0.50      1.00      0.67         4
         158       0.89      0.89      0.89         9
         159       0.56      1.00      0.71         5
         160       1.00      1.00      1.00         4
         161       0.50      0.80      0.62         5
         162       0.83      1.00      0.91         5
         163       1.00      0.75      0.86         4
         164       1.00      1.00      1.00         5
         165       0.00      0.00      0.00         4
         166       0.88      0.78      0.82         9
         167       1.00      0.80      0.89         5
         168       1.00      1.00      1.00         4
         169       0.25      0.22      0.24         9
         170       1.00      1.00      1.00         4
         171       1.00      1.00      1.00         4
         172       0.75      1.00      0.86         9
         173       0.80      1.00      0.89         4
         174       0.82      1.00      0.90         9
         175       1.00      0.78      0.88         9
         176       0.67      0.80      0.73         5
         177       0.90      1.00      0.95         9
         178       1.00      0.80      0.89         5
         179       0.60      0.67      0.63         9
         180       1.00      0.50      0.67         4
         181       0.00      0.00      0.00         4
         182       1.00      1.00      1.00         5
         183       1.00      0.50      0.67         4
         184       0.50      0.44      0.47         9
         185       0.80      1.00      0.89         4
         186       0.90      1.00      0.95         9
         187       1.00      0.78      0.88         9
         188       0.50      0.80      0.62         5
         189       0.80      0.80      0.80         5
         190       1.00      1.00      1.00         4
         191       1.00      0.67      0.80         9
         192       0.50      0.50      0.50         4
         193       0.78      0.78      0.78         9
         194       0.71      1.00      0.83         5
         195       1.00      0.80      0.89         5
         196       0.62      0.89      0.73         9
         197       0.00      0.00      0.00         4
         198       1.00      0.25      0.40         4
         199       0.00      0.00      0.00         4
         200       0.10      0.22      0.13         9
         201       0.60      0.60      0.60         5
         202       1.00      0.75      0.86         4
         203       0.60      0.75      0.67         4
         204       1.00      0.25      0.40         4
         205       1.00      0.50      0.67         4
         206       0.00      0.00      0.00         4
         207       1.00      0.25      0.40         4
         208       0.80      1.00      0.89         4
         209       0.67      0.40      0.50         5
         210       0.64      0.78      0.70         9
         211       0.80      1.00      0.89         4
         212       0.73      0.89      0.80         9
         213       0.80      1.00      0.89         4
         214       0.67      1.00      0.80         4
         215       0.71      1.00      0.83         5
         216       0.00      0.00      0.00         4
         217       0.80      1.00      0.89         4
         218       1.00      1.00      1.00         5
         219       0.00      0.00      0.00         4
         220       0.40      0.50      0.44         4
         221       0.83      1.00      0.91         5
         222       0.89      0.89      0.89         9
         223       0.67      0.50      0.57         4
         224       0.60      0.75      0.67         4
         225       0.67      0.50      0.57         4
         226       0.50      0.25      0.33         4
         227       0.67      0.50      0.57         4
         228       0.00      0.00      0.00         9
         229       1.00      1.00      1.00         4
         230       0.00      0.00      0.00         4
         231       0.00      0.00      0.00         4
         232       1.00      0.75      0.86         4
         233       0.64      0.78      0.70         9
         234       1.00      0.75      0.86         4
         235       0.89      0.89      0.89         9
         236       0.78      0.78      0.78         9
         237       0.71      1.00      0.83         5
         238       0.33      0.25      0.29         4
         239       0.50      0.25      0.33         4
         240       1.00      0.60      0.75         5
         241       0.90      1.00      0.95         9
         242       1.00      0.50      0.67         4
         243       0.30      0.60      0.40         5
         244       0.75      0.75      0.75         4
         245       1.00      0.80      0.89         5
         246       1.00      0.75      0.86         4
         247       0.89      0.89      0.89         9
         248       1.00      1.00      1.00         9
         249       1.00      1.00      1.00         5
         250       0.75      0.75      0.75         4
         251       0.80      1.00      0.89         4
         252       1.00      1.00      1.00         4
         253       0.60      0.75      0.67         4
         254       1.00      0.50      0.67         4
         255       0.67      1.00      0.80         4
         256       1.00      0.89      0.94         9
         257       0.75      0.75      0.75         4
         258       1.00      1.00      1.00         4
         259       0.29      0.50      0.36         4
         260       0.89      0.89      0.89         9
         261       0.89      0.89      0.89         9
         262       0.00      0.00      0.00         4
         263       1.00      1.00      1.00         9
         264       0.75      0.75      0.75         4
         265       0.88      0.78      0.82         9
         266       0.33      0.50      0.40         4
         267       0.44      0.44      0.44         9
         268       0.40      0.50      0.44         4
         269       0.86      0.67      0.75         9
         270       0.80      1.00      0.89         4
         271       0.71      0.56      0.63         9
         272       1.00      0.80      0.89         5
         273       0.67      0.80      0.73         5
         274       0.00      0.00      0.00         4
         275       0.80      1.00      0.89         4
         276       0.00      0.00      0.00         4
         277       1.00      0.25      0.40         4
         278       1.00      0.75      0.86         4
         279       1.00      1.00      1.00         9
         280       0.50      0.50      0.50         4
         281       0.80      0.89      0.84         9
         282       1.00      0.75      0.86         4
         283       0.00      0.00      0.00         4
         284       0.00      0.00      0.00         9
         285       1.00      0.75      0.86         4
         286       0.50      0.25      0.33         4
         287       1.00      0.80      0.89         5
         288       0.50      0.33      0.40         9
         289       1.00      1.00      1.00         5
         290       0.83      1.00      0.91         5
         291       0.80      1.00      0.89         4
         292       1.00      1.00      1.00         9
         293       1.00      0.67      0.80         9
         294       0.56      0.56      0.56         9
         295       0.33      0.33      0.33         9
         296       0.62      1.00      0.77         5
         297       0.00      0.00      0.00         4
         298       0.20      0.25      0.22         4
         299       1.00      0.50      0.67         4
         300       1.00      0.80      0.89         5
         301       1.00      0.80      0.89         5
         302       0.67      1.00      0.80         4
         303       1.00      1.00      1.00         5
         304       1.00      1.00      1.00         4
         305       0.00      0.00      0.00         4
         306       0.73      1.00      0.84         8
         307       0.80      0.80      0.80         5
         308       0.60      0.75      0.67         4
         309       0.60      0.75      0.67         4
         310       0.80      1.00      0.89         4
         311       1.00      1.00      1.00         4
         312       1.00      1.00      1.00         4
         313       0.00      0.00      0.00         4
         314       0.67      1.00      0.80         4
         315       0.00      0.00      0.00         4
         316       1.00      0.80      0.89         5
         317       0.67      0.89      0.76         9
         318       0.00      0.00      0.00         4
         319       0.50      0.50      0.50         4
         320       0.00      0.00      0.00         4
         321       0.80      1.00      0.89         4
         322       1.00      1.00      1.00         4
         323       0.00      0.00      0.00         9
         324       1.00      0.60      0.75         5
         325       0.80      1.00      0.89         4
         326       0.50      0.75      0.60         4
         327       0.80      1.00      0.89         4
         328       0.67      1.00      0.80         4
         329       0.80      1.00      0.89         4
         330       0.00      0.00      0.00         4
         331       0.90      1.00      0.95         9
         332       0.80      1.00      0.89         4
         333       0.83      1.00      0.91         5
         334       1.00      1.00      1.00         9
         335       1.00      0.50      0.67         4
         336       0.75      0.75      0.75         4
         337       1.00      0.60      0.75         5
         338       0.67      0.67      0.67         9
         339       0.67      1.00      0.80         4
         340       0.67      1.00      0.80         4
         341       0.75      0.75      0.75         4
         342       0.80      0.89      0.84         9
         343       1.00      0.25      0.40         4
         344       0.00      0.00      0.00         4
         345       0.67      0.44      0.53         9
         346       1.00      1.00      1.00         4
         347       0.75      0.60      0.67         5
         348       0.90      1.00      0.95         9
         349       0.80      1.00      0.89         4
         350       1.00      1.00      1.00         5
         351       0.75      0.75      0.75         4
         352       1.00      0.75      0.86         4
         353       1.00      1.00      1.00         5
         354       0.50      0.50      0.50         4
         355       0.67      1.00      0.80         8
         356       1.00      1.00      1.00         9
         357       0.75      0.75      0.75         4
         358       0.00      0.00      0.00         4
         359       1.00      0.75      0.86         4
         360       0.00      0.00      0.00         4
         361       1.00      1.00      1.00         9
         362       0.62      0.56      0.59         9
         363       1.00      1.00      1.00         4
         364       0.71      1.00      0.83         5
         365       1.00      1.00      1.00         9
         366       0.60      0.75      0.67         4
         367       0.80      0.80      0.80         5
         368       1.00      1.00      1.00         5
         369       1.00      1.00      1.00         5
         370       0.25      0.25      0.25         4
         371       0.80      0.89      0.84         9
         372       1.00      1.00      1.00         4
         373       0.00      0.00      0.00         4
         374       1.00      1.00      1.00         4
         375       1.00      0.25      0.40         4
         376       0.20      0.25      0.22         4
         377       0.00      0.00      0.00         4
         378       0.88      0.78      0.82         9
         379       0.67      1.00      0.80         4
         380       1.00      1.00      1.00         4
         381       0.67      0.50      0.57         4
         382       0.67      0.67      0.67         9
         383       1.00      1.00      1.00         5
         384       1.00      0.80      0.89         5
         385       0.88      0.78      0.82         9
         386       0.60      0.75      0.67         4
         387       0.88      0.78      0.82         9
         388       1.00      0.75      0.86         4
         389       0.60      0.75      0.67         4
         390       0.00      0.00      0.00         4
         391       1.00      0.89      0.94         9
         392       0.71      0.56      0.63         9
         393       1.00      0.50      0.67         4
         394       0.00      0.00      0.00         4
         395       0.57      0.57      0.57         7
         396       0.80      1.00      0.89         4
         397       0.44      1.00      0.62         4
         398       0.75      0.75      0.75         4
         399       0.17      0.25      0.20         4
         400       0.60      0.75      0.67         4
         401       1.00      0.60      0.75         5
         402       0.40      0.40      0.40         5
         403       1.00      0.80      0.89         5
         404       0.82      1.00      0.90         9
         405       0.50      1.00      0.67         4
         406       0.80      1.00      0.89         4
         407       0.25      0.20      0.22         5
         408       1.00      1.00      1.00         4
         409       1.00      0.50      0.67         4
         410       1.00      0.80      0.89         5
         411       0.89      0.89      0.89         9
         412       0.64      0.78      0.70         9
         413       0.80      0.44      0.57         9
         414       1.00      1.00      1.00         4
         415       0.75      0.75      0.75         4
         416       1.00      1.00      1.00         9
         417       0.90      1.00      0.95         9
         418       0.00      0.00      0.00         4
         419       0.50      1.00      0.67         4
         420       0.83      1.00      0.91         5
         421       1.00      1.00      1.00         9
         422       0.00      0.00      0.00         4
         423       0.86      0.67      0.75         9
         424       0.80      0.89      0.84         9
         425       0.33      0.25      0.29         4
         426       0.62      0.56      0.59         9
         427       0.89      0.89      0.89         9
         428       0.43      0.75      0.55         4
         429       0.80      1.00      0.89         4
         430       1.00      0.80      0.89         5
         431       0.75      0.75      0.75         4
         432       0.60      0.75      0.67         4
         433       1.00      1.00      1.00         5
         434       0.00      0.00      0.00         4
         435       1.00      0.50      0.67         4
         436       0.67      1.00      0.80         4
         437       0.89      0.89      0.89         9
         438       0.00      0.00      0.00         4
         439       0.75      1.00      0.86         9
         440       0.50      0.50      0.50         4
         441       0.90      1.00      0.95         9
         442       0.00      0.00      0.00         4
         443       1.00      0.89      0.94         9
         444       0.80      1.00      0.89         4
         445       0.00      0.00      0.00         4
         446       0.90      1.00      0.95         9
         447       1.00      0.25      0.40         4
         448       1.00      0.50      0.67         4
         449       0.83      1.00      0.91         5
         450       1.00      1.00      1.00         4
         451       0.90      1.00      0.95         9
         452       1.00      1.00      1.00         5
         453       0.80      1.00      0.89         4
         454       1.00      1.00      1.00         4
         455       0.57      1.00      0.73         4
         456       0.00      0.00      0.00         4
         457       0.06      0.11      0.08         9
         458       0.00      0.00      0.00         4
         459       0.00      0.00      0.00         4
         460       0.75      0.75      0.75         4
         461       0.64      0.78      0.70         9
         462       0.78      0.78      0.78         9
         463       0.11      0.11      0.11         9
         464       1.00      1.00      1.00         4
         465       0.67      0.50      0.57         4
         466       0.00      0.00      0.00         9
         467       0.90      1.00      0.95         9
         468       1.00      0.50      0.67         4
         469       0.09      0.11      0.10         9
         470       0.60      0.60      0.60         5
         471       1.00      0.75      0.86         4
         472       1.00      1.00      1.00         5
         473       1.00      1.00      1.00         4
         474       1.00      0.75      0.86         4
         475       0.67      0.44      0.53         9
         476       0.50      0.25      0.33         4
         477       0.00      0.00      0.00         4
         478       0.89      0.89      0.89         9
         479       0.71      1.00      0.83         5
         480       1.00      0.75      0.86         4
         481       1.00      0.75      0.86         4
         482       1.00      1.00      1.00         4
         483       1.00      1.00      1.00         5
         484       1.00      1.00      1.00         4
         485       0.67      1.00      0.80         4
         486       0.86      0.67      0.75         9
         487       1.00      0.50      0.67         4
         488       0.00      0.00      0.00         4
         489       1.00      1.00      1.00         4
         490       1.00      1.00      1.00         5
         491       0.75      0.75      0.75         4
         492       1.00      0.80      0.89         5
         493       0.00      0.00      0.00         4
         494       0.89      0.89      0.89         9
         495       1.00      1.00      1.00         4
         496       0.50      0.75      0.60         4
         497       1.00      0.78      0.88         9
         498       0.60      0.60      0.60         5
         499       0.67      1.00      0.80         4
         500       1.00      1.00      1.00         9
         501       0.89      0.89      0.89         9
         502       1.00      0.80      0.89         5
         503       0.60      0.60      0.60         5
         504       1.00      1.00      1.00         4
         505       0.57      1.00      0.73         4
         506       0.00      0.00      0.00         4
         507       0.44      0.44      0.44         9
         508       0.75      0.75      0.75         4
         509       0.00      0.00      0.00         4
         510       1.00      0.80      0.89         5
         511       1.00      1.00      1.00         4
         512       0.67      0.50      0.57         4
         513       0.00      0.00      0.00         4
         514       1.00      0.67      0.80         9
         515       0.00      0.00      0.00         4
         516       1.00      0.75      0.86         4
         517       0.00      0.00      0.00         4
         518       1.00      0.89      0.94         9
         519       0.00      0.00      0.00         9
         520       1.00      1.00      1.00         4
         521       0.75      0.75      0.75         4
         522       0.50      0.50      0.50         4
         523       0.67      0.50      0.57         4
         524       0.83      0.56      0.67         9
         525       1.00      1.00      1.00         5
         526       0.40      0.29      0.33         7
         527       1.00      0.78      0.88         9
         528       0.50      0.25      0.33         4
         529       1.00      1.00      1.00         5
         530       1.00      0.75      0.86         4
         531       0.33      0.60      0.43         5
         532       0.33      0.40      0.36         5
         533       0.78      0.78      0.78         9
         534       0.90      1.00      0.95         9
         535       0.50      0.56      0.53         9
         536       0.60      0.75      0.67         4
         537       1.00      0.25      0.40         4
         538       0.00      0.00      0.00         4
         539       0.89      0.89      0.89         9
         540       1.00      0.89      0.94         9
         541       0.75      0.75      0.75         4
         542       1.00      1.00      1.00         4
         543       1.00      1.00      1.00         5
         544       0.50      0.50      0.50         4
         545       1.00      1.00      1.00         4
         546       0.86      0.67      0.75         9
         547       0.86      0.67      0.75         9
         548       0.67      1.00      0.80         4
         549       0.89      0.89      0.89         9
         550       0.00      0.00      0.00         4
         551       1.00      0.50      0.67         4
         552       0.67      0.50      0.57         4
         553       0.56      0.56      0.56         9
         554       1.00      1.00      1.00         4
         555       0.00      0.00      0.00         9
         556       1.00      0.75      0.86         4
         557       0.88      0.78      0.82         9
         558       1.00      0.78      0.88         9
         559       1.00      0.89      0.94         9
         560       0.75      0.60      0.67         5
         561       1.00      0.75      0.86         4
         562       1.00      1.00      1.00         4
         563       1.00      0.78      0.88         9
         564       0.82      1.00      0.90         9
         565       0.80      1.00      0.89         4
         566       1.00      1.00      1.00         4
         567       0.88      0.78      0.82         9
         568       0.80      0.89      0.84         9
         569       0.75      0.75      0.75         4
         570       1.00      1.00      1.00         5
         571       1.00      1.00      1.00         4
         572       0.50      0.75      0.60         4
         573       0.00      0.00      0.00         4
         574       1.00      1.00      1.00         4
         575       1.00      1.00      1.00         4
         576       0.00      0.00      0.00         4
         577       0.06      0.25      0.10         4
         578       0.90      1.00      0.95         9
         579       0.57      0.80      0.67         5
         580       0.00      0.00      0.00         9
         581       0.80      1.00      0.89         4
         582       1.00      1.00      1.00         4
         583       0.80      0.89      0.84         9
         584       1.00      1.00      1.00         4
         585       1.00      0.89      0.94         9
         586       1.00      1.00      1.00         4
         587       0.67      0.80      0.73         5
         588       0.29      0.50      0.36         4
         589       0.40      0.80      0.53         5
         590       1.00      1.00      1.00         4
         591       1.00      1.00      1.00         5
         592       0.78      0.78      0.78         9
         593       1.00      1.00      1.00         4
         594       0.80      1.00      0.89         4
         595       0.60      0.75      0.67         4
         596       0.67      0.67      0.67         9
         597       0.90      1.00      0.95         9
         598       0.60      0.75      0.67         4
         599       1.00      1.00      1.00         4
         600       1.00      1.00      1.00         4
         601       1.00      0.50      0.67         4
         602       0.80      1.00      0.89         4
         603       0.60      0.75      0.67         4
         604       0.67      1.00      0.80         4
         605       0.57      0.89      0.70         9
         606       0.00      0.00      0.00         4
         607       0.67      0.50      0.57         4
         608       1.00      1.00      1.00         5
         609       1.00      1.00      1.00         5
         610       0.57      0.80      0.67         5
         611       0.75      0.75      0.75         4
         612       1.00      0.78      0.88         9
         613       0.67      1.00      0.80         4
         614       0.71      0.71      0.71         7
         615       1.00      0.50      0.67         4
         616       1.00      1.00      1.00         5
         617       0.89      0.89      0.89         9
         618       0.43      0.75      0.55         4
         619       1.00      1.00      1.00         5
         620       0.67      1.00      0.80         4
         621       0.00      0.00      0.00         4
         622       0.88      0.78      0.82         9
         623       1.00      1.00      1.00         4
         624       0.83      1.00      0.91         5
         625       1.00      0.75      0.86         4
         626       0.75      0.75      0.75         4
         627       0.00      0.00      0.00         4
         628       0.00      0.00      0.00         9
         629       0.09      0.25      0.13         4
         630       0.67      0.50      0.57         4
         631       0.89      0.89      0.89         9
         632       1.00      1.00      1.00         4
         633       1.00      0.40      0.57         5
         634       0.00      0.00      0.00         4
         635       0.00      0.00      0.00         4
         636       1.00      0.67      0.80         9
         637       0.80      0.89      0.84         9
         638       0.89      0.89      0.89         9
         639       0.00      0.00      0.00         4
         640       0.15      0.22      0.18         9
         641       0.90      1.00      0.95         9
         642       0.60      0.60      0.60         5
         643       0.50      0.25      0.33         4
         644       1.00      0.89      0.94         9
         645       0.00      0.00      0.00         4
         646       0.75      0.60      0.67         5
         647       0.67      0.50      0.57         4
         648       0.00      0.00      0.00         4
         649       0.64      1.00      0.78         9
         650       1.00      1.00      1.00         4
         651       1.00      0.75      0.86         4
         652       0.00      0.00      0.00         9
         653       1.00      1.00      1.00         9
         654       0.83      1.00      0.91         5
         655       0.67      0.50      0.57         4
         656       1.00      0.25      0.40         4
         657       0.33      0.25      0.29         4
         658       0.75      0.75      0.75         4
         659       0.67      0.89      0.76         9
         660       0.33      0.25      0.29         4
         661       1.00      1.00      1.00         4
         662       0.75      0.75      0.75         4
         663       1.00      1.00      1.00         5
         664       1.00      1.00      1.00         4
         665       0.00      0.00      0.00         4
         666       0.75      0.67      0.71         9
         667       0.33      0.50      0.40         4
         668       0.88      0.78      0.82         9
         669       1.00      1.00      1.00         5
         670       0.00      0.00      0.00         4
         671       0.50      0.75      0.60         4
         672       0.57      0.89      0.70         9
         673       1.00      0.67      0.80         9
         674       1.00      0.50      0.67         4
         675       0.67      1.00      0.80         4
         676       1.00      0.80      0.89         5
         677       0.33      0.40      0.36         5
         678       0.67      1.00      0.80         4
         679       0.00      0.00      0.00         4
         680       0.67      0.80      0.73         5
         681       1.00      1.00      1.00         4
         682       0.75      1.00      0.86         9
         683       0.10      0.25      0.14         4
         684       1.00      1.00      1.00         5
         685       0.62      0.83      0.71         6
         686       0.00      0.00      0.00         4
         687       0.75      0.33      0.46         9
         688       0.75      0.75      0.75         4
         689       0.00      0.00      0.00         4
         690       0.00      0.00      0.00         4
         691       1.00      0.78      0.88         9
         692       0.75      0.75      0.75         4
         693       1.00      0.80      0.89         5
         694       0.83      1.00      0.91         5
         695       0.83      0.56      0.67         9
         696       1.00      1.00      1.00         4
         697       0.00      0.00      0.00         4
         698       0.00      0.00      0.00         4
         699       0.80      0.80      0.80         5
         700       0.88      0.78      0.82         9
         701       0.75      0.75      0.75         4
         702       1.00      1.00      1.00         4
         703       0.57      0.44      0.50         9
         704       0.67      0.89      0.76         9
         705       0.00      0.00      0.00         4
         706       1.00      1.00      1.00         4
         707       0.60      0.75      0.67         4
         708       0.00      0.00      0.00         4
         709       0.71      1.00      0.83         5
         710       1.00      1.00      1.00         4
         711       0.88      0.78      0.82         9
         712       1.00      0.75      0.86         4
         713       0.80      0.80      0.80         5
         714       0.50      0.25      0.33         4
         715       0.05      0.25      0.09         4
         716       1.00      0.75      0.86         4
         717       1.00      0.25      0.40         4
         718       0.57      0.80      0.67         5
         719       0.78      0.78      0.78         9
         720       0.82      1.00      0.90         9
         721       0.40      0.50      0.44         4
         722       1.00      0.50      0.67         4
         723       0.54      0.78      0.64         9
         724       0.80      1.00      0.89         4
         725       1.00      1.00      1.00         9
         726       0.75      0.60      0.67         5
         727       0.80      1.00      0.89         4
         728       0.00      0.00      0.00         4
         729       0.11      0.25      0.15         4
         730       0.00      0.00      0.00         4
         731       0.80      0.80      0.80         5
         732       0.80      1.00      0.89         4
         733       1.00      1.00      1.00         4
         734       0.67      1.00      0.80         4
         735       1.00      1.00      1.00         4
         736       1.00      0.75      0.86         4
         737       1.00      0.89      0.94         9
         738       1.00      0.75      0.86         4
         739       0.60      0.60      0.60         5
         740       0.50      0.80      0.62         5
         741       0.44      0.44      0.44         9
         742       0.67      1.00      0.80         4
         743       0.75      0.75      0.75         4
         744       0.50      0.40      0.44         5
         745       0.83      0.56      0.67         9
         746       0.80      1.00      0.89         4
         747       0.67      1.00      0.80         4
         748       0.12      0.50      0.19         4
         749       0.00      0.00      0.00         4
         750       0.00      0.00      0.00         4
         751       1.00      0.75      0.86         4
         752       0.67      1.00      0.80         4
         753       1.00      1.00      1.00         5
         754       1.00      0.20      0.33         5
         755       0.55      0.67      0.60         9
         756       0.80      1.00      0.89         4
         757       0.88      0.78      0.82         9
         758       0.80      1.00      0.89         4
         759       0.78      0.78      0.78         9
         760       1.00      0.75      0.86         4
         761       0.71      1.00      0.83         5
         762       1.00      0.50      0.67         4
         763       1.00      0.75      0.86         4
         764       1.00      0.50      0.67         4
         765       1.00      0.89      0.94         9
         766       0.89      0.89      0.89         9
         767       0.86      0.67      0.75         9
         768       0.00      0.00      0.00         9
         769       0.00      0.00      0.00         4
         770       0.80      0.80      0.80         5
         771       1.00      0.75      0.86         4
         772       0.89      0.89      0.89         9
         773       0.50      0.50      0.50         4
         774       1.00      1.00      1.00         4
         775       0.80      0.89      0.84         9
         776       0.67      1.00      0.80         4
         777       0.71      0.56      0.63         9
         778       0.67      1.00      0.80         4
         779       0.12      0.25      0.17         4
         780       0.67      0.50      0.57         4
         781       0.67      1.00      0.80         4
         782       0.33      0.50      0.40         4
         783       1.00      1.00      1.00         5
         784       0.67      0.50      0.57         4
         785       1.00      0.20      0.33         5
         786       1.00      0.60      0.75         5
         787       0.89      0.89      0.89         9
         788       0.50      0.25      0.33         4
         789       0.33      0.25      0.29         4
         790       0.71      1.00      0.83         5
         791       0.83      0.56      0.67         9
         792       0.50      0.50      0.50         4
         793       0.82      1.00      0.90         9
         794       0.43      0.60      0.50         5
         795       0.67      1.00      0.80         4
         796       1.00      0.78      0.88         9
         797       0.86      0.67      0.75         9
         798       0.00      0.00      0.00         4
         799       1.00      0.89      0.94         9
         800       0.00      0.00      0.00         4
         801       0.50      0.33      0.40         9
         802       1.00      0.75      0.86         4
         803       1.00      1.00      1.00         5
         804       1.00      1.00      1.00         4
         805       0.00      0.00      0.00         4
         806       0.71      1.00      0.83         5
         807       0.00      0.00      0.00         4
         808       1.00      1.00      1.00         5
         809       1.00      1.00      1.00         4
         810       1.00      1.00      1.00         9
         811       0.50      0.50      0.50         4
         812       0.43      0.75      0.55         4
         813       0.90      1.00      0.95         9
         814       0.80      0.89      0.84         9
         815       1.00      0.75      0.86         4
         816       0.75      0.75      0.75         4
         817       0.00      0.00      0.00         4
         818       0.00      0.00      0.00         9
         819       0.00      0.00      0.00         4
         820       0.75      0.75      0.75         4
         821       0.71      0.56      0.63         9
         822       1.00      0.50      0.67         4
         823       1.00      1.00      1.00         4
         824       0.00      0.00      0.00         4
         825       1.00      1.00      1.00         4
         826       0.71      0.56      0.63         9
         827       0.00      0.00      0.00         4
         828       1.00      1.00      1.00         4
         829       0.00      0.00      0.00         4
         830       1.00      0.75      0.86         4
         831       0.80      0.80      0.80         5
         832       0.43      0.75      0.55         4
         833       1.00      1.00      1.00         4
         834       1.00      0.89      0.94         9
         835       0.80      0.44      0.57         9
         836       1.00      1.00      1.00         9
         837       0.00      0.00      0.00         9
         838       1.00      0.75      0.86         4
         839       1.00      0.50      0.67         4
         840       0.67      1.00      0.80         4
         841       1.00      1.00      1.00         9
         842       1.00      1.00      1.00         5
         843       0.80      1.00      0.89         4
         844       1.00      0.75      0.86         4
         845       0.67      0.50      0.57         4
         846       1.00      0.50      0.67         4
         847       0.82      1.00      0.90         9
         848       0.75      0.75      0.75         4
         849       0.75      0.75      0.75         4
         850       0.75      0.75      0.75         4
         851       1.00      1.00      1.00         4
         852       0.50      0.60      0.55         5
         853       1.00      0.89      0.94         9
         854       0.00      0.00      0.00         4
         855       0.67      1.00      0.80         4
         856       0.69      1.00      0.82         9
         857       0.80      1.00      0.89         4
         858       1.00      0.25      0.40         4
         859       0.10      0.25      0.14         4
         860       0.80      1.00      0.89         4
         861       0.90      1.00      0.95         9
         862       1.00      1.00      1.00         9
         863       1.00      1.00      1.00         9
         864       0.57      1.00      0.73         4
         865       0.75      0.60      0.67         5
         866       0.80      1.00      0.89         4
         867       0.75      0.75      0.75         4
         868       0.80      0.80      0.80         5
         869       0.83      1.00      0.91         5
         870       0.75      0.75      0.75         4
         871       0.89      0.89      0.89         9
         872       0.80      1.00      0.89         4
         873       0.60      0.75      0.67         4
         874       0.00      0.00      0.00         4
         875       0.67      0.50      0.57         4
         876       1.00      0.56      0.71         9
         877       0.75      0.75      0.75         4
         878       0.67      1.00      0.80         4
         879       0.67      0.50      0.57         4
         880       0.50      0.60      0.55         5
         881       1.00      1.00      1.00         4
         882       0.80      1.00      0.89         8
         883       0.78      0.78      0.78         9
         884       0.80      1.00      0.89         4
         885       0.67      0.50      0.57         4
         886       1.00      1.00      1.00         4
         887       1.00      0.75      0.86         4
         888       0.67      1.00      0.80         4
         889       1.00      0.75      0.86         4
         890       0.67      0.50      0.57         4
         891       0.00      0.00      0.00         4
         892       0.75      0.75      0.75         4
         893       1.00      1.00      1.00         4

    accuracy                           0.70      4917
   macro avg       0.69      0.68      0.67      4917
weighted avg       0.71      0.70      0.69      4917

task_train_time: {0: 0.12389244799999943, 1: 0.03832800999999897, 2: 0.029873424999999898, 3: 0.02753563899999989, 4: 0.03286509800000026, 5: 0.028219875999999644, 6: 0.03646793900000134, 7: 0.03265644199999862, 8: 0.03802610099999981, 9: 0.03065652499999949, 10: 0.0308030059999993, 11: 0.03296295799999882, 12: 0.03695601699999962, 13: 0.034102554000000396, 14: 0.029972215999999108, 15: 0.029584511000001257, 16: 0.03351812999999915, 17: 0.03310391099999954, 18: 0.033770098000001525, 19: 0.031934117000000484, 20: 0.037415393999999935, 21: 0.03520431399999957, 22: 0.03542365700000083, 23: 0.030204341000001023, 24: 0.03463963000000092, 25: 0.03517256199999963, 26: 0.03928656700000133, 27: 0.04304338100000038, 28: 0.03530353100000028, 29: 0.032490350000001555, 30: 0.033633323000000104, 31: 0.03495137900000067, 32: 0.036588457000000574, 33: 0.03001399000000049, 34: 0.033262196000002575, 35: 0.031406670999999164, 36: 0.032211587999999125, 37: 0.03793773700000003, 38: 0.0347372739999976, 39: 0.036335892000000314, 40: 0.031119513000000154, 41: 0.03708035500000051, 42: 0.03362751999999958, 43: 0.029203009999999807}
prediction_time: 0.00030415999999888754
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
