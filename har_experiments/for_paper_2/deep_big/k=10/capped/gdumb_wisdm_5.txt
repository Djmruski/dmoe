Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='5aa7aae7-f125-40ca-b3c8-b6c8c05f0bfa', conf_timestamp='2023-08-14 11:32:19.767725', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 66.67 % 	 [Task-IL]: 40.11 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 56.28 % 	 [Task-IL]: 39.2 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 41.9 % 	 [Task-IL]: 33.65 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 38.06 % 	 [Task-IL]: 30.04 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 29.85 % 	 [Task-IL]: 28.57 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 23.11 % 	 [Task-IL]: 26.89 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 25.61 % 	 [Task-IL]: 26.21 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 23.33 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 22.68 % 	 [Task-IL]: 27.46 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.63 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 16.85 % 	 [Task-IL]: 26.79 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 15.81 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 19.46 % 	 [Task-IL]: 27.47 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 14.26 % 	 [Task-IL]: 26.52 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.27 % 	 [Task-IL]: 26.37 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 8.37 % 	 [Task-IL]: 26.51 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.15 % 	 [Task-IL]: 26.15 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 13.49 % 	 [Task-IL]: 25.86 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.79 % 	 [Task-IL]: 25.72 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.61 % 	 [Task-IL]: 25.17 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.36 % 	 [Task-IL]: 25.59 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 9.66 % 	 [Task-IL]: 25.27 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 7.9 % 	 [Task-IL]: 25.73 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.47 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.66 % 	 [Task-IL]: 26.06 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.69 % 	 [Task-IL]: 26.69 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.69 % 	 [Task-IL]: 26.7 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.55 % 	 [Task-IL]: 26.24 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.29 % 	 [Task-IL]: 26.54 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.06 % 	 [Task-IL]: 26.66 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.32 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 8.08 % 	 [Task-IL]: 26.75 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.51 % 	 [Task-IL]: 27.01 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.51 % 	 [Task-IL]: 27.09 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.46 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.9 % 	 [Task-IL]: 26.56 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.4 % 	 [Task-IL]: 26.31 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.74 % 	 [Task-IL]: 25.79 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.24 % 	 [Task-IL]: 25.96 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.06 % 	 [Task-IL]: 25.98 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.96 % 	 [Task-IL]: 25.86 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.13 % 	 [Task-IL]: 26.09 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.07 % 	 [Task-IL]: 26.13 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({607: 25, 145: 25, 317: 24, 429: 24, 806: 23, 776: 23, 614: 23, 693: 23, 235: 23, 857: 22, 745: 22, 680: 22, 162: 22, 179: 22, 218: 22, 221: 22, 535: 22, 32: 21, 821: 21, 689: 21, 788: 21, 838: 21, 682: 21, 138: 21, 168: 21, 282: 21, 365: 21, 402: 21, 451: 21, 496: 21, 876: 20, 786: 20, 832: 20, 622: 20, 678: 20, 64: 20, 61: 20, 60: 20, 714: 20, 82: 20, 101: 20, 122: 20, 548: 20, 328: 20, 339: 20, 408: 20, 446: 20, 506: 20, 494: 20, 885: 19, 690: 19, 701: 19, 655: 19, 855: 19, 880: 19, 615: 19, 866: 19, 659: 19, 751: 19, 601: 19, 575: 19, 35: 19, 44: 19, 704: 19, 634: 19, 55: 19, 69: 19, 59: 19, 73: 19, 759: 19, 97: 19, 109: 19, 143: 19, 667: 19, 193: 19, 202: 19, 196: 19, 209: 19, 239: 19, 278: 19, 308: 19, 343: 19, 348: 19, 338: 19, 368: 19, 376: 19, 397: 19, 406: 19, 467: 19, 476: 19, 872: 18, 632: 18, 640: 18, 686: 18, 605: 18, 602: 18, 699: 18, 629: 18, 703: 18, 706: 18, 677: 18, 104: 18, 107: 18, 100: 18, 189: 18, 187: 18, 212: 18, 319: 18, 324: 18, 323: 18, 390: 18, 383: 18, 471: 18, 456: 18, 510: 18, 513: 18, 540: 18, 18: 17, 30: 17, 592: 17, 834: 17, 713: 17, 647: 17, 700: 17, 764: 17, 688: 17, 600: 17, 797: 17, 679: 17, 718: 17, 554: 17, 598: 17, 39: 17, 569: 17, 888: 17, 90: 17, 612: 17, 96: 17, 132: 17, 197: 17, 203: 17, 219: 17, 267: 17, 382: 17, 392: 17, 385: 17, 418: 17, 420: 17, 459: 17, 475: 17, 727: 16, 0: 16, 840: 16, 643: 16, 808: 16, 882: 16, 752: 16, 654: 16, 627: 16, 771: 16, 65: 16, 779: 16, 642: 16, 81: 16, 616: 16, 83: 16, 111: 16, 134: 16, 233: 16, 281: 16, 290: 16, 292: 16, 289: 16, 371: 16, 400: 16, 493: 16, 523: 16, 532: 16, 520: 16, 29: 15, 670: 15, 22: 15, 790: 15, 563: 15, 875: 15, 795: 15, 41: 15, 870: 15, 204: 15, 225: 15, 250: 15, 258: 15, 345: 15, 352: 15, 366: 15, 389: 15, 396: 15, 478: 15, 479: 15, 533: 15, 514: 15, 803: 14, 887: 14, 62: 14, 93: 14, 80: 14, 171: 14, 377: 14, 432: 14, 719: 13, 573: 13, 590: 13, 574: 13, 48: 13, 753: 13, 802: 13, 657: 13, 127: 13, 553: 13, 154: 13, 552: 13, 254: 13, 306: 13, 386: 13, 444: 13, 466: 13, 522: 13, 692: 12, 34: 12, 66: 12, 868: 12, 705: 12, 87: 12, 148: 12, 695: 12, 223: 12, 222: 12, 234: 12, 293: 12, 320: 12, 422: 12, 474: 12, 508: 12, 498: 12, 1: 11, 741: 11, 733: 11, 813: 11, 864: 11, 822: 11, 820: 11, 555: 11, 92: 11, 99: 11, 110: 11, 144: 11, 140: 11, 155: 11, 184: 11, 178: 11, 231: 11, 230: 11, 263: 11, 265: 11, 305: 11, 322: 11, 359: 11, 430: 11, 500: 11, 529: 11, 524: 11, 23: 10, 664: 10, 28: 10, 831: 10, 683: 10, 17: 10, 812: 10, 828: 10, 578: 10, 568: 10, 837: 10, 847: 10, 740: 10, 725: 10, 608: 10, 625: 10, 53: 10, 50: 10, 51: 10, 815: 10, 656: 10, 736: 10, 56: 10, 687: 10, 79: 10, 799: 10, 105: 10, 106: 10, 131: 10, 123: 10, 114: 10, 115: 10, 798: 10, 136: 10, 142: 10, 147: 10, 561: 10, 157: 10, 173: 10, 161: 10, 185: 10, 216: 10, 217: 10, 746: 10, 242: 10, 269: 10, 266: 10, 271: 10, 279: 10, 296: 10, 299: 10, 315: 10, 353: 10, 349: 10, 350: 10, 367: 10, 363: 10, 364: 10, 407: 10, 409: 10, 417: 10, 416: 10, 453: 10, 470: 10, 458: 10, 480: 10, 490: 10, 497: 10, 511: 10, 12: 9, 31: 9, 842: 9, 15: 9, 9: 9, 671: 9, 637: 9, 886: 9, 807: 9, 672: 9, 685: 9, 697: 9, 789: 9, 811: 9, 794: 9, 650: 9, 854: 9, 72: 9, 58: 9, 707: 9, 859: 9, 892: 9, 856: 9, 698: 9, 89: 9, 85: 9, 646: 9, 624: 9, 94: 9, 749: 9, 800: 9, 734: 9, 118: 9, 117: 9, 572: 9, 744: 9, 729: 9, 720: 9, 152: 9, 137: 9, 816: 9, 595: 9, 541: 9, 641: 9, 158: 9, 188: 9, 581: 9, 562: 9, 863: 9, 245: 9, 241: 9, 270: 9, 288: 9, 277: 9, 287: 9, 311: 9, 309: 9, 310: 9, 314: 9, 321: 9, 334: 9, 342: 9, 373: 9, 378: 9, 399: 9, 425: 9, 421: 9, 426: 9, 449: 9, 452: 9, 457: 9, 504: 9, 502: 9, 528: 9, 515: 9, 613: 8, 711: 8, 747: 8, 7: 8, 784: 8, 10: 8, 766: 8, 3: 8, 558: 8, 651: 8, 805: 8, 560: 8, 556: 8, 596: 8, 5: 8, 810: 8, 865: 8, 785: 8, 669: 8, 591: 8, 879: 8, 675: 8, 824: 8, 772: 8, 754: 8, 889: 8, 674: 8, 599: 8, 577: 8, 792: 8, 36: 8, 644: 8, 758: 8, 43: 8, 570: 8, 770: 8, 38: 8, 846: 8, 823: 8, 881: 8, 851: 8, 662: 8, 71: 8, 54: 8, 768: 8, 76: 8, 663: 8, 77: 8, 88: 8, 661: 8, 696: 8, 108: 8, 777: 8, 102: 8, 830: 8, 619: 8, 550: 8, 843: 8, 588: 8, 735: 8, 709: 8, 862: 8, 135: 8, 153: 8, 658: 8, 660: 8, 167: 8, 164: 8, 159: 8, 169: 8, 694: 8, 542: 8, 175: 8, 587: 8, 186: 8, 726: 8, 845: 8, 210: 8, 211: 8, 201: 8, 207: 8, 214: 8, 224: 8, 253: 8, 249: 8, 236: 8, 246: 8, 255: 8, 291: 8, 283: 8, 285: 8, 284: 8, 286: 8, 298: 8, 300: 8, 304: 8, 325: 8, 330: 8, 318: 8, 332: 8, 341: 8, 346: 8, 337: 8, 344: 8, 356: 8, 362: 8, 360: 8, 361: 8, 375: 8, 394: 8, 412: 8, 410: 8, 401: 8, 414: 8, 439: 8, 440: 8, 442: 8, 441: 8, 448: 8, 445: 8, 465: 8, 454: 8, 464: 8, 463: 8, 492: 8, 491: 8, 482: 8, 485: 8, 484: 8, 543: 8, 505: 8, 530: 8, 531: 8, 519: 8, 551: 8, 538: 8, 546: 8, 26: 7, 742: 7, 829: 7, 722: 7, 649: 7, 8: 7, 20: 7, 6: 7, 33: 7, 27: 7, 739: 7, 630: 7, 585: 7, 757: 7, 21: 7, 717: 7, 559: 7, 594: 7, 597: 7, 604: 7, 567: 7, 890: 7, 760: 7, 708: 7, 767: 7, 47: 7, 817: 7, 37: 7, 49: 7, 565: 7, 721: 7, 580: 7, 871: 7, 63: 7, 70: 7, 737: 7, 836: 7, 750: 7, 549: 7, 841: 7, 537: 7, 609: 7, 731: 7, 582: 7, 804: 7, 835: 7, 78: 7, 844: 7, 773: 7, 716: 7, 861: 7, 666: 7, 103: 7, 665: 7, 120: 7, 116: 7, 126: 7, 884: 7, 755: 7, 544: 7, 141: 7, 139: 7, 724: 7, 172: 7, 165: 7, 166: 7, 156: 7, 170: 7, 684: 7, 673: 7, 176: 7, 180: 7, 177: 7, 190: 7, 195: 7, 208: 7, 226: 7, 215: 7, 228: 7, 247: 7, 237: 7, 243: 7, 238: 7, 743: 7, 260: 7, 264: 7, 256: 7, 262: 7, 272: 7, 275: 7, 280: 7, 312: 7, 294: 7, 331: 7, 347: 7, 370: 7, 355: 7, 387: 7, 391: 7, 381: 7, 384: 7, 404: 7, 413: 7, 415: 7, 427: 7, 450: 7, 447: 7, 461: 7, 460: 7, 462: 7, 472: 7, 481: 7, 489: 7, 539: 7, 512: 7, 527: 7, 525: 7, 516: 7, 25: 6, 606: 6, 791: 6, 653: 6, 24: 6, 4: 6, 761: 6, 691: 6, 16: 6, 801: 6, 652: 6, 853: 6, 566: 6, 769: 6, 576: 6, 778: 6, 648: 6, 833: 6, 858: 6, 564: 6, 52: 6, 46: 6, 40: 6, 860: 6, 756: 6, 45: 6, 610: 6, 878: 6, 809: 6, 869: 6, 825: 6, 780: 6, 645: 6, 883: 6, 638: 6, 611: 6, 586: 6, 623: 6, 848: 6, 819: 6, 74: 6, 710: 6, 676: 6, 631: 6, 618: 6, 98: 6, 95: 6, 112: 6, 715: 6, 620: 6, 128: 6, 129: 6, 133: 6, 124: 6, 151: 6, 730: 6, 783: 6, 163: 6, 160: 6, 826: 6, 748: 6, 181: 6, 213: 6, 762: 6, 636: 6, 232: 6, 774: 6, 617: 6, 547: 6, 639: 6, 273: 6, 257: 6, 301: 6, 307: 6, 297: 6, 295: 6, 326: 6, 327: 6, 333: 6, 316: 6, 329: 6, 545: 6, 335: 6, 336: 6, 357: 6, 393: 6, 403: 6, 411: 6, 419: 6, 436: 6, 455: 6, 469: 6, 468: 6, 488: 6, 477: 6, 509: 6, 521: 6, 518: 6, 534: 6, 13: 5, 2: 5, 877: 5, 763: 5, 19: 5, 583: 5, 782: 5, 633: 5, 781: 5, 867: 5, 42: 5, 579: 5, 849: 5, 68: 5, 793: 5, 603: 5, 86: 5, 84: 5, 873: 5, 728: 5, 874: 5, 723: 5, 818: 5, 571: 5, 593: 5, 121: 5, 891: 5, 668: 5, 146: 5, 621: 5, 150: 5, 149: 5, 787: 5, 814: 5, 174: 5, 765: 5, 192: 5, 183: 5, 198: 5, 206: 5, 200: 5, 194: 5, 205: 5, 251: 5, 248: 5, 252: 5, 240: 5, 261: 5, 259: 5, 276: 5, 313: 5, 303: 5, 340: 5, 351: 5, 372: 5, 354: 5, 374: 5, 398: 5, 405: 5, 431: 5, 424: 5, 428: 5, 437: 5, 443: 5, 435: 5, 434: 5, 473: 5, 486: 5, 483: 5, 499: 5, 14: 4, 852: 4, 775: 4, 628: 4, 57: 4, 893: 4, 91: 4, 839: 4, 75: 4, 113: 4, 557: 4, 796: 4, 125: 4, 130: 4, 635: 4, 712: 4, 191: 4, 182: 4, 199: 4, 229: 4, 220: 4, 268: 4, 274: 4, 738: 4, 302: 4, 850: 4, 732: 4, 358: 4, 369: 4, 388: 4, 380: 4, 379: 4, 395: 4, 423: 4, 433: 4, 438: 4, 487: 4, 507: 4, 501: 4, 503: 4, 517: 4, 827: 3, 536: 3, 11: 3, 67: 3, 589: 3, 119: 3, 227: 3, 526: 3, 584: 2, 681: 2, 702: 2, 244: 2, 626: 2, 495: 2})
Total buffer: 8940
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 10, 1: 10, 17: 10, 18: 10, 22: 10, 23: 10, 28: 10, 29: 10, 30: 10, 32: 10, 34: 10, 35: 10, 39: 10, 41: 10, 44: 10, 48: 10, 50: 10, 51: 10, 53: 10, 55: 10, 56: 10, 59: 10, 60: 10, 61: 10, 62: 10, 64: 10, 65: 10, 66: 10, 69: 10, 73: 10, 79: 10, 80: 10, 81: 10, 82: 10, 83: 10, 87: 10, 90: 10, 92: 10, 93: 10, 96: 10, 97: 10, 99: 10, 100: 10, 101: 10, 104: 10, 105: 10, 106: 10, 107: 10, 109: 10, 110: 10, 111: 10, 114: 10, 115: 10, 122: 10, 123: 10, 127: 10, 131: 10, 132: 10, 134: 10, 136: 10, 138: 10, 140: 10, 142: 10, 143: 10, 144: 10, 145: 10, 147: 10, 148: 10, 154: 10, 155: 10, 157: 10, 161: 10, 162: 10, 168: 10, 171: 10, 173: 10, 178: 10, 179: 10, 184: 10, 185: 10, 187: 10, 189: 10, 193: 10, 196: 10, 197: 10, 202: 10, 203: 10, 204: 10, 209: 10, 212: 10, 216: 10, 217: 10, 218: 10, 219: 10, 221: 10, 222: 10, 223: 10, 225: 10, 230: 10, 231: 10, 233: 10, 234: 10, 235: 10, 239: 10, 242: 10, 250: 10, 254: 10, 258: 10, 263: 10, 265: 10, 266: 10, 267: 10, 269: 10, 271: 10, 278: 10, 279: 10, 281: 10, 282: 10, 289: 10, 290: 10, 292: 10, 293: 10, 296: 10, 299: 10, 305: 10, 306: 10, 308: 10, 315: 10, 317: 10, 319: 10, 320: 10, 322: 10, 323: 10, 324: 10, 328: 10, 338: 10, 339: 10, 343: 10, 345: 10, 348: 10, 349: 10, 350: 10, 352: 10, 353: 10, 359: 10, 363: 10, 364: 10, 365: 10, 366: 10, 367: 10, 368: 10, 371: 10, 376: 10, 377: 10, 382: 10, 383: 10, 385: 10, 386: 10, 389: 10, 390: 10, 392: 10, 396: 10, 397: 10, 400: 10, 402: 10, 406: 10, 407: 10, 408: 10, 409: 10, 416: 10, 417: 10, 418: 10, 420: 10, 422: 10, 429: 10, 430: 10, 432: 10, 444: 10, 446: 10, 451: 10, 453: 10, 456: 10, 458: 10, 459: 10, 466: 10, 467: 10, 470: 10, 471: 10, 474: 10, 475: 10, 476: 10, 478: 10, 479: 10, 480: 10, 490: 10, 493: 10, 494: 10, 496: 10, 497: 10, 498: 10, 500: 10, 506: 10, 508: 10, 510: 10, 511: 10, 513: 10, 514: 10, 520: 10, 522: 10, 523: 10, 524: 10, 529: 10, 532: 10, 533: 10, 535: 10, 540: 10, 548: 10, 552: 10, 553: 10, 554: 10, 555: 10, 561: 10, 563: 10, 568: 10, 569: 10, 573: 10, 574: 10, 575: 10, 578: 10, 590: 10, 592: 10, 598: 10, 600: 10, 601: 10, 602: 10, 605: 10, 607: 10, 608: 10, 612: 10, 614: 10, 615: 10, 616: 10, 622: 10, 625: 10, 627: 10, 629: 10, 632: 10, 634: 10, 640: 10, 642: 10, 643: 10, 647: 10, 654: 10, 655: 10, 656: 10, 657: 10, 659: 10, 664: 10, 667: 10, 670: 10, 677: 10, 678: 10, 679: 10, 680: 10, 682: 10, 683: 10, 686: 10, 687: 10, 688: 10, 689: 10, 690: 10, 692: 10, 693: 10, 695: 10, 699: 10, 700: 10, 701: 10, 703: 10, 704: 10, 705: 10, 706: 10, 713: 10, 714: 10, 718: 10, 719: 10, 725: 10, 727: 10, 733: 10, 736: 10, 740: 10, 741: 10, 745: 10, 746: 10, 751: 10, 752: 10, 753: 10, 759: 10, 764: 10, 771: 10, 776: 10, 779: 10, 786: 10, 788: 10, 790: 10, 795: 10, 797: 10, 798: 10, 799: 10, 802: 10, 803: 10, 806: 10, 808: 10, 812: 10, 813: 10, 815: 10, 820: 10, 821: 10, 822: 10, 828: 10, 831: 10, 832: 10, 834: 10, 837: 10, 838: 10, 840: 10, 847: 10, 855: 10, 857: 10, 864: 10, 866: 10, 868: 10, 870: 10, 872: 10, 875: 10, 876: 10, 880: 10, 882: 10, 885: 10, 887: 10, 888: 10, 9: 9, 12: 9, 15: 9, 31: 9, 58: 9, 72: 9, 85: 9, 89: 9, 94: 9, 117: 9, 118: 9, 137: 9, 152: 9, 158: 9, 188: 9, 241: 9, 245: 9, 270: 9, 277: 9, 287: 9, 288: 9, 309: 9, 310: 9, 311: 9, 314: 9, 321: 9, 334: 9, 342: 9, 373: 9, 378: 9, 399: 9, 421: 9, 425: 9, 426: 9, 449: 9, 452: 9, 457: 9, 502: 9, 504: 9, 515: 9, 528: 9, 541: 9, 562: 9, 572: 9, 581: 9, 595: 9, 624: 9, 637: 9, 641: 9, 646: 9, 650: 9, 671: 9, 672: 9, 685: 9, 697: 9, 698: 9, 707: 9, 720: 9, 729: 9, 734: 9, 744: 9, 749: 9, 789: 9, 794: 9, 800: 9, 807: 9, 811: 9, 816: 9, 842: 9, 854: 9, 856: 9, 859: 9, 863: 9, 886: 9, 892: 9, 3: 8, 5: 8, 7: 8, 10: 8, 36: 8, 38: 8, 43: 8, 54: 8, 71: 8, 76: 8, 77: 8, 88: 8, 102: 8, 108: 8, 135: 8, 153: 8, 159: 8, 164: 8, 167: 8, 169: 8, 175: 8, 186: 8, 201: 8, 207: 8, 210: 8, 211: 8, 214: 8, 224: 8, 236: 8, 246: 8, 249: 8, 253: 8, 255: 8, 283: 8, 284: 8, 285: 8, 286: 8, 291: 8, 298: 8, 300: 8, 304: 8, 318: 8, 325: 8, 330: 8, 332: 8, 337: 8, 341: 8, 344: 8, 346: 8, 356: 8, 360: 8, 361: 8, 362: 8, 375: 8, 394: 8, 401: 8, 410: 8, 412: 8, 414: 8, 439: 8, 440: 8, 441: 8, 442: 8, 445: 8, 448: 8, 454: 8, 463: 8, 464: 8, 465: 8, 482: 8, 484: 8, 485: 8, 491: 8, 492: 8, 505: 8, 519: 8, 530: 8, 531: 8, 538: 8, 542: 8, 543: 8, 546: 8, 550: 8, 551: 8, 556: 8, 558: 8, 560: 8, 570: 8, 577: 8, 587: 8, 588: 8, 591: 8, 596: 8, 599: 8, 613: 8, 619: 8, 644: 8, 651: 8, 658: 8, 660: 8, 661: 8, 662: 8, 663: 8, 669: 8, 674: 8, 675: 8, 694: 8, 696: 8, 709: 8, 711: 8, 726: 8, 735: 8, 747: 8, 754: 8, 758: 8, 766: 8, 768: 8, 770: 8, 772: 8, 777: 8, 784: 8, 785: 8, 792: 8, 805: 8, 810: 8, 823: 8, 824: 8, 830: 8, 843: 8, 845: 8, 846: 8, 851: 8, 862: 8, 865: 8, 879: 8, 881: 8, 889: 8, 6: 7, 8: 7, 20: 7, 21: 7, 26: 7, 27: 7, 33: 7, 37: 7, 47: 7, 49: 7, 63: 7, 70: 7, 78: 7, 103: 7, 116: 7, 120: 7, 126: 7, 139: 7, 141: 7, 156: 7, 165: 7, 166: 7, 170: 7, 172: 7, 176: 7, 177: 7, 180: 7, 190: 7, 195: 7, 208: 7, 215: 7, 226: 7, 228: 7, 237: 7, 238: 7, 243: 7, 247: 7, 256: 7, 260: 7, 262: 7, 264: 7, 272: 7, 275: 7, 280: 7, 294: 7, 312: 7, 331: 7, 347: 7, 355: 7, 370: 7, 381: 7, 384: 7, 387: 7, 391: 7, 404: 7, 413: 7, 415: 7, 427: 7, 447: 7, 450: 7, 460: 7, 461: 7, 462: 7, 472: 7, 481: 7, 489: 7, 512: 7, 516: 7, 525: 7, 527: 7, 537: 7, 539: 7, 544: 7, 549: 7, 559: 7, 565: 7, 567: 7, 580: 7, 582: 7, 585: 7, 594: 7, 597: 7, 604: 7, 609: 7, 630: 7, 649: 7, 665: 7, 666: 7, 673: 7, 684: 7, 708: 7, 716: 7, 717: 7, 721: 7, 722: 7, 724: 7, 731: 7, 737: 7, 739: 7, 742: 7, 743: 7, 750: 7, 755: 7, 757: 7, 760: 7, 767: 7, 773: 7, 804: 7, 817: 7, 829: 7, 835: 7, 836: 7, 841: 7, 844: 7, 861: 7, 871: 7, 884: 7, 890: 7, 4: 6, 16: 6, 24: 6, 25: 6, 40: 6, 45: 6, 46: 6, 52: 6, 74: 6, 95: 6, 98: 6, 112: 6, 124: 6, 128: 6, 129: 6, 133: 6, 151: 6, 160: 6, 163: 6, 181: 6, 213: 6, 232: 6, 257: 6, 273: 6, 295: 6, 297: 6, 301: 6, 307: 6, 316: 6, 326: 6, 327: 6, 329: 6, 333: 6, 335: 6, 336: 6, 357: 6, 393: 6, 403: 6, 411: 6, 419: 6, 436: 6, 455: 6, 468: 6, 469: 6, 477: 6, 488: 6, 509: 6, 518: 6, 521: 6, 534: 6, 545: 6, 547: 6, 564: 6, 566: 6, 576: 6, 586: 6, 606: 6, 610: 6, 611: 6, 617: 6, 618: 6, 620: 6, 623: 6, 631: 6, 636: 6, 638: 6, 639: 6, 645: 6, 648: 6, 652: 6, 653: 6, 676: 6, 691: 6, 710: 6, 715: 6, 730: 6, 748: 6, 756: 6, 761: 6, 762: 6, 769: 6, 774: 6, 778: 6, 780: 6, 783: 6, 791: 6, 801: 6, 809: 6, 819: 6, 825: 6, 826: 6, 833: 6, 848: 6, 853: 6, 858: 6, 860: 6, 869: 6, 878: 6, 883: 6, 2: 5, 13: 5, 19: 5, 42: 5, 68: 5, 84: 5, 86: 5, 121: 5, 146: 5, 149: 5, 150: 5, 174: 5, 183: 5, 192: 5, 194: 5, 198: 5, 200: 5, 205: 5, 206: 5, 240: 5, 248: 5, 251: 5, 252: 5, 259: 5, 261: 5, 276: 5, 303: 5, 313: 5, 340: 5, 351: 5, 354: 5, 372: 5, 374: 5, 398: 5, 405: 5, 424: 5, 428: 5, 431: 5, 434: 5, 435: 5, 437: 5, 443: 5, 473: 5, 483: 5, 486: 5, 499: 5, 571: 5, 579: 5, 583: 5, 593: 5, 603: 5, 621: 5, 633: 5, 668: 5, 723: 5, 728: 5, 763: 5, 765: 5, 781: 5, 782: 5, 787: 5, 793: 5, 814: 5, 818: 5, 849: 5, 867: 5, 873: 5, 874: 5, 877: 5, 891: 5, 14: 4, 57: 4, 75: 4, 91: 4, 113: 4, 125: 4, 130: 4, 182: 4, 191: 4, 199: 4, 220: 4, 229: 4, 268: 4, 274: 4, 302: 4, 358: 4, 369: 4, 379: 4, 380: 4, 388: 4, 395: 4, 423: 4, 433: 4, 438: 4, 487: 4, 501: 4, 503: 4, 507: 4, 517: 4, 557: 4, 628: 4, 635: 4, 712: 4, 732: 4, 738: 4, 775: 4, 796: 4, 839: 4, 850: 4, 852: 4, 893: 4, 11: 3, 67: 3, 119: 3, 227: 3, 526: 3, 536: 3, 589: 3, 827: 3, 244: 2, 495: 2, 584: 2, 626: 2, 681: 2, 702: 2})
Total buffer: 7141
fit_time: 59.49260740900001

Accuracy for 44 task(s): 	 [Class-IL]: 69.76 % 	 [Task-IL]: 30.77 %

CLASS_IL_ACC: 
	[67.2316384180791, 72.64150943396226, 62.878787878787875, 75.65217391304347, 75.2, 74.48979591836735, 69.91150442477876, 64.81481481481481, 61.46788990825688, 62.93103448275862, 61.06194690265486, 63.26530612244898, 81.05263157894737, 75.0, 68.47826086956522, 75.0, 72.80701754385966, 62.857142857142854, 66.14173228346458, 65.76576576576578, 84.40366972477065, 67.02127659574468, 80.73394495412845, 60.0, 67.24137931034483, 74.78260869565217, 76.41509433962264, 75.22935779816514, 72.38095238095238, 63.47826086956522, 71.1864406779661, 71.69811320754717, 71.81818181818181, 65.9090909090909, 66.93548387096774, 65.3061224489796, 79.0909090909091, 70.10309278350515, 79.43925233644859, 71.55172413793103, 56.12244897959183, 65.625, 67.82608695652173, 66.37931034482759]
TASK_IL_ACC: 
	[53.10734463276836, 32.075471698113205, 21.21212121212121, 20.869565217391305, 26.400000000000002, 25.510204081632654, 30.08849557522124, 31.48148148148148, 28.440366972477065, 29.310344827586203, 30.08849557522124, 34.69387755102041, 29.47368421052631, 25.0, 25.0, 31.666666666666664, 28.947368421052634, 23.809523809523807, 25.196850393700785, 27.927927927927925, 29.357798165137616, 22.340425531914892, 31.19266055045872, 40.909090909090914, 31.03448275862069, 26.08695652173913, 27.358490566037734, 26.605504587155966, 37.142857142857146, 22.608695652173914, 33.89830508474576, 26.41509433962264, 39.09090909090909, 24.242424242424242, 23.387096774193548, 33.6734693877551, 26.36363636363636, 27.835051546391753, 29.906542056074763, 32.758620689655174, 23.46938775510204, 34.375, 30.434782608695656, 93.10344827586206]
f1_micro: 69.6969696969697
f1_macro: 66.79175270431989
              precision    recall  f1-score   support

           0       0.60      0.67      0.63         9
           1       1.00      1.00      1.00         5
           2       0.00      0.00      0.00         4
           3       1.00      0.50      0.67         4
           4       0.00      0.00      0.00         4
           5       1.00      0.25      0.40         4
           6       0.80      0.80      0.80         5
           7       0.75      0.75      0.75         4
           8       0.75      0.60      0.67         5
           9       1.00      1.00      1.00         5
          10       0.50      0.50      0.50         4
          11       1.00      1.00      1.00         4
          12       0.67      0.80      0.73         5
          13       1.00      0.75      0.86         4
          14       1.00      1.00      1.00         4
          15       0.80      1.00      0.89         4
          16       0.40      0.50      0.44         4
          17       0.00      0.00      0.00         4
          18       1.00      0.44      0.62         9
          19       0.67      0.50      0.57         4
          20       0.67      1.00      0.80         4
          21       0.27      0.60      0.37         5
          22       0.08      0.11      0.10         9
          23       1.00      1.00      1.00         5
          24       0.80      1.00      0.89         4
          25       0.83      1.00      0.91         5
          26       1.00      0.60      0.75         5
          27       1.00      1.00      1.00         4
          28       0.80      0.80      0.80         5
          29       1.00      0.78      0.88         9
          30       1.00      0.67      0.80         9
          31       0.27      0.80      0.40         5
          32       1.00      0.89      0.94         9
          33       0.75      0.75      0.75         4
          34       1.00      1.00      1.00         5
          35       1.00      0.89      0.94         9
          36       0.50      0.25      0.33         4
          37       0.75      0.75      0.75         4
          38       0.00      0.00      0.00         4
          39       0.82      1.00      0.90         9
          40       0.80      1.00      0.89         4
          41       1.00      1.00      1.00         9
          42       0.80      1.00      0.89         4
          43       0.83      1.00      0.91         5
          44       0.88      0.78      0.82         9
          45       0.80      1.00      0.89         4
          46       0.00      0.00      0.00         4
          47       0.00      0.00      0.00         5
          48       0.40      0.40      0.40         5
          49       0.00      0.00      0.00         4
          50       0.83      1.00      0.91         5
          51       0.75      0.75      0.75         4
          52       1.00      1.00      1.00         4
          53       0.80      0.80      0.80         5
          54       0.75      0.75      0.75         4
          55       1.00      0.89      0.94         9
          56       1.00      0.75      0.86         4
          57       0.33      0.25      0.29         4
          58       0.00      0.00      0.00         5
          59       1.00      0.67      0.80         9
          60       0.80      0.89      0.84         9
          61       0.73      0.89      0.80         9
          62       0.90      1.00      0.95         9
          63       1.00      0.75      0.86         4
          64       0.88      0.78      0.82         9
          65       0.90      1.00      0.95         9
          66       0.11      0.11      0.11         9
          67       1.00      0.50      0.67         4
          68       0.00      0.00      0.00         4
          69       0.00      0.00      0.00         9
          70       0.67      1.00      0.80         4
          71       0.25      0.25      0.25         4
          72       1.00      0.60      0.75         5
          73       0.88      0.78      0.82         9
          74       1.00      0.75      0.86         4
          75       0.00      0.00      0.00         4
          76       0.67      0.40      0.50         5
          77       0.75      0.75      0.75         4
          78       1.00      0.75      0.86         4
          79       1.00      0.75      0.86         4
          80       0.83      1.00      0.91         5
          81       0.78      0.78      0.78         9
          82       0.89      0.89      0.89         9
          83       0.83      0.56      0.67         9
          84       0.80      1.00      0.89         4
          85       1.00      1.00      1.00         5
          86       1.00      1.00      1.00         4
          87       1.00      1.00      1.00         9
          88       0.10      0.25      0.14         4
          89       0.71      1.00      0.83         5
          90       1.00      0.89      0.94         9
          91       0.00      0.00      0.00         4
          92       1.00      0.80      0.89         5
          93       0.67      0.89      0.76         9
          94       0.71      1.00      0.83         5
          95       0.33      0.25      0.29         4
          96       1.00      1.00      1.00         9
          97       0.90      1.00      0.95         9
          98       1.00      0.40      0.57         5
          99       0.67      0.40      0.50         5
         100       1.00      1.00      1.00         9
         101       0.80      0.89      0.84         9
         102       0.44      1.00      0.62         4
         103       0.75      0.75      0.75         4
         104       0.78      0.78      0.78         9
         105       0.71      1.00      0.83         5
         106       0.83      1.00      0.91         5
         107       0.83      0.56      0.67         9
         108       0.75      0.75      0.75         4
         109       0.89      0.89      0.89         9
         110       0.40      0.50      0.44         4
         111       1.00      0.67      0.80         9
         112       0.50      0.25      0.33         4
         113       0.00      0.00      0.00         4
         114       0.57      1.00      0.73         4
         115       1.00      1.00      1.00         5
         116       1.00      1.00      1.00         5
         117       1.00      0.50      0.67         4
         118       0.00      0.00      0.00         4
         119       0.80      1.00      0.89         4
         120       0.40      0.50      0.44         4
         121       0.67      0.80      0.73         5
         122       0.78      0.78      0.78         9
         123       1.00      1.00      1.00         4
         124       0.80      1.00      0.89         4
         125       1.00      0.50      0.67         4
         126       0.80      1.00      0.89         4
         127       0.67      0.75      0.71         8
         128       1.00      1.00      1.00         4
         129       1.00      0.80      0.89         5
         130       0.50      0.75      0.60         4
         131       0.80      1.00      0.89         4
         132       0.71      0.56      0.63         9
         133       0.00      0.00      0.00         4
         134       1.00      1.00      1.00         9
         135       0.80      0.80      0.80         5
         136       1.00      0.75      0.86         4
         137       1.00      0.80      0.89         5
         138       0.60      0.67      0.63         9
         139       0.80      1.00      0.89         4
         140       0.50      0.75      0.60         4
         141       0.43      0.75      0.55         4
         142       1.00      1.00      1.00         4
         143       0.88      0.78      0.82         9
         144       0.58      0.78      0.67         9
         145       0.89      0.89      0.89         9
         146       0.67      0.50      0.57         4
         147       0.71      1.00      0.83         5
         148       0.10      0.11      0.11         9
         149       0.00      0.00      0.00         4
         150       0.50      0.50      0.50         4
         151       0.00      0.00      0.00         4
         152       1.00      1.00      1.00         4
         153       0.75      0.75      0.75         4
         154       0.57      0.44      0.50         9
         155       1.00      0.88      0.93         8
         156       1.00      1.00      1.00         4
         157       1.00      1.00      1.00         4
         158       0.80      1.00      0.89         4
         159       0.75      0.60      0.67         5
         160       1.00      0.75      0.86         4
         161       0.00      0.00      0.00         4
         162       0.00      0.00      0.00         9
         163       1.00      1.00      1.00         4
         164       0.00      0.00      0.00         4
         165       1.00      0.50      0.67         4
         166       1.00      0.75      0.86         4
         167       1.00      1.00      1.00         5
         168       0.90      1.00      0.95         9
         169       0.57      0.80      0.67         5
         170       1.00      1.00      1.00         4
         171       0.75      0.67      0.71         9
         172       0.60      0.75      0.67         4
         173       1.00      0.20      0.33         5
         174       1.00      1.00      1.00         4
         175       1.00      0.75      0.86         4
         176       0.12      0.25      0.17         4
         177       1.00      0.25      0.40         4
         178       0.00      0.00      0.00         9
         179       1.00      0.44      0.62         9
         180       1.00      0.80      0.89         5
         181       1.00      0.75      0.86         4
         182       1.00      0.75      0.86         4
         183       0.75      0.75      0.75         4
         184       0.00      0.00      0.00         4
         185       1.00      1.00      1.00         5
         186       0.75      0.50      0.60         6
         187       0.89      0.89      0.89         9
         188       0.67      1.00      0.80         4
         189       1.00      1.00      1.00         9
         190       0.00      0.00      0.00         4
         191       1.00      1.00      1.00         4
         192       0.00      0.00      0.00         4
         193       0.80      0.89      0.84         9
         194       1.00      0.50      0.67         4
         195       1.00      0.75      0.86         4
         196       1.00      1.00      1.00         9
         197       0.50      0.44      0.47         9
         198       0.00      0.00      0.00         4
         199       1.00      0.75      0.86         4
         200       0.00      0.00      0.00         4
         201       0.80      1.00      0.89         4
         202       0.00      0.00      0.00         9
         203       0.12      0.22      0.16         9
         204       0.53      0.89      0.67         9
         205       1.00      1.00      1.00         4
         206       1.00      1.00      1.00         4
         207       0.00      0.00      0.00         5
         208       0.80      1.00      0.89         4
         209       0.90      1.00      0.95         9
         210       1.00      0.75      0.86         4
         211       1.00      1.00      1.00         4
         212       1.00      0.89      0.94         9
         213       0.67      0.50      0.57         4
         214       0.50      0.50      0.50         4
         215       1.00      0.75      0.86         4
         216       0.83      1.00      0.91         5
         217       1.00      0.80      0.89         5
         218       0.64      0.78      0.70         9
         219       0.86      0.67      0.75         9
         220       0.67      0.50      0.57         4
         221       1.00      1.00      1.00         9
         222       1.00      0.80      0.89         5
         223       0.83      1.00      0.91         5
         224       1.00      1.00      1.00         5
         225       0.00      0.00      0.00         9
         226       1.00      0.75      0.86         4
         227       1.00      0.25      0.40         4
         228       0.00      0.00      0.00         4
         229       1.00      0.50      0.67         4
         230       0.80      1.00      0.89         4
         231       0.86      0.86      0.86         7
         232       0.33      0.25      0.29         4
         233       0.00      0.00      0.00         9
         234       0.83      1.00      0.91         5
         235       0.90      1.00      0.95         9
         236       1.00      1.00      1.00         4
         237       0.33      0.50      0.40         4
         238       0.00      0.00      0.00         4
         239       1.00      0.89      0.94         9
         240       1.00      1.00      1.00         4
         241       0.12      0.25      0.17         4
         242       0.80      0.80      0.80         5
         243       0.80      0.80      0.80         5
         244       0.00      0.00      0.00         4
         245       0.14      0.25      0.18         4
         246       1.00      1.00      1.00         4
         247       0.75      0.75      0.75         4
         248       0.00      0.00      0.00         4
         249       0.40      1.00      0.57         4
         250       0.17      0.11      0.13         9
         251       0.50      1.00      0.67         4
         252       1.00      0.25      0.40         4
         253       1.00      0.75      0.86         4
         254       0.71      1.00      0.83         5
         255       0.80      1.00      0.89         4
         256       0.00      0.00      0.00         4
         257       0.56      1.00      0.71         5
         258       0.60      1.00      0.75         9
         259       0.67      1.00      0.80         4
         260       0.80      1.00      0.89         4
         261       1.00      1.00      1.00         4
         262       1.00      0.75      0.86         4
         263       1.00      1.00      1.00         4
         264       1.00      0.75      0.86         4
         265       0.25      0.40      0.31         5
         266       0.67      0.80      0.73         5
         267       0.82      1.00      0.90         9
         268       1.00      0.25      0.40         4
         269       0.00      0.00      0.00         4
         270       0.80      0.80      0.80         5
         271       0.67      1.00      0.80         4
         272       1.00      1.00      1.00         4
         273       1.00      1.00      1.00         4
         274       0.80      1.00      0.89         4
         275       0.00      0.00      0.00         4
         276       1.00      0.75      0.86         4
         277       0.00      0.00      0.00         4
         278       0.89      0.89      0.89         9
         279       0.80      1.00      0.89         4
         280       0.67      1.00      0.80         4
         281       0.80      0.89      0.84         9
         282       0.89      0.89      0.89         9
         283       0.80      1.00      0.89         4
         284       0.50      0.60      0.55         5
         285       1.00      1.00      1.00         4
         286       0.00      0.00      0.00         4
         287       0.80      1.00      0.89         4
         288       0.00      0.00      0.00         4
         289       1.00      0.56      0.71         9
         290       0.73      0.89      0.80         9
         291       1.00      1.00      1.00         5
         292       1.00      0.89      0.94         9
         293       1.00      1.00      1.00         4
         294       0.67      1.00      0.80         4
         295       1.00      0.75      0.86         4
         296       1.00      0.80      0.89         5
         297       1.00      0.25      0.40         4
         298       0.00      0.00      0.00         4
         299       0.00      0.00      0.00         4
         300       0.00      0.00      0.00         4
         301       1.00      0.75      0.86         4
         302       1.00      0.50      0.67         4
         303       0.80      1.00      0.89         4
         304       1.00      1.00      1.00         4
         305       0.00      0.00      0.00         4
         306       0.90      1.00      0.95         9
         307       1.00      1.00      1.00         4
         308       0.89      0.89      0.89         9
         309       1.00      1.00      1.00         5
         310       1.00      0.75      0.86         4
         311       0.38      0.75      0.50         4
         312       1.00      0.50      0.67         4
         313       1.00      1.00      1.00         4
         314       0.50      0.60      0.55         5
         315       0.89      0.89      0.89         9
         316       0.50      0.50      0.50         4
         317       0.58      0.78      0.67         9
         318       0.60      0.75      0.67         4
         319       0.90      1.00      0.95         9
         320       0.90      1.00      0.95         9
         321       0.80      1.00      0.89         4
         322       0.07      0.80      0.14         5
         323       0.60      0.67      0.63         9
         324       0.70      0.78      0.74         9
         325       0.20      0.25      0.22         4
         326       1.00      0.75      0.86         4
         327       0.80      1.00      0.89         4
         328       0.50      0.22      0.31         9
         329       0.80      1.00      0.89         4
         330       0.50      0.50      0.50         4
         331       1.00      0.60      0.75         5
         332       1.00      0.80      0.89         5
         333       1.00      1.00      1.00         5
         334       0.00      0.00      0.00         4
         335       1.00      1.00      1.00         4
         336       0.00      0.00      0.00         4
         337       1.00      1.00      1.00         4
         338       0.60      0.67      0.63         9
         339       0.90      1.00      0.95         9
         340       1.00      0.80      0.89         5
         341       1.00      0.75      0.86         4
         342       0.00      0.00      0.00         4
         343       0.75      0.67      0.71         9
         344       1.00      0.75      0.86         4
         345       0.57      0.44      0.50         9
         346       1.00      1.00      1.00         5
         347       0.50      0.25      0.33         4
         348       1.00      1.00      1.00         9
         349       0.40      1.00      0.57         4
         350       1.00      1.00      1.00         5
         351       0.80      1.00      0.89         4
         352       0.78      0.78      0.78         9
         353       1.00      1.00      1.00         5
         354       0.00      0.00      0.00         4
         355       1.00      1.00      1.00         5
         356       0.75      0.75      0.75         4
         357       0.25      0.25      0.25         4
         358       0.75      0.75      0.75         4
         359       1.00      1.00      1.00         5
         360       1.00      0.75      0.86         4
         361       0.00      0.00      0.00         4
         362       0.50      0.25      0.33         4
         363       0.06      0.25      0.10         4
         364       0.67      0.80      0.73         5
         365       1.00      0.89      0.94         9
         366       0.86      0.67      0.75         9
         367       0.83      1.00      0.91         5
         368       0.80      0.44      0.57         9
         369       0.00      0.00      0.00         4
         370       1.00      1.00      1.00         4
         371       0.73      0.89      0.80         9
         372       0.00      0.00      0.00         4
         373       0.71      1.00      0.83         5
         374       0.67      1.00      0.80         4
         375       0.75      0.60      0.67         5
         376       0.88      0.78      0.82         9
         377       0.90      1.00      0.95         9
         378       0.50      0.25      0.33         4
         379       0.00      0.00      0.00         4
         380       0.67      0.40      0.50         5
         381       1.00      0.75      0.86         4
         382       0.50      0.56      0.53         9
         383       0.88      0.78      0.82         9
         384       0.25      0.25      0.25         4
         385       1.00      1.00      1.00         9
         386       0.80      0.89      0.84         9
         387       1.00      1.00      1.00         4
         388       0.00      0.00      0.00         4
         389       1.00      0.78      0.88         9
         390       0.64      0.78      0.70         9
         391       0.00      0.00      0.00         4
         392       0.60      0.33      0.43         9
         393       1.00      1.00      1.00         4
         394       0.80      1.00      0.89         4
         395       1.00      0.75      0.86         4
         396       1.00      0.78      0.88         9
         397       0.67      0.67      0.67         9
         398       0.67      0.50      0.57         4
         399       0.75      0.75      0.75         4
         400       0.90      1.00      0.95         9
         401       1.00      0.75      0.86         4
         402       0.73      0.89      0.80         9
         403       0.00      0.00      0.00         4
         404       1.00      1.00      1.00         4
         405       0.00      0.00      0.00         4
         406       0.89      0.89      0.89         9
         407       0.33      0.60      0.43         5
         408       0.00      0.00      0.00         9
         409       0.80      1.00      0.89         4
         410       0.67      1.00      0.80         4
         411       1.00      0.50      0.67         4
         412       1.00      0.75      0.86         4
         413       0.00      0.00      0.00         4
         414       1.00      0.80      0.89         5
         415       1.00      1.00      1.00         4
         416       0.38      0.60      0.46         5
         417       0.29      0.40      0.33         5
         418       1.00      1.00      1.00         9
         419       1.00      1.00      1.00         4
         420       0.82      1.00      0.90         9
         421       1.00      0.50      0.67         4
         422       1.00      1.00      1.00         9
         423       0.80      1.00      0.89         4
         424       1.00      0.80      0.89         5
         425       0.80      1.00      0.89         4
         426       0.75      0.75      0.75         4
         427       0.80      1.00      0.89         4
         428       0.60      0.75      0.67         4
         429       0.90      1.00      0.95         9
         430       0.00      0.00      0.00         4
         431       1.00      0.50      0.67         4
         432       1.00      1.00      1.00         9
         433       1.00      1.00      1.00         4
         434       1.00      0.75      0.86         4
         435       0.80      1.00      0.89         4
         436       1.00      1.00      1.00         4
         437       1.00      0.50      0.67         4
         438       1.00      0.25      0.40         4
         439       1.00      0.75      0.86         4
         440       0.10      0.25      0.14         4
         441       0.00      0.00      0.00         4
         442       1.00      0.25      0.40         4
         443       1.00      0.50      0.67         4
         444       1.00      0.80      0.89         5
         445       0.83      1.00      0.91         5
         446       0.90      1.00      0.95         9
         447       0.00      0.00      0.00         4
         448       0.67      0.50      0.57         4
         449       0.75      0.75      0.75         4
         450       1.00      1.00      1.00         4
         451       1.00      0.78      0.88         9
         452       1.00      1.00      1.00         5
         453       0.50      0.60      0.55         5
         454       0.83      1.00      0.91         5
         455       1.00      0.75      0.86         4
         456       1.00      0.89      0.94         9
         457       0.67      0.50      0.57         4
         458       0.57      1.00      0.73         4
         459       1.00      1.00      1.00         9
         460       0.80      1.00      0.89         4
         461       0.80      1.00      0.89         4
         462       1.00      1.00      1.00         5
         463       0.67      1.00      0.80         4
         464       0.00      0.00      0.00         4
         465       0.56      1.00      0.71         5
         466       0.89      0.89      0.89         9
         467       0.70      0.78      0.74         9
         468       0.60      0.60      0.60         5
         469       1.00      1.00      1.00         4
         470       0.17      0.25      0.20         4
         471       0.73      0.89      0.80         9
         472       0.00      0.00      0.00         4
         473       0.80      1.00      0.89         4
         474       1.00      0.60      0.75         5
         475       0.70      0.78      0.74         9
         476       0.86      0.67      0.75         9
         477       1.00      1.00      1.00         4
         478       0.75      1.00      0.86         9
         479       1.00      0.78      0.88         9
         480       1.00      0.20      0.33         5
         481       0.83      1.00      0.91         5
         482       1.00      1.00      1.00         4
         483       0.00      0.00      0.00         4
         484       1.00      1.00      1.00         5
         485       0.67      0.80      0.73         5
         486       1.00      1.00      1.00         4
         487       0.00      0.00      0.00         4
         488       0.00      0.00      0.00         4
         489       0.00      0.00      0.00         4
         490       0.00      0.00      0.00         4
         491       0.00      0.00      0.00         4
         492       0.00      0.00      0.00         4
         493       0.64      0.78      0.70         9
         494       1.00      0.89      0.94         9
         495       1.00      1.00      1.00         5
         496       0.00      0.00      0.00         9
         497       1.00      1.00      1.00         5
         498       0.06      0.25      0.10         4
         499       1.00      0.75      0.86         4
         500       0.50      0.80      0.62         5
         501       0.50      0.75      0.60         4
         502       0.67      0.50      0.57         4
         503       1.00      0.40      0.57         5
         504       0.00      0.00      0.00         4
         505       0.80      0.80      0.80         5
         506       1.00      0.89      0.94         9
         507       0.60      0.60      0.60         5
         508       0.89      0.89      0.89         9
         509       1.00      0.75      0.86         4
         510       0.90      1.00      0.95         9
         511       0.75      0.75      0.75         4
         512       0.00      0.00      0.00         4
         513       0.88      0.78      0.82         9
         514       0.89      0.89      0.89         9
         515       0.71      1.00      0.83         5
         516       1.00      1.00      1.00         5
         517       1.00      0.75      0.86         4
         518       0.60      0.75      0.67         4
         519       0.80      0.80      0.80         5
         520       0.67      0.67      0.67         9
         521       1.00      0.80      0.89         5
         522       0.86      0.67      0.75         9
         523       0.89      0.89      0.89         9
         524       0.00      0.00      0.00         4
         525       0.80      1.00      0.89         4
         526       0.00      0.00      0.00         4
         527       0.00      0.00      0.00         4
         528       0.75      0.75      0.75         4
         529       1.00      0.80      0.89         5
         530       0.75      0.75      0.75         4
         531       1.00      0.50      0.67         4
         532       1.00      1.00      1.00         9
         533       1.00      1.00      1.00         9
         534       0.80      1.00      0.89         4
         535       1.00      0.89      0.94         9
         536       0.75      0.75      0.75         4
         537       0.07      0.25      0.11         4
         538       1.00      1.00      1.00         4
         539       0.60      0.75      0.67         4
         540       0.89      0.89      0.89         9
         541       0.75      0.75      0.75         4
         542       1.00      0.50      0.67         4
         543       0.75      0.75      0.75         4
         544       0.60      0.60      0.60         5
         545       0.50      0.75      0.60         4
         546       0.17      0.25      0.20         4
         547       0.00      0.00      0.00         4
         548       1.00      0.89      0.94         9
         549       1.00      0.75      0.86         4
         550       0.67      1.00      0.80         4
         551       0.57      1.00      0.73         4
         552       0.89      0.89      0.89         9
         553       0.80      0.89      0.84         9
         554       0.89      0.89      0.89         9
         555       0.38      0.60      0.46         5
         556       0.50      1.00      0.67         4
         557       0.00      0.00      0.00         4
         558       0.80      0.80      0.80         5
         559       1.00      0.60      0.75         5
         560       1.00      1.00      1.00         4
         561       1.00      1.00      1.00         4
         562       1.00      1.00      1.00         9
         563       1.00      1.00      1.00         9
         564       0.00      0.00      0.00         4
         565       1.00      0.40      0.57         5
         566       0.00      0.00      0.00         4
         567       1.00      1.00      1.00         4
         568       0.00      0.00      0.00         4
         569       1.00      0.89      0.94         9
         570       1.00      1.00      1.00         4
         571       1.00      1.00      1.00         4
         572       0.75      0.75      0.75         4
         573       0.69      1.00      0.82         9
         574       0.73      0.89      0.80         9
         575       1.00      1.00      1.00         9
         576       1.00      1.00      1.00         4
         577       1.00      0.75      0.86         4
         578       1.00      0.89      0.94         9
         579       1.00      1.00      1.00         4
         580       0.00      0.00      0.00         4
         581       1.00      1.00      1.00         4
         582       1.00      0.75      0.86         4
         583       0.00      0.00      0.00         4
         584       1.00      0.50      0.67         4
         585       0.50      0.50      0.50         4
         586       1.00      1.00      1.00         4
         587       1.00      1.00      1.00         4
         588       0.06      0.25      0.10         4
         589       0.00      0.00      0.00         4
         590       0.73      0.89      0.80         9
         591       0.00      0.00      0.00         4
         592       1.00      1.00      1.00         9
         593       1.00      0.75      0.86         4
         594       0.00      0.00      0.00         4
         595       0.00      0.00      0.00         4
         596       0.75      0.75      0.75         4
         597       1.00      0.75      0.86         4
         598       0.00      0.00      0.00         9
         599       0.75      0.75      0.75         4
         600       0.82      1.00      0.90         9
         601       0.89      0.89      0.89         9
         602       0.89      0.89      0.89         9
         603       1.00      0.75      0.86         4
         604       1.00      0.50      0.67         4
         605       0.80      0.89      0.84         9
         606       0.75      0.75      0.75         4
         607       1.00      0.89      0.94         9
         608       1.00      0.50      0.67         4
         609       0.80      1.00      0.89         4
         610       0.80      1.00      0.89         4
         611       0.67      0.50      0.57         4
         612       0.00      0.00      0.00         9
         613       1.00      0.75      0.86         4
         614       0.67      0.89      0.76         9
         615       0.43      0.33      0.38         9
         616       0.75      0.67      0.71         9
         617       0.12      0.25      0.17         4
         618       1.00      1.00      1.00         4
         619       1.00      1.00      1.00         5
         620       1.00      0.75      0.86         4
         621       0.00      0.00      0.00         4
         622       0.60      0.67      0.63         9
         623       0.50      0.25      0.33         4
         624       1.00      1.00      1.00         4
         625       0.60      0.60      0.60         5
         626       1.00      1.00      1.00         4
         627       0.73      0.89      0.80         9
         628       1.00      0.60      0.75         5
         629       0.90      1.00      0.95         9
         630       1.00      0.75      0.86         4
         631       0.14      0.25      0.18         4
         632       0.89      0.89      0.89         9
         633       1.00      1.00      1.00         4
         634       0.89      0.89      0.89         9
         635       1.00      1.00      1.00         4
         636       1.00      1.00      1.00         4
         637       0.00      0.00      0.00         4
         638       1.00      1.00      1.00         4
         639       0.80      1.00      0.89         4
         640       0.50      0.11      0.18         9
         641       0.57      1.00      0.73         4
         642       0.75      1.00      0.86         9
         643       0.78      0.78      0.78         9
         644       1.00      0.25      0.40         4
         645       1.00      0.75      0.86         4
         646       0.00      0.00      0.00         4
         647       1.00      1.00      1.00         9
         648       0.60      0.75      0.67         4
         649       1.00      1.00      1.00         4
         650       1.00      1.00      1.00         4
         651       1.00      0.60      0.75         5
         652       0.00      0.00      0.00         4
         653       0.80      1.00      0.89         4
         654       0.88      0.78      0.82         9
         655       0.75      0.67      0.71         9
         656       1.00      1.00      1.00         5
         657       0.86      0.67      0.75         9
         658       0.33      0.50      0.40         4
         659       0.90      1.00      0.95         9
         660       1.00      0.25      0.40         4
         661       1.00      1.00      1.00         4
         662       1.00      1.00      1.00         4
         663       1.00      0.25      0.40         4
         664       1.00      1.00      1.00         5
         665       1.00      1.00      1.00         4
         666       1.00      1.00      1.00         4
         667       0.00      0.00      0.00         9
         668       1.00      0.75      0.86         4
         669       0.57      1.00      0.73         4
         670       0.71      0.71      0.71         7
         671       0.67      1.00      0.80         4
         672       1.00      0.75      0.86         4
         673       0.67      0.50      0.57         4
         674       1.00      1.00      1.00         4
         675       0.00      0.00      0.00         4
         676       0.67      0.50      0.57         4
         677       0.14      0.22      0.17         9
         678       0.67      0.44      0.53         9
         679       0.80      0.89      0.84         9
         680       0.90      1.00      0.95         9
         681       0.00      0.00      0.00         4
         682       0.73      0.89      0.80         9
         683       0.00      0.00      0.00         4
         684       0.67      0.80      0.73         5
         685       0.80      1.00      0.89         4
         686       1.00      0.89      0.94         9
         687       1.00      0.50      0.67         4
         688       0.89      0.89      0.89         9
         689       1.00      0.89      0.94         9
         690       1.00      0.89      0.94         9
         691       0.11      0.25      0.15         4
         692       1.00      1.00      1.00         5
         693       0.67      0.22      0.33         9
         694       1.00      1.00      1.00         5
         695       0.14      0.20      0.17         5
         696       0.80      1.00      0.89         4
         697       1.00      0.80      0.89         5
         698       1.00      0.75      0.86         4
         699       1.00      0.67      0.80         9
         700       0.75      0.67      0.71         9
         701       1.00      1.00      1.00         9
         702       1.00      0.75      0.86         4
         703       0.80      0.89      0.84         9
         704       1.00      0.89      0.94         9
         705       0.00      0.00      0.00         9
         706       0.88      0.78      0.82         9
         707       0.00      0.00      0.00         4
         708       0.00      0.00      0.00         4
         709       0.75      0.75      0.75         4
         710       1.00      0.75      0.86         4
         711       0.80      0.80      0.80         5
         712       0.25      0.25      0.25         4
         713       0.89      0.89      0.89         9
         714       0.89      0.89      0.89         9
         715       0.33      0.25      0.29         4
         716       1.00      0.50      0.67         4
         717       1.00      0.20      0.33         5
         718       0.78      0.88      0.82         8
         719       0.75      0.60      0.67         5
         720       1.00      1.00      1.00         4
         721       0.44      1.00      0.62         4
         722       1.00      1.00      1.00         5
         723       0.00      0.00      0.00         4
         724       0.80      1.00      0.89         4
         725       0.00      0.00      0.00         4
         726       0.80      0.80      0.80         5
         727       0.83      0.56      0.67         9
         728       1.00      0.75      0.86         4
         729       0.50      0.50      0.50         4
         730       0.80      1.00      0.89         4
         731       1.00      1.00      1.00         4
         732       0.00      0.00      0.00         4
         733       1.00      0.75      0.86         4
         734       0.80      1.00      0.89         4
         735       0.67      1.00      0.80         4
         736       1.00      1.00      1.00         9
         737       0.80      1.00      0.89         4
         738       0.60      0.75      0.67         4
         739       0.57      1.00      0.73         4
         740       0.80      0.80      0.80         5
         741       0.50      0.60      0.55         5
         742       1.00      1.00      1.00         5
         743       0.80      1.00      0.89         4
         744       0.67      1.00      0.80         4
         745       0.70      0.78      0.74         9
         746       1.00      0.80      0.89         5
         747       1.00      0.75      0.86         4
         748       0.00      0.00      0.00         4
         749       0.50      0.60      0.55         5
         750       0.00      0.00      0.00         4
         751       0.80      0.89      0.84         9
         752       0.89      0.89      0.89         9
         753       0.50      0.67      0.57         9
         754       0.08      0.25      0.12         4
         755       0.67      1.00      0.80         4
         756       0.67      1.00      0.80         4
         757       1.00      0.75      0.86         4
         758       1.00      0.75      0.86         4
         759       0.73      0.89      0.80         9
         760       1.00      1.00      1.00         4
         761       0.50      0.25      0.33         4
         762       0.71      1.00      0.83         5
         763       0.80      1.00      0.89         4
         764       0.67      0.44      0.53         9
         765       0.75      0.75      0.75         4
         766       0.00      0.00      0.00         4
         767       0.80      1.00      0.89         4
         768       1.00      1.00      1.00         4
         769       0.75      0.75      0.75         4
         770       0.00      0.00      0.00         4
         771       0.90      1.00      0.95         9
         772       0.00      0.00      0.00         5
         773       0.80      1.00      0.89         4
         774       1.00      1.00      1.00         4
         775       0.75      0.75      0.75         4
         776       0.78      0.78      0.78         9
         777       1.00      1.00      1.00         4
         778       0.67      0.50      0.57         4
         779       0.90      1.00      0.95         9
         780       0.00      0.00      0.00         4
         781       0.50      0.75      0.60         4
         782       1.00      0.75      0.86         4
         783       1.00      0.75      0.86         4
         784       1.00      0.80      0.89         5
         785       1.00      1.00      1.00         4
         786       1.00      1.00      1.00         9
         787       1.00      0.75      0.86         4
         788       1.00      0.89      0.94         9
         789       0.00      0.00      0.00         4
         790       1.00      1.00      1.00         9
         791       1.00      0.50      0.67         4
         792       0.71      1.00      0.83         5
         793       1.00      0.75      0.86         4
         794       0.40      0.50      0.44         4
         795       0.62      0.56      0.59         9
         796       0.67      1.00      0.80         4
         797       1.00      0.89      0.94         9
         798       1.00      1.00      1.00         4
         799       1.00      0.78      0.88         9
         800       0.09      0.25      0.13         4
         801       0.57      0.80      0.67         5
         802       1.00      0.43      0.60         7
         803       0.62      0.56      0.59         9
         804       1.00      1.00      1.00         4
         805       1.00      0.25      0.40         4
         806       0.73      0.89      0.80         9
         807       1.00      0.60      0.75         5
         808       1.00      1.00      1.00         9
         809       0.00      0.00      0.00         4
         810       1.00      1.00      1.00         4
         811       0.80      1.00      0.89         4
         812       0.75      0.75      0.75         4
         813       1.00      0.80      0.89         5
         814       1.00      0.25      0.40         4
         815       0.00      0.00      0.00         4
         816       0.40      0.50      0.44         4
         817       1.00      0.75      0.86         4
         818       0.50      0.25      0.33         4
         819       1.00      1.00      1.00         4
         820       1.00      0.25      0.40         4
         821       0.00      0.00      0.00         9
         822       0.80      0.80      0.80         5
         823       1.00      1.00      1.00         5
         824       0.00      0.00      0.00         4
         825       0.67      0.50      0.57         4
         826       0.50      0.75      0.60         4
         827       1.00      0.50      0.67         4
         828       1.00      0.89      0.94         9
         829       0.50      0.50      0.50         4
         830       1.00      0.75      0.86         4
         831       1.00      0.40      0.57         5
         832       1.00      1.00      1.00         9
         833       1.00      0.75      0.86         4
         834       0.73      0.89      0.80         9
         835       1.00      0.75      0.86         4
         836       0.67      1.00      0.80         4
         837       0.80      1.00      0.89         4
         838       0.75      0.33      0.46         9
         839       1.00      0.50      0.67         4
         840       0.62      0.89      0.73         9
         841       1.00      0.75      0.86         4
         842       0.40      1.00      0.57         4
         843       1.00      1.00      1.00         5
         844       1.00      1.00      1.00         4
         845       0.80      1.00      0.89         4
         846       0.80      1.00      0.89         4
         847       1.00      0.75      0.86         4
         848       0.75      0.75      0.75         4
         849       0.00      0.00      0.00         4
         850       0.00      0.00      0.00         4
         851       0.00      0.00      0.00         4
         852       0.33      0.25      0.29         4
         853       0.00      0.00      0.00         4
         854       1.00      1.00      1.00         4
         855       1.00      1.00      1.00         9
         856       0.44      1.00      0.62         4
         857       1.00      0.78      0.88         9
         858       0.60      0.75      0.67         4
         859       1.00      1.00      1.00         5
         860       0.40      0.50      0.44         4
         861       1.00      1.00      1.00         4
         862       0.50      0.20      0.29         5
         863       1.00      1.00      1.00         5
         864       0.00      0.00      0.00         9
         865       0.57      1.00      0.73         4
         866       0.07      0.11      0.09         9
         867       0.50      0.75      0.60         4
         868       1.00      0.80      0.89         5
         869       0.83      1.00      0.91         5
         870       0.80      0.89      0.84         9
         871       0.75      0.75      0.75         4
         872       0.75      0.67      0.71         9
         873       0.00      0.00      0.00         4
         874       0.80      1.00      0.89         4
         875       0.88      0.78      0.82         9
         876       0.86      0.67      0.75         9
         877       1.00      1.00      1.00         4
         878       1.00      0.50      0.67         4
         879       0.00      0.00      0.00         4
         880       0.60      1.00      0.75         9
         881       0.17      0.25      0.20         4
         882       0.78      0.78      0.78         9
         883       1.00      1.00      1.00         5
         884       0.75      0.75      0.75         4
         885       1.00      0.78      0.88         9
         886       1.00      0.75      0.86         4
         887       1.00      0.78      0.88         9
         888       0.71      0.56      0.63         9
         889       1.00      1.00      1.00         4
         890       0.75      0.75      0.75         4
         891       0.00      0.00      0.00         4
         892       0.00      0.00      0.00         4
         893       0.00      0.00      0.00         4

    accuracy                           0.70      4917
   macro avg       0.70      0.67      0.67      4917
weighted avg       0.72      0.70      0.69      4917

task_train_time: {0: 0.1202291940000002, 1: 0.0328576690000002, 2: 0.03855903500000046, 3: 0.034917575999999784, 4: 0.03878836099999994, 5: 0.03210452599999947, 6: 0.031978287999999466, 7: 0.030209931999999995, 8: 0.03375371999999999, 9: 0.03424636699999972, 10: 0.0315244400000001, 11: 0.02827233999999912, 12: 0.028962066000000064, 13: 0.0326265190000008, 14: 0.027657165000000816, 15: 0.03544891700000008, 16: 0.033257473000000815, 17: 0.03132538499999882, 18: 0.03875551800000032, 19: 0.03374873899999997, 20: 0.0328244049999995, 21: 0.02925117900000096, 22: 0.03447714800000057, 23: 0.034090279000000834, 24: 0.03812721199999913, 25: 0.03724638299999938, 26: 0.03598457300000035, 27: 0.033562128999999885, 28: 0.032874052000000376, 29: 0.035372317999998515, 30: 0.035309004000000144, 31: 0.03194653999999986, 32: 0.033261459000000215, 33: 0.043739651999999296, 34: 0.03778301600000056, 35: 0.02982027200000026, 36: 0.03500343500000014, 37: 0.031090019000000524, 38: 0.03200582299999866, 39: 0.03383065699999932, 40: 0.029743184999997396, 41: 0.02793867600000155, 42: 0.03478919300000172, 43: 0.036003186999998604}
prediction_time: 0.0003784390000021176
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
