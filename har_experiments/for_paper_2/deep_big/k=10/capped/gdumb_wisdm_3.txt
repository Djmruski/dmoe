Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='976e1356-ec17-4d87-a874-ee698746356d', conf_timestamp='2023-08-14 11:29:29.771713', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 73.44 % 	 [Task-IL]: 49.48 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 52.62 % 	 [Task-IL]: 40.87 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 43.71 % 	 [Task-IL]: 36.7 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 33.03 % 	 [Task-IL]: 32.18 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 32.31 % 	 [Task-IL]: 28.89 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 25.07 % 	 [Task-IL]: 29.74 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 22.82 % 	 [Task-IL]: 29.69 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 17.79 % 	 [Task-IL]: 29.73 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 14.21 % 	 [Task-IL]: 27.61 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.67 % 	 [Task-IL]: 28.11 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 13.29 % 	 [Task-IL]: 27.18 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.61 % 	 [Task-IL]: 27.36 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 13.77 % 	 [Task-IL]: 27.49 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.15 % 	 [Task-IL]: 28.25 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.31 % 	 [Task-IL]: 28.26 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 10.4 % 	 [Task-IL]: 27.79 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 11.07 % 	 [Task-IL]: 28.1 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.69 % 	 [Task-IL]: 27.99 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 9.86 % 	 [Task-IL]: 28.09 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 7.88 % 	 [Task-IL]: 28.22 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 7.96 % 	 [Task-IL]: 27.82 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 9.62 % 	 [Task-IL]: 27.93 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.87 % 	 [Task-IL]: 27.9 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.34 % 	 [Task-IL]: 27.73 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.83 % 	 [Task-IL]: 27.78 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.05 % 	 [Task-IL]: 27.47 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 9.13 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 9.02 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.26 % 	 [Task-IL]: 26.51 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.58 % 	 [Task-IL]: 26.71 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 7.74 % 	 [Task-IL]: 26.94 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 5.87 % 	 [Task-IL]: 26.73 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.53 % 	 [Task-IL]: 26.51 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.28 % 	 [Task-IL]: 26.59 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.45 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.75 % 	 [Task-IL]: 26.34 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.43 % 	 [Task-IL]: 26.23 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 6.28 % 	 [Task-IL]: 26.12 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.14 % 	 [Task-IL]: 26.45 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.46 % 	 [Task-IL]: 26.4 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.29 % 	 [Task-IL]: 26.34 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.67 % 	 [Task-IL]: 26.58 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 6.13 % 	 [Task-IL]: 26.69 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({487: 25, 437: 24, 743: 23, 816: 23, 565: 23, 595: 23, 598: 23, 588: 23, 180: 23, 268: 23, 303: 23, 366: 23, 70: 22, 198: 22, 195: 22, 301: 22, 456: 22, 515: 22, 617: 21, 753: 21, 39: 21, 645: 21, 681: 21, 91: 21, 728: 21, 545: 21, 193: 21, 263: 21, 371: 21, 427: 21, 455: 21, 767: 20, 862: 20, 712: 20, 702: 20, 573: 20, 824: 20, 827: 20, 789: 20, 35: 20, 52: 20, 642: 20, 881: 20, 667: 20, 116: 20, 158: 20, 550: 20, 246: 20, 275: 20, 320: 20, 315: 20, 339: 20, 364: 20, 381: 20, 406: 20, 477: 20, 495: 20, 15: 19, 5: 19, 625: 19, 679: 19, 851: 19, 659: 19, 638: 19, 890: 19, 798: 19, 666: 19, 674: 19, 577: 19, 88: 19, 850: 19, 109: 19, 133: 19, 125: 19, 135: 19, 147: 19, 539: 19, 218: 19, 541: 19, 358: 19, 389: 19, 470: 19, 465: 19, 505: 19, 503: 19, 3: 18, 849: 18, 799: 18, 760: 18, 808: 18, 592: 18, 880: 18, 649: 18, 60: 18, 622: 18, 101: 18, 825: 18, 222: 18, 233: 18, 240: 18, 266: 18, 264: 18, 304: 18, 312: 18, 354: 18, 355: 18, 373: 18, 379: 18, 376: 18, 390: 18, 398: 18, 423: 18, 415: 18, 7: 17, 30: 17, 11: 17, 661: 17, 857: 17, 782: 17, 602: 17, 548: 17, 756: 17, 586: 17, 854: 17, 43: 17, 37: 17, 853: 17, 838: 17, 580: 17, 613: 17, 90: 17, 81: 17, 800: 17, 828: 17, 115: 17, 117: 17, 114: 17, 152: 17, 164: 17, 205: 17, 280: 17, 276: 17, 287: 17, 293: 17, 332: 17, 324: 17, 412: 17, 396: 17, 457: 17, 529: 17, 776: 16, 791: 16, 750: 16, 887: 16, 765: 16, 877: 16, 707: 16, 813: 16, 797: 16, 777: 16, 44: 16, 774: 16, 885: 16, 874: 16, 758: 16, 600: 16, 629: 16, 55: 16, 66: 16, 132: 16, 590: 16, 211: 16, 201: 16, 242: 16, 245: 16, 309: 16, 361: 16, 393: 16, 399: 16, 433: 16, 451: 16, 466: 16, 482: 16, 489: 16, 506: 16, 14: 15, 606: 15, 644: 15, 722: 15, 771: 15, 53: 15, 612: 15, 197: 15, 238: 15, 265: 15, 255: 15, 319: 15, 370: 15, 359: 15, 410: 15, 425: 15, 472: 15, 31: 14, 570: 14, 837: 14, 703: 14, 643: 14, 856: 14, 818: 14, 623: 14, 58: 14, 891: 14, 181: 14, 188: 14, 203: 14, 230: 14, 279: 14, 313: 14, 351: 14, 343: 14, 363: 14, 463: 14, 522: 14, 26: 13, 691: 13, 697: 13, 705: 13, 889: 13, 883: 13, 720: 13, 209: 13, 261: 13, 317: 13, 369: 13, 500: 13, 527: 13, 13: 12, 736: 12, 630: 12, 603: 12, 575: 12, 841: 12, 75: 12, 159: 12, 173: 12, 185: 12, 206: 12, 214: 12, 350: 12, 383: 12, 387: 12, 526: 12, 6: 11, 773: 11, 671: 11, 634: 11, 564: 11, 882: 11, 83: 11, 779: 11, 126: 11, 127: 11, 227: 11, 239: 11, 300: 11, 318: 11, 347: 11, 362: 11, 476: 11, 494: 11, 516: 11, 2: 10, 817: 10, 662: 10, 20: 10, 794: 10, 823: 10, 726: 10, 840: 10, 717: 10, 670: 10, 893: 10, 833: 10, 860: 10, 831: 10, 589: 10, 683: 10, 631: 10, 809: 10, 715: 10, 685: 10, 605: 10, 67: 10, 665: 10, 678: 10, 77: 10, 103: 10, 761: 10, 552: 10, 131: 10, 582: 10, 628: 10, 151: 10, 884: 10, 176: 10, 194: 10, 219: 10, 225: 10, 244: 10, 234: 10, 549: 10, 271: 10, 273: 10, 291: 10, 278: 10, 322: 10, 596: 10, 336: 10, 340: 10, 382: 10, 378: 10, 404: 10, 405: 10, 407: 10, 420: 10, 417: 10, 471: 10, 543: 10, 488: 10, 521: 10, 749: 9, 792: 9, 12: 9, 830: 9, 28: 9, 604: 9, 1: 9, 742: 9, 699: 9, 706: 9, 8: 9, 727: 9, 888: 9, 718: 9, 688: 9, 803: 9, 738: 9, 847: 9, 619: 9, 616: 9, 538: 9, 639: 9, 574: 9, 682: 9, 656: 9, 36: 9, 50: 9, 693: 9, 677: 9, 34: 9, 594: 9, 540: 9, 54: 9, 714: 9, 59: 9, 786: 9, 57: 9, 740: 9, 89: 9, 626: 9, 829: 9, 607: 9, 832: 9, 94: 9, 571: 9, 124: 9, 128: 9, 146: 9, 145: 9, 139: 9, 778: 9, 737: 9, 168: 9, 593: 9, 175: 9, 191: 9, 562: 9, 208: 9, 202: 9, 228: 9, 248: 9, 258: 9, 289: 9, 310: 9, 295: 9, 294: 9, 297: 9, 298: 9, 328: 9, 321: 9, 335: 9, 368: 9, 367: 9, 385: 9, 395: 9, 400: 9, 419: 9, 428: 9, 421: 9, 416: 9, 442: 9, 444: 9, 464: 9, 462: 9, 473: 9, 454: 9, 483: 9, 490: 9, 510: 9, 513: 9, 496: 9, 518: 9, 530: 9, 517: 9, 532: 9, 690: 8, 591: 8, 4: 8, 17: 8, 29: 8, 751: 8, 637: 8, 9: 8, 772: 8, 864: 8, 546: 8, 568: 8, 855: 8, 658: 8, 713: 8, 846: 8, 788: 8, 676: 8, 556: 8, 51: 8, 746: 8, 861: 8, 725: 8, 615: 8, 673: 8, 560: 8, 695: 8, 585: 8, 872: 8, 848: 8, 72: 8, 68: 8, 64: 8, 716: 8, 61: 8, 764: 8, 69: 8, 863: 8, 710: 8, 859: 8, 74: 8, 731: 8, 84: 8, 92: 8, 729: 8, 845: 8, 78: 8, 821: 8, 879: 8, 576: 8, 99: 8, 97: 8, 752: 8, 106: 8, 668: 8, 748: 8, 121: 8, 744: 8, 870: 8, 149: 8, 142: 8, 148: 8, 141: 8, 157: 8, 166: 8, 189: 8, 177: 8, 204: 8, 200: 8, 199: 8, 213: 8, 196: 8, 249: 8, 237: 8, 243: 8, 283: 8, 285: 8, 284: 8, 302: 8, 307: 8, 329: 8, 341: 8, 342: 8, 348: 8, 372: 8, 384: 8, 391: 8, 380: 8, 536: 8, 409: 8, 411: 8, 432: 8, 426: 8, 424: 8, 429: 8, 438: 8, 440: 8, 481: 8, 486: 8, 475: 8, 491: 8, 478: 8, 507: 8, 504: 8, 501: 8, 502: 8, 519: 8, 544: 8, 10: 7, 16: 7, 640: 7, 19: 7, 24: 7, 876: 7, 650: 7, 27: 7, 23: 7, 653: 7, 869: 7, 701: 7, 886: 7, 689: 7, 719: 7, 651: 7, 572: 7, 709: 7, 878: 7, 892: 7, 755: 7, 796: 7, 648: 7, 814: 7, 734: 7, 775: 7, 652: 7, 694: 7, 686: 7, 45: 7, 569: 7, 784: 7, 42: 7, 41: 7, 770: 7, 611: 7, 581: 7, 65: 7, 766: 7, 63: 7, 71: 7, 597: 7, 730: 7, 687: 7, 875: 7, 839: 7, 692: 7, 700: 7, 535: 7, 684: 7, 86: 7, 567: 7, 704: 7, 79: 7, 696: 7, 868: 7, 111: 7, 96: 7, 100: 7, 95: 7, 119: 7, 130: 7, 655: 7, 787: 7, 858: 7, 144: 7, 143: 7, 721: 7, 783: 7, 557: 7, 154: 7, 163: 7, 155: 7, 156: 7, 186: 7, 804: 7, 210: 7, 231: 7, 241: 7, 235: 7, 250: 7, 614: 7, 256: 7, 262: 7, 259: 7, 260: 7, 257: 7, 254: 7, 843: 7, 290: 7, 281: 7, 296: 7, 299: 7, 327: 7, 314: 7, 353: 7, 349: 7, 334: 7, 352: 7, 357: 7, 356: 7, 375: 7, 392: 7, 394: 7, 431: 7, 449: 7, 446: 7, 450: 7, 436: 7, 445: 7, 460: 7, 459: 7, 492: 7, 493: 7, 497: 7, 509: 7, 512: 7, 508: 7, 499: 7, 520: 7, 25: 6, 18: 6, 33: 6, 866: 6, 733: 6, 834: 6, 795: 6, 618: 6, 802: 6, 0: 6, 578: 6, 826: 6, 660: 6, 741: 6, 842: 6, 554: 6, 583: 6, 754: 6, 40: 6, 723: 6, 47: 6, 663: 6, 555: 6, 38: 6, 669: 6, 608: 6, 664: 6, 871: 6, 675: 6, 56: 6, 820: 6, 62: 6, 815: 6, 647: 6, 806: 6, 844: 6, 82: 6, 93: 6, 646: 6, 76: 6, 732: 6, 98: 6, 769: 6, 108: 6, 584: 6, 110: 6, 104: 6, 561: 6, 105: 6, 123: 6, 610: 6, 118: 6, 150: 6, 134: 6, 140: 6, 153: 6, 873: 6, 762: 6, 170: 6, 167: 6, 165: 6, 172: 6, 169: 6, 790: 6, 620: 6, 537: 6, 190: 6, 174: 6, 179: 6, 184: 6, 182: 6, 178: 6, 192: 6, 636: 6, 822: 6, 654: 6, 212: 6, 220: 6, 229: 6, 253: 6, 252: 6, 236: 6, 247: 6, 785: 6, 657: 6, 559: 6, 269: 6, 274: 6, 286: 6, 282: 6, 292: 6, 308: 6, 311: 6, 305: 6, 768: 6, 326: 6, 333: 6, 331: 6, 344: 6, 337: 6, 547: 6, 365: 6, 377: 6, 388: 6, 403: 6, 397: 6, 413: 6, 441: 6, 447: 6, 439: 6, 448: 6, 443: 6, 452: 6, 458: 6, 467: 6, 480: 6, 498: 6, 525: 6, 523: 6, 531: 6, 514: 6, 533: 6, 32: 5, 21: 5, 698: 5, 22: 5, 780: 5, 759: 5, 805: 5, 553: 5, 835: 5, 587: 5, 627: 5, 48: 5, 633: 5, 810: 5, 49: 5, 641: 5, 601: 5, 812: 5, 542: 5, 867: 5, 793: 5, 708: 5, 624: 5, 801: 5, 563: 5, 757: 5, 735: 5, 129: 5, 120: 5, 807: 5, 122: 5, 138: 5, 811: 5, 161: 5, 160: 5, 187: 5, 534: 5, 672: 5, 747: 5, 635: 5, 232: 5, 551: 5, 226: 5, 852: 5, 267: 5, 270: 5, 306: 5, 316: 5, 325: 5, 345: 5, 338: 5, 360: 5, 386: 5, 402: 5, 408: 5, 430: 5, 414: 5, 434: 5, 461: 5, 485: 5, 524: 5, 865: 4, 566: 4, 46: 4, 621: 4, 73: 4, 87: 4, 745: 4, 85: 4, 836: 4, 102: 4, 739: 4, 579: 4, 558: 4, 137: 4, 763: 4, 819: 4, 632: 4, 207: 4, 215: 4, 221: 4, 216: 4, 272: 4, 288: 4, 277: 4, 330: 4, 323: 4, 346: 4, 680: 4, 374: 4, 724: 4, 418: 4, 422: 4, 453: 4, 435: 4, 468: 4, 484: 4, 474: 4, 609: 3, 80: 3, 113: 3, 112: 3, 107: 3, 711: 3, 599: 3, 171: 3, 162: 3, 223: 3, 251: 3, 781: 3, 401: 3, 469: 3, 479: 3, 511: 3, 528: 3, 136: 2, 217: 2, 224: 2, 183: 1})
Total buffer: 8940
CAPPING TO BUFFER_SIZE/CLASS
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({2: 10, 3: 10, 5: 10, 6: 10, 7: 10, 11: 10, 13: 10, 14: 10, 15: 10, 20: 10, 26: 10, 30: 10, 31: 10, 35: 10, 37: 10, 39: 10, 43: 10, 44: 10, 52: 10, 53: 10, 55: 10, 58: 10, 60: 10, 66: 10, 67: 10, 70: 10, 75: 10, 77: 10, 81: 10, 83: 10, 88: 10, 90: 10, 91: 10, 101: 10, 103: 10, 109: 10, 114: 10, 115: 10, 116: 10, 117: 10, 125: 10, 126: 10, 127: 10, 131: 10, 132: 10, 133: 10, 135: 10, 147: 10, 151: 10, 152: 10, 158: 10, 159: 10, 164: 10, 173: 10, 176: 10, 180: 10, 181: 10, 185: 10, 188: 10, 193: 10, 194: 10, 195: 10, 197: 10, 198: 10, 201: 10, 203: 10, 205: 10, 206: 10, 209: 10, 211: 10, 214: 10, 218: 10, 219: 10, 222: 10, 225: 10, 227: 10, 230: 10, 233: 10, 234: 10, 238: 10, 239: 10, 240: 10, 242: 10, 244: 10, 245: 10, 246: 10, 255: 10, 261: 10, 263: 10, 264: 10, 265: 10, 266: 10, 268: 10, 271: 10, 273: 10, 275: 10, 276: 10, 278: 10, 279: 10, 280: 10, 287: 10, 291: 10, 293: 10, 300: 10, 301: 10, 303: 10, 304: 10, 309: 10, 312: 10, 313: 10, 315: 10, 317: 10, 318: 10, 319: 10, 320: 10, 322: 10, 324: 10, 332: 10, 336: 10, 339: 10, 340: 10, 343: 10, 347: 10, 350: 10, 351: 10, 354: 10, 355: 10, 358: 10, 359: 10, 361: 10, 362: 10, 363: 10, 364: 10, 366: 10, 369: 10, 370: 10, 371: 10, 373: 10, 376: 10, 378: 10, 379: 10, 381: 10, 382: 10, 383: 10, 387: 10, 389: 10, 390: 10, 393: 10, 396: 10, 398: 10, 399: 10, 404: 10, 405: 10, 406: 10, 407: 10, 410: 10, 412: 10, 415: 10, 417: 10, 420: 10, 423: 10, 425: 10, 427: 10, 433: 10, 437: 10, 451: 10, 455: 10, 456: 10, 457: 10, 463: 10, 465: 10, 466: 10, 470: 10, 471: 10, 472: 10, 476: 10, 477: 10, 482: 10, 487: 10, 488: 10, 489: 10, 494: 10, 495: 10, 500: 10, 503: 10, 505: 10, 506: 10, 515: 10, 516: 10, 521: 10, 522: 10, 526: 10, 527: 10, 529: 10, 539: 10, 541: 10, 543: 10, 545: 10, 548: 10, 549: 10, 550: 10, 552: 10, 564: 10, 565: 10, 570: 10, 573: 10, 575: 10, 577: 10, 580: 10, 582: 10, 586: 10, 588: 10, 589: 10, 590: 10, 592: 10, 595: 10, 596: 10, 598: 10, 600: 10, 602: 10, 603: 10, 605: 10, 606: 10, 612: 10, 613: 10, 617: 10, 622: 10, 623: 10, 625: 10, 628: 10, 629: 10, 630: 10, 631: 10, 634: 10, 638: 10, 642: 10, 643: 10, 644: 10, 645: 10, 649: 10, 659: 10, 661: 10, 662: 10, 665: 10, 666: 10, 667: 10, 670: 10, 671: 10, 674: 10, 678: 10, 679: 10, 681: 10, 683: 10, 685: 10, 691: 10, 697: 10, 702: 10, 703: 10, 705: 10, 707: 10, 712: 10, 715: 10, 717: 10, 720: 10, 722: 10, 726: 10, 728: 10, 736: 10, 743: 10, 750: 10, 753: 10, 756: 10, 758: 10, 760: 10, 761: 10, 765: 10, 767: 10, 771: 10, 773: 10, 774: 10, 776: 10, 777: 10, 779: 10, 782: 10, 789: 10, 791: 10, 794: 10, 797: 10, 798: 10, 799: 10, 800: 10, 808: 10, 809: 10, 813: 10, 816: 10, 817: 10, 818: 10, 823: 10, 824: 10, 825: 10, 827: 10, 828: 10, 831: 10, 833: 10, 837: 10, 838: 10, 840: 10, 841: 10, 849: 10, 850: 10, 851: 10, 853: 10, 854: 10, 856: 10, 857: 10, 860: 10, 862: 10, 874: 10, 877: 10, 880: 10, 881: 10, 882: 10, 883: 10, 884: 10, 885: 10, 887: 10, 889: 10, 890: 10, 891: 10, 893: 10, 1: 9, 8: 9, 12: 9, 28: 9, 34: 9, 36: 9, 50: 9, 54: 9, 57: 9, 59: 9, 89: 9, 94: 9, 124: 9, 128: 9, 139: 9, 145: 9, 146: 9, 168: 9, 175: 9, 191: 9, 202: 9, 208: 9, 228: 9, 248: 9, 258: 9, 289: 9, 294: 9, 295: 9, 297: 9, 298: 9, 310: 9, 321: 9, 328: 9, 335: 9, 367: 9, 368: 9, 385: 9, 395: 9, 400: 9, 416: 9, 419: 9, 421: 9, 428: 9, 442: 9, 444: 9, 454: 9, 462: 9, 464: 9, 473: 9, 483: 9, 490: 9, 496: 9, 510: 9, 513: 9, 517: 9, 518: 9, 530: 9, 532: 9, 538: 9, 540: 9, 562: 9, 571: 9, 574: 9, 593: 9, 594: 9, 604: 9, 607: 9, 616: 9, 619: 9, 626: 9, 639: 9, 656: 9, 677: 9, 682: 9, 688: 9, 693: 9, 699: 9, 706: 9, 714: 9, 718: 9, 727: 9, 737: 9, 738: 9, 740: 9, 742: 9, 749: 9, 778: 9, 786: 9, 792: 9, 803: 9, 829: 9, 830: 9, 832: 9, 847: 9, 888: 9, 4: 8, 9: 8, 17: 8, 29: 8, 51: 8, 61: 8, 64: 8, 68: 8, 69: 8, 72: 8, 74: 8, 78: 8, 84: 8, 92: 8, 97: 8, 99: 8, 106: 8, 121: 8, 141: 8, 142: 8, 148: 8, 149: 8, 157: 8, 166: 8, 177: 8, 189: 8, 196: 8, 199: 8, 200: 8, 204: 8, 213: 8, 237: 8, 243: 8, 249: 8, 283: 8, 284: 8, 285: 8, 302: 8, 307: 8, 329: 8, 341: 8, 342: 8, 348: 8, 372: 8, 380: 8, 384: 8, 391: 8, 409: 8, 411: 8, 424: 8, 426: 8, 429: 8, 432: 8, 438: 8, 440: 8, 475: 8, 478: 8, 481: 8, 486: 8, 491: 8, 501: 8, 502: 8, 504: 8, 507: 8, 519: 8, 536: 8, 544: 8, 546: 8, 556: 8, 560: 8, 568: 8, 576: 8, 585: 8, 591: 8, 615: 8, 637: 8, 658: 8, 668: 8, 673: 8, 676: 8, 690: 8, 695: 8, 710: 8, 713: 8, 716: 8, 725: 8, 729: 8, 731: 8, 744: 8, 746: 8, 748: 8, 751: 8, 752: 8, 764: 8, 772: 8, 788: 8, 821: 8, 845: 8, 846: 8, 848: 8, 855: 8, 859: 8, 861: 8, 863: 8, 864: 8, 870: 8, 872: 8, 879: 8, 10: 7, 16: 7, 19: 7, 23: 7, 24: 7, 27: 7, 41: 7, 42: 7, 45: 7, 63: 7, 65: 7, 71: 7, 79: 7, 86: 7, 95: 7, 96: 7, 100: 7, 111: 7, 119: 7, 130: 7, 143: 7, 144: 7, 154: 7, 155: 7, 156: 7, 163: 7, 186: 7, 210: 7, 231: 7, 235: 7, 241: 7, 250: 7, 254: 7, 256: 7, 257: 7, 259: 7, 260: 7, 262: 7, 281: 7, 290: 7, 296: 7, 299: 7, 314: 7, 327: 7, 334: 7, 349: 7, 352: 7, 353: 7, 356: 7, 357: 7, 375: 7, 392: 7, 394: 7, 431: 7, 436: 7, 445: 7, 446: 7, 449: 7, 450: 7, 459: 7, 460: 7, 492: 7, 493: 7, 497: 7, 499: 7, 508: 7, 509: 7, 512: 7, 520: 7, 535: 7, 557: 7, 567: 7, 569: 7, 572: 7, 581: 7, 597: 7, 611: 7, 614: 7, 640: 7, 648: 7, 650: 7, 651: 7, 652: 7, 653: 7, 655: 7, 684: 7, 686: 7, 687: 7, 689: 7, 692: 7, 694: 7, 696: 7, 700: 7, 701: 7, 704: 7, 709: 7, 719: 7, 721: 7, 730: 7, 734: 7, 755: 7, 766: 7, 770: 7, 775: 7, 783: 7, 784: 7, 787: 7, 796: 7, 804: 7, 814: 7, 839: 7, 843: 7, 858: 7, 868: 7, 869: 7, 875: 7, 876: 7, 878: 7, 886: 7, 892: 7, 0: 6, 18: 6, 25: 6, 33: 6, 38: 6, 40: 6, 47: 6, 56: 6, 62: 6, 76: 6, 82: 6, 93: 6, 98: 6, 104: 6, 105: 6, 108: 6, 110: 6, 118: 6, 123: 6, 134: 6, 140: 6, 150: 6, 153: 6, 165: 6, 167: 6, 169: 6, 170: 6, 172: 6, 174: 6, 178: 6, 179: 6, 182: 6, 184: 6, 190: 6, 192: 6, 212: 6, 220: 6, 229: 6, 236: 6, 247: 6, 252: 6, 253: 6, 269: 6, 274: 6, 282: 6, 286: 6, 292: 6, 305: 6, 308: 6, 311: 6, 326: 6, 331: 6, 333: 6, 337: 6, 344: 6, 365: 6, 377: 6, 388: 6, 397: 6, 403: 6, 413: 6, 439: 6, 441: 6, 443: 6, 447: 6, 448: 6, 452: 6, 458: 6, 467: 6, 480: 6, 498: 6, 514: 6, 523: 6, 525: 6, 531: 6, 533: 6, 537: 6, 547: 6, 554: 6, 555: 6, 559: 6, 561: 6, 578: 6, 583: 6, 584: 6, 608: 6, 610: 6, 618: 6, 620: 6, 636: 6, 646: 6, 647: 6, 654: 6, 657: 6, 660: 6, 663: 6, 664: 6, 669: 6, 675: 6, 723: 6, 732: 6, 733: 6, 741: 6, 754: 6, 762: 6, 768: 6, 769: 6, 785: 6, 790: 6, 795: 6, 802: 6, 806: 6, 815: 6, 820: 6, 822: 6, 826: 6, 834: 6, 842: 6, 844: 6, 866: 6, 871: 6, 873: 6, 21: 5, 22: 5, 32: 5, 48: 5, 49: 5, 120: 5, 122: 5, 129: 5, 138: 5, 160: 5, 161: 5, 187: 5, 226: 5, 232: 5, 267: 5, 270: 5, 306: 5, 316: 5, 325: 5, 338: 5, 345: 5, 360: 5, 386: 5, 402: 5, 408: 5, 414: 5, 430: 5, 434: 5, 461: 5, 485: 5, 524: 5, 534: 5, 542: 5, 551: 5, 553: 5, 563: 5, 587: 5, 601: 5, 624: 5, 627: 5, 633: 5, 635: 5, 641: 5, 672: 5, 698: 5, 708: 5, 735: 5, 747: 5, 757: 5, 759: 5, 780: 5, 793: 5, 801: 5, 805: 5, 807: 5, 810: 5, 811: 5, 812: 5, 835: 5, 852: 5, 867: 5, 46: 4, 73: 4, 85: 4, 87: 4, 102: 4, 137: 4, 207: 4, 215: 4, 216: 4, 221: 4, 272: 4, 277: 4, 288: 4, 323: 4, 330: 4, 346: 4, 374: 4, 418: 4, 422: 4, 435: 4, 453: 4, 468: 4, 474: 4, 484: 4, 558: 4, 566: 4, 579: 4, 621: 4, 632: 4, 680: 4, 724: 4, 739: 4, 745: 4, 763: 4, 819: 4, 836: 4, 865: 4, 80: 3, 107: 3, 112: 3, 113: 3, 162: 3, 171: 3, 223: 3, 251: 3, 401: 3, 469: 3, 479: 3, 511: 3, 528: 3, 599: 3, 609: 3, 711: 3, 781: 3, 136: 2, 217: 2, 224: 2, 183: 1})
Total buffer: 7102
fit_time: 60.067446475

Accuracy for 44 task(s): 	 [Class-IL]: 70.44 % 	 [Task-IL]: 30.58 %

CLASS_IL_ACC: 
	[78.125, 83.89830508474576, 76.57657657657657, 75.22935779816514, 57.446808510638306, 70.58823529411765, 62.62626262626263, 68.31683168316832, 55.44554455445545, 72.03389830508475, 78.84615384615384, 74.77477477477478, 66.94915254237289, 68.46846846846847, 78.26086956521739, 59.63302752293578, 71.56862745098039, 75.88652482269504, 80.0, 71.68141592920354, 80.0, 68.13186813186813, 75.60975609756098, 74.75728155339806, 69.52380952380952, 66.66666666666666, 69.1588785046729, 52.57731958762887, 67.24137931034483, 66.10169491525424, 78.70370370370371, 80.0, 79.43925233644859, 60.57692307692307, 64.60176991150442, 67.70833333333334, 67.3469387755102, 65.17857142857143, 69.91150442477876, 71.42857142857143, 64.03508771929825, 75.0, 71.0, 68.42105263157895]
TASK_IL_ACC: 
	[60.416666666666664, 33.05084745762712, 30.630630630630627, 23.853211009174313, 23.404255319148938, 33.61344537815126, 24.242424242424242, 29.7029702970297, 21.782178217821784, 33.05084745762712, 26.923076923076923, 25.225225225225223, 25.423728813559322, 32.432432432432435, 24.347826086956523, 30.275229357798167, 25.49019607843137, 30.49645390070922, 30.434782608695656, 31.858407079646017, 26.08695652173913, 28.57142857142857, 30.89430894308943, 25.24271844660194, 28.57142857142857, 25.71428571428571, 26.168224299065418, 23.711340206185564, 25.862068965517242, 27.966101694915253, 26.851851851851855, 26.36363636363636, 26.168224299065418, 32.69230769230769, 24.778761061946902, 26.041666666666668, 24.489795918367346, 26.785714285714285, 35.39823008849557, 35.714285714285715, 28.947368421052634, 29.310344827586203, 38.0, 98.49624060150376]
f1_micro: 70.79520032540167
f1_macro: 68.11162840134985
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       1.00      1.00      1.00         5
           2       0.50      1.00      0.67         5
           3       0.36      0.57      0.44         7
           4       0.10      0.50      0.17         4
           5       0.89      0.89      0.89         9
           6       0.57      0.44      0.50         9
           7       1.00      0.89      0.94         9
           8       1.00      0.50      0.67         4
           9       0.00      0.00      0.00         4
          10       1.00      1.00      1.00         5
          11       1.00      0.78      0.88         9
          12       1.00      1.00      1.00         5
          13       0.00      0.00      0.00         4
          14       0.82      1.00      0.90         9
          15       0.90      1.00      0.95         9
          16       0.80      1.00      0.89         4
          17       1.00      0.80      0.89         5
          18       0.80      1.00      0.89         4
          19       0.60      0.75      0.67         4
          20       0.60      0.60      0.60         5
          21       1.00      0.75      0.86         4
          22       1.00      0.50      0.67         4
          23       1.00      0.75      0.86         4
          24       0.67      0.80      0.73         5
          25       0.75      0.75      0.75         4
          26       0.50      0.78      0.61         9
          27       1.00      1.00      1.00         5
          28       0.57      1.00      0.73         4
          29       0.00      0.00      0.00         4
          30       0.73      0.89      0.80         9
          31       0.90      1.00      0.95         9
          32       1.00      1.00      1.00         4
          33       1.00      0.75      0.86         4
          34       1.00      1.00      1.00         5
          35       1.00      0.89      0.94         9
          36       0.83      1.00      0.91         5
          37       0.83      0.56      0.67         9
          38       1.00      1.00      1.00         4
          39       1.00      0.78      0.88         9
          40       1.00      1.00      1.00         4
          41       1.00      1.00      1.00         4
          42       1.00      0.75      0.86         4
          43       1.00      1.00      1.00         9
          44       0.90      1.00      0.95         9
          45       0.80      1.00      0.89         4
          46       0.50      0.25      0.33         4
          47       1.00      1.00      1.00         4
          48       0.80      1.00      0.89         4
          49       0.00      0.00      0.00         4
          50       1.00      1.00      1.00         5
          51       0.60      0.75      0.67         4
          52       1.00      0.78      0.88         9
          53       0.80      0.89      0.84         9
          54       0.33      0.20      0.25         5
          55       0.90      1.00      0.95         9
          56       0.33      0.25      0.29         4
          57       0.80      1.00      0.89         4
          58       0.89      0.89      0.89         9
          59       1.00      1.00      1.00         4
          60       1.00      1.00      1.00         9
          61       0.80      1.00      0.89         4
          62       0.67      0.50      0.57         4
          63       0.80      1.00      0.89         4
          64       0.75      0.75      0.75         4
          65       0.50      0.50      0.50         4
          66       0.89      0.89      0.89         9
          67       1.00      0.89      0.94         9
          68       1.00      1.00      1.00         4
          69       1.00      1.00      1.00         4
          70       0.80      0.89      0.84         9
          71       0.00      0.00      0.00         4
          72       0.00      0.00      0.00         4
          73       0.50      0.50      0.50         4
          74       1.00      0.60      0.75         5
          75       0.75      0.75      0.75         4
          76       1.00      0.50      0.67         4
          77       0.80      0.80      0.80         5
          78       1.00      0.75      0.86         4
          79       0.75      0.60      0.67         5
          80       1.00      0.75      0.86         4
          81       0.78      0.78      0.78         9
          82       0.00      0.00      0.00         4
          83       0.78      0.78      0.78         9
          84       0.75      0.60      0.67         5
          85       1.00      0.75      0.86         4
          86       0.67      1.00      0.80         4
          87       0.60      0.75      0.67         4
          88       0.89      0.89      0.89         9
          89       0.44      1.00      0.62         4
          90       0.90      1.00      0.95         9
          91       0.82      1.00      0.90         9
          92       0.00      0.00      0.00         4
          93       1.00      1.00      1.00         4
          94       1.00      0.50      0.67         4
          95       1.00      0.50      0.67         4
          96       1.00      0.25      0.40         4
          97       0.17      0.25      0.20         4
          98       0.00      0.00      0.00         4
          99       0.00      0.00      0.00         4
         100       1.00      0.75      0.86         4
         101       1.00      0.89      0.94         9
         102       0.00      0.00      0.00         4
         103       1.00      1.00      1.00         5
         104       1.00      0.40      0.57         5
         105       0.80      1.00      0.89         4
         106       1.00      0.80      0.89         5
         107       1.00      0.80      0.89         5
         108       0.80      1.00      0.89         4
         109       0.83      0.56      0.67         9
         110       0.80      1.00      0.89         4
         111       0.00      0.00      0.00         4
         112       1.00      1.00      1.00         4
         113       0.33      0.25      0.29         4
         114       0.73      1.00      0.84         8
         115       0.75      0.33      0.46         9
         116       1.00      1.00      1.00         9
         117       0.78      0.78      0.78         9
         118       0.40      0.50      0.44         4
         119       1.00      0.75      0.86         4
         120       1.00      0.25      0.40         4
         121       0.00      0.00      0.00         4
         122       0.67      0.50      0.57         4
         123       1.00      1.00      1.00         5
         124       0.25      0.25      0.25         4
         125       0.70      0.78      0.74         9
         126       0.83      1.00      0.91         5
         127       1.00      1.00      1.00         5
         128       1.00      1.00      1.00         5
         129       0.00      0.00      0.00         4
         130       0.80      1.00      0.89         4
         131       0.50      0.60      0.55         5
         132       0.60      0.67      0.63         9
         133       0.80      0.89      0.84         9
         134       0.00      0.00      0.00         4
         135       1.00      0.78      0.88         9
         136       1.00      1.00      1.00         4
         137       0.00      0.00      0.00         4
         138       1.00      0.75      0.86         4
         139       0.33      0.20      0.25         5
         140       0.67      1.00      0.80         4
         141       1.00      1.00      1.00         5
         142       0.50      0.50      0.50         4
         143       0.80      1.00      0.89         4
         144       1.00      1.00      1.00         4
         145       0.29      0.50      0.36         4
         146       0.80      0.80      0.80         5
         147       0.60      0.33      0.43         9
         148       1.00      0.75      0.86         4
         149       0.12      1.00      0.21         4
         150       0.00      0.00      0.00         4
         151       1.00      1.00      1.00         4
         152       0.43      0.33      0.38         9
         153       0.83      1.00      0.91         5
         154       0.00      0.00      0.00         4
         155       0.00      0.00      0.00         4
         156       0.80      1.00      0.89         4
         157       0.67      0.80      0.73         5
         158       0.90      1.00      0.95         9
         159       0.67      0.44      0.53         9
         160       1.00      1.00      1.00         4
         161       1.00      1.00      1.00         4
         162       0.50      0.40      0.44         5
         163       1.00      0.75      0.86         4
         164       0.69      1.00      0.82         9
         165       1.00      1.00      1.00         4
         166       0.75      0.60      0.67         5
         167       0.80      1.00      0.89         4
         168       0.50      0.80      0.62         5
         169       0.67      0.50      0.57         4
         170       0.60      0.75      0.67         4
         171       1.00      0.75      0.86         4
         172       0.00      0.00      0.00         4
         173       0.75      0.50      0.60         6
         174       0.00      0.00      0.00         4
         175       1.00      0.75      0.86         4
         176       0.57      1.00      0.73         4
         177       0.40      0.50      0.44         4
         178       0.00      0.00      0.00         4
         179       0.75      0.75      0.75         4
         180       0.83      0.56      0.67         9
         181       0.00      0.00      0.00         9
         182       0.00      0.00      0.00         4
         183       0.00      0.00      0.00         4
         184       0.00      0.00      0.00         4
         185       1.00      1.00      1.00         5
         186       1.00      1.00      1.00         4
         187       1.00      0.75      0.86         4
         188       0.44      0.44      0.44         9
         189       0.67      1.00      0.80         4
         190       0.80      1.00      0.89         4
         191       0.67      1.00      0.80         4
         192       0.75      0.75      0.75         4
         193       0.80      0.89      0.84         9
         194       0.75      0.75      0.75         4
         195       0.73      0.89      0.80         9
         196       0.33      0.50      0.40         4
         197       1.00      1.00      1.00         9
         198       1.00      0.78      0.88         9
         199       1.00      1.00      1.00         5
         200       0.50      0.50      0.50         4
         201       0.00      0.00      0.00         9
         202       1.00      1.00      1.00         4
         203       0.82      1.00      0.90         9
         204       1.00      1.00      1.00         4
         205       0.00      0.00      0.00         9
         206       0.57      0.80      0.67         5
         207       0.00      0.00      0.00         4
         208       0.50      0.75      0.60         4
         209       0.71      1.00      0.83         5
         210       1.00      1.00      1.00         4
         211       1.00      1.00      1.00         9
         212       0.80      1.00      0.89         4
         213       0.75      0.75      0.75         4
         214       0.71      1.00      0.83         5
         215       1.00      1.00      1.00         4
         216       0.14      0.75      0.24         4
         217       0.00      0.00      0.00         4
         218       1.00      1.00      1.00         9
         219       0.83      1.00      0.91         5
         220       0.80      1.00      0.89         4
         221       0.60      0.75      0.67         4
         222       0.71      0.56      0.63         9
         223       1.00      1.00      1.00         4
         224       1.00      0.75      0.86         4
         225       0.60      0.60      0.60         5
         226       0.75      0.75      0.75         4
         227       0.80      0.80      0.80         5
         228       1.00      1.00      1.00         4
         229       1.00      0.25      0.40         4
         230       0.90      1.00      0.95         9
         231       0.80      1.00      0.89         4
         232       0.50      1.00      0.67         4
         233       0.83      0.56      0.67         9
         234       0.56      1.00      0.71         5
         235       0.67      1.00      0.80         4
         236       1.00      0.50      0.67         4
         237       1.00      0.50      0.67         4
         238       0.55      0.67      0.60         9
         239       0.07      0.11      0.09         9
         240       0.90      1.00      0.95         9
         241       1.00      0.75      0.86         4
         242       1.00      1.00      1.00         9
         243       0.00      0.00      0.00         4
         244       1.00      1.00      1.00         4
         245       0.64      0.78      0.70         9
         246       0.58      0.78      0.67         9
         247       1.00      0.75      0.86         4
         248       0.60      0.75      0.67         4
         249       0.67      1.00      0.80         4
         250       1.00      1.00      1.00         4
         251       1.00      0.75      0.86         4
         252       0.80      1.00      0.89         4
         253       0.60      0.75      0.67         4
         254       1.00      1.00      1.00         4
         255       0.00      0.00      0.00         9
         256       1.00      0.80      0.89         5
         257       0.83      1.00      0.91         5
         258       0.80      1.00      0.89         4
         259       1.00      0.75      0.86         4
         260       0.00      0.00      0.00         4
         261       0.75      1.00      0.86         9
         262       1.00      1.00      1.00         4
         263       0.00      0.00      0.00         9
         264       1.00      0.89      0.94         9
         265       0.90      1.00      0.95         9
         266       1.00      0.33      0.50         9
         267       0.67      1.00      0.80         4
         268       0.82      1.00      0.90         9
         269       1.00      1.00      1.00         4
         270       0.00      0.00      0.00         4
         271       0.25      0.40      0.31         5
         272       1.00      0.75      0.86         4
         273       0.80      1.00      0.89         4
         274       1.00      0.75      0.86         4
         275       0.69      1.00      0.82         9
         276       0.80      0.44      0.57         9
         277       0.67      1.00      0.80         4
         278       0.00      0.00      0.00         4
         279       0.67      0.57      0.62         7
         280       1.00      1.00      1.00         9
         281       0.80      1.00      0.89         4
         282       0.75      0.60      0.67         5
         283       0.83      1.00      0.91         5
         284       0.83      1.00      0.91         5
         285       0.67      1.00      0.80         4
         286       1.00      0.75      0.86         4
         287       0.89      0.89      0.89         9
         288       0.00      0.00      0.00         4
         289       0.00      0.00      0.00         4
         290       0.80      1.00      0.89         4
         291       0.00      0.00      0.00         4
         292       0.00      0.00      0.00         4
         293       0.64      0.78      0.70         9
         294       0.56      1.00      0.71         5
         295       1.00      0.80      0.89         5
         296       1.00      1.00      1.00         5
         297       1.00      1.00      1.00         5
         298       0.75      0.75      0.75         4
         299       1.00      0.25      0.40         4
         300       0.50      0.50      0.50         4
         301       0.12      0.22      0.15         9
         302       0.60      0.75      0.67         4
         303       1.00      1.00      1.00         9
         304       1.00      1.00      1.00         9
         305       0.57      1.00      0.73         4
         306       1.00      0.50      0.67         4
         307       0.75      0.60      0.67         5
         308       0.21      1.00      0.35         4
         309       1.00      1.00      1.00         9
         310       1.00      1.00      1.00         4
         311       0.00      0.00      0.00         4
         312       0.90      1.00      0.95         9
         313       0.58      0.78      0.67         9
         314       1.00      0.75      0.86         4
         315       0.69      1.00      0.82         9
         316       0.80      1.00      0.89         4
         317       0.00      0.00      0.00         9
         318       0.75      0.75      0.75         4
         319       1.00      1.00      1.00         8
         320       0.57      0.89      0.70         9
         321       0.80      1.00      0.89         4
         322       0.00      0.00      0.00         4
         323       1.00      0.75      0.86         4
         324       0.00      0.00      0.00         9
         325       0.00      0.00      0.00         4
         326       0.50      0.50      0.50         4
         327       0.75      0.75      0.75         4
         328       0.38      0.75      0.50         4
         329       0.00      0.00      0.00         4
         330       1.00      0.25      0.40         4
         331       1.00      0.50      0.67         4
         332       0.89      0.89      0.89         9
         333       1.00      1.00      1.00         4
         334       0.75      0.75      0.75         4
         335       0.20      0.25      0.22         4
         336       1.00      0.80      0.89         5
         337       1.00      0.75      0.86         4
         338       1.00      0.75      0.86         4
         339       0.75      0.33      0.46         9
         340       0.43      0.60      0.50         5
         341       0.67      0.50      0.57         4
         342       0.75      0.60      0.67         5
         343       0.60      1.00      0.75         9
         344       1.00      1.00      1.00         5
         345       1.00      0.75      0.86         4
         346       0.00      0.00      0.00         4
         347       0.83      1.00      0.91         5
         348       0.50      0.40      0.44         5
         349       0.80      1.00      0.89         4
         350       0.80      0.80      0.80         5
         351       1.00      0.89      0.94         9
         352       1.00      1.00      1.00         4
         353       1.00      1.00      1.00         4
         354       0.82      1.00      0.90         9
         355       0.75      1.00      0.86         9
         356       0.20      0.25      0.22         4
         357       0.00      0.00      0.00         4
         358       1.00      1.00      1.00         9
         359       0.88      0.78      0.82         9
         360       1.00      0.25      0.40         4
         361       0.67      0.67      0.67         9
         362       1.00      0.80      0.89         5
         363       1.00      0.78      0.88         9
         364       0.62      0.56      0.59         9
         365       1.00      0.25      0.40         4
         366       1.00      1.00      1.00         9
         367       0.80      1.00      0.89         4
         368       0.80      1.00      0.89         4
         369       0.90      1.00      0.95         9
         370       0.88      0.78      0.82         9
         371       1.00      0.89      0.94         9
         372       0.00      0.00      0.00         4
         373       0.88      0.78      0.82         9
         374       1.00      1.00      1.00         4
         375       0.57      1.00      0.73         4
         376       1.00      0.78      0.88         9
         377       0.00      0.00      0.00         4
         378       0.00      0.00      0.00         5
         379       1.00      1.00      1.00         9
         380       0.67      1.00      0.80         4
         381       1.00      0.78      0.88         9
         382       0.83      1.00      0.91         5
         383       1.00      1.00      1.00         4
         384       0.71      1.00      0.83         5
         385       0.57      1.00      0.73         4
         386       0.60      0.75      0.67         4
         387       1.00      0.80      0.89         5
         388       0.00      0.00      0.00         4
         389       1.00      0.67      0.80         9
         390       0.56      1.00      0.72         9
         391       1.00      1.00      1.00         5
         392       0.75      0.75      0.75         4
         393       0.90      1.00      0.95         9
         394       0.80      1.00      0.89         4
         395       1.00      0.75      0.86         4
         396       0.00      0.00      0.00         9
         397       1.00      0.75      0.86         4
         398       1.00      0.78      0.88         9
         399       1.00      1.00      1.00         9
         400       1.00      1.00      1.00         4
         401       1.00      0.50      0.67         4
         402       0.67      0.50      0.57         4
         403       1.00      1.00      1.00         4
         404       1.00      0.80      0.89         5
         405       1.00      0.60      0.75         5
         406       0.64      0.78      0.70         9
         407       0.00      0.00      0.00         4
         408       1.00      1.00      1.00         4
         409       0.67      1.00      0.80         4
         410       0.55      0.67      0.60         9
         411       0.71      1.00      0.83         5
         412       0.58      0.78      0.67         9
         413       1.00      0.75      0.86         4
         414       1.00      0.50      0.67         4
         415       1.00      0.78      0.88         9
         416       1.00      1.00      1.00         5
         417       0.83      1.00      0.91         5
         418       1.00      0.50      0.67         4
         419       0.43      0.75      0.55         4
         420       0.80      1.00      0.89         4
         421       1.00      0.75      0.86         4
         422       0.80      1.00      0.89         4
         423       0.86      0.67      0.75         9
         424       0.00      0.00      0.00         4
         425       0.88      0.78      0.82         9
         426       0.00      0.00      0.00         4
         427       1.00      1.00      1.00         9
         428       0.90      1.00      0.95         9
         429       0.83      1.00      0.91         5
         430       0.75      0.75      0.75         4
         431       0.80      0.80      0.80         5
         432       1.00      1.00      1.00         5
         433       0.82      1.00      0.90         9
         434       0.00      0.00      0.00         4
         435       1.00      1.00      1.00         4
         436       0.50      0.75      0.60         4
         437       1.00      0.89      0.94         9
         438       1.00      0.75      0.86         4
         439       1.00      1.00      1.00         4
         440       0.80      1.00      0.89         4
         441       0.00      0.00      0.00         4
         442       0.80      1.00      0.89         4
         443       1.00      0.75      0.86         4
         444       1.00      1.00      1.00         5
         445       0.67      1.00      0.80         4
         446       0.80      1.00      0.89         4
         447       0.75      0.75      0.75         4
         448       0.57      1.00      0.73         4
         449       0.00      0.00      0.00         4
         450       1.00      0.25      0.40         4
         451       0.80      0.89      0.84         9
         452       0.00      0.00      0.00         4
         453       0.00      0.00      0.00         4
         454       0.75      0.75      0.75         4
         455       0.50      0.56      0.53         9
         456       0.82      1.00      0.90         9
         457       1.00      0.89      0.94         9
         458       1.00      1.00      1.00         4
         459       1.00      1.00      1.00         4
         460       1.00      1.00      1.00         4
         461       0.00      0.00      0.00         4
         462       0.50      0.40      0.44         5
         463       1.00      0.89      0.94         9
         464       0.80      1.00      0.89         4
         465       0.86      0.67      0.75         9
         466       0.78      0.78      0.78         9
         467       0.00      0.00      0.00         4
         468       1.00      0.25      0.40         4
         469       0.75      0.75      0.75         4
         470       0.86      0.67      0.75         9
         471       1.00      1.00      1.00         5
         472       1.00      1.00      1.00         9
         473       0.83      1.00      0.91         5
         474       1.00      0.75      0.86         4
         475       0.00      0.00      0.00         5
         476       1.00      1.00      1.00         5
         477       1.00      0.89      0.94         9
         478       1.00      0.75      0.86         4
         479       0.33      0.25      0.29         4
         480       0.00      0.00      0.00         4
         481       0.67      1.00      0.80         4
         482       1.00      1.00      1.00         9
         483       1.00      1.00      1.00         4
         484       0.00      0.00      0.00         4
         485       1.00      0.75      0.86         4
         486       0.80      1.00      0.89         4
         487       1.00      1.00      1.00         9
         488       1.00      0.75      0.86         4
         489       0.80      0.89      0.84         9
         490       1.00      0.50      0.67         4
         491       1.00      1.00      1.00         5
         492       1.00      0.50      0.67         4
         493       0.80      1.00      0.89         4
         494       1.00      0.60      0.75         5
         495       0.12      0.11      0.12         9
         496       0.83      1.00      0.91         5
         497       0.75      0.75      0.75         4
         498       0.00      0.00      0.00         4
         499       1.00      0.75      0.86         4
         500       1.00      0.75      0.86         4
         501       1.00      0.80      0.89         5
         502       1.00      1.00      1.00         4
         503       0.88      0.78      0.82         9
         504       1.00      0.75      0.86         4
         505       1.00      1.00      1.00         9
         506       1.00      0.89      0.94         9
         507       1.00      1.00      1.00         5
         508       1.00      0.50      0.67         4
         509       0.00      0.00      0.00         4
         510       0.71      1.00      0.83         5
         511       1.00      1.00      1.00         4
         512       1.00      1.00      1.00         4
         513       0.00      0.00      0.00         4
         514       1.00      0.75      0.86         4
         515       0.88      0.78      0.82         9
         516       0.75      0.60      0.67         5
         517       0.67      1.00      0.80         4
         518       0.75      0.75      0.75         4
         519       1.00      0.75      0.86         4
         520       0.00      0.00      0.00         4
         521       0.67      0.50      0.57         4
         522       1.00      0.89      0.94         9
         523       1.00      0.60      0.75         5
         524       1.00      0.40      0.57         5
         525       0.80      1.00      0.89         4
         526       1.00      1.00      1.00         5
         527       0.08      0.11      0.09         9
         528       1.00      0.50      0.67         4
         529       0.90      1.00      0.95         9
         530       0.80      1.00      0.89         4
         531       0.80      1.00      0.89         4
         532       0.75      0.60      0.67         5
         533       0.00      0.00      0.00         4
         534       1.00      0.75      0.86         4
         535       1.00      0.50      0.67         4
         536       0.75      0.75      0.75         4
         537       1.00      0.75      0.86         4
         538       1.00      0.80      0.89         5
         539       1.00      0.78      0.88         9
         540       0.80      0.80      0.80         5
         541       0.88      0.78      0.82         9
         542       0.00      0.00      0.00         4
         543       0.44      1.00      0.62         4
         544       0.11      0.25      0.15         4
         545       0.88      0.78      0.82         9
         546       0.00      0.00      0.00         4
         547       0.57      1.00      0.73         4
         548       0.67      0.44      0.53         9
         549       1.00      1.00      1.00         4
         550       0.62      0.89      0.73         9
         551       1.00      0.75      0.86         4
         552       0.80      1.00      0.89         4
         553       1.00      0.50      0.67         4
         554       0.75      0.75      0.75         4
         555       1.00      0.75      0.86         4
         556       0.67      0.50      0.57         4
         557       1.00      1.00      1.00         4
         558       0.67      0.50      0.57         4
         559       0.80      1.00      0.89         4
         560       0.00      0.00      0.00         4
         561       0.00      0.00      0.00         4
         562       0.40      0.40      0.40         5
         563       0.00      0.00      0.00         4
         564       0.60      0.60      0.60         5
         565       0.75      1.00      0.86         9
         566       0.00      0.00      0.00         4
         567       1.00      0.50      0.67         4
         568       1.00      1.00      1.00         4
         569       0.67      0.50      0.57         4
         570       0.00      0.00      0.00         9
         571       0.80      1.00      0.89         4
         572       0.00      0.00      0.00         4
         573       0.54      0.78      0.64         9
         574       0.83      1.00      0.91         5
         575       1.00      1.00      1.00         5
         576       0.00      0.00      0.00         4
         577       0.71      0.56      0.63         9
         578       1.00      0.40      0.57         5
         579       0.00      0.00      0.00         4
         580       1.00      0.67      0.80         9
         581       0.67      0.50      0.57         4
         582       0.75      0.75      0.75         4
         583       0.50      0.25      0.33         4
         584       1.00      1.00      1.00         4
         585       0.80      1.00      0.89         4
         586       1.00      0.89      0.94         9
         587       0.00      0.00      0.00         4
         588       0.89      0.89      0.89         9
         589       0.71      1.00      0.83         5
         590       0.67      0.44      0.53         9
         591       1.00      1.00      1.00         5
         592       0.78      0.78      0.78         9
         593       0.67      0.80      0.73         5
         594       1.00      0.60      0.75         5
         595       0.64      0.78      0.70         9
         596       0.80      0.80      0.80         5
         597       1.00      1.00      1.00         4
         598       0.80      0.44      0.57         9
         599       1.00      1.00      1.00         4
         600       0.67      0.44      0.53         9
         601       1.00      0.75      0.86         4
         602       0.75      0.67      0.71         9
         603       0.40      0.40      0.40         5
         604       1.00      0.75      0.86         4
         605       0.50      0.50      0.50         4
         606       0.90      1.00      0.95         9
         607       0.09      0.25      0.13         4
         608       1.00      1.00      1.00         4
         609       0.00      0.00      0.00         4
         610       0.80      1.00      0.89         4
         611       0.00      0.00      0.00         4
         612       0.60      0.67      0.63         9
         613       1.00      0.89      0.94         9
         614       0.00      0.00      0.00         4
         615       1.00      1.00      1.00         4
         616       0.67      1.00      0.80         4
         617       1.00      1.00      1.00         9
         618       0.00      0.00      0.00         4
         619       1.00      0.20      0.33         5
         620       0.75      0.75      0.75         4
         621       0.00      0.00      0.00         4
         622       0.70      0.78      0.74         9
         623       1.00      1.00      1.00         9
         624       1.00      1.00      1.00         4
         625       0.67      0.89      0.76         9
         626       1.00      1.00      1.00         4
         627       1.00      0.75      0.86         4
         628       1.00      1.00      1.00         5
         629       0.89      0.89      0.89         9
         630       1.00      1.00      1.00         5
         631       0.43      0.75      0.55         4
         632       0.80      1.00      0.89         4
         633       1.00      1.00      1.00         4
         634       1.00      1.00      1.00         4
         635       0.67      1.00      0.80         4
         636       1.00      0.75      0.86         4
         637       1.00      1.00      1.00         4
         638       0.82      1.00      0.90         9
         639       0.80      1.00      0.89         4
         640       0.00      0.00      0.00         4
         641       0.83      1.00      0.91         5
         642       1.00      0.89      0.94         9
         643       1.00      0.75      0.86         8
         644       1.00      1.00      1.00         9
         645       0.83      0.56      0.67         9
         646       0.75      0.75      0.75         4
         647       0.67      0.50      0.57         4
         648       1.00      1.00      1.00         4
         649       1.00      0.78      0.88         9
         650       1.00      1.00      1.00         4
         651       1.00      0.50      0.67         4
         652       1.00      0.50      0.67         4
         653       0.75      0.75      0.75         4
         654       0.09      0.25      0.13         4
         655       0.67      0.50      0.57         4
         656       0.50      0.75      0.60         4
         657       1.00      0.80      0.89         5
         658       0.00      0.00      0.00         4
         659       0.90      1.00      0.95         9
         660       0.00      0.00      0.00         4
         661       1.00      1.00      1.00         9
         662       1.00      1.00      1.00         4
         663       1.00      1.00      1.00         4
         664       1.00      0.80      0.89         5
         665       0.80      1.00      0.89         4
         666       0.75      0.67      0.71         9
         667       0.80      0.89      0.84         9
         668       1.00      1.00      1.00         4
         669       0.67      1.00      0.80         4
         670       0.50      0.75      0.60         4
         671       0.88      1.00      0.93         7
         672       0.83      1.00      0.91         5
         673       0.80      0.80      0.80         5
         674       0.00      0.00      0.00         9
         675       0.00      0.00      0.00         4
         676       1.00      1.00      1.00         5
         677       0.00      0.00      0.00         4
         678       1.00      0.80      0.89         5
         679       1.00      0.78      0.88         9
         680       1.00      0.50      0.67         4
         681       1.00      0.67      0.80         9
         682       1.00      1.00      1.00         4
         683       1.00      1.00      1.00         4
         684       0.38      0.75      0.50         4
         685       0.83      1.00      0.91         5
         686       1.00      1.00      1.00         4
         687       0.00      0.00      0.00         4
         688       0.60      0.75      0.67         4
         689       1.00      1.00      1.00         4
         690       1.00      1.00      1.00         5
         691       0.00      0.00      0.00         9
         692       0.75      0.75      0.75         4
         693       1.00      1.00      1.00         4
         694       0.00      0.00      0.00         4
         695       0.50      0.50      0.50         4
         696       0.00      0.00      0.00         4
         697       1.00      0.89      0.94         9
         698       0.83      1.00      0.91         5
         699       0.43      0.60      0.50         5
         700       1.00      0.50      0.67         4
         701       1.00      1.00      1.00         4
         702       0.75      0.67      0.71         9
         703       1.00      0.78      0.88         9
         704       0.00      0.00      0.00         4
         705       1.00      0.44      0.62         9
         706       0.00      0.00      0.00         4
         707       0.89      0.89      0.89         9
         708       1.00      0.75      0.86         4
         709       0.67      0.40      0.50         5
         710       1.00      0.75      0.86         4
         711       1.00      1.00      1.00         4
         712       0.90      1.00      0.95         9
         713       1.00      0.75      0.86         4
         714       1.00      0.75      0.86         4
         715       1.00      0.50      0.67         4
         716       1.00      0.80      0.89         5
         717       0.67      0.80      0.73         5
         718       0.75      0.60      0.67         5
         719       0.67      1.00      0.80         4
         720       1.00      0.80      0.89         5
         721       0.38      0.75      0.50         4
         722       1.00      0.78      0.88         9
         723       0.40      0.50      0.44         4
         724       0.00      0.00      0.00         4
         725       0.00      0.00      0.00         4
         726       0.83      1.00      0.91         5
         727       1.00      0.80      0.89         5
         728       1.00      1.00      1.00         9
         729       0.33      0.25      0.29         4
         730       0.67      1.00      0.80         4
         731       0.20      0.25      0.22         4
         732       0.80      1.00      0.89         4
         733       0.33      0.25      0.29         4
         734       1.00      1.00      1.00         4
         735       0.00      0.00      0.00         4
         736       1.00      0.80      0.89         5
         737       1.00      0.75      0.86         4
         738       1.00      1.00      1.00         5
         739       0.80      1.00      0.89         4
         740       1.00      0.75      0.86         4
         741       0.50      0.25      0.33         4
         742       0.00      0.00      0.00         4
         743       0.89      0.89      0.89         9
         744       0.67      1.00      0.80         4
         745       0.75      0.75      0.75         4
         746       1.00      0.75      0.86         4
         747       1.00      0.75      0.86         4
         748       1.00      0.80      0.89         5
         749       1.00      1.00      1.00         4
         750       0.73      0.89      0.80         9
         751       0.09      0.25      0.13         4
         752       1.00      1.00      1.00         4
         753       0.00      0.00      0.00         9
         754       0.60      0.75      0.67         4
         755       0.00      0.00      0.00         4
         756       0.71      0.56      0.63         9
         757       0.40      0.50      0.44         4
         758       0.55      0.67      0.60         9
         759       0.67      1.00      0.80         4
         760       1.00      1.00      1.00         9
         761       1.00      0.75      0.86         4
         762       1.00      0.25      0.40         4
         763       0.80      1.00      0.89         4
         764       0.00      0.00      0.00         4
         765       0.70      0.78      0.74         9
         766       0.00      0.00      0.00         4
         767       0.80      0.89      0.84         9
         768       1.00      0.75      0.86         4
         769       1.00      1.00      1.00         4
         770       1.00      0.60      0.75         5
         771       0.75      0.67      0.71         9
         772       0.67      0.50      0.57         4
         773       1.00      0.60      0.75         5
         774       1.00      1.00      1.00         9
         775       1.00      1.00      1.00         4
         776       0.90      1.00      0.95         9
         777       0.75      1.00      0.86         9
         778       0.80      1.00      0.89         4
         779       1.00      1.00      1.00         5
         780       0.00      0.00      0.00         4
         781       0.67      0.50      0.57         4
         782       1.00      0.44      0.62         9
         783       0.50      0.50      0.50         4
         784       0.40      0.50      0.44         4
         785       1.00      0.80      0.89         5
         786       0.00      0.00      0.00         4
         787       0.67      1.00      0.80         4
         788       1.00      1.00      1.00         4
         789       0.88      0.78      0.82         9
         790       1.00      0.50      0.67         4
         791       0.00      0.00      0.00         9
         792       0.67      0.80      0.73         5
         793       0.80      1.00      0.89         4
         794       0.62      1.00      0.77         5
         795       0.75      0.75      0.75         4
         796       0.50      0.25      0.33         4
         797       1.00      1.00      1.00         9
         798       1.00      0.89      0.94         9
         799       1.00      1.00      1.00         9
         800       0.78      0.78      0.78         9
         801       1.00      0.75      0.86         4
         802       0.00      0.00      0.00         4
         803       0.67      0.50      0.57         4
         804       1.00      1.00      1.00         4
         805       1.00      1.00      1.00         4
         806       0.33      0.50      0.40         4
         807       0.50      0.50      0.50         4
         808       0.07      0.11      0.09         9
         809       0.71      1.00      0.83         5
         810       1.00      0.75      0.86         4
         811       0.80      1.00      0.89         4
         812       0.75      0.75      0.75         4
         813       0.83      0.56      0.67         9
         814       0.67      0.50      0.57         4
         815       0.80      1.00      0.89         4
         816       0.00      0.00      0.00         9
         817       1.00      1.00      1.00         5
         818       0.70      0.78      0.74         9
         819       0.80      1.00      0.89         4
         820       0.75      0.75      0.75         4
         821       1.00      1.00      1.00         5
         822       0.00      0.00      0.00         4
         823       0.60      0.75      0.67         4
         824       0.67      0.44      0.53         9
         825       0.89      0.89      0.89         9
         826       0.08      0.25      0.12         4
         827       0.00      0.00      0.00         9
         828       0.80      0.89      0.84         9
         829       1.00      1.00      1.00         4
         830       1.00      1.00      1.00         4
         831       1.00      0.80      0.89         5
         832       1.00      1.00      1.00         4
         833       0.60      0.60      0.60         5
         834       0.50      0.25      0.33         4
         835       1.00      0.75      0.86         4
         836       1.00      0.25      0.40         4
         837       0.69      1.00      0.82         9
         838       0.90      1.00      0.95         9
         839       0.60      0.75      0.67         4
         840       0.50      0.80      0.62         5
         841       1.00      1.00      1.00         5
         842       1.00      0.20      0.33         5
         843       1.00      0.75      0.86         4
         844       1.00      0.80      0.89         5
         845       0.80      0.80      0.80         5
         846       1.00      0.75      0.86         4
         847       1.00      0.60      0.75         5
         848       1.00      1.00      1.00         4
         849       0.90      1.00      0.95         9
         850       0.75      0.67      0.71         9
         851       0.90      1.00      0.95         9
         852       1.00      0.25      0.40         4
         853       0.56      0.56      0.56         9
         854       0.78      0.78      0.78         9
         855       0.80      1.00      0.89         4
         856       1.00      0.78      0.88         9
         857       0.90      1.00      0.95         9
         858       0.33      0.25      0.29         4
         859       0.00      0.00      0.00         4
         860       1.00      0.75      0.86         4
         861       0.50      1.00      0.67         4
         862       0.50      0.44      0.47         9
         863       1.00      0.75      0.86         4
         864       1.00      1.00      1.00         4
         865       1.00      1.00      1.00         4
         866       0.00      0.00      0.00         4
         867       0.80      1.00      0.89         4
         868       0.00      0.00      0.00         4
         869       1.00      1.00      1.00         4
         870       0.07      0.25      0.11         4
         871       1.00      1.00      1.00         4
         872       0.57      1.00      0.73         4
         873       1.00      1.00      1.00         4
         874       0.73      0.89      0.80         9
         875       1.00      1.00      1.00         5
         876       1.00      1.00      1.00         5
         877       0.88      0.78      0.82         9
         878       1.00      1.00      1.00         4
         879       0.00      0.00      0.00         4
         880       0.00      0.00      0.00         9
         881       0.90      1.00      0.95         9
         882       0.60      0.60      0.60         5
         883       0.50      0.89      0.64         9
         884       0.80      1.00      0.89         4
         885       0.88      0.78      0.82         9
         886       0.00      0.00      0.00         4
         887       0.71      0.56      0.63         9
         888       0.25      0.25      0.25         4
         889       0.90      1.00      0.95         9
         890       0.83      0.56      0.67         9
         891       0.78      0.78      0.78         9
         892       0.08      0.25      0.12         4
         893       1.00      0.75      0.86         4

    accuracy                           0.71      4917
   macro avg       0.71      0.69      0.68      4917
weighted avg       0.73      0.71      0.70      4917

task_train_time: {0: 0.12546740899999875, 1: 0.03575979999999923, 2: 0.032757841000000454, 3: 0.033361963999999134, 4: 0.02942947000000018, 5: 0.03455795400000028, 6: 0.028927482000000282, 7: 0.03075349099999869, 8: 0.029646213000001254, 9: 0.0387712570000005, 10: 0.032705647000000226, 11: 0.04383525699999957, 12: 0.049788733999999835, 13: 0.04092634300000064, 14: 0.03663803600000115, 15: 0.03357755899999937, 16: 0.031129157999998824, 17: 0.04508272800000057, 18: 0.03575782200000077, 19: 0.03395434799999997, 20: 0.03468408600000039, 21: 0.02794355500000023, 22: 0.03728929300000061, 23: 0.033798062000000684, 24: 0.03514300400000003, 25: 0.03337435099999908, 26: 0.03425813700000013, 27: 0.032211996999999215, 28: 0.03862565800000084, 29: 0.031062116000001083, 30: 0.03467756300000069, 31: 0.0287630649999997, 32: 0.028954250000001736, 33: 0.0336881379999987, 34: 0.034900224000001145, 35: 0.029853288000001754, 36: 0.02999696899999904, 37: 0.03384813799999975, 38: 0.035200455000001796, 39: 0.034328116999997604, 40: 0.03527865200000235, 41: 0.0375156479999994, 42: 0.03255082499999773, 43: 0.04654468800000089}
prediction_time: 0.00028607700001259673
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
