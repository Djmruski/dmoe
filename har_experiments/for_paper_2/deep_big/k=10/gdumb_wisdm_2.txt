Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='54dcf47a-3f5c-447a-85e5-ebc41d6c7f36', conf_timestamp='2023-08-13 15:34:02.090525', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 60.64 % 	 [Task-IL]: 47.34 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 50.99 % 	 [Task-IL]: 36.24 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 41.4 % 	 [Task-IL]: 33.34 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 28.26 % 	 [Task-IL]: 31.23 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 26.46 % 	 [Task-IL]: 31.97 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 22.94 % 	 [Task-IL]: 32.24 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.55 % 	 [Task-IL]: 31.76 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 23.39 % 	 [Task-IL]: 30.22 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 22.81 % 	 [Task-IL]: 29.83 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 19.62 % 	 [Task-IL]: 30.9 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 16.46 % 	 [Task-IL]: 29.88 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 15.96 % 	 [Task-IL]: 28.86 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 17.52 % 	 [Task-IL]: 29.6 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 13.79 % 	 [Task-IL]: 29.32 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.78 % 	 [Task-IL]: 28.1 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 13.96 % 	 [Task-IL]: 27.74 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 14.76 % 	 [Task-IL]: 27.95 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 12.97 % 	 [Task-IL]: 28.21 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 10.31 % 	 [Task-IL]: 28.05 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.23 % 	 [Task-IL]: 28.18 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.24 % 	 [Task-IL]: 28.7 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.75 % 	 [Task-IL]: 28.29 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.26 % 	 [Task-IL]: 28.33 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 9.01 % 	 [Task-IL]: 28.02 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.96 % 	 [Task-IL]: 28.06 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.11 % 	 [Task-IL]: 28.05 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 8.51 % 	 [Task-IL]: 27.65 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 8.56 % 	 [Task-IL]: 27.64 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.5 % 	 [Task-IL]: 27.37 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 5.51 % 	 [Task-IL]: 27.26 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.7 % 	 [Task-IL]: 27.61 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.38 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.72 % 	 [Task-IL]: 27.37 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 7.28 % 	 [Task-IL]: 27.49 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.67 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.32 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.87 % 	 [Task-IL]: 26.69 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.26 % 	 [Task-IL]: 26.71 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.36 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.0 % 	 [Task-IL]: 27.15 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.54 % 	 [Task-IL]: 27.29 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.52 % 	 [Task-IL]: 27.32 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.71 % 	 [Task-IL]: 26.77 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({865: 24, 709: 24, 267: 24, 395: 24, 599: 23, 669: 23, 764: 23, 225: 23, 247: 23, 379: 23, 667: 22, 34: 22, 543: 22, 324: 22, 337: 22, 474: 22, 519: 22, 4: 21, 754: 21, 623: 21, 560: 21, 732: 21, 615: 21, 594: 21, 574: 21, 884: 21, 158: 21, 161: 21, 219: 21, 311: 21, 410: 21, 404: 21, 415: 21, 425: 21, 681: 20, 684: 20, 720: 20, 759: 20, 871: 20, 861: 20, 763: 20, 751: 20, 77: 20, 88: 20, 122: 20, 146: 20, 201: 20, 204: 20, 236: 20, 313: 20, 405: 20, 398: 20, 432: 20, 454: 20, 481: 20, 499: 20, 525: 20, 8: 19, 637: 19, 557: 19, 5: 19, 833: 19, 633: 19, 718: 19, 670: 19, 815: 19, 40: 19, 798: 19, 116: 19, 605: 19, 135: 19, 154: 19, 192: 19, 181: 19, 187: 19, 195: 19, 194: 19, 270: 19, 255: 19, 256: 19, 276: 19, 331: 19, 361: 19, 359: 19, 386: 19, 408: 19, 448: 19, 553: 19, 523: 19, 522: 19, 767: 18, 885: 18, 741: 18, 817: 18, 876: 18, 872: 18, 631: 18, 831: 18, 837: 18, 635: 18, 598: 18, 43: 18, 626: 18, 749: 18, 841: 18, 711: 18, 60: 18, 617: 18, 875: 18, 113: 18, 123: 18, 138: 18, 162: 18, 182: 18, 199: 18, 262: 18, 277: 18, 296: 18, 350: 18, 354: 18, 393: 18, 387: 18, 385: 18, 488: 18, 819: 17, 804: 17, 810: 17, 648: 17, 864: 17, 795: 17, 730: 17, 48: 17, 64: 17, 692: 17, 582: 17, 151: 17, 304: 17, 299: 17, 328: 17, 383: 17, 423: 17, 493: 17, 27: 16, 22: 16, 743: 16, 860: 16, 562: 16, 682: 16, 575: 16, 838: 16, 731: 16, 869: 16, 843: 16, 770: 16, 45: 16, 801: 16, 82: 16, 119: 16, 127: 16, 115: 16, 167: 16, 224: 16, 229: 16, 242: 16, 260: 16, 285: 16, 306: 16, 326: 16, 321: 16, 315: 16, 402: 16, 433: 16, 466: 16, 462: 16, 496: 16, 497: 16, 1: 15, 28: 15, 848: 15, 881: 15, 651: 15, 809: 15, 618: 15, 595: 15, 822: 15, 780: 15, 740: 15, 665: 15, 816: 15, 107: 15, 111: 15, 131: 15, 205: 15, 220: 15, 232: 15, 222: 15, 248: 15, 329: 15, 429: 15, 416: 15, 426: 15, 546: 15, 444: 15, 469: 15, 480: 15, 500: 15, 11: 14, 658: 14, 701: 14, 888: 14, 793: 14, 549: 14, 748: 14, 98: 14, 179: 14, 345: 14, 348: 14, 417: 14, 436: 14, 459: 14, 511: 14, 700: 13, 794: 13, 99: 13, 768: 13, 144: 13, 234: 13, 241: 13, 471: 13, 19: 12, 29: 12, 866: 12, 839: 12, 745: 12, 612: 12, 873: 12, 893: 12, 563: 12, 654: 12, 538: 12, 689: 12, 185: 12, 271: 12, 272: 12, 269: 12, 552: 12, 333: 12, 335: 12, 375: 12, 401: 12, 447: 12, 533: 12, 811: 11, 823: 11, 16: 11, 674: 11, 645: 11, 807: 11, 542: 11, 778: 11, 781: 11, 683: 11, 620: 11, 646: 11, 53: 11, 868: 11, 61: 11, 545: 11, 604: 11, 705: 11, 103: 11, 142: 11, 288: 11, 327: 11, 314: 11, 344: 11, 368: 11, 366: 11, 376: 11, 419: 11, 443: 11, 456: 11, 458: 11, 487: 11, 476: 11, 520: 11, 857: 10, 15: 10, 694: 10, 576: 10, 628: 10, 642: 10, 613: 10, 774: 10, 829: 10, 675: 10, 47: 10, 652: 10, 849: 10, 863: 10, 55: 10, 717: 10, 67: 10, 86: 10, 783: 10, 655: 10, 785: 10, 679: 10, 141: 10, 137: 10, 840: 10, 640: 10, 850: 10, 209: 10, 278: 10, 287: 10, 330: 10, 353: 10, 364: 10, 370: 10, 382: 10, 380: 10, 411: 10, 407: 10, 418: 10, 535: 10, 445: 10, 442: 10, 484: 10, 510: 10, 532: 10, 517: 10, 548: 10, 756: 9, 736: 9, 708: 9, 568: 9, 844: 9, 614: 9, 691: 9, 579: 9, 559: 9, 716: 9, 775: 9, 10: 9, 571: 9, 643: 9, 880: 9, 750: 9, 713: 9, 580: 9, 661: 9, 587: 9, 830: 9, 641: 9, 664: 9, 805: 9, 762: 9, 35: 9, 537: 9, 738: 9, 680: 9, 877: 9, 845: 9, 630: 9, 887: 9, 739: 9, 75: 9, 83: 9, 80: 9, 600: 9, 81: 9, 572: 9, 859: 9, 94: 9, 97: 9, 695: 9, 715: 9, 150: 9, 140: 9, 168: 9, 157: 9, 180: 9, 190: 9, 186: 9, 203: 9, 197: 9, 198: 9, 228: 9, 243: 9, 237: 9, 266: 9, 257: 9, 291: 9, 303: 9, 334: 9, 338: 9, 355: 9, 373: 9, 372: 9, 384: 9, 377: 9, 391: 9, 409: 9, 427: 9, 451: 9, 437: 9, 452: 9, 453: 9, 450: 9, 435: 9, 464: 9, 479: 9, 505: 9, 506: 9, 530: 9, 528: 9, 13: 8, 25: 8, 818: 8, 644: 8, 32: 8, 760: 8, 550: 8, 14: 8, 890: 8, 753: 8, 622: 8, 802: 8, 653: 8, 786: 8, 541: 8, 591: 8, 697: 8, 858: 8, 828: 8, 846: 8, 824: 8, 825: 8, 634: 8, 39: 8, 726: 8, 821: 8, 36: 8, 776: 8, 37: 8, 38: 8, 773: 8, 712: 8, 632: 8, 771: 8, 566: 8, 71: 8, 59: 8, 797: 8, 657: 8, 558: 8, 671: 8, 87: 8, 601: 8, 659: 8, 799: 8, 95: 8, 101: 8, 109: 8, 638: 8, 104: 8, 772: 8, 124: 8, 126: 8, 133: 8, 128: 8, 597: 8, 147: 8, 152: 8, 171: 8, 173: 8, 842: 8, 193: 8, 191: 8, 206: 8, 214: 8, 218: 8, 226: 8, 250: 8, 244: 8, 238: 8, 240: 8, 253: 8, 252: 8, 703: 8, 259: 8, 268: 8, 534: 8, 258: 8, 282: 8, 279: 8, 286: 8, 305: 8, 298: 8, 295: 8, 301: 8, 297: 8, 307: 8, 318: 8, 357: 8, 371: 8, 363: 8, 365: 8, 369: 8, 388: 8, 390: 8, 400: 8, 413: 8, 412: 8, 420: 8, 449: 8, 438: 8, 461: 8, 473: 8, 460: 8, 467: 8, 472: 8, 455: 8, 490: 8, 491: 8, 508: 8, 512: 8, 504: 8, 494: 8, 515: 8, 531: 8, 24: 7, 26: 7, 0: 7, 722: 7, 20: 7, 737: 7, 892: 7, 806: 7, 18: 7, 728: 7, 835: 7, 12: 7, 570: 7, 744: 7, 723: 7, 870: 7, 650: 7, 672: 7, 554: 7, 610: 7, 625: 7, 41: 7, 42: 7, 746: 7, 755: 7, 789: 7, 702: 7, 590: 7, 52: 7, 742: 7, 57: 7, 63: 7, 66: 7, 54: 7, 593: 7, 636: 7, 647: 7, 602: 7, 660: 7, 855: 7, 74: 7, 78: 7, 84: 7, 89: 7, 91: 7, 92: 7, 90: 7, 93: 7, 758: 7, 886: 7, 564: 7, 883: 7, 629: 7, 686: 7, 105: 7, 102: 7, 725: 7, 704: 7, 117: 7, 619: 7, 592: 7, 567: 7, 769: 7, 561: 7, 757: 7, 585: 7, 143: 7, 134: 7, 889: 7, 136: 7, 145: 7, 677: 7, 734: 7, 156: 7, 169: 7, 172: 7, 164: 7, 159: 7, 616: 7, 189: 7, 196: 7, 212: 7, 202: 7, 213: 7, 227: 7, 246: 7, 245: 7, 261: 7, 293: 7, 292: 7, 284: 7, 309: 7, 310: 7, 294: 7, 300: 7, 332: 7, 325: 7, 323: 7, 340: 7, 342: 7, 347: 7, 389: 7, 381: 7, 392: 7, 397: 7, 399: 7, 421: 7, 422: 7, 441: 7, 470: 7, 482: 7, 475: 7, 507: 7, 502: 7, 513: 7, 498: 7, 527: 7, 521: 7, 540: 7, 547: 7, 699: 6, 17: 6, 555: 6, 2: 6, 23: 6, 693: 6, 603: 6, 3: 6, 649: 6, 7: 6, 777: 6, 565: 6, 874: 6, 678: 6, 656: 6, 853: 6, 609: 6, 747: 6, 729: 6, 752: 6, 719: 6, 49: 6, 596: 6, 790: 6, 891: 6, 56: 6, 68: 6, 65: 6, 72: 6, 62: 6, 663: 6, 685: 6, 698: 6, 710: 6, 573: 6, 76: 6, 79: 6, 796: 6, 551: 6, 862: 6, 878: 6, 611: 6, 106: 6, 96: 6, 761: 6, 110: 6, 690: 6, 727: 6, 114: 6, 706: 6, 556: 6, 125: 6, 139: 6, 148: 6, 163: 6, 170: 6, 166: 6, 827: 6, 803: 6, 175: 6, 178: 6, 183: 6, 627: 6, 177: 6, 188: 6, 176: 6, 200: 6, 217: 6, 216: 6, 223: 6, 221: 6, 233: 6, 249: 6, 251: 6, 235: 6, 624: 6, 588: 6, 668: 6, 265: 6, 273: 6, 289: 6, 283: 6, 274: 6, 275: 6, 322: 6, 349: 6, 341: 6, 352: 6, 346: 6, 351: 6, 356: 6, 374: 6, 394: 6, 406: 6, 430: 6, 414: 6, 424: 6, 440: 6, 439: 6, 463: 6, 468: 6, 465: 6, 485: 6, 478: 6, 489: 6, 503: 6, 501: 6, 495: 6, 529: 6, 516: 6, 514: 6, 539: 6, 9: 5, 31: 5, 856: 5, 33: 5, 583: 5, 6: 5, 578: 5, 688: 5, 808: 5, 673: 5, 707: 5, 792: 5, 696: 5, 851: 5, 46: 5, 50: 5, 639: 5, 51: 5, 791: 5, 676: 5, 606: 5, 58: 5, 812: 5, 69: 5, 70: 5, 784: 5, 714: 5, 834: 5, 73: 5, 662: 5, 765: 5, 85: 5, 820: 5, 852: 5, 766: 5, 112: 5, 569: 5, 832: 5, 586: 5, 581: 5, 121: 5, 130: 5, 120: 5, 666: 5, 132: 5, 584: 5, 160: 5, 155: 5, 165: 5, 174: 5, 782: 5, 847: 5, 800: 5, 239: 5, 264: 5, 254: 5, 281: 5, 302: 5, 308: 5, 320: 5, 319: 5, 316: 5, 336: 5, 339: 5, 360: 5, 358: 5, 396: 5, 428: 5, 431: 5, 457: 5, 477: 5, 536: 5, 483: 5, 524: 5, 526: 5, 518: 5, 735: 4, 21: 4, 30: 4, 577: 4, 826: 4, 44: 4, 787: 4, 608: 4, 544: 4, 687: 4, 882: 4, 721: 4, 118: 4, 779: 4, 129: 4, 149: 4, 854: 4, 211: 4, 208: 4, 207: 4, 231: 4, 215: 4, 263: 4, 290: 4, 280: 4, 814: 4, 836: 4, 317: 4, 343: 4, 367: 4, 362: 4, 434: 4, 446: 4, 492: 4, 509: 4, 621: 3, 867: 3, 733: 3, 100: 3, 108: 3, 724: 3, 184: 3, 210: 3, 230: 3, 788: 3, 312: 3, 813: 3, 879: 3, 378: 3, 403: 3, 486: 3, 589: 2, 153: 2, 607: 2})
Total buffer: 8940
fit_time: 78.841236806

Accuracy for 44 task(s): 	 [Class-IL]: 71.28 % 	 [Task-IL]: 30.36 %

CLASS_IL_ACC: 
	[65.42553191489363, 69.02654867256636, 70.52631578947368, 83.50515463917526, 69.72477064220183, 64.75409836065575, 72.81553398058253, 72.89719626168224, 76.63551401869158, 81.41592920353983, 55.55555555555556, 57.943925233644855, 72.32142857142857, 73.07692307692307, 60.71428571428571, 70.16129032258065, 78.43137254901961, 61.0, 74.35897435897436, 81.35593220338984, 67.71653543307087, 76.19047619047619, 61.6822429906542, 71.02803738317756, 57.65765765765766, 81.48148148148148, 81.9047619047619, 67.32673267326733, 75.25773195876289, 74.10714285714286, 72.03389830508475, 76.85185185185185, 72.32142857142857, 77.39130434782608, 72.81553398058253, 67.88990825688074, 84.87394957983193, 64.91228070175438, 61.29032258064516, 56.896551724137936, 80.83333333333333, 68.22429906542055, 78.2258064516129, 75.89285714285714]
TASK_IL_ACC: 
	[50.0, 24.778761061946902, 23.157894736842106, 28.865979381443296, 32.11009174311927, 31.147540983606557, 27.184466019417474, 30.8411214953271, 24.299065420560748, 35.39823008849557, 23.931623931623932, 30.8411214953271, 28.57142857142857, 32.69230769230769, 29.464285714285715, 24.193548387096776, 29.411764705882355, 28.999999999999996, 29.914529914529915, 27.966101694915253, 31.496062992125985, 24.761904761904763, 27.102803738317753, 27.102803738317753, 36.03603603603604, 26.851851851851855, 22.857142857142858, 29.7029702970297, 31.958762886597935, 36.607142857142854, 30.508474576271187, 30.555555555555557, 26.785714285714285, 26.08695652173913, 20.388349514563107, 27.522935779816514, 22.689075630252102, 29.82456140350877, 22.58064516129032, 31.896551724137932, 36.666666666666664, 28.037383177570092, 19.35483870967742, 94.64285714285714]
f1_micro: 71.22229001423632
f1_macro: 67.77882520781111
              precision    recall  f1-score   support

           0       1.00      0.75      0.86         4
           1       0.71      0.56      0.63         9
           2       0.00      0.00      0.00         4
           3       1.00      0.75      0.86         4
           4       0.75      1.00      0.86         9
           5       0.90      1.00      0.95         9
           6       0.50      0.25      0.33         4
           7       0.14      0.25      0.18         4
           8       0.64      0.78      0.70         9
           9       1.00      1.00      1.00         4
          10       0.75      0.75      0.75         4
          11       0.75      0.67      0.71         9
          12       1.00      0.50      0.67         4
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         4
          15       1.00      1.00      1.00         5
          16       1.00      1.00      1.00         5
          17       0.00      0.00      0.00         4
          18       0.75      0.75      0.75         4
          19       0.80      0.57      0.67         7
          20       0.00      0.00      0.00         4
          21       1.00      0.50      0.67         4
          22       0.64      0.78      0.70         9
          23       0.67      0.80      0.73         5
          24       1.00      0.75      0.86         4
          25       0.75      0.75      0.75         4
          26       1.00      0.75      0.86         4
          27       0.86      0.67      0.75         9
          28       1.00      0.67      0.80         9
          29       0.90      1.00      0.95         9
          30       1.00      0.75      0.86         4
          31       1.00      0.50      0.67         4
          32       0.80      0.80      0.80         5
          33       1.00      0.25      0.40         4
          34       1.00      0.89      0.94         9
          35       1.00      1.00      1.00         4
          36       1.00      1.00      1.00         4
          37       1.00      0.80      0.89         5
          38       0.67      0.50      0.57         4
          39       0.80      0.80      0.80         5
          40       0.00      0.00      0.00         9
          41       0.50      0.75      0.60         4
          42       0.80      1.00      0.89         4
          43       0.88      0.78      0.82         9
          44       1.00      0.75      0.86         4
          45       0.82      1.00      0.90         9
          46       1.00      0.40      0.57         5
          47       1.00      0.29      0.44         7
          48       1.00      1.00      1.00         9
          49       1.00      1.00      1.00         4
          50       0.00      0.00      0.00         4
          51       1.00      0.40      0.57         5
          52       0.67      1.00      0.80         4
          53       1.00      0.60      0.75         5
          54       0.75      0.75      0.75         4
          55       0.57      1.00      0.73         4
          56       0.00      0.00      0.00         4
          57       1.00      1.00      1.00         4
          58       0.67      0.40      0.50         5
          59       1.00      1.00      1.00         5
          60       1.00      1.00      1.00         9
          61       1.00      1.00      1.00         5
          62       0.80      1.00      0.89         4
          63       1.00      1.00      1.00         4
          64       0.62      0.89      0.73         9
          65       0.00      0.00      0.00         4
          66       0.50      0.50      0.50         4
          67       1.00      1.00      1.00         5
          68       0.00      0.00      0.00         4
          69       0.00      0.00      0.00         4
          70       1.00      1.00      1.00         5
          71       0.75      0.75      0.75         4
          72       1.00      1.00      1.00         4
          73       0.00      0.00      0.00         4
          74       1.00      1.00      1.00         4
          75       0.67      1.00      0.80         4
          76       1.00      0.50      0.67         4
          77       1.00      0.89      0.94         9
          78       0.12      0.25      0.17         4
          79       0.80      1.00      0.89         4
          80       0.75      0.75      0.75         4
          81       0.67      1.00      0.80         4
          82       1.00      0.89      0.94         9
          83       0.83      1.00      0.91         5
          84       0.75      0.75      0.75         4
          85       1.00      0.50      0.67         4
          86       1.00      1.00      1.00         5
          87       1.00      0.75      0.86         4
          88       0.90      1.00      0.95         9
          89       0.80      1.00      0.89         4
          90       1.00      0.50      0.67         4
          91       1.00      1.00      1.00         4
          92       1.00      1.00      1.00         4
          93       1.00      0.50      0.67         4
          94       1.00      1.00      1.00         4
          95       0.00      0.00      0.00         4
          96       0.71      1.00      0.83         5
          97       0.80      0.80      0.80         5
          98       1.00      0.89      0.94         9
          99       1.00      1.00      1.00         9
         100       1.00      0.25      0.40         4
         101       1.00      1.00      1.00         5
         102       0.83      1.00      0.91         5
         103       1.00      0.80      0.89         5
         104       0.80      1.00      0.89         4
         105       0.75      0.75      0.75         4
         106       0.00      0.00      0.00         4
         107       1.00      0.88      0.93         8
         108       1.00      0.25      0.40         4
         109       0.80      1.00      0.89         4
         110       1.00      0.75      0.86         4
         111       0.00      0.00      0.00         9
         112       0.00      0.00      0.00         4
         113       1.00      1.00      1.00         9
         114       1.00      0.75      0.86         4
         115       0.00      0.00      0.00         9
         116       0.83      0.56      0.67         9
         117       1.00      0.80      0.89         5
         118       0.67      0.50      0.57         4
         119       0.55      0.67      0.60         9
         120       0.80      1.00      0.89         4
         121       0.00      0.00      0.00         4
         122       0.89      0.89      0.89         9
         123       1.00      0.67      0.80         9
         124       0.83      1.00      0.91         5
         125       0.67      0.50      0.57         4
         126       1.00      1.00      1.00         5
         127       0.80      0.89      0.84         9
         128       0.33      0.20      0.25         5
         129       1.00      0.60      0.75         5
         130       0.50      0.17      0.25         6
         131       0.90      1.00      0.95         9
         132       0.75      0.75      0.75         4
         133       1.00      1.00      1.00         4
         134       0.33      0.25      0.29         4
         135       0.73      0.89      0.80         9
         136       0.00      0.00      0.00         4
         137       1.00      1.00      1.00         5
         138       1.00      1.00      1.00         9
         139       0.00      0.00      0.00         4
         140       0.33      0.25      0.29         4
         141       0.75      0.75      0.75         4
         142       0.80      1.00      0.89         4
         143       0.50      0.75      0.60         4
         144       0.71      1.00      0.83         5
         145       0.75      0.75      0.75         4
         146       0.56      0.56      0.56         9
         147       0.67      0.50      0.57         4
         148       0.71      1.00      0.83         5
         149       1.00      1.00      1.00         4
         150       0.00      0.00      0.00         4
         151       0.75      1.00      0.86         9
         152       0.80      1.00      0.89         4
         153       1.00      1.00      1.00         4
         154       0.75      1.00      0.86         9
         155       1.00      0.50      0.67         4
         156       1.00      0.75      0.86         4
         157       1.00      0.75      0.86         4
         158       0.80      0.89      0.84         9
         159       1.00      1.00      1.00         4
         160       0.00      0.00      0.00         4
         161       0.78      0.78      0.78         9
         162       1.00      1.00      1.00         9
         163       0.00      0.00      0.00         4
         164       0.50      0.50      0.50         4
         165       0.80      1.00      0.89         4
         166       1.00      1.00      1.00         4
         167       0.57      0.44      0.50         9
         168       1.00      0.75      0.86         4
         169       0.80      1.00      0.89         4
         170       0.75      0.60      0.67         5
         171       0.33      0.75      0.46         4
         172       1.00      0.50      0.67         4
         173       0.80      0.80      0.80         5
         174       0.33      0.50      0.40         4
         175       0.75      0.75      0.75         4
         176       1.00      0.75      0.86         4
         177       1.00      1.00      1.00         4
         178       1.00      0.75      0.86         4
         179       1.00      0.89      0.94         9
         180       0.50      0.50      0.50         4
         181       0.90      1.00      0.95         9
         182       0.75      1.00      0.86         9
         183       0.00      0.00      0.00         4
         184       1.00      0.50      0.67         4
         185       0.50      0.40      0.44         5
         186       0.75      0.75      0.75         4
         187       0.90      1.00      0.95         9
         188       0.00      0.00      0.00         4
         189       0.80      1.00      0.89         4
         190       0.56      1.00      0.71         5
         191       1.00      1.00      1.00         4
         192       0.67      0.67      0.67         9
         193       1.00      1.00      1.00         4
         194       1.00      0.89      0.94         9
         195       0.80      0.89      0.84         9
         196       0.75      0.75      0.75         4
         197       1.00      1.00      1.00         5
         198       0.20      0.25      0.22         4
         199       0.90      1.00      0.95         9
         200       1.00      1.00      1.00         4
         201       1.00      0.67      0.80         9
         202       1.00      1.00      1.00         4
         203       1.00      1.00      1.00         4
         204       0.90      1.00      0.95         9
         205       0.90      1.00      0.95         9
         206       0.83      1.00      0.91         5
         207       1.00      0.75      0.86         4
         208       1.00      0.75      0.86         4
         209       0.62      1.00      0.77         5
         210       0.20      0.25      0.22         4
         211       1.00      0.75      0.86         4
         212       0.12      0.25      0.17         4
         213       0.09      0.25      0.13         4
         214       0.29      0.40      0.33         5
         215       0.00      0.00      0.00         4
         216       1.00      1.00      1.00         4
         217       0.00      0.00      0.00         4
         218       0.00      0.00      0.00         4
         219       0.00      0.00      0.00         9
         220       0.89      0.89      0.89         9
         221       0.50      0.75      0.60         4
         222       0.89      0.89      0.89         9
         223       1.00      0.75      0.86         4
         224       0.00      0.00      0.00         9
         225       0.89      0.89      0.89         9
         226       1.00      0.80      0.89         5
         227       0.67      1.00      0.80         4
         228       0.50      0.50      0.50         4
         229       0.57      0.44      0.50         9
         230       0.75      0.75      0.75         4
         231       0.67      1.00      0.80         4
         232       0.89      0.89      0.89         9
         233       0.00      0.00      0.00         4
         234       1.00      0.89      0.94         9
         235       0.50      0.50      0.50         4
         236       1.00      0.67      0.80         9
         237       1.00      1.00      1.00         4
         238       1.00      0.75      0.86         4
         239       0.67      0.50      0.57         4
         240       0.50      0.25      0.33         4
         241       0.57      0.80      0.67         5
         242       0.44      0.44      0.44         9
         243       0.80      1.00      0.89         4
         244       0.80      1.00      0.89         4
         245       0.75      0.75      0.75         4
         246       1.00      0.75      0.86         4
         247       1.00      1.00      1.00         9
         248       0.00      0.00      0.00         9
         249       0.50      0.25      0.33         4
         250       1.00      0.60      0.75         5
         251       0.00      0.00      0.00         4
         252       0.08      0.25      0.12         4
         253       0.00      0.00      0.00         4
         254       1.00      1.00      1.00         4
         255       0.90      1.00      0.95         9
         256       0.00      0.00      0.00         9
         257       0.80      1.00      0.89         4
         258       1.00      1.00      1.00         4
         259       1.00      0.75      0.86         4
         260       1.00      0.78      0.88         9
         261       0.00      0.00      0.00         4
         262       0.75      0.67      0.71         9
         263       1.00      1.00      1.00         4
         264       1.00      1.00      1.00         4
         265       1.00      1.00      1.00         4
         266       1.00      0.75      0.86         4
         267       0.90      1.00      0.95         9
         268       0.17      0.50      0.25         4
         269       0.07      0.25      0.11         4
         270       0.90      1.00      0.95         9
         271       0.80      0.80      0.80         5
         272       0.80      0.80      0.80         5
         273       0.00      0.00      0.00         4
         274       1.00      1.00      1.00         4
         275       1.00      1.00      1.00         4
         276       0.82      1.00      0.90         9
         277       0.73      0.89      0.80         9
         278       0.80      0.80      0.80         5
         279       0.50      0.75      0.60         4
         280       1.00      0.75      0.86         4
         281       0.00      0.00      0.00         4
         282       0.80      1.00      0.89         4
         283       0.67      1.00      0.80         4
         284       0.50      1.00      0.67         4
         285       0.80      0.89      0.84         9
         286       0.67      0.40      0.50         5
         287       1.00      1.00      1.00         5
         288       0.83      0.56      0.67         9
         289       0.00      0.00      0.00         4
         290       1.00      0.50      0.67         4
         291       1.00      0.40      0.57         5
         292       1.00      1.00      1.00         4
         293       0.12      0.25      0.17         4
         294       1.00      1.00      1.00         4
         295       0.40      0.50      0.44         4
         296       0.90      1.00      0.95         9
         297       1.00      1.00      1.00         5
         298       1.00      1.00      1.00         4
         299       0.89      0.89      0.89         9
         300       0.00      0.00      0.00         4
         301       1.00      0.75      0.86         4
         302       1.00      1.00      1.00         4
         303       0.00      0.00      0.00         4
         304       0.60      0.33      0.43         9
         305       1.00      1.00      1.00         5
         306       1.00      1.00      1.00         9
         307       1.00      0.75      0.86         4
         308       1.00      0.75      0.86         4
         309       0.80      1.00      0.89         4
         310       0.00      0.00      0.00         4
         311       0.00      0.00      0.00         9
         312       1.00      0.50      0.67         4
         313       0.00      0.00      0.00         9
         314       0.71      0.56      0.63         9
         315       0.67      0.67      0.67         9
         316       1.00      1.00      1.00         4
         317       0.50      0.25      0.33         4
         318       0.00      0.00      0.00         4
         319       0.67      1.00      0.80         4
         320       1.00      1.00      1.00         4
         321       1.00      0.89      0.94         9
         322       1.00      1.00      1.00         5
         323       1.00      0.75      0.86         4
         324       0.00      0.00      0.00         9
         325       1.00      0.25      0.40         4
         326       0.58      0.78      0.67         9
         327       0.30      0.60      0.40         5
         328       0.82      1.00      0.90         9
         329       0.90      1.00      0.95         9
         330       0.75      0.75      0.75         4
         331       0.89      0.89      0.89         9
         332       0.29      0.40      0.33         5
         333       1.00      1.00      1.00         5
         334       0.83      1.00      0.91         5
         335       1.00      1.00      1.00         5
         336       1.00      0.80      0.89         5
         337       0.86      0.67      0.75         9
         338       0.71      1.00      0.83         5
         339       1.00      1.00      1.00         4
         340       0.00      0.00      0.00         4
         341       0.57      1.00      0.73         4
         342       0.75      0.75      0.75         4
         343       1.00      0.25      0.40         4
         344       0.71      1.00      0.83         5
         345       1.00      1.00      1.00         9
         346       1.00      0.75      0.86         4
         347       1.00      1.00      1.00         4
         348       1.00      1.00      1.00         5
         349       1.00      0.75      0.86         4
         350       0.78      0.78      0.78         9
         351       0.60      0.75      0.67         4
         352       1.00      0.25      0.40         4
         353       0.60      0.60      0.60         5
         354       1.00      0.56      0.71         9
         355       0.10      0.50      0.16         4
         356       1.00      1.00      1.00         4
         357       0.00      0.00      0.00         4
         358       1.00      0.25      0.40         4
         359       0.75      1.00      0.86         9
         360       0.75      0.75      0.75         4
         361       0.67      0.67      0.67         9
         362       1.00      0.75      0.86         4
         363       0.00      0.00      0.00         4
         364       1.00      0.50      0.67         4
         365       0.60      0.60      0.60         5
         366       0.50      1.00      0.67         5
         367       1.00      0.25      0.40         4
         368       0.83      1.00      0.91         5
         369       1.00      1.00      1.00         4
         370       1.00      0.20      0.33         5
         371       0.80      1.00      0.89         4
         372       0.00      0.00      0.00         4
         373       0.75      0.60      0.67         5
         374       0.75      0.75      0.75         4
         375       0.67      0.67      0.67         9
         376       1.00      1.00      1.00         5
         377       0.11      0.25      0.15         4
         378       1.00      0.25      0.40         4
         379       0.82      1.00      0.90         9
         380       0.57      1.00      0.73         4
         381       0.67      1.00      0.80         4
         382       0.67      0.50      0.57         4
         383       0.00      0.00      0.00         9
         384       0.80      1.00      0.89         4
         385       1.00      0.89      0.94         9
         386       0.90      1.00      0.95         9
         387       1.00      1.00      1.00         9
         388       1.00      1.00      1.00         4
         389       1.00      0.75      0.86         4
         390       0.00      0.00      0.00         5
         391       0.50      0.75      0.60         4
         392       0.80      1.00      0.89         4
         393       0.62      0.89      0.73         9
         394       0.00      0.00      0.00         4
         395       0.75      1.00      0.86         9
         396       0.83      1.00      0.91         5
         397       1.00      1.00      1.00         4
         398       0.55      0.67      0.60         9
         399       0.00      0.00      0.00         4
         400       0.57      1.00      0.73         4
         401       1.00      1.00      1.00         5
         402       1.00      1.00      1.00         9
         403       1.00      0.25      0.40         4
         404       0.75      0.67      0.71         9
         405       1.00      1.00      1.00         9
         406       1.00      0.50      0.67         4
         407       0.43      0.75      0.55         4
         408       0.57      0.89      0.70         9
         409       0.80      1.00      0.89         4
         410       0.89      0.89      0.89         9
         411       1.00      1.00      1.00         5
         412       0.80      1.00      0.89         4
         413       1.00      1.00      1.00         4
         414       0.00      0.00      0.00         4
         415       1.00      1.00      1.00         9
         416       0.00      0.00      0.00         9
         417       0.90      1.00      0.95         9
         418       1.00      1.00      1.00         5
         419       1.00      0.80      0.89         5
         420       0.00      0.00      0.00         4
         421       0.80      1.00      0.89         4
         422       1.00      1.00      1.00         4
         423       1.00      0.89      0.94         9
         424       1.00      0.75      0.86         4
         425       0.89      0.89      0.89         9
         426       1.00      0.78      0.88         9
         427       0.00      0.00      0.00         4
         428       0.67      0.50      0.57         4
         429       1.00      1.00      1.00         9
         430       0.60      0.75      0.67         4
         431       1.00      0.75      0.86         4
         432       0.00      0.00      0.00         9
         433       1.00      0.89      0.94         9
         434       1.00      1.00      1.00         4
         435       0.50      0.75      0.60         4
         436       0.70      0.78      0.74         9
         437       1.00      0.25      0.40         4
         438       0.00      0.00      0.00         4
         439       1.00      1.00      1.00         5
         440       1.00      0.75      0.86         4
         441       0.50      0.25      0.33         4
         442       0.50      0.40      0.44         5
         443       1.00      1.00      1.00         5
         444       1.00      1.00      1.00         9
         445       0.67      1.00      0.80         4
         446       0.80      0.80      0.80         5
         447       0.82      1.00      0.90         9
         448       0.75      1.00      0.86         9
         449       0.62      1.00      0.77         5
         450       0.50      0.50      0.50         4
         451       1.00      1.00      1.00         4
         452       1.00      0.75      0.86         4
         453       0.00      0.00      0.00         4
         454       0.08      0.22      0.12         9
         455       0.00      0.00      0.00         4
         456       0.57      1.00      0.73         4
         457       0.80      1.00      0.89         4
         458       1.00      0.75      0.86         4
         459       1.00      1.00      1.00         5
         460       1.00      0.50      0.67         4
         461       0.67      0.50      0.57         4
         462       0.86      0.67      0.75         9
         463       1.00      1.00      1.00         4
         464       0.75      0.75      0.75         4
         465       1.00      0.20      0.33         5
         466       0.00      0.00      0.00         9
         467       0.12      0.50      0.19         4
         468       1.00      1.00      1.00         4
         469       0.80      0.89      0.84         9
         470       1.00      0.50      0.67         4
         471       0.82      1.00      0.90         9
         472       1.00      0.75      0.86         4
         473       0.50      0.50      0.50         4
         474       1.00      1.00      1.00         9
         475       1.00      1.00      1.00         4
         476       1.00      1.00      1.00         4
         477       0.60      0.75      0.67         4
         478       0.25      0.25      0.25         4
         479       1.00      1.00      1.00         5
         480       1.00      0.89      0.94         9
         481       0.04      0.11      0.06         9
         482       1.00      0.50      0.67         4
         483       1.00      1.00      1.00         4
         484       1.00      1.00      1.00         4
         485       0.80      1.00      0.89         4
         486       0.67      0.50      0.57         4
         487       0.83      1.00      0.91         5
         488       0.67      0.67      0.67         9
         489       1.00      1.00      1.00         4
         490       0.00      0.00      0.00         4
         491       0.50      0.50      0.50         4
         492       0.33      0.50      0.40         4
         493       0.86      0.67      0.75         9
         494       0.75      0.75      0.75         4
         495       1.00      1.00      1.00         5
         496       1.00      1.00      1.00         9
         497       0.00      0.00      0.00         9
         498       1.00      0.20      0.33         5
         499       1.00      0.67      0.80         9
         500       0.83      0.56      0.67         9
         501       1.00      0.50      0.67         4
         502       0.00      0.00      0.00         4
         503       1.00      0.50      0.67         4
         504       0.57      0.80      0.67         5
         505       0.80      0.80      0.80         5
         506       0.00      0.00      0.00         4
         507       0.00      0.00      0.00         4
         508       0.50      0.50      0.50         4
         509       1.00      0.75      0.86         4
         510       0.83      1.00      0.91         5
         511       1.00      0.78      0.88         9
         512       1.00      0.60      0.75         5
         513       0.60      0.75      0.67         4
         514       0.20      0.25      0.22         4
         515       0.67      1.00      0.80         4
         516       0.40      0.50      0.44         4
         517       0.80      0.80      0.80         5
         518       1.00      1.00      1.00         4
         519       1.00      1.00      1.00         9
         520       0.80      0.89      0.84         9
         521       1.00      1.00      1.00         4
         522       1.00      1.00      1.00         9
         523       1.00      1.00      1.00         9
         524       0.75      0.75      0.75         4
         525       1.00      0.89      0.94         9
         526       0.00      0.00      0.00         4
         527       0.75      0.75      0.75         4
         528       0.67      1.00      0.80         4
         529       0.50      1.00      0.67         4
         530       0.60      0.60      0.60         5
         531       0.00      0.00      0.00         4
         532       0.80      1.00      0.89         4
         533       0.71      1.00      0.83         5
         534       0.08      0.25      0.12         4
         535       0.80      1.00      0.89         4
         536       0.75      0.75      0.75         4
         537       0.60      0.75      0.67         4
         538       0.50      0.40      0.44         5
         539       1.00      1.00      1.00         4
         540       1.00      0.60      0.75         5
         541       0.67      1.00      0.80         4
         542       0.80      1.00      0.89         4
         543       0.88      0.78      0.82         9
         544       0.60      0.75      0.67         4
         545       0.80      0.80      0.80         5
         546       1.00      1.00      1.00         9
         547       0.60      0.75      0.67         4
         548       1.00      1.00      1.00         5
         549       0.67      0.89      0.76         9
         550       0.75      0.75      0.75         4
         551       0.67      1.00      0.80         4
         552       1.00      0.80      0.89         5
         553       0.89      0.89      0.89         9
         554       1.00      1.00      1.00         5
         555       1.00      0.50      0.67         4
         556       0.00      0.00      0.00         4
         557       0.82      1.00      0.90         9
         558       0.00      0.00      0.00         4
         559       1.00      0.75      0.86         4
         560       1.00      0.89      0.94         9
         561       1.00      0.75      0.86         4
         562       1.00      1.00      1.00         9
         563       1.00      1.00      1.00         9
         564       1.00      0.50      0.67         4
         565       0.75      0.75      0.75         4
         566       0.80      1.00      0.89         4
         567       0.80      1.00      0.89         4
         568       0.00      0.00      0.00         4
         569       0.38      0.75      0.50         4
         570       0.00      0.00      0.00         4
         571       1.00      1.00      1.00         4
         572       0.00      0.00      0.00         4
         573       0.00      0.00      0.00         4
         574       0.89      0.89      0.89         9
         575       0.89      0.89      0.89         9
         576       0.00      0.00      0.00         4
         577       0.67      0.50      0.57         4
         578       0.80      1.00      0.89         4
         579       0.75      0.75      0.75         4
         580       1.00      0.80      0.89         5
         581       1.00      1.00      1.00         4
         582       1.00      0.89      0.94         9
         583       1.00      1.00      1.00         4
         584       0.75      0.75      0.75         4
         585       1.00      0.75      0.86         4
         586       0.75      0.75      0.75         4
         587       0.50      0.75      0.60         4
         588       0.83      1.00      0.91         5
         589       0.00      0.00      0.00         4
         590       0.00      0.00      0.00         4
         591       0.80      1.00      0.89         4
         592       0.80      1.00      0.89         4
         593       1.00      0.75      0.86         4
         594       0.00      0.00      0.00         9
         595       1.00      0.67      0.80         9
         596       1.00      0.75      0.86         4
         597       0.67      1.00      0.80         4
         598       0.89      0.89      0.89         9
         599       0.56      1.00      0.72         9
         600       0.67      1.00      0.80         4
         601       1.00      1.00      1.00         5
         602       0.67      1.00      0.80         4
         603       0.80      1.00      0.89         4
         604       1.00      0.40      0.57         5
         605       1.00      1.00      1.00         9
         606       1.00      0.75      0.86         4
         607       0.00      0.00      0.00         4
         608       0.80      1.00      0.89         4
         609       0.20      0.25      0.22         4
         610       0.80      1.00      0.89         4
         611       1.00      0.75      0.86         4
         612       0.75      0.67      0.71         9
         613       0.80      1.00      0.89         4
         614       1.00      1.00      1.00         4
         615       0.71      0.56      0.63         9
         616       0.50      0.75      0.60         4
         617       1.00      1.00      1.00         9
         618       0.80      0.89      0.84         9
         619       0.80      1.00      0.89         4
         620       0.62      1.00      0.77         5
         621       0.00      0.00      0.00         4
         622       1.00      0.50      0.67         4
         623       0.88      0.78      0.82         9
         624       0.67      0.50      0.57         4
         625       0.50      0.25      0.33         4
         626       0.67      0.44      0.53         9
         627       1.00      1.00      1.00         4
         628       0.83      1.00      0.91         5
         629       0.25      0.25      0.25         4
         630       1.00      0.60      0.75         5
         631       0.83      0.56      0.67         9
         632       1.00      1.00      1.00         4
         633       0.90      1.00      0.95         9
         634       1.00      1.00      1.00         4
         635       0.73      0.89      0.80         9
         636       1.00      1.00      1.00         4
         637       1.00      0.56      0.71         9
         638       0.80      1.00      0.89         4
         639       0.00      0.00      0.00         4
         640       1.00      0.80      0.89         5
         641       1.00      0.75      0.86         4
         642       0.83      1.00      0.91         5
         643       1.00      1.00      1.00         5
         644       0.67      0.50      0.57         4
         645       0.43      0.60      0.50         5
         646       0.62      1.00      0.77         5
         647       0.83      1.00      0.91         5
         648       0.75      1.00      0.86         9
         649       0.00      0.00      0.00         4
         650       1.00      0.75      0.86         4
         651       0.88      0.78      0.82         9
         652       0.67      0.40      0.50         5
         653       0.71      1.00      0.83         5
         654       0.75      0.67      0.71         9
         655       1.00      1.00      1.00         4
         656       0.00      0.00      0.00         4
         657       0.00      0.00      0.00         4
         658       0.75      0.33      0.46         9
         659       1.00      0.50      0.67         4
         660       1.00      0.50      0.67         4
         661       1.00      0.75      0.86         4
         662       0.00      0.00      0.00         4
         663       0.00      0.00      0.00         4
         664       0.67      0.80      0.73         5
         665       0.90      1.00      0.95         9
         666       1.00      1.00      1.00         4
         667       1.00      1.00      1.00         9
         668       0.80      1.00      0.89         4
         669       0.90      1.00      0.95         9
         670       0.60      1.00      0.75         9
         671       1.00      1.00      1.00         4
         672       0.83      1.00      0.91         5
         673       0.80      1.00      0.89         4
         674       0.50      1.00      0.67         5
         675       1.00      0.80      0.89         5
         676       0.00      0.00      0.00         4
         677       1.00      1.00      1.00         4
         678       0.00      0.00      0.00         4
         679       0.55      0.75      0.63         8
         680       1.00      0.80      0.89         5
         681       0.86      0.67      0.75         9
         682       0.70      0.78      0.74         9
         683       0.40      0.80      0.53         5
         684       1.00      1.00      1.00         9
         685       0.75      0.60      0.67         5
         686       1.00      1.00      1.00         4
         687       0.38      0.75      0.50         4
         688       0.00      0.00      0.00         4
         689       1.00      1.00      1.00         9
         690       1.00      0.75      0.86         4
         691       0.67      1.00      0.80         4
         692       1.00      1.00      1.00         9
         693       1.00      1.00      1.00         5
         694       0.00      0.00      0.00         4
         695       0.57      1.00      0.73         4
         696       0.00      0.00      0.00         4
         697       1.00      1.00      1.00         5
         698       0.00      0.00      0.00         4
         699       0.75      0.75      0.75         4
         700       1.00      0.89      0.94         9
         701       0.64      0.78      0.70         9
         702       0.75      0.75      0.75         4
         703       0.00      0.00      0.00         4
         704       0.80      1.00      0.89         4
         705       0.80      1.00      0.89         4
         706       1.00      1.00      1.00         4
         707       0.80      1.00      0.89         4
         708       0.50      0.50      0.50         4
         709       0.58      0.78      0.67         9
         710       0.60      0.75      0.67         4
         711       0.82      1.00      0.90         9
         712       1.00      1.00      1.00         5
         713       0.43      0.60      0.50         5
         714       1.00      1.00      1.00         4
         715       1.00      1.00      1.00         5
         716       0.43      0.75      0.55         4
         717       0.08      0.25      0.12         4
         718       0.88      0.78      0.82         9
         719       1.00      0.80      0.89         5
         720       0.89      0.89      0.89         9
         721       0.67      0.50      0.57         4
         722       0.44      1.00      0.62         4
         723       0.00      0.00      0.00         4
         724       0.00      0.00      0.00         4
         725       1.00      0.75      0.86         4
         726       0.38      0.75      0.50         4
         727       0.25      0.25      0.25         4
         728       0.25      0.20      0.22         5
         729       0.60      0.60      0.60         5
         730       0.60      1.00      0.75         9
         731       1.00      0.89      0.94         9
         732       1.00      0.89      0.94         9
         733       0.00      0.00      0.00         4
         734       0.83      1.00      0.91         5
         735       0.40      0.50      0.44         4
         736       0.83      1.00      0.91         5
         737       1.00      1.00      1.00         4
         738       1.00      1.00      1.00         5
         739       1.00      0.80      0.89         5
         740       0.75      0.67      0.71         9
         741       1.00      0.78      0.88         9
         742       0.80      1.00      0.89         4
         743       1.00      1.00      1.00         8
         744       1.00      1.00      1.00         4
         745       1.00      0.78      0.88         9
         746       1.00      1.00      1.00         4
         747       1.00      1.00      1.00         4
         748       1.00      0.67      0.80         9
         749       1.00      0.89      0.94         9
         750       0.83      1.00      0.91         5
         751       1.00      1.00      1.00         9
         752       1.00      0.25      0.40         4
         753       0.50      0.75      0.60         4
         754       1.00      1.00      1.00         9
         755       0.50      0.75      0.60         4
         756       0.33      0.25      0.29         4
         757       1.00      1.00      1.00         5
         758       0.80      1.00      0.89         4
         759       0.60      0.67      0.63         9
         760       0.80      1.00      0.89         4
         761       0.00      0.00      0.00         4
         762       0.00      0.00      0.00         4
         763       1.00      0.89      0.94         9
         764       0.82      1.00      0.90         9
         765       1.00      1.00      1.00         4
         766       0.00      0.00      0.00         4
         767       1.00      1.00      1.00         9
         768       0.80      0.57      0.67         7
         769       0.00      0.00      0.00         4
         770       0.00      0.00      0.00         9
         771       0.50      0.25      0.33         4
         772       0.60      0.75      0.67         4
         773       0.80      1.00      0.89         4
         774       1.00      0.40      0.57         5
         775       0.60      0.75      0.67         4
         776       0.75      0.75      0.75         4
         777       0.50      0.75      0.60         4
         778       1.00      0.80      0.89         5
         779       0.12      0.25      0.17         4
         780       1.00      1.00      1.00         9
         781       0.00      0.00      0.00         4
         782       0.00      0.00      0.00         4
         783       0.80      1.00      0.89         4
         784       0.00      0.00      0.00         4
         785       0.67      0.80      0.73         5
         786       1.00      1.00      1.00         4
         787       0.00      0.00      0.00         4
         788       1.00      0.25      0.40         4
         789       1.00      1.00      1.00         4
         790       0.00      0.00      0.00         4
         791       1.00      0.75      0.86         4
         792       0.80      1.00      0.89         4
         793       0.80      0.89      0.84         9
         794       0.57      0.44      0.50         9
         795       0.75      1.00      0.86         9
         796       0.67      1.00      0.80         4
         797       0.00      0.00      0.00         4
         798       0.75      0.33      0.46         9
         799       1.00      1.00      1.00         4
         800       1.00      1.00      1.00         4
         801       0.80      0.44      0.57         9
         802       0.00      0.00      0.00         4
         803       0.07      0.25      0.11         4
         804       0.00      0.00      0.00         9
         805       1.00      1.00      1.00         5
         806       0.75      0.75      0.75         4
         807       0.08      0.25      0.12         4
         808       0.00      0.00      0.00         4
         809       0.86      0.67      0.75         9
         810       1.00      0.89      0.94         9
         811       0.12      0.75      0.20         4
         812       1.00      1.00      1.00         4
         813       0.80      1.00      0.89         4
         814       0.67      1.00      0.80         4
         815       1.00      1.00      1.00         9
         816       1.00      0.89      0.94         9
         817       0.64      0.78      0.70         9
         818       1.00      1.00      1.00         5
         819       0.90      1.00      0.95         9
         820       0.60      0.75      0.67         4
         821       0.00      0.00      0.00         4
         822       0.80      0.89      0.84         9
         823       0.50      0.60      0.55         5
         824       0.75      0.60      0.67         5
         825       1.00      0.40      0.57         5
         826       1.00      1.00      1.00         4
         827       0.00      0.00      0.00         4
         828       0.80      1.00      0.89         4
         829       0.62      1.00      0.77         5
         830       1.00      0.75      0.86         4
         831       0.89      0.89      0.89         9
         832       1.00      0.75      0.86         4
         833       0.75      1.00      0.86         9
         834       1.00      1.00      1.00         4
         835       0.40      0.50      0.44         4
         836       1.00      0.50      0.67         4
         837       0.00      0.00      0.00         9
         838       0.88      0.78      0.82         9
         839       0.44      1.00      0.62         4
         840       0.80      1.00      0.89         4
         841       0.73      0.89      0.80         9
         842       1.00      1.00      1.00         4
         843       0.73      0.89      0.80         9
         844       1.00      1.00      1.00         4
         845       1.00      0.20      0.33         5
         846       0.00      0.00      0.00         4
         847       1.00      1.00      1.00         4
         848       0.89      0.89      0.89         9
         849       0.83      1.00      0.91         5
         850       1.00      0.75      0.86         4
         851       0.00      0.00      0.00         4
         852       0.75      0.75      0.75         4
         853       0.50      0.50      0.50         4
         854       1.00      0.75      0.86         4
         855       1.00      1.00      1.00         4
         856       0.50      0.25      0.33         4
         857       1.00      1.00      1.00         5
         858       1.00      1.00      1.00         4
         859       0.50      0.75      0.60         4
         860       0.78      0.78      0.78         9
         861       0.75      0.67      0.71         9
         862       0.00      0.00      0.00         4
         863       1.00      0.80      0.89         5
         864       0.89      0.89      0.89         9
         865       0.89      0.89      0.89         9
         866       0.45      1.00      0.62         5
         867       0.00      0.00      0.00         4
         868       1.00      0.56      0.71         9
         869       1.00      1.00      1.00         9
         870       1.00      1.00      1.00         4
         871       0.89      0.89      0.89         9
         872       1.00      0.89      0.94         9
         873       1.00      1.00      1.00         5
         874       0.00      0.00      0.00         4
         875       0.89      0.89      0.89         9
         876       1.00      0.89      0.94         9
         877       1.00      0.75      0.86         4
         878       1.00      0.80      0.89         5
         879       0.67      0.50      0.57         4
         880       0.00      0.00      0.00         4
         881       1.00      1.00      1.00         9
         882       1.00      0.75      0.86         4
         883       0.33      0.25      0.29         4
         884       1.00      1.00      1.00         9
         885       0.56      0.56      0.56         9
         886       0.75      0.75      0.75         4
         887       0.67      1.00      0.80         4
         888       0.88      0.78      0.82         9
         889       0.67      1.00      0.80         4
         890       1.00      0.75      0.86         4
         891       1.00      1.00      1.00         4
         892       0.80      1.00      0.89         4
         893       1.00      0.80      0.89         5

    accuracy                           0.71      4917
   macro avg       0.70      0.69      0.68      4917
weighted avg       0.73      0.71      0.70      4917

task_train_time: {0: 0.11313735299999905, 1: 0.029649121000000278, 2: 0.023800522000000157, 3: 0.02566692399999937, 4: 0.03329428700000037, 5: 0.03402984599999925, 6: 0.026888538999999767, 7: 0.027275282999999817, 8: 0.026685774000000606, 9: 0.033860409999999064, 10: 0.03637997399999904, 11: 0.0334131890000009, 12: 0.03458638299999883, 13: 0.034591082000000384, 14: 0.03256440599999877, 15: 0.038214517000000114, 16: 0.028886459999998948, 17: 0.028009155999999535, 18: 0.03543981900000048, 19: 0.03713755999999968, 20: 0.038298165000000495, 21: 0.02987985799999926, 22: 0.032229580999999285, 23: 0.031413491999998655, 24: 0.036825301000000366, 25: 0.03344238600000082, 26: 0.030881001000000907, 27: 0.03466872600000137, 28: 0.034296946999999633, 29: 0.033916785000000615, 30: 0.03711488999999979, 31: 0.032167724000000675, 32: 0.03418803399999959, 33: 0.03591090699999988, 34: 0.030610919999999098, 35: 0.034430925000000556, 36: 0.04021437399999961, 37: 0.0347551810000013, 38: 0.028053220000000323, 39: 0.03581765900000278, 40: 0.03595104000000049, 41: 0.03275278300000295, 42: 0.03230507299999985, 43: 0.02895308699999788}
prediction_time: 0.0003641130000033854
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
