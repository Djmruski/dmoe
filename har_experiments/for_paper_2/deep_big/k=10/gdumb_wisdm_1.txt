Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='f383218d-5815-4b2c-add1-4e2e142be7ce', conf_timestamp='2023-08-13 15:32:12.623968', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 75.82 % 	 [Task-IL]: 46.15 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 43.81 % 	 [Task-IL]: 35.68 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 47.03 % 	 [Task-IL]: 30.97 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 27.98 % 	 [Task-IL]: 27.15 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 27.08 % 	 [Task-IL]: 27.85 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 25.93 % 	 [Task-IL]: 27.96 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.17 % 	 [Task-IL]: 27.41 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 23.27 % 	 [Task-IL]: 28.08 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 13.94 % 	 [Task-IL]: 29.15 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 16.43 % 	 [Task-IL]: 28.67 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.03 % 	 [Task-IL]: 27.66 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 15.24 % 	 [Task-IL]: 28.53 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 11.94 % 	 [Task-IL]: 28.83 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 11.86 % 	 [Task-IL]: 27.83 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.56 % 	 [Task-IL]: 28.43 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.38 % 	 [Task-IL]: 28.27 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.06 % 	 [Task-IL]: 27.89 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 11.16 % 	 [Task-IL]: 27.43 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.47 % 	 [Task-IL]: 26.51 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.96 % 	 [Task-IL]: 25.96 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.51 % 	 [Task-IL]: 25.64 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.3 % 	 [Task-IL]: 25.51 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.6 % 	 [Task-IL]: 26.02 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 6.57 % 	 [Task-IL]: 26.0 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.37 % 	 [Task-IL]: 25.99 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.42 % 	 [Task-IL]: 26.01 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.51 % 	 [Task-IL]: 26.4 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 8.47 % 	 [Task-IL]: 25.91 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.44 % 	 [Task-IL]: 25.66 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.43 % 	 [Task-IL]: 25.74 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.24 % 	 [Task-IL]: 25.35 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.18 % 	 [Task-IL]: 25.43 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 7.19 % 	 [Task-IL]: 24.97 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.93 % 	 [Task-IL]: 24.77 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.32 % 	 [Task-IL]: 24.97 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 4.75 % 	 [Task-IL]: 24.55 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.51 % 	 [Task-IL]: 25.17 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.95 % 	 [Task-IL]: 25.13 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.22 % 	 [Task-IL]: 25.27 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.89 % 	 [Task-IL]: 24.69 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.62 % 	 [Task-IL]: 24.99 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.57 % 	 [Task-IL]: 25.0 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.33 % 	 [Task-IL]: 24.96 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({256: 26, 282: 24, 885: 23, 17: 23, 732: 23, 873: 23, 244: 23, 266: 23, 294: 23, 448: 23, 630: 22, 564: 22, 862: 22, 96: 22, 147: 22, 239: 22, 414: 22, 25: 21, 581: 21, 689: 21, 685: 21, 64: 21, 786: 21, 145: 21, 176: 21, 207: 21, 301: 21, 363: 21, 391: 21, 376: 21, 406: 21, 8: 20, 29: 20, 641: 20, 829: 20, 739: 20, 817: 20, 852: 20, 788: 20, 53: 20, 535: 20, 552: 20, 110: 20, 126: 20, 232: 20, 288: 20, 296: 20, 337: 20, 386: 20, 388: 20, 457: 20, 489: 20, 474: 20, 528: 20, 515: 20, 633: 19, 816: 19, 682: 19, 773: 19, 834: 19, 609: 19, 607: 19, 86: 19, 669: 19, 203: 19, 221: 19, 225: 19, 248: 19, 237: 19, 269: 19, 293: 19, 275: 19, 313: 19, 308: 19, 390: 19, 430: 19, 432: 19, 455: 19, 454: 19, 475: 19, 531: 19, 615: 18, 877: 18, 680: 18, 663: 18, 734: 18, 867: 18, 863: 18, 631: 18, 676: 18, 83: 18, 80: 18, 718: 18, 653: 18, 135: 18, 143: 18, 168: 18, 155: 18, 553: 18, 230: 18, 247: 18, 235: 18, 299: 18, 304: 18, 328: 18, 331: 18, 407: 18, 439: 18, 506: 18, 532: 18, 20: 17, 13: 17, 585: 17, 707: 17, 736: 17, 620: 17, 858: 17, 720: 17, 774: 17, 747: 17, 656: 17, 713: 17, 36: 17, 874: 17, 82: 17, 109: 17, 114: 17, 805: 17, 159: 17, 195: 17, 254: 17, 289: 17, 309: 17, 322: 17, 357: 17, 446: 17, 442: 17, 451: 17, 779: 16, 0: 16, 832: 16, 836: 16, 741: 16, 833: 16, 588: 16, 854: 16, 537: 16, 693: 16, 48: 16, 844: 16, 589: 16, 674: 16, 695: 16, 69: 16, 725: 16, 85: 16, 81: 16, 152: 16, 151: 16, 158: 16, 178: 16, 220: 16, 222: 16, 290: 16, 361: 16, 382: 16, 392: 16, 421: 16, 431: 16, 482: 16, 493: 16, 522: 16, 28: 15, 565: 15, 710: 15, 760: 15, 756: 15, 37: 15, 784: 15, 688: 15, 772: 15, 691: 15, 123: 15, 840: 15, 174: 15, 262: 15, 270: 15, 267: 15, 401: 15, 412: 15, 423: 15, 420: 15, 460: 15, 503: 15, 514: 15, 864: 14, 882: 14, 876: 14, 662: 14, 868: 14, 781: 14, 660: 14, 887: 14, 606: 14, 598: 14, 722: 14, 63: 14, 745: 14, 200: 14, 199: 14, 280: 14, 303: 14, 295: 14, 329: 14, 370: 14, 490: 14, 841: 13, 686: 13, 549: 13, 559: 13, 72: 13, 568: 13, 650: 13, 91: 13, 661: 13, 191: 13, 307: 13, 546: 13, 516: 13, 4: 12, 5: 12, 803: 12, 770: 12, 847: 12, 658: 12, 41: 12, 45: 12, 61: 12, 60: 12, 90: 12, 705: 12, 738: 12, 97: 12, 104: 12, 755: 12, 205: 12, 217: 12, 238: 12, 408: 12, 403: 12, 465: 12, 500: 12, 610: 11, 10: 11, 600: 11, 30: 11, 825: 11, 634: 11, 746: 11, 62: 11, 93: 11, 821: 11, 88: 11, 687: 11, 795: 11, 765: 11, 776: 11, 157: 11, 161: 11, 286: 11, 297: 11, 321: 11, 422: 11, 471: 11, 478: 11, 481: 11, 495: 11, 2: 10, 681: 10, 545: 10, 715: 10, 576: 10, 814: 10, 754: 10, 861: 10, 843: 10, 872: 10, 664: 10, 752: 10, 699: 10, 811: 10, 789: 10, 43: 10, 571: 10, 70: 10, 68: 10, 880: 10, 597: 10, 726: 10, 668: 10, 724: 10, 78: 10, 573: 10, 578: 10, 100: 10, 113: 10, 102: 10, 116: 10, 136: 10, 188: 10, 210: 10, 196: 10, 236: 10, 257: 10, 274: 10, 284: 10, 305: 10, 300: 10, 310: 10, 324: 10, 333: 10, 389: 10, 381: 10, 428: 10, 453: 10, 450: 10, 468: 10, 467: 10, 486: 10, 487: 10, 484: 10, 504: 10, 494: 10, 33: 9, 31: 9, 3: 9, 665: 9, 558: 9, 18: 9, 644: 9, 642: 9, 855: 9, 683: 9, 809: 9, 884: 9, 818: 9, 775: 9, 801: 9, 879: 9, 869: 9, 604: 9, 623: 9, 52: 9, 46: 9, 797: 9, 591: 9, 806: 9, 800: 9, 839: 9, 706: 9, 54: 9, 696: 9, 837: 9, 787: 9, 74: 9, 810: 9, 101: 9, 98: 9, 728: 9, 118: 9, 115: 9, 130: 9, 125: 9, 848: 9, 670: 9, 567: 9, 148: 9, 138: 9, 796: 9, 652: 9, 162: 9, 169: 9, 177: 9, 185: 9, 181: 9, 175: 9, 193: 9, 213: 9, 206: 9, 219: 9, 242: 9, 234: 9, 243: 9, 255: 9, 271: 9, 261: 9, 276: 9, 314: 9, 316: 9, 569: 9, 349: 9, 348: 9, 367: 9, 359: 9, 385: 9, 417: 9, 429: 9, 426: 9, 427: 9, 449: 9, 550: 9, 456: 9, 479: 9, 492: 9, 477: 9, 480: 9, 539: 9, 497: 9, 502: 9, 518: 9, 517: 9, 21: 8, 24: 8, 717: 8, 777: 8, 783: 8, 574: 8, 845: 8, 657: 8, 719: 8, 679: 8, 611: 8, 778: 8, 835: 8, 602: 8, 763: 8, 750: 8, 622: 8, 554: 8, 767: 8, 793: 8, 813: 8, 830: 8, 819: 8, 627: 8, 38: 8, 678: 8, 39: 8, 47: 8, 826: 8, 570: 8, 596: 8, 40: 8, 859: 8, 659: 8, 577: 8, 711: 8, 556: 8, 66: 8, 58: 8, 57: 8, 73: 8, 782: 8, 807: 8, 856: 8, 866: 8, 632: 8, 831: 8, 87: 8, 79: 8, 881: 8, 92: 8, 846: 8, 628: 8, 865: 8, 105: 8, 108: 8, 103: 8, 107: 8, 842: 8, 740: 8, 648: 8, 635: 8, 572: 8, 119: 8, 624: 8, 690: 8, 134: 8, 640: 8, 139: 8, 149: 8, 614: 8, 172: 8, 170: 8, 190: 8, 209: 8, 204: 8, 215: 8, 233: 8, 231: 8, 250: 8, 253: 8, 258: 8, 259: 8, 263: 8, 268: 8, 878: 8, 281: 8, 285: 8, 278: 8, 323: 8, 330: 8, 332: 8, 346: 8, 335: 8, 338: 8, 343: 8, 341: 8, 352: 8, 366: 8, 368: 8, 364: 8, 380: 8, 379: 8, 387: 8, 395: 8, 396: 8, 397: 8, 394: 8, 399: 8, 411: 8, 398: 8, 541: 8, 424: 8, 418: 8, 444: 8, 434: 8, 472: 8, 464: 8, 458: 8, 512: 8, 501: 8, 499: 8, 513: 8, 529: 8, 533: 8, 520: 8, 530: 8, 586: 7, 1: 7, 23: 7, 575: 7, 785: 7, 547: 7, 619: 7, 737: 7, 824: 7, 625: 7, 637: 7, 636: 7, 673: 7, 639: 7, 671: 7, 764: 7, 651: 7, 44: 7, 34: 7, 850: 7, 50: 7, 42: 7, 792: 7, 672: 7, 766: 7, 828: 7, 71: 7, 851: 7, 743: 7, 698: 7, 626: 7, 730: 7, 889: 7, 76: 7, 75: 7, 812: 7, 870: 7, 89: 7, 587: 7, 112: 7, 601: 7, 106: 7, 768: 7, 802: 7, 95: 7, 111: 7, 716: 7, 621: 7, 655: 7, 133: 7, 127: 7, 560: 7, 122: 7, 117: 7, 753: 7, 749: 7, 146: 7, 142: 7, 144: 7, 820: 7, 697: 7, 582: 7, 164: 7, 163: 7, 166: 7, 167: 7, 156: 7, 723: 7, 654: 7, 183: 7, 179: 7, 189: 7, 182: 7, 613: 7, 208: 7, 212: 7, 838: 7, 727: 7, 580: 7, 227: 7, 224: 7, 249: 7, 892: 7, 272: 7, 283: 7, 292: 7, 311: 7, 298: 7, 666: 7, 771: 7, 318: 7, 320: 7, 315: 7, 327: 7, 351: 7, 334: 7, 345: 7, 369: 7, 358: 7, 365: 7, 360: 7, 354: 7, 548: 7, 375: 7, 404: 7, 400: 7, 409: 7, 415: 7, 425: 7, 435: 7, 441: 7, 445: 7, 469: 7, 476: 7, 485: 7, 483: 7, 507: 7, 511: 7, 510: 7, 521: 7, 519: 7, 527: 7, 523: 7, 526: 7, 543: 7, 12: 6, 14: 6, 6: 6, 16: 6, 593: 6, 27: 6, 32: 6, 22: 6, 9: 6, 798: 6, 645: 6, 692: 6, 594: 6, 853: 6, 849: 6, 617: 6, 823: 6, 790: 6, 758: 6, 700: 6, 886: 6, 762: 6, 827: 6, 759: 6, 735: 6, 751: 6, 583: 6, 566: 6, 709: 6, 794: 6, 67: 6, 65: 6, 857: 6, 815: 6, 557: 6, 729: 6, 712: 6, 599: 6, 748: 6, 562: 6, 875: 6, 84: 6, 605: 6, 592: 6, 714: 6, 871: 6, 584: 6, 94: 6, 99: 6, 761: 6, 677: 6, 791: 6, 121: 6, 131: 6, 128: 6, 708: 6, 804: 6, 140: 6, 137: 6, 150: 6, 893: 6, 551: 6, 731: 6, 160: 6, 702: 6, 638: 6, 187: 6, 202: 6, 595: 6, 612: 6, 226: 6, 733: 6, 216: 6, 214: 6, 260: 6, 273: 6, 265: 6, 291: 6, 563: 6, 579: 6, 312: 6, 306: 6, 319: 6, 317: 6, 344: 6, 336: 6, 353: 6, 347: 6, 372: 6, 393: 6, 378: 6, 413: 6, 410: 6, 402: 6, 542: 6, 405: 6, 419: 6, 416: 6, 438: 6, 436: 6, 447: 6, 437: 6, 462: 6, 461: 6, 470: 6, 459: 6, 491: 6, 488: 6, 508: 6, 505: 6, 498: 6, 524: 6, 536: 6, 540: 6, 538: 6, 26: 5, 15: 5, 704: 5, 684: 5, 19: 5, 11: 5, 646: 5, 890: 5, 51: 5, 561: 5, 56: 5, 647: 5, 120: 5, 129: 5, 124: 5, 141: 5, 165: 5, 643: 5, 154: 5, 822: 5, 192: 5, 186: 5, 184: 5, 198: 5, 201: 5, 229: 5, 246: 5, 241: 5, 251: 5, 240: 5, 888: 5, 264: 5, 287: 5, 279: 5, 277: 5, 326: 5, 339: 5, 350: 5, 362: 5, 373: 5, 374: 5, 377: 5, 433: 5, 443: 5, 452: 5, 466: 5, 463: 5, 496: 5, 509: 5, 525: 5, 7: 4, 649: 4, 721: 4, 703: 4, 49: 4, 544: 4, 35: 4, 59: 4, 769: 4, 590: 4, 77: 4, 616: 4, 603: 4, 675: 4, 618: 4, 667: 4, 153: 4, 180: 4, 694: 4, 194: 4, 744: 4, 197: 4, 218: 4, 883: 4, 757: 4, 799: 4, 252: 4, 245: 4, 701: 4, 302: 4, 325: 4, 340: 4, 371: 4, 356: 4, 384: 4, 383: 4, 440: 4, 473: 4, 534: 4, 555: 3, 629: 3, 55: 3, 132: 3, 173: 3, 171: 3, 891: 3, 780: 3, 742: 3, 860: 3, 342: 3, 355: 3, 808: 2, 608: 2, 223: 2, 211: 1, 228: 1})
Total buffer: 8940
fit_time: 81.095403799

Accuracy for 44 task(s): 	 [Class-IL]: 70.48 % 	 [Task-IL]: 29.62 %

CLASS_IL_ACC: 
	[76.37362637362637, 61.165048543689316, 79.24528301886792, 74.16666666666667, 70.47619047619048, 55.10204081632652, 57.89473684210527, 72.22222222222221, 74.75728155339806, 58.92857142857143, 66.3716814159292, 70.58823529411765, 70.24793388429752, 74.57627118644068, 80.88235294117648, 66.33663366336634, 61.79775280898876, 68.62745098039215, 81.89655172413794, 68.51851851851852, 79.83193277310924, 75.0, 73.14814814814815, 69.2982456140351, 70.40816326530613, 72.88135593220339, 71.96261682242991, 68.26923076923077, 79.20792079207921, 71.28712871287128, 86.11111111111111, 60.416666666666664, 75.21367521367522, 74.61538461538461, 63.8095238095238, 69.0909090909091, 69.23076923076923, 73.39449541284404, 71.05263157894737, 70.83333333333334, 69.44444444444444, 71.7948717948718, 73.01587301587301, 51.78571428571429]
TASK_IL_ACC: 
	[52.197802197802204, 33.980582524271846, 21.69811320754717, 18.333333333333332, 28.57142857142857, 30.612244897959183, 20.175438596491226, 34.25925925925926, 38.83495145631068, 27.67857142857143, 23.008849557522122, 36.97478991596639, 27.27272727272727, 23.728813559322035, 33.088235294117645, 23.762376237623762, 31.46067415730337, 27.450980392156865, 23.275862068965516, 18.51851851851852, 23.52941176470588, 25.925925925925924, 40.74074074074074, 30.701754385964914, 25.510204081632654, 31.35593220338983, 28.971962616822427, 26.923076923076923, 21.782178217821784, 27.722772277227726, 27.77777777777778, 21.875, 27.350427350427353, 26.153846153846157, 27.61904761904762, 28.18181818181818, 32.47863247863248, 32.11009174311927, 28.947368421052634, 25.0, 26.851851851851855, 29.914529914529915, 26.190476190476193, 84.82142857142857]
f1_micro: 70.77486272117144
f1_macro: 67.6262830468187
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         9
           1       0.00      0.00      0.00         4
           2       1.00      0.75      0.86         4
           3       0.67      0.50      0.57         4
           4       0.50      1.00      0.67         4
           5       0.56      1.00      0.71         5
           6       0.00      0.00      0.00         4
           7       1.00      1.00      1.00         4
           8       1.00      0.89      0.94         9
           9       0.00      0.00      0.00         4
          10       0.83      1.00      0.91         5
          11       1.00      1.00      1.00         4
          12       1.00      0.75      0.86         4
          13       0.80      0.89      0.84         9
          14       0.00      0.00      0.00         4
          15       0.80      1.00      0.89         4
          16       0.80      1.00      0.89         4
          17       1.00      0.89      0.94         9
          18       0.33      0.25      0.29         4
          19       1.00      0.50      0.67         4
          20       0.57      0.89      0.70         9
          21       1.00      1.00      1.00         4
          22       0.60      0.75      0.67         4
          23       1.00      1.00      1.00         4
          24       0.60      0.75      0.67         4
          25       1.00      1.00      1.00         9
          26       0.50      0.25      0.33         4
          27       1.00      1.00      1.00         4
          28       0.86      0.67      0.75         9
          29       1.00      1.00      1.00         9
          30       0.89      1.00      0.94         8
          31       0.00      0.00      0.00         4
          32       0.67      0.50      0.57         4
          33       1.00      1.00      1.00         4
          34       1.00      0.75      0.86         4
          35       0.60      0.75      0.67         4
          36       0.73      0.89      0.80         9
          37       0.36      0.44      0.40         9
          38       0.50      0.40      0.44         5
          39       0.60      0.75      0.67         4
          40       1.00      1.00      1.00         4
          41       1.00      1.00      1.00         5
          42       0.00      0.00      0.00         4
          43       0.57      1.00      0.73         4
          44       1.00      0.75      0.86         4
          45       1.00      1.00      1.00         5
          46       0.00      0.00      0.00         4
          47       0.75      0.75      0.75         4
          48       1.00      0.67      0.80         9
          49       0.80      1.00      0.89         4
          50       0.00      0.00      0.00         4
          51       0.50      0.50      0.50         4
          52       0.00      0.00      0.00         4
          53       0.80      0.44      0.57         9
          54       0.40      0.50      0.44         4
          55       1.00      0.75      0.86         4
          56       0.33      0.25      0.29         4
          57       0.40      0.40      0.40         5
          58       0.67      0.50      0.57         4
          59       1.00      0.75      0.86         4
          60       1.00      1.00      1.00         4
          61       1.00      1.00      1.00         5
          62       1.00      1.00      1.00         5
          63       0.80      0.89      0.84         9
          64       1.00      1.00      1.00         9
          65       0.75      0.75      0.75         4
          66       1.00      1.00      1.00         5
          67       0.00      0.00      0.00         4
          68       0.45      1.00      0.62         5
          69       0.89      0.89      0.89         9
          70       0.83      1.00      0.91         5
          71       1.00      0.75      0.86         4
          72       0.88      0.78      0.82         9
          73       0.80      1.00      0.89         4
          74       0.00      0.00      0.00         4
          75       0.50      1.00      0.67         4
          76       0.33      0.25      0.29         4
          77       1.00      0.25      0.40         4
          78       1.00      1.00      1.00         4
          79       1.00      1.00      1.00         5
          80       0.62      0.89      0.73         9
          81       0.60      1.00      0.75         9
          82       0.90      1.00      0.95         9
          83       0.75      0.67      0.71         9
          84       0.80      1.00      0.89         4
          85       0.80      0.89      0.84         9
          86       1.00      0.89      0.94         9
          87       0.00      0.00      0.00         4
          88       0.80      1.00      0.89         4
          89       0.25      0.20      0.22         5
          90       0.67      0.44      0.53         9
          91       1.00      0.80      0.89         5
          92       1.00      0.80      0.89         5
          93       0.83      1.00      0.91         5
          94       1.00      1.00      1.00         4
          95       0.75      0.75      0.75         4
          96       0.57      0.44      0.50         9
          97       1.00      1.00      1.00         5
          98       0.80      0.80      0.80         5
          99       1.00      1.00      1.00         4
         100       1.00      1.00      1.00         4
         101       0.00      0.00      0.00         4
         102       0.50      0.40      0.44         5
         103       0.60      0.60      0.60         5
         104       0.78      0.78      0.78         9
         105       0.80      1.00      0.89         4
         106       0.80      0.80      0.80         5
         107       0.00      0.00      0.00         4
         108       1.00      1.00      1.00         4
         109       0.70      0.78      0.74         9
         110       1.00      0.89      0.94         9
         111       1.00      1.00      1.00         4
         112       0.00      0.00      0.00         4
         113       0.12      0.75      0.20         4
         114       0.00      0.00      0.00         9
         115       0.67      0.80      0.73         5
         116       0.67      0.50      0.57         4
         117       0.38      0.75      0.50         4
         118       0.80      1.00      0.89         4
         119       0.67      0.80      0.73         5
         120       0.67      0.50      0.57         4
         121       0.00      0.00      0.00         4
         122       1.00      0.60      0.75         5
         123       1.00      1.00      1.00         9
         124       0.25      0.25      0.25         4
         125       1.00      1.00      1.00         4
         126       0.00      0.00      0.00         9
         127       1.00      1.00      1.00         4
         128       0.80      1.00      0.89         4
         129       0.75      0.75      0.75         4
         130       0.75      0.75      0.75         4
         131       0.00      0.00      0.00         4
         132       0.00      0.00      0.00         4
         133       1.00      1.00      1.00         4
         134       0.67      0.50      0.57         4
         135       0.00      0.00      0.00         9
         136       0.83      1.00      0.91         5
         137       1.00      0.60      0.75         5
         138       0.80      1.00      0.89         4
         139       0.75      0.75      0.75         4
         140       0.00      0.00      0.00         4
         141       0.00      0.00      0.00         4
         142       0.67      0.80      0.73         5
         143       0.00      0.00      0.00         9
         144       0.00      0.00      0.00         4
         145       1.00      0.89      0.94         9
         146       0.67      1.00      0.80         4
         147       0.83      0.56      0.67         9
         148       1.00      0.50      0.67         4
         149       0.50      0.20      0.29         5
         150       1.00      1.00      1.00         4
         151       0.82      1.00      0.90         9
         152       0.90      1.00      0.95         9
         153       1.00      0.75      0.86         4
         154       0.00      0.00      0.00         4
         155       0.88      0.78      0.82         9
         156       0.75      0.75      0.75         4
         157       1.00      1.00      1.00         5
         158       0.86      0.67      0.75         9
         159       1.00      1.00      1.00         9
         160       1.00      1.00      1.00         4
         161       1.00      1.00      1.00         9
         162       0.75      0.75      0.75         4
         163       1.00      0.75      0.86         4
         164       0.00      0.00      0.00         4
         165       0.00      0.00      0.00         4
         166       1.00      0.40      0.57         5
         167       0.80      1.00      0.89         4
         168       0.67      0.67      0.67         9
         169       0.83      1.00      0.91         5
         170       0.00      0.00      0.00         4
         171       1.00      1.00      1.00         4
         172       0.67      1.00      0.80         4
         173       1.00      1.00      1.00         4
         174       1.00      1.00      1.00         9
         175       0.80      1.00      0.89         4
         176       0.64      1.00      0.78         9
         177       1.00      1.00      1.00         4
         178       0.90      1.00      0.95         9
         179       0.60      0.60      0.60         5
         180       0.67      0.50      0.57         4
         181       0.83      1.00      0.91         5
         182       1.00      1.00      1.00         4
         183       1.00      0.75      0.86         4
         184       0.00      0.00      0.00         4
         185       1.00      0.80      0.89         5
         186       0.20      0.25      0.22         4
         187       0.80      1.00      0.89         4
         188       0.50      0.50      0.50         4
         189       0.75      0.75      0.75         4
         190       0.00      0.00      0.00         4
         191       0.89      0.89      0.89         9
         192       0.00      0.00      0.00         4
         193       1.00      0.75      0.86         4
         194       1.00      0.75      0.86         4
         195       0.57      0.44      0.50         9
         196       0.60      0.75      0.67         4
         197       0.75      0.75      0.75         4
         198       0.00      0.00      0.00         4
         199       0.00      0.00      0.00         9
         200       0.80      0.89      0.84         9
         201       1.00      0.75      0.86         4
         202       1.00      1.00      1.00         4
         203       1.00      0.89      0.94         9
         204       0.50      0.50      0.50         4
         205       0.67      0.44      0.53         9
         206       0.71      1.00      0.83         5
         207       1.00      1.00      1.00         9
         208       0.09      0.25      0.13         4
         209       0.50      0.75      0.60         4
         210       0.80      0.80      0.80         5
         211       1.00      0.25      0.40         4
         212       0.00      0.00      0.00         4
         213       0.14      0.25      0.18         4
         214       1.00      1.00      1.00         5
         215       1.00      0.50      0.67         4
         216       0.00      0.00      0.00         4
         217       1.00      1.00      1.00         5
         218       1.00      0.75      0.86         4
         219       0.00      0.00      0.00         4
         220       0.88      0.78      0.82         9
         221       0.82      1.00      0.90         9
         222       0.75      1.00      0.86         9
         223       0.80      1.00      0.89         4
         224       1.00      1.00      1.00         4
         225       1.00      0.67      0.80         9
         226       1.00      1.00      1.00         5
         227       1.00      1.00      1.00         4
         228       0.00      0.00      0.00         4
         229       0.00      0.00      0.00         4
         230       0.80      0.89      0.84         9
         231       0.50      1.00      0.67         4
         232       0.00      0.00      0.00         9
         233       0.00      0.00      0.00         4
         234       0.71      1.00      0.83         5
         235       1.00      0.89      0.94         9
         236       0.83      1.00      0.91         5
         237       0.38      0.56      0.45         9
         238       1.00      1.00      1.00         8
         239       0.50      0.33      0.40         9
         240       1.00      0.50      0.67         4
         241       1.00      1.00      1.00         4
         242       0.80      0.80      0.80         5
         243       0.50      0.75      0.60         4
         244       1.00      0.67      0.80         9
         245       0.50      0.25      0.33         4
         246       0.80      0.80      0.80         5
         247       0.82      1.00      0.90         9
         248       1.00      1.00      1.00         9
         249       0.50      0.25      0.33         4
         250       0.60      0.60      0.60         5
         251       0.00      0.00      0.00         4
         252       0.00      0.00      0.00         4
         253       1.00      1.00      1.00         4
         254       0.89      0.89      0.89         9
         255       0.67      0.80      0.73         5
         256       1.00      0.89      0.94         9
         257       0.60      0.60      0.60         5
         258       1.00      1.00      1.00         4
         259       1.00      1.00      1.00         4
         260       0.80      1.00      0.89         4
         261       0.60      0.75      0.67         4
         262       0.56      0.56      0.56         9
         263       1.00      0.50      0.67         4
         264       0.00      0.00      0.00         5
         265       0.00      0.00      0.00         4
         266       0.00      0.00      0.00         9
         267       0.60      0.67      0.63         9
         268       1.00      1.00      1.00         5
         269       1.00      1.00      1.00         9
         270       1.00      1.00      1.00         9
         271       0.80      0.80      0.80         5
         272       1.00      1.00      1.00         4
         273       0.75      0.60      0.67         5
         274       1.00      1.00      1.00         4
         275       0.33      0.22      0.27         9
         276       0.43      0.75      0.55         4
         277       1.00      0.75      0.86         4
         278       1.00      1.00      1.00         4
         279       1.00      1.00      1.00         4
         280       1.00      0.89      0.94         9
         281       1.00      0.80      0.89         5
         282       0.90      1.00      0.95         9
         283       1.00      1.00      1.00         5
         284       0.20      0.20      0.20         5
         285       1.00      1.00      1.00         4
         286       0.67      0.50      0.57         4
         287       0.00      0.00      0.00         4
         288       0.88      0.78      0.82         9
         289       1.00      1.00      1.00         9
         290       1.00      0.67      0.80         9
         291       0.60      0.75      0.67         4
         292       1.00      0.50      0.67         4
         293       1.00      0.89      0.94         9
         294       0.75      0.67      0.71         9
         295       0.75      1.00      0.86         9
         296       0.90      1.00      0.95         9
         297       1.00      0.80      0.89         5
         298       0.33      0.50      0.40         4
         299       0.80      0.89      0.84         9
         300       0.22      0.50      0.31         4
         301       1.00      0.67      0.80         9
         302       1.00      1.00      1.00         4
         303       1.00      1.00      1.00         9
         304       0.90      1.00      0.95         9
         305       0.80      1.00      0.89         4
         306       1.00      1.00      1.00         4
         307       1.00      0.56      0.71         9
         308       0.89      0.89      0.89         9
         309       0.73      0.89      0.80         9
         310       0.67      0.50      0.57         4
         311       0.00      0.00      0.00         4
         312       0.60      0.75      0.67         4
         313       0.89      0.89      0.89         9
         314       0.75      0.60      0.67         5
         315       1.00      1.00      1.00         5
         316       1.00      1.00      1.00         5
         317       0.50      0.25      0.33         4
         318       0.00      0.00      0.00         4
         319       0.75      0.75      0.75         4
         320       0.60      0.75      0.67         4
         321       0.00      0.00      0.00         4
         322       0.88      0.78      0.82         9
         323       1.00      1.00      1.00         4
         324       0.00      0.00      0.00         4
         325       0.75      0.75      0.75         4
         326       0.00      0.00      0.00         4
         327       0.00      0.00      0.00         4
         328       1.00      0.89      0.94         9
         329       0.50      0.80      0.62         5
         330       1.00      1.00      1.00         5
         331       1.00      0.89      0.94         9
         332       0.75      0.75      0.75         4
         333       0.83      1.00      0.91         5
         334       0.50      1.00      0.67         4
         335       1.00      1.00      1.00         4
         336       1.00      1.00      1.00         4
         337       0.89      0.89      0.89         9
         338       0.25      0.25      0.25         4
         339       0.67      0.80      0.73         5
         340       0.00      0.00      0.00         4
         341       1.00      0.40      0.57         5
         342       1.00      0.25      0.40         4
         343       1.00      0.75      0.86         4
         344       0.00      0.00      0.00         4
         345       0.83      1.00      0.91         5
         346       0.80      1.00      0.89         4
         347       0.00      0.00      0.00         4
         348       0.67      1.00      0.80         4
         349       0.75      0.75      0.75         4
         350       1.00      0.50      0.67         4
         351       0.00      0.00      0.00         4
         352       0.71      1.00      0.83         5
         353       0.50      0.25      0.33         4
         354       0.67      1.00      0.80         4
         355       1.00      0.50      0.67         4
         356       0.80      1.00      0.89         4
         357       0.80      0.89      0.84         9
         358       0.57      1.00      0.73         4
         359       1.00      1.00      1.00         4
         360       1.00      1.00      1.00         5
         361       0.00      0.00      0.00         9
         362       0.00      0.00      0.00         4
         363       0.80      0.89      0.84         9
         364       0.50      0.75      0.60         4
         365       1.00      0.75      0.86         4
         366       1.00      1.00      1.00         4
         367       0.75      0.75      0.75         4
         368       0.00      0.00      0.00         4
         369       0.00      0.00      0.00         4
         370       0.82      1.00      0.90         9
         371       0.00      0.00      0.00         4
         372       1.00      1.00      1.00         4
         373       0.83      1.00      0.91         5
         374       0.00      0.00      0.00         4
         375       1.00      1.00      1.00         4
         376       0.88      0.78      0.82         9
         377       1.00      1.00      1.00         4
         378       1.00      1.00      1.00         4
         379       1.00      0.50      0.67         4
         380       1.00      0.75      0.86         4
         381       0.80      0.80      0.80         5
         382       0.78      0.78      0.78         9
         383       1.00      0.75      0.86         4
         384       0.67      1.00      0.80         4
         385       1.00      1.00      1.00         4
         386       1.00      0.89      0.94         9
         387       0.75      0.75      0.75         4
         388       0.90      1.00      0.95         9
         389       0.00      0.00      0.00         4
         390       0.89      0.89      0.89         9
         391       0.89      0.89      0.89         9
         392       1.00      1.00      1.00         9
         393       1.00      1.00      1.00         4
         394       1.00      0.40      0.57         5
         395       0.67      1.00      0.80         4
         396       0.75      0.75      0.75         4
         397       0.00      0.00      0.00         4
         398       1.00      0.75      0.86         4
         399       0.13      0.50      0.21         4
         400       1.00      1.00      1.00         4
         401       0.86      0.67      0.75         9
         402       1.00      0.50      0.67         4
         403       0.83      1.00      0.91         5
         404       1.00      0.50      0.67         4
         405       0.67      0.50      0.57         4
         406       1.00      0.89      0.94         9
         407       0.43      0.67      0.52         9
         408       1.00      0.67      0.80         9
         409       1.00      1.00      1.00         4
         410       0.00      0.00      0.00         4
         411       0.50      0.40      0.44         5
         412       0.69      1.00      0.82         9
         413       1.00      1.00      1.00         4
         414       1.00      1.00      1.00         9
         415       1.00      1.00      1.00         4
         416       1.00      0.25      0.40         4
         417       1.00      1.00      1.00         5
         418       1.00      0.75      0.86         4
         419       1.00      1.00      1.00         4
         420       1.00      1.00      1.00         9
         421       0.10      0.22      0.13         9
         422       0.50      0.50      0.50         4
         423       0.78      0.78      0.78         9
         424       0.80      1.00      0.89         4
         425       0.83      1.00      0.91         5
         426       0.80      1.00      0.89         4
         427       1.00      1.00      1.00         4
         428       0.40      0.40      0.40         5
         429       0.83      1.00      0.91         5
         430       0.90      1.00      0.95         9
         431       1.00      0.78      0.88         9
         432       0.89      0.89      0.89         9
         433       0.50      0.25      0.33         4
         434       0.75      0.75      0.75         4
         435       0.60      0.75      0.67         4
         436       0.67      1.00      0.80         4
         437       0.00      0.00      0.00         4
         438       0.80      1.00      0.89         4
         439       0.89      0.89      0.89         9
         440       1.00      1.00      1.00         4
         441       1.00      1.00      1.00         5
         442       0.64      0.78      0.70         9
         443       0.00      0.00      0.00         4
         444       0.75      0.75      0.75         4
         445       0.83      1.00      0.91         5
         446       0.80      0.89      0.84         9
         447       0.00      0.00      0.00         4
         448       0.89      0.89      0.89         9
         449       0.00      0.00      0.00         5
         450       1.00      1.00      1.00         4
         451       1.00      1.00      1.00         9
         452       1.00      0.50      0.67         4
         453       1.00      1.00      1.00         4
         454       0.00      0.00      0.00         9
         455       1.00      1.00      1.00         9
         456       1.00      0.67      0.80         9
         457       0.89      0.89      0.89         9
         458       0.80      1.00      0.89         4
         459       1.00      0.75      0.86         4
         460       1.00      1.00      1.00         9
         461       1.00      1.00      1.00         5
         462       0.67      0.50      0.57         4
         463       1.00      0.40      0.57         5
         464       0.67      1.00      0.80         4
         465       0.80      1.00      0.89         4
         466       0.75      0.75      0.75         4
         467       1.00      0.60      0.75         5
         468       0.00      0.00      0.00         4
         469       0.80      1.00      0.89         4
         470       1.00      1.00      1.00         4
         471       0.80      1.00      0.89         4
         472       0.75      0.75      0.75         4
         473       0.67      0.50      0.57         4
         474       0.86      0.67      0.75         9
         475       0.50      0.33      0.40         9
         476       0.00      0.00      0.00         4
         477       0.50      0.80      0.62         5
         478       1.00      0.80      0.89         5
         479       0.43      0.75      0.55         4
         480       0.75      0.75      0.75         4
         481       1.00      1.00      1.00         4
         482       0.00      0.00      0.00         9
         483       0.00      0.00      0.00         4
         484       0.40      0.80      0.53         5
         485       0.80      1.00      0.89         4
         486       1.00      0.75      0.86         4
         487       1.00      0.80      0.89         5
         488       1.00      1.00      1.00         4
         489       0.82      1.00      0.90         9
         490       1.00      1.00      1.00         9
         491       1.00      1.00      1.00         4
         492       0.67      0.50      0.57         4
         493       1.00      1.00      1.00         9
         494       1.00      1.00      1.00         4
         495       0.83      1.00      0.91         5
         496       1.00      0.75      0.86         4
         497       1.00      1.00      1.00         5
         498       1.00      0.40      0.57         5
         499       0.00      0.00      0.00         4
         500       1.00      0.50      0.67         6
         501       0.83      1.00      0.91         5
         502       1.00      0.20      0.33         5
         503       1.00      0.89      0.94         9
         504       0.00      0.00      0.00         4
         505       1.00      0.80      0.89         5
         506       1.00      0.89      0.94         9
         507       1.00      0.75      0.86         4
         508       1.00      1.00      1.00         4
         509       0.75      0.75      0.75         4
         510       0.60      0.75      0.67         4
         511       0.29      0.50      0.36         4
         512       1.00      1.00      1.00         4
         513       1.00      0.50      0.67         4
         514       0.78      0.78      0.78         9
         515       1.00      0.56      0.71         9
         516       1.00      1.00      1.00         9
         517       0.29      1.00      0.44         4
         518       0.83      1.00      0.91         5
         519       0.00      0.00      0.00         4
         520       0.57      1.00      0.73         4
         521       1.00      0.50      0.67         4
         522       0.00      0.00      0.00         9
         523       1.00      1.00      1.00         4
         524       0.75      0.75      0.75         4
         525       1.00      0.80      0.89         5
         526       0.75      0.75      0.75         4
         527       0.80      1.00      0.89         4
         528       0.88      0.78      0.82         9
         529       0.80      0.80      0.80         5
         530       0.67      1.00      0.80         4
         531       0.89      0.89      0.89         9
         532       0.46      0.67      0.55         9
         533       1.00      0.75      0.86         4
         534       0.00      0.00      0.00         4
         535       0.62      0.89      0.73         9
         536       0.00      0.00      0.00         4
         537       0.75      1.00      0.86         9
         538       1.00      1.00      1.00         4
         539       1.00      0.75      0.86         4
         540       0.25      0.25      0.25         4
         541       1.00      1.00      1.00         4
         542       0.25      0.50      0.33         4
         543       0.60      0.75      0.67         4
         544       1.00      0.50      0.67         4
         545       0.80      0.80      0.80         5
         546       1.00      0.67      0.80         9
         547       0.50      0.75      0.60         4
         548       0.00      0.00      0.00         4
         549       0.71      1.00      0.83         5
         550       1.00      1.00      1.00         4
         551       0.33      0.50      0.40         4
         552       0.75      1.00      0.86         9
         553       0.89      0.89      0.89         9
         554       0.40      0.50      0.44         4
         555       1.00      0.50      0.67         4
         556       0.00      0.00      0.00         4
         557       0.00      0.00      0.00         4
         558       0.67      1.00      0.80         4
         559       0.82      1.00      0.90         9
         560       0.50      0.20      0.29         5
         561       1.00      1.00      1.00         4
         562       1.00      1.00      1.00         4
         563       0.75      0.75      0.75         4
         564       0.80      0.89      0.84         9
         565       1.00      1.00      1.00         9
         566       1.00      1.00      1.00         5
         567       0.75      0.60      0.67         5
         568       0.45      1.00      0.62         5
         569       0.00      0.00      0.00         4
         570       0.00      0.00      0.00         4
         571       0.75      1.00      0.86         9
         572       0.50      0.75      0.60         4
         573       0.00      0.00      0.00         4
         574       1.00      1.00      1.00         4
         575       0.00      0.00      0.00         4
         576       0.06      0.25      0.10         4
         577       1.00      0.50      0.67         4
         578       0.83      1.00      0.91         5
         579       1.00      0.75      0.86         4
         580       1.00      0.75      0.86         4
         581       1.00      0.78      0.88         9
         582       1.00      0.75      0.86         4
         583       0.50      0.75      0.60         4
         584       0.00      0.00      0.00         4
         585       1.00      1.00      1.00         9
         586       0.80      1.00      0.89         4
         587       1.00      1.00      1.00         4
         588       0.89      0.89      0.89         9
         589       1.00      0.89      0.94         9
         590       1.00      1.00      1.00         4
         591       1.00      1.00      1.00         4
         592       0.67      1.00      0.80         4
         593       0.80      1.00      0.89         4
         594       0.57      1.00      0.73         4
         595       0.14      0.25      0.18         4
         596       1.00      1.00      1.00         4
         597       0.67      1.00      0.80         4
         598       0.88      0.78      0.82         9
         599       0.80      1.00      0.89         4
         600       1.00      1.00      1.00         5
         601       1.00      1.00      1.00         4
         602       1.00      1.00      1.00         4
         603       1.00      0.75      0.86         4
         604       1.00      0.75      0.86         4
         605       0.00      0.00      0.00         4
         606       1.00      0.89      0.94         9
         607       0.88      0.78      0.82         9
         608       0.00      0.00      0.00         4
         609       0.89      0.89      0.89         9
         610       1.00      0.75      0.86         4
         611       0.00      0.00      0.00         4
         612       1.00      0.75      0.86         4
         613       0.00      0.00      0.00         4
         614       0.50      0.40      0.44         5
         615       0.80      0.89      0.84         9
         616       1.00      1.00      1.00         4
         617       0.75      0.75      0.75         4
         618       0.80      1.00      0.89         4
         619       0.80      1.00      0.89         4
         620       1.00      1.00      1.00         9
         621       0.67      0.50      0.57         4
         622       1.00      1.00      1.00         4
         623       0.57      1.00      0.73         4
         624       0.67      0.50      0.57         4
         625       0.71      1.00      0.83         5
         626       0.67      1.00      0.80         4
         627       1.00      0.75      0.86         4
         628       1.00      0.80      0.89         5
         629       1.00      1.00      1.00         4
         630       0.82      1.00      0.90         9
         631       0.70      0.78      0.74         9
         632       1.00      0.50      0.67         4
         633       0.69      1.00      0.82         9
         634       0.80      0.80      0.80         5
         635       0.00      0.00      0.00         4
         636       1.00      1.00      1.00         4
         637       0.00      0.00      0.00         4
         638       0.00      0.00      0.00         4
         639       0.00      0.00      0.00         4
         640       1.00      1.00      1.00         4
         641       0.80      0.89      0.84         9
         642       1.00      0.75      0.86         4
         643       1.00      1.00      1.00         4
         644       1.00      0.50      0.67         4
         645       1.00      0.75      0.86         4
         646       0.75      0.75      0.75         4
         647       0.50      0.25      0.33         4
         648       1.00      0.25      0.40         4
         649       0.00      0.00      0.00         4
         650       1.00      0.89      0.94         9
         651       0.00      0.00      0.00         4
         652       0.80      1.00      0.89         4
         653       1.00      1.00      1.00         9
         654       0.75      0.60      0.67         5
         655       0.67      1.00      0.80         4
         656       0.82      1.00      0.90         9
         657       1.00      0.80      0.89         5
         658       0.83      1.00      0.91         5
         659       1.00      1.00      1.00         5
         660       0.00      0.00      0.00         9
         661       0.71      0.56      0.63         9
         662       0.90      1.00      0.95         9
         663       1.00      1.00      1.00         9
         664       0.80      1.00      0.89         4
         665       0.80      0.80      0.80         5
         666       1.00      0.75      0.86         4
         667       1.00      0.75      0.86         4
         668       1.00      0.80      0.89         5
         669       0.88      0.78      0.82         9
         670       0.71      1.00      0.83         5
         671       0.12      0.25      0.17         4
         672       1.00      1.00      1.00         4
         673       0.00      0.00      0.00         4
         674       0.67      0.44      0.53         9
         675       0.67      1.00      0.80         4
         676       1.00      1.00      1.00         9
         677       0.80      1.00      0.89         4
         678       0.00      0.00      0.00         4
         679       1.00      1.00      1.00         4
         680       1.00      0.89      0.94         9
         681       0.50      0.75      0.60         4
         682       0.50      0.33      0.40         9
         683       1.00      0.75      0.86         4
         684       0.75      0.75      0.75         4
         685       0.89      0.89      0.89         9
         686       1.00      0.78      0.88         9
         687       1.00      0.75      0.86         4
         688       0.40      0.22      0.29         9
         689       0.73      0.89      0.80         9
         690       1.00      1.00      1.00         4
         691       1.00      0.89      0.94         9
         692       1.00      1.00      1.00         4
         693       0.89      0.89      0.89         9
         694       1.00      0.40      0.57         5
         695       0.62      0.56      0.59         9
         696       0.75      0.75      0.75         4
         697       0.50      0.50      0.50         4
         698       1.00      0.60      0.75         5
         699       1.00      0.75      0.86         4
         700       1.00      1.00      1.00         4
         701       0.00      0.00      0.00         4
         702       0.67      0.50      0.57         4
         703       0.67      1.00      0.80         4
         704       1.00      0.75      0.86         4
         705       0.86      0.86      0.86         7
         706       0.00      0.00      0.00         4
         707       0.83      0.56      0.67         9
         708       0.75      0.75      0.75         4
         709       0.80      1.00      0.89         4
         710       0.36      0.56      0.43         9
         711       0.10      0.25      0.14         4
         712       0.75      0.75      0.75         4
         713       0.82      1.00      0.90         9
         714       1.00      1.00      1.00         4
         715       0.67      0.80      0.73         5
         716       1.00      1.00      1.00         5
         717       0.67      0.40      0.50         5
         718       1.00      0.67      0.80         9
         719       0.00      0.00      0.00         4
         720       0.90      1.00      0.95         9
         721       1.00      0.25      0.40         4
         722       1.00      0.78      0.88         9
         723       1.00      0.60      0.75         5
         724       1.00      0.75      0.86         4
         725       0.00      0.00      0.00         9
         726       0.83      1.00      0.91         5
         727       1.00      1.00      1.00         4
         728       0.80      1.00      0.89         4
         729       0.60      0.75      0.67         4
         730       1.00      0.75      0.86         4
         731       0.00      0.00      0.00         4
         732       1.00      1.00      1.00         9
         733       1.00      1.00      1.00         4
         734       0.00      0.00      0.00         9
         735       1.00      0.75      0.86         4
         736       0.70      0.78      0.74         9
         737       1.00      1.00      1.00         4
         738       0.86      0.67      0.75         9
         739       1.00      0.67      0.80         9
         740       1.00      1.00      1.00         4
         741       0.89      0.89      0.89         9
         742       1.00      0.75      0.86         4
         743       0.00      0.00      0.00         4
         744       0.71      1.00      0.83         5
         745       1.00      1.00      1.00         9
         746       0.62      1.00      0.77         5
         747       0.57      0.89      0.70         9
         748       0.80      1.00      0.89         4
         749       0.50      0.25      0.33         4
         750       1.00      0.75      0.86         4
         751       0.50      0.25      0.33         4
         752       0.50      0.50      0.50         4
         753       0.50      0.50      0.50         4
         754       0.80      0.80      0.80         5
         755       0.90      1.00      0.95         9
         756       1.00      1.00      1.00         9
         757       0.50      0.25      0.33         4
         758       0.50      0.75      0.60         4
         759       1.00      0.50      0.67         4
         760       1.00      1.00      1.00         9
         761       0.60      0.75      0.67         4
         762       1.00      1.00      1.00         4
         763       0.40      0.50      0.44         4
         764       0.67      1.00      0.80         4
         765       1.00      0.60      0.75         5
         766       0.80      1.00      0.89         4
         767       1.00      0.75      0.86         4
         768       0.50      0.40      0.44         5
         769       0.50      0.25      0.33         4
         770       0.40      1.00      0.57         4
         771       1.00      0.60      0.75         5
         772       1.00      1.00      1.00         9
         773       0.04      0.11      0.06         9
         774       0.82      1.00      0.90         9
         775       0.75      0.75      0.75         4
         776       0.80      0.80      0.80         5
         777       0.20      0.25      0.22         4
         778       0.67      1.00      0.80         4
         779       0.75      1.00      0.86         9
         780       1.00      1.00      1.00         4
         781       1.00      0.89      0.94         9
         782       0.00      0.00      0.00         4
         783       0.00      0.00      0.00         4
         784       0.00      0.00      0.00         9
         785       1.00      1.00      1.00         5
         786       0.82      1.00      0.90         9
         787       1.00      0.40      0.57         5
         788       0.89      0.89      0.89         9
         789       1.00      1.00      1.00         5
         790       0.80      1.00      0.89         4
         791       0.50      0.50      0.50         4
         792       1.00      1.00      1.00         4
         793       0.00      0.00      0.00         4
         794       1.00      1.00      1.00         4
         795       0.80      0.80      0.80         5
         796       0.50      0.25      0.33         4
         797       0.75      0.75      0.75         4
         798       1.00      1.00      1.00         4
         799       1.00      1.00      1.00         4
         800       0.00      0.00      0.00         4
         801       0.83      1.00      0.91         5
         802       0.50      0.75      0.60         4
         803       1.00      0.89      0.94         9
         804       1.00      0.80      0.89         5
         805       0.00      0.00      0.00         9
         806       0.80      1.00      0.89         4
         807       1.00      0.75      0.86         4
         808       1.00      1.00      1.00         4
         809       0.57      0.80      0.67         5
         810       1.00      0.80      0.89         5
         811       1.00      1.00      1.00         4
         812       0.50      0.50      0.50         4
         813       0.50      0.60      0.55         5
         814       1.00      0.75      0.86         4
         815       0.33      0.50      0.40         4
         816       0.88      0.78      0.82         9
         817       0.50      0.67      0.57         9
         818       0.00      0.00      0.00         4
         819       0.67      1.00      0.80         4
         820       0.67      0.50      0.57         4
         821       1.00      1.00      1.00         5
         822       0.40      0.50      0.44         4
         823       1.00      0.75      0.86         4
         824       1.00      1.00      1.00         4
         825       0.00      0.00      0.00         5
         826       0.08      0.25      0.12         4
         827       1.00      1.00      1.00         4
         828       0.80      1.00      0.89         4
         829       0.86      0.67      0.75         9
         830       1.00      1.00      1.00         5
         831       0.75      0.75      0.75         4
         832       0.89      0.89      0.89         9
         833       0.86      0.67      0.75         9
         834       1.00      1.00      1.00         9
         835       0.80      1.00      0.89         4
         836       1.00      0.67      0.80         9
         837       1.00      1.00      1.00         5
         838       0.60      0.75      0.67         4
         839       0.80      1.00      0.89         4
         840       0.64      0.78      0.70         9
         841       0.00      0.00      0.00         9
         842       1.00      1.00      1.00         5
         843       0.00      0.00      0.00         4
         844       1.00      0.56      0.71         9
         845       0.60      0.75      0.67         4
         846       0.60      0.75      0.67         4
         847       1.00      0.86      0.92         7
         848       0.83      1.00      0.91         5
         849       1.00      0.75      0.86         4
         850       0.00      0.00      0.00         4
         851       0.80      1.00      0.89         4
         852       0.82      1.00      0.90         9
         853       1.00      0.60      0.75         5
         854       0.89      0.89      0.89         9
         855       1.00      0.50      0.67         4
         856       0.80      0.80      0.80         5
         857       1.00      0.75      0.86         4
         858       1.00      0.75      0.86         8
         859       0.38      0.60      0.46         5
         860       0.33      0.25      0.29         4
         861       0.10      0.50      0.16         4
         862       0.73      0.89      0.80         9
         863       0.73      0.89      0.80         9
         864       0.89      0.89      0.89         9
         865       0.33      0.25      0.29         4
         866       0.83      0.71      0.77         7
         867       0.89      0.89      0.89         9
         868       0.75      0.67      0.71         9
         869       0.67      0.80      0.73         5
         870       0.80      1.00      0.89         4
         871       0.00      0.00      0.00         4
         872       0.80      0.80      0.80         5
         873       1.00      0.78      0.88         9
         874       0.73      0.89      0.80         9
         875       0.00      0.00      0.00         4
         876       1.00      1.00      1.00         9
         877       0.00      0.00      0.00         9
         878       0.00      0.00      0.00         4
         879       0.60      0.75      0.67         4
         880       0.00      0.00      0.00         4
         881       1.00      0.80      0.89         5
         882       0.00      0.00      0.00         9
         883       1.00      1.00      1.00         4
         884       1.00      1.00      1.00         5
         885       1.00      0.89      0.94         9
         886       0.00      0.00      0.00         4
         887       1.00      0.67      0.80         9
         888       0.00      0.00      0.00         4
         889       0.00      0.00      0.00         4
         890       1.00      1.00      1.00         4
         891       0.00      0.00      0.00         4
         892       1.00      0.75      0.86         4
         893       0.80      1.00      0.89         4

    accuracy                           0.71      4917
   macro avg       0.70      0.68      0.68      4917
weighted avg       0.72      0.71      0.70      4917

task_train_time: {0: 0.1294971199999999, 1: 0.03350354999999894, 2: 0.032686278999999985, 3: 0.034972753999999995, 4: 0.03323051699999979, 5: 0.029864515999999952, 6: 0.03668502300000043, 7: 0.034282333000000165, 8: 0.030578965000000125, 9: 0.035996745000000274, 10: 0.03226249699999961, 11: 0.03809865700000081, 12: 0.03772873499999996, 13: 0.03625411900000053, 14: 0.042057742000000786, 15: 0.023197422000000856, 16: 0.02236461400000067, 17: 0.02950711799999972, 18: 0.0321684960000006, 19: 0.030034514000000456, 20: 0.03572267300000043, 21: 0.03359585199999948, 22: 0.027939015999999484, 23: 0.030549361000000275, 24: 0.02385407399999906, 25: 0.029799803999999597, 26: 0.028227044999999507, 27: 0.02914261299999943, 28: 0.02886984999999953, 29: 0.030078887000000165, 30: 0.03056403899999971, 31: 0.023973218000000074, 32: 0.039446112000000255, 33: 0.03555157299999934, 34: 0.030812347999999545, 35: 0.035119439000000696, 36: 0.03064862799999979, 37: 0.025770676000000492, 38: 0.03544949399999808, 39: 0.024755797000000968, 40: 0.030550682000001217, 41: 0.03631297800000155, 42: 0.03411303299999702, 43: 0.026745808000001148}
prediction_time: 0.00029100499999401563
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
