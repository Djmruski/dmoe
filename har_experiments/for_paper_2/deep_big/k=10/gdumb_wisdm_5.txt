Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='95f6b4da-d5b4-4d93-8985-c38808108130', conf_timestamp='2023-08-13 15:39:14.148336', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 76.17 % 	 [Task-IL]: 51.81 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 55.54 % 	 [Task-IL]: 41.23 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 44.09 % 	 [Task-IL]: 34.59 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 38.76 % 	 [Task-IL]: 31.36 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 31.84 % 	 [Task-IL]: 28.49 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 24.42 % 	 [Task-IL]: 27.77 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.63 % 	 [Task-IL]: 28.08 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 20.76 % 	 [Task-IL]: 26.99 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 15.8 % 	 [Task-IL]: 26.52 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 14.15 % 	 [Task-IL]: 26.81 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.65 % 	 [Task-IL]: 27.17 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 12.84 % 	 [Task-IL]: 26.7 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 14.17 % 	 [Task-IL]: 27.45 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.85 % 	 [Task-IL]: 27.35 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.97 % 	 [Task-IL]: 27.33 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.96 % 	 [Task-IL]: 26.85 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 10.71 % 	 [Task-IL]: 26.82 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 13.91 % 	 [Task-IL]: 26.44 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.49 % 	 [Task-IL]: 26.6 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.78 % 	 [Task-IL]: 25.99 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.03 % 	 [Task-IL]: 25.71 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 10.0 % 	 [Task-IL]: 25.75 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.37 % 	 [Task-IL]: 26.14 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.06 % 	 [Task-IL]: 26.62 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 6.61 % 	 [Task-IL]: 26.45 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.14 % 	 [Task-IL]: 26.08 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 5.98 % 	 [Task-IL]: 26.65 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.01 % 	 [Task-IL]: 26.12 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.77 % 	 [Task-IL]: 25.65 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.64 % 	 [Task-IL]: 26.28 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.99 % 	 [Task-IL]: 26.25 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.21 % 	 [Task-IL]: 26.14 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.7 % 	 [Task-IL]: 26.22 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 5.93 % 	 [Task-IL]: 26.07 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.9 % 	 [Task-IL]: 26.35 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.75 % 	 [Task-IL]: 25.94 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.22 % 	 [Task-IL]: 25.8 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.9 % 	 [Task-IL]: 25.76 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.19 % 	 [Task-IL]: 25.61 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.42 % 	 [Task-IL]: 25.64 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 6.59 % 	 [Task-IL]: 25.48 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.48 % 	 [Task-IL]: 25.21 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 5.8 % 	 [Task-IL]: 24.96 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({720: 27, 58: 24, 189: 24, 679: 23, 616: 23, 691: 23, 799: 23, 334: 23, 391: 23, 463: 23, 33: 22, 890: 22, 682: 22, 702: 22, 568: 22, 562: 22, 810: 22, 577: 22, 275: 22, 494: 22, 503: 22, 849: 21, 706: 21, 842: 21, 595: 21, 857: 21, 599: 21, 73: 21, 815: 21, 235: 21, 328: 21, 326: 21, 442: 21, 447: 21, 509: 21, 517: 21, 840: 20, 692: 20, 740: 20, 735: 20, 886: 20, 834: 20, 893: 20, 780: 20, 649: 20, 697: 20, 138: 20, 331: 20, 364: 20, 363: 20, 397: 20, 449: 20, 458: 20, 31: 19, 9: 19, 823: 19, 808: 19, 792: 19, 586: 19, 710: 19, 752: 19, 844: 19, 664: 19, 644: 19, 659: 19, 807: 19, 848: 19, 658: 19, 764: 19, 785: 19, 107: 19, 124: 19, 238: 19, 264: 19, 262: 19, 261: 19, 258: 19, 330: 19, 365: 19, 399: 19, 413: 19, 477: 19, 481: 19, 513: 19, 526: 19, 519: 19, 542: 19, 551: 19, 546: 19, 11: 18, 1: 18, 880: 18, 670: 18, 753: 18, 569: 18, 739: 18, 640: 18, 787: 18, 830: 18, 784: 18, 772: 18, 875: 18, 854: 18, 52: 18, 625: 18, 90: 18, 677: 18, 127: 18, 168: 18, 187: 18, 214: 18, 245: 18, 251: 18, 246: 18, 311: 18, 294: 18, 298: 18, 340: 18, 389: 18, 395: 18, 401: 18, 404: 18, 435: 18, 501: 18, 25: 17, 796: 17, 20: 17, 642: 17, 675: 17, 804: 17, 47: 17, 889: 17, 633: 17, 684: 17, 829: 17, 64: 17, 707: 17, 128: 17, 194: 17, 222: 17, 361: 17, 358: 17, 422: 17, 461: 17, 466: 17, 480: 17, 533: 17, 535: 17, 2: 16, 12: 16, 18: 16, 594: 16, 776: 16, 660: 16, 821: 16, 34: 16, 827: 16, 744: 16, 80: 16, 103: 16, 111: 16, 119: 16, 123: 16, 162: 16, 193: 16, 184: 16, 203: 16, 223: 16, 273: 16, 270: 16, 366: 16, 377: 16, 420: 16, 462: 16, 495: 16, 523: 16, 681: 15, 583: 15, 887: 15, 719: 15, 43: 15, 852: 15, 788: 15, 102: 15, 204: 15, 241: 15, 276: 15, 289: 15, 351: 15, 409: 15, 430: 15, 434: 15, 436: 15, 460: 15, 499: 15, 550: 15, 759: 14, 627: 14, 629: 14, 572: 14, 892: 14, 600: 14, 70: 14, 63: 14, 69: 14, 742: 14, 769: 14, 850: 14, 101: 14, 131: 14, 121: 14, 135: 14, 155: 14, 201: 14, 247: 14, 296: 14, 353: 14, 343: 14, 376: 14, 410: 14, 598: 13, 867: 13, 688: 13, 597: 13, 86: 13, 146: 13, 192: 13, 217: 13, 306: 13, 332: 13, 453: 13, 482: 13, 506: 13, 537: 13, 774: 12, 749: 12, 672: 12, 613: 12, 85: 12, 156: 12, 191: 12, 177: 12, 259: 12, 254: 12, 290: 12, 313: 12, 300: 12, 348: 12, 345: 12, 403: 12, 405: 12, 527: 12, 552: 12, 16: 11, 826: 11, 828: 11, 626: 11, 686: 11, 728: 11, 38: 11, 36: 11, 603: 11, 654: 11, 730: 11, 655: 11, 169: 11, 865: 11, 240: 11, 242: 11, 295: 11, 329: 11, 429: 11, 416: 11, 426: 11, 465: 11, 490: 11, 553: 11, 4: 10, 630: 10, 858: 10, 578: 10, 673: 10, 566: 10, 767: 10, 705: 10, 676: 10, 711: 10, 731: 10, 582: 10, 824: 10, 40: 10, 37: 10, 589: 10, 721: 10, 819: 10, 59: 10, 737: 10, 717: 10, 803: 10, 565: 10, 690: 10, 87: 10, 733: 10, 76: 10, 605: 10, 581: 10, 811: 10, 888: 10, 116: 10, 117: 10, 141: 10, 144: 10, 145: 10, 149: 10, 202: 10, 213: 10, 197: 10, 210: 10, 607: 10, 695: 10, 252: 10, 249: 10, 304: 10, 323: 10, 319: 10, 327: 10, 314: 10, 342: 10, 359: 10, 385: 10, 473: 10, 455: 10, 474: 10, 484: 10, 13: 9, 722: 9, 872: 9, 17: 9, 28: 9, 822: 9, 794: 9, 621: 9, 758: 9, 554: 9, 839: 9, 843: 9, 782: 9, 678: 9, 762: 9, 593: 9, 617: 9, 715: 9, 747: 9, 563: 9, 738: 9, 757: 9, 42: 9, 809: 9, 41: 9, 837: 9, 610: 9, 869: 9, 713: 9, 560: 9, 62: 9, 861: 9, 835: 9, 714: 9, 817: 9, 666: 9, 95: 9, 765: 9, 727: 9, 104: 9, 645: 9, 588: 9, 133: 9, 140: 9, 137: 9, 150: 9, 171: 9, 166: 9, 174: 9, 205: 9, 207: 9, 226: 9, 218: 9, 231: 9, 674: 9, 244: 9, 716: 9, 268: 9, 279: 9, 287: 9, 277: 9, 303: 9, 301: 9, 308: 9, 321: 9, 315: 9, 322: 9, 325: 9, 347: 9, 350: 9, 344: 9, 335: 9, 369: 9, 371: 9, 367: 9, 368: 9, 383: 9, 386: 9, 388: 9, 411: 9, 402: 9, 398: 9, 418: 9, 424: 9, 414: 9, 427: 9, 452: 9, 438: 9, 451: 9, 459: 9, 456: 9, 475: 9, 486: 9, 505: 9, 545: 9, 543: 9, 751: 8, 21: 8, 636: 8, 634: 8, 15: 8, 602: 8, 699: 8, 585: 8, 6: 8, 745: 8, 19: 8, 646: 8, 696: 8, 567: 8, 798: 8, 667: 8, 561: 8, 855: 8, 624: 8, 48: 8, 558: 8, 736: 8, 49: 8, 571: 8, 863: 8, 615: 8, 778: 8, 55: 8, 68: 8, 72: 8, 801: 8, 637: 8, 876: 8, 663: 8, 574: 8, 79: 8, 648: 8, 92: 8, 841: 8, 94: 8, 652: 8, 587: 8, 608: 8, 118: 8, 132: 8, 114: 8, 115: 8, 606: 8, 142: 8, 669: 8, 154: 8, 159: 8, 165: 8, 161: 8, 746: 8, 179: 8, 185: 8, 188: 8, 224: 8, 220: 8, 234: 8, 257: 8, 271: 8, 269: 8, 293: 8, 285: 8, 297: 8, 339: 8, 336: 8, 341: 8, 349: 8, 357: 8, 373: 8, 392: 8, 378: 8, 387: 8, 406: 8, 432: 8, 431: 8, 444: 8, 445: 8, 464: 8, 457: 8, 478: 8, 483: 8, 492: 8, 476: 8, 500: 8, 496: 8, 516: 8, 541: 8, 534: 8, 14: 7, 10: 7, 866: 7, 23: 7, 665: 7, 851: 7, 689: 7, 3: 7, 709: 7, 29: 7, 879: 7, 725: 7, 575: 7, 882: 7, 622: 7, 651: 7, 708: 7, 766: 7, 756: 7, 853: 7, 789: 7, 777: 7, 833: 7, 825: 7, 700: 7, 761: 7, 698: 7, 885: 7, 573: 7, 45: 7, 46: 7, 35: 7, 39: 7, 584: 7, 884: 7, 783: 7, 723: 7, 631: 7, 71: 7, 591: 7, 874: 7, 724: 7, 632: 7, 741: 7, 612: 7, 91: 7, 74: 7, 877: 7, 89: 7, 846: 7, 668: 7, 650: 7, 864: 7, 800: 7, 618: 7, 98: 7, 113: 7, 99: 7, 105: 7, 820: 7, 718: 7, 555: 7, 703: 7, 680: 7, 576: 7, 596: 7, 748: 7, 671: 7, 770: 7, 134: 7, 143: 7, 619: 7, 614: 7, 164: 7, 157: 7, 158: 7, 873: 7, 190: 7, 768: 7, 178: 7, 175: 7, 186: 7, 182: 7, 209: 7, 212: 7, 211: 7, 195: 7, 229: 7, 225: 7, 232: 7, 219: 7, 228: 7, 216: 7, 243: 7, 250: 7, 265: 7, 272: 7, 267: 7, 685: 7, 288: 7, 291: 7, 278: 7, 292: 7, 281: 7, 316: 7, 346: 7, 352: 7, 355: 7, 384: 7, 379: 7, 407: 7, 412: 7, 396: 7, 417: 7, 419: 7, 421: 7, 448: 7, 437: 7, 441: 7, 443: 7, 468: 7, 471: 7, 479: 7, 488: 7, 491: 7, 504: 7, 498: 7, 497: 7, 507: 7, 529: 7, 531: 7, 525: 7, 522: 7, 30: 6, 734: 6, 8: 6, 647: 6, 22: 6, 5: 6, 726: 6, 27: 6, 559: 6, 0: 6, 687: 6, 805: 6, 604: 6, 795: 6, 755: 6, 623: 6, 831: 6, 818: 6, 635: 6, 51: 6, 50: 6, 44: 6, 53: 6, 813: 6, 570: 6, 662: 6, 65: 6, 760: 6, 641: 6, 750: 6, 75: 6, 83: 6, 601: 6, 82: 6, 814: 6, 579: 6, 802: 6, 108: 6, 96: 6, 112: 6, 106: 6, 881: 6, 781: 6, 100: 6, 109: 6, 592: 6, 816: 6, 130: 6, 763: 6, 125: 6, 557: 6, 643: 6, 148: 6, 153: 6, 147: 6, 701: 6, 870: 6, 172: 6, 170: 6, 181: 6, 180: 6, 183: 6, 176: 6, 556: 6, 206: 6, 200: 6, 199: 6, 233: 6, 215: 6, 891: 6, 236: 6, 248: 6, 871: 6, 266: 6, 661: 6, 639: 6, 274: 6, 280: 6, 307: 6, 312: 6, 310: 6, 317: 6, 320: 6, 324: 6, 337: 6, 360: 6, 362: 6, 354: 6, 370: 6, 382: 6, 390: 6, 374: 6, 380: 6, 381: 6, 400: 6, 408: 6, 433: 6, 415: 6, 450: 6, 440: 6, 446: 6, 439: 6, 469: 6, 489: 6, 493: 6, 487: 6, 518: 6, 521: 6, 528: 6, 520: 6, 544: 6, 540: 6, 547: 6, 538: 6, 832: 5, 26: 5, 704: 5, 773: 5, 878: 5, 56: 5, 54: 5, 60: 5, 57: 5, 61: 5, 743: 5, 653: 5, 77: 5, 88: 5, 81: 5, 791: 5, 78: 5, 110: 5, 97: 5, 693: 5, 120: 5, 129: 5, 883: 5, 806: 5, 126: 5, 860: 5, 683: 5, 868: 5, 151: 5, 136: 5, 590: 5, 160: 5, 167: 5, 163: 5, 754: 5, 628: 5, 198: 5, 237: 5, 253: 5, 239: 5, 712: 5, 564: 5, 255: 5, 260: 5, 657: 5, 286: 5, 283: 5, 282: 5, 299: 5, 305: 5, 318: 5, 338: 5, 356: 5, 372: 5, 393: 5, 394: 5, 470: 5, 454: 5, 485: 5, 502: 5, 508: 5, 530: 5, 536: 5, 548: 5, 24: 4, 32: 4, 812: 4, 638: 4, 609: 4, 729: 4, 771: 4, 786: 4, 620: 4, 67: 4, 84: 4, 93: 4, 656: 4, 122: 4, 856: 4, 797: 4, 732: 4, 580: 4, 845: 4, 152: 4, 862: 4, 173: 4, 611: 4, 694: 4, 836: 4, 208: 4, 196: 4, 230: 4, 227: 4, 256: 4, 284: 4, 302: 4, 309: 4, 790: 4, 375: 4, 423: 4, 425: 4, 428: 4, 467: 4, 472: 4, 514: 4, 515: 4, 549: 4, 7: 3, 793: 3, 66: 3, 859: 3, 139: 3, 779: 3, 838: 3, 263: 3, 333: 3, 510: 3, 512: 3, 511: 3, 524: 3, 539: 3, 775: 2, 847: 2, 221: 2, 532: 2})
Total buffer: 8940
fit_time: 80.896547403

Accuracy for 44 task(s): 	 [Class-IL]: 70.71 % 	 [Task-IL]: 29.35 %

CLASS_IL_ACC: 
	[70.46632124352331, 65.71428571428571, 64.60176991150442, 64.51612903225806, 72.64150943396226, 63.86554621848739, 73.19587628865979, 57.73195876288659, 64.22018348623854, 70.29702970297029, 55.33980582524271, 85.0, 70.24793388429752, 76.23762376237624, 76.10619469026548, 75.0, 82.14285714285714, 87.61061946902655, 70.37037037037037, 60.0, 79.41176470588235, 75.43859649122807, 78.76106194690266, 73.7864077669903, 80.83333333333333, 64.48598130841121, 58.03571428571429, 67.5925925925926, 70.40816326530613, 74.57627118644068, 66.66666666666666, 66.01941747572816, 63.39285714285714, 71.65354330708661, 65.17857142857143, 70.87378640776699, 73.72881355932203, 69.6969696969697, 77.31092436974791, 78.94736842105263, 85.96491228070175, 63.559322033898304, 58.51063829787234, 71.07438016528926]
TASK_IL_ACC: 
	[55.95854922279793, 23.809523809523807, 23.008849557522122, 24.731182795698924, 21.69811320754717, 17.647058823529413, 34.02061855670103, 27.835051546391753, 22.93577981651376, 25.742574257425744, 31.06796116504854, 30.0, 28.09917355371901, 32.67326732673268, 33.6283185840708, 23.14814814814815, 26.785714285714285, 26.548672566371685, 30.555555555555557, 28.799999999999997, 24.509803921568626, 32.45614035087719, 26.548672566371685, 28.155339805825243, 32.5, 28.037383177570092, 21.428571428571427, 21.296296296296298, 26.53061224489796, 37.28813559322034, 25.225225225225223, 21.35922330097087, 32.142857142857146, 28.346456692913385, 26.785714285714285, 20.388349514563107, 27.966101694915253, 25.252525252525253, 25.210084033613445, 29.82456140350877, 26.31578947368421, 23.728813559322035, 36.17021276595745, 95.0413223140496]
f1_micro: 70.85621313809233
f1_macro: 68.00801143840891
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.78      0.78      0.78         9
           2       0.70      0.78      0.74         9
           3       1.00      0.80      0.89         5
           4       0.80      1.00      0.89         4
           5       0.40      0.50      0.44         4
           6       0.75      0.75      0.75         4
           7       0.60      0.75      0.67         4
           8       0.30      0.75      0.43         4
           9       0.00      0.00      0.00         9
          10       1.00      0.75      0.86         4
          11       0.80      0.89      0.84         9
          12       0.89      0.89      0.89         9
          13       0.43      0.75      0.55         4
          14       1.00      0.80      0.89         5
          15       1.00      1.00      1.00         4
          16       0.80      0.80      0.80         5
          17       0.67      0.40      0.50         5
          18       0.78      0.78      0.78         9
          19       1.00      1.00      1.00         5
          20       0.88      0.78      0.82         9
          21       0.50      0.50      0.50         4
          22       1.00      0.75      0.86         4
          23       0.67      0.50      0.57         4
          24       0.60      0.75      0.67         4
          25       0.31      0.44      0.36         9
          26       0.67      0.50      0.57         4
          27       0.83      1.00      0.91         5
          28       0.80      0.80      0.80         5
          29       1.00      1.00      1.00         4
          30       0.75      0.75      0.75         4
          31       0.75      0.67      0.71         9
          32       1.00      0.50      0.67         4
          33       1.00      0.89      0.94         9
          34       0.00      0.00      0.00         9
          35       1.00      1.00      1.00         4
          36       0.83      1.00      0.91         5
          37       0.33      0.25      0.29         4
          38       0.67      0.80      0.73         5
          39       0.60      0.75      0.67         4
          40       0.71      1.00      0.83         5
          41       0.00      0.00      0.00         4
          42       0.57      1.00      0.73         4
          43       0.88      0.78      0.82         9
          44       0.60      0.60      0.60         5
          45       0.00      0.00      0.00         4
          46       1.00      0.80      0.89         5
          47       1.00      1.00      1.00         9
          48       0.67      1.00      0.80         4
          49       0.50      0.50      0.50         4
          50       1.00      0.50      0.67         4
          51       0.00      0.00      0.00         4
          52       0.89      0.89      0.89         9
          53       0.80      1.00      0.89         4
          54       0.50      0.25      0.33         4
          55       1.00      0.75      0.86         4
          56       0.80      1.00      0.89         4
          57       0.60      0.75      0.67         4
          58       0.89      0.89      0.89         9
          59       1.00      1.00      1.00         5
          60       0.00      0.00      0.00         4
          61       1.00      1.00      1.00         4
          62       0.00      0.00      0.00         5
          63       0.82      1.00      0.90         9
          64       0.00      0.00      0.00         9
          65       1.00      1.00      1.00         4
          66       0.00      0.00      0.00         4
          67       0.67      1.00      0.80         4
          68       0.57      1.00      0.73         4
          69       1.00      0.89      0.94         9
          70       0.50      0.22      0.31         9
          71       1.00      0.75      0.86         4
          72       0.40      0.40      0.40         5
          73       1.00      1.00      1.00         9
          74       0.67      0.50      0.57         4
          75       0.80      1.00      0.89         4
          76       0.75      0.60      0.67         5
          77       0.80      1.00      0.89         4
          78       0.00      0.00      0.00         4
          79       0.00      0.00      0.00         4
          80       0.80      0.89      0.84         9
          81       1.00      0.50      0.67         4
          82       0.67      1.00      0.80         4
          83       0.12      0.25      0.17         4
          84       1.00      0.75      0.86         4
          85       1.00      1.00      1.00         4
          86       0.83      1.00      0.91         5
          87       0.75      0.75      0.75         4
          88       1.00      1.00      1.00         4
          89       1.00      0.75      0.86         4
          90       0.88      0.78      0.82         9
          91       1.00      0.40      0.57         5
          92       0.00      0.00      0.00         4
          93       0.50      0.25      0.33         4
          94       0.00      0.00      0.00         4
          95       0.60      0.75      0.67         4
          96       0.67      0.40      0.50         5
          97       1.00      0.75      0.86         4
          98       0.00      0.00      0.00         4
          99       1.00      1.00      1.00         4
         100       0.43      0.75      0.55         4
         101       1.00      1.00      1.00         9
         102       0.70      0.78      0.74         9
         103       0.62      0.56      0.59         9
         104       0.33      0.25      0.29         4
         105       0.75      0.75      0.75         4
         106       1.00      0.75      0.86         4
         107       0.88      0.78      0.82         9
         108       1.00      0.75      0.86         4
         109       1.00      1.00      1.00         4
         110       1.00      0.75      0.86         4
         111       1.00      1.00      1.00         9
         112       1.00      1.00      1.00         4
         113       0.67      1.00      0.80         4
         114       0.25      0.50      0.33         4
         115       0.40      0.40      0.40         5
         116       0.67      1.00      0.80         4
         117       0.67      0.80      0.73         5
         118       0.00      0.00      0.00         4
         119       0.00      0.00      0.00         9
         120       0.60      0.60      0.60         5
         121       0.71      0.56      0.63         9
         122       1.00      0.75      0.86         4
         123       0.73      0.89      0.80         9
         124       0.55      0.67      0.60         9
         125       1.00      1.00      1.00         4
         126       1.00      0.75      0.86         4
         127       0.38      0.33      0.35         9
         128       1.00      0.67      0.80         9
         129       0.80      1.00      0.89         4
         130       0.75      0.75      0.75         4
         131       0.70      0.78      0.74         9
         132       0.80      1.00      0.89         4
         133       0.83      1.00      0.91         5
         134       1.00      1.00      1.00         4
         135       1.00      0.78      0.88         9
         136       0.00      0.00      0.00         4
         137       0.67      0.50      0.57         4
         138       0.80      0.89      0.84         9
         139       1.00      0.75      0.86         4
         140       0.57      1.00      0.73         4
         141       0.00      0.00      0.00         4
         142       0.60      0.60      0.60         5
         143       0.67      1.00      0.80         4
         144       1.00      0.75      0.86         4
         145       1.00      1.00      1.00         4
         146       1.00      0.89      0.94         9
         147       1.00      0.50      0.67         4
         148       1.00      1.00      1.00         4
         149       1.00      1.00      1.00         5
         150       0.00      0.00      0.00         4
         151       1.00      0.75      0.86         4
         152       1.00      1.00      1.00         4
         153       1.00      0.75      0.86         4
         154       1.00      1.00      1.00         4
         155       1.00      0.78      0.88         9
         156       1.00      1.00      1.00         5
         157       0.67      0.50      0.57         4
         158       0.00      0.00      0.00         4
         159       1.00      0.75      0.86         4
         160       1.00      1.00      1.00         4
         161       0.75      0.75      0.75         4
         162       0.80      0.89      0.84         9
         163       1.00      1.00      1.00         4
         164       0.00      0.00      0.00         4
         165       0.57      1.00      0.73         4
         166       0.00      0.00      0.00         4
         167       1.00      0.25      0.40         4
         168       0.00      0.00      0.00         9
         169       0.80      0.80      0.80         5
         170       0.00      0.00      0.00         4
         171       0.40      0.50      0.44         4
         172       1.00      1.00      1.00         4
         173       1.00      0.25      0.40         4
         174       0.83      1.00      0.91         5
         175       1.00      0.50      0.67         4
         176       1.00      0.75      0.86         4
         177       0.50      1.00      0.67         5
         178       1.00      1.00      1.00         4
         179       1.00      0.75      0.86         4
         180       0.00      0.00      0.00         4
         181       0.50      0.25      0.33         4
         182       1.00      0.75      0.86         4
         183       0.00      0.00      0.00         4
         184       0.06      0.11      0.08         9
         185       1.00      1.00      1.00         4
         186       0.00      0.00      0.00         4
         187       0.00      0.00      0.00         9
         188       1.00      1.00      1.00         5
         189       0.89      0.89      0.89         9
         190       0.75      0.75      0.75         4
         191       1.00      1.00      1.00         5
         192       0.90      1.00      0.95         9
         193       1.00      1.00      1.00         9
         194       0.82      1.00      0.90         9
         195       1.00      1.00      1.00         4
         196       1.00      1.00      1.00         4
         197       0.00      0.00      0.00         4
         198       1.00      1.00      1.00         4
         199       0.67      0.50      0.57         4
         200       0.75      0.75      0.75         4
         201       1.00      0.71      0.83         7
         202       0.80      0.80      0.80         5
         203       0.69      1.00      0.82         9
         204       0.73      0.89      0.80         9
         205       1.00      0.80      0.89         5
         206       0.80      1.00      0.89         4
         207       0.50      0.25      0.33         4
         208       0.00      0.00      0.00         4
         209       1.00      0.25      0.40         4
         210       1.00      0.50      0.67         4
         211       1.00      0.60      0.75         5
         212       0.00      0.00      0.00         4
         213       1.00      1.00      1.00         4
         214       0.00      0.00      0.00         9
         215       1.00      1.00      1.00         4
         216       0.67      1.00      0.80         4
         217       0.75      0.67      0.71         9
         218       1.00      1.00      1.00         4
         219       0.00      0.00      0.00         4
         220       0.00      0.00      0.00         4
         221       0.00      0.00      0.00         4
         222       0.53      0.89      0.67         9
         223       0.00      0.00      0.00         9
         224       0.80      1.00      0.89         4
         225       1.00      0.75      0.86         4
         226       1.00      0.80      0.89         5
         227       0.50      0.25      0.33         4
         228       1.00      0.75      0.86         4
         229       1.00      1.00      1.00         5
         230       0.67      0.50      0.57         4
         231       1.00      0.50      0.67         4
         232       1.00      0.60      0.75         5
         233       1.00      1.00      1.00         4
         234       0.00      0.00      0.00         4
         235       0.75      1.00      0.86         9
         236       1.00      1.00      1.00         5
         237       1.00      1.00      1.00         5
         238       1.00      1.00      1.00         9
         239       0.60      0.75      0.67         4
         240       0.57      0.80      0.67         5
         241       0.90      1.00      0.95         9
         242       0.83      1.00      0.91         5
         243       0.00      0.00      0.00         4
         244       1.00      1.00      1.00         4
         245       1.00      1.00      1.00         9
         246       0.73      0.89      0.80         9
         247       1.00      0.89      0.94         9
         248       1.00      1.00      1.00         4
         249       1.00      0.75      0.86         4
         250       0.00      0.00      0.00         4
         251       0.90      1.00      0.95         9
         252       0.83      1.00      0.91         5
         253       0.75      0.75      0.75         4
         254       0.83      1.00      0.91         5
         255       1.00      1.00      1.00         4
         256       1.00      0.40      0.57         5
         257       0.80      1.00      0.89         4
         258       0.60      0.67      0.63         9
         259       0.88      0.78      0.82         9
         260       1.00      0.75      0.86         4
         261       0.82      1.00      0.90         9
         262       1.00      0.89      0.94         9
         263       1.00      1.00      1.00         4
         264       0.00      0.00      0.00         9
         265       0.80      1.00      0.89         4
         266       1.00      1.00      1.00         4
         267       0.00      0.00      0.00         4
         268       1.00      0.11      0.20         9
         269       0.67      0.50      0.57         4
         270       0.86      0.75      0.80         8
         271       1.00      1.00      1.00         4
         272       0.80      1.00      0.89         4
         273       1.00      0.89      0.94         9
         274       1.00      1.00      1.00         4
         275       0.89      0.89      0.89         9
         276       1.00      1.00      1.00         9
         277       1.00      0.75      0.86         4
         278       0.00      0.00      0.00         4
         279       0.67      1.00      0.80         4
         280       0.75      0.75      0.75         4
         281       1.00      1.00      1.00         4
         282       0.00      0.00      0.00         4
         283       1.00      1.00      1.00         4
         284       0.00      0.00      0.00         4
         285       0.80      1.00      0.89         4
         286       0.80      1.00      0.89         4
         287       1.00      0.60      0.75         5
         288       0.80      0.80      0.80         5
         289       0.80      0.89      0.84         9
         290       0.86      0.86      0.86         7
         291       0.57      1.00      0.73         4
         292       0.00      0.00      0.00         4
         293       0.83      1.00      0.91         5
         294       0.78      0.78      0.78         9
         295       1.00      0.80      0.89         5
         296       1.00      0.89      0.94         9
         297       1.00      0.50      0.67         4
         298       1.00      1.00      1.00         9
         299       1.00      0.50      0.67         4
         300       0.88      0.78      0.82         9
         301       1.00      0.75      0.86         4
         302       0.33      0.25      0.29         4
         303       1.00      1.00      1.00         4
         304       0.71      0.56      0.63         9
         305       0.00      0.00      0.00         4
         306       1.00      0.80      0.89         5
         307       0.50      0.50      0.50         4
         308       0.80      1.00      0.89         4
         309       1.00      1.00      1.00         4
         310       0.60      0.75      0.67         4
         311       0.80      0.89      0.84         9
         312       1.00      1.00      1.00         4
         313       1.00      1.00      1.00         5
         314       1.00      1.00      1.00         4
         315       0.50      0.50      0.50         4
         316       1.00      0.50      0.67         4
         317       0.00      0.00      0.00         4
         318       1.00      0.75      0.86         4
         319       1.00      1.00      1.00         5
         320       0.80      1.00      0.89         4
         321       0.00      0.00      0.00         4
         322       0.80      0.80      0.80         5
         323       1.00      1.00      1.00         4
         324       0.75      0.75      0.75         4
         325       1.00      0.75      0.86         4
         326       0.73      0.89      0.80         9
         327       0.50      1.00      0.67         4
         328       1.00      1.00      1.00         9
         329       1.00      1.00      1.00         9
         330       0.80      0.44      0.57         9
         331       0.75      1.00      0.86         9
         332       0.50      0.80      0.62         5
         333       0.00      0.00      0.00         4
         334       0.80      0.89      0.84         9
         335       0.80      1.00      0.89         4
         336       1.00      1.00      1.00         5
         337       1.00      1.00      1.00         5
         338       1.00      0.25      0.40         4
         339       1.00      1.00      1.00         4
         340       0.80      0.89      0.84         9
         341       1.00      1.00      1.00         4
         342       1.00      1.00      1.00         5
         343       0.89      0.89      0.89         9
         344       0.43      0.60      0.50         5
         345       0.67      0.80      0.73         5
         346       0.67      0.50      0.57         4
         347       0.00      0.00      0.00         5
         348       0.56      1.00      0.71         5
         349       1.00      0.75      0.86         4
         350       0.80      1.00      0.89         4
         351       1.00      1.00      1.00         9
         352       1.00      0.50      0.67         4
         353       1.00      0.89      0.94         9
         354       0.60      0.75      0.67         4
         355       1.00      1.00      1.00         4
         356       1.00      0.80      0.89         5
         357       0.80      1.00      0.89         4
         358       1.00      1.00      1.00         9
         359       0.80      1.00      0.89         4
         360       1.00      0.75      0.86         4
         361       0.90      1.00      0.95         9
         362       1.00      1.00      1.00         4
         363       1.00      1.00      1.00         9
         364       1.00      1.00      1.00         9
         365       0.78      0.78      0.78         9
         366       1.00      1.00      1.00         9
         367       0.80      1.00      0.89         4
         368       0.50      0.80      0.62         5
         369       0.80      0.80      0.80         5
         370       0.80      1.00      0.89         4
         371       1.00      0.25      0.40         4
         372       0.75      0.75      0.75         4
         373       0.20      0.25      0.22         4
         374       0.67      0.40      0.50         5
         375       0.00      0.00      0.00         4
         376       1.00      0.89      0.94         9
         377       1.00      0.78      0.88         9
         378       0.00      0.00      0.00         4
         379       1.00      0.80      0.89         5
         380       1.00      1.00      1.00         5
         381       0.00      0.00      0.00         4
         382       0.80      1.00      0.89         4
         383       0.00      0.00      0.00         4
         384       0.43      0.60      0.50         5
         385       0.50      1.00      0.67         5
         386       0.83      1.00      0.91         5
         387       0.00      0.00      0.00         4
         388       1.00      1.00      1.00         5
         389       0.80      0.89      0.84         9
         390       0.75      0.75      0.75         4
         391       1.00      0.89      0.94         9
         392       1.00      1.00      1.00         5
         393       0.80      1.00      0.89         4
         394       1.00      1.00      1.00         5
         395       1.00      0.67      0.80         9
         396       0.67      0.80      0.73         5
         397       0.03      0.11      0.05         9
         398       0.40      0.40      0.40         5
         399       0.09      0.11      0.10         9
         400       0.00      0.00      0.00         4
         401       0.73      0.89      0.80         9
         402       0.00      0.00      0.00         4
         403       1.00      0.60      0.75         5
         404       0.88      0.78      0.82         9
         405       0.67      0.80      0.73         5
         406       0.00      0.00      0.00         4
         407       1.00      1.00      1.00         4
         408       0.00      0.00      0.00         4
         409       1.00      1.00      1.00         9
         410       0.82      1.00      0.90         9
         411       0.16      0.75      0.26         4
         412       0.43      0.75      0.55         4
         413       1.00      0.67      0.80         9
         414       1.00      1.00      1.00         5
         415       1.00      0.75      0.86         4
         416       1.00      1.00      1.00         5
         417       1.00      1.00      1.00         4
         418       0.80      1.00      0.89         4
         419       1.00      0.25      0.40         4
         420       0.86      0.67      0.75         9
         421       1.00      1.00      1.00         4
         422       0.69      1.00      0.82         9
         423       1.00      1.00      1.00         4
         424       0.83      1.00      0.91         5
         425       0.00      0.00      0.00         4
         426       1.00      1.00      1.00         5
         427       0.50      0.25      0.33         4
         428       1.00      1.00      1.00         4
         429       1.00      0.80      0.89         5
         430       1.00      0.89      0.94         9
         431       1.00      0.80      0.89         5
         432       1.00      0.80      0.89         5
         433       0.33      0.25      0.29         4
         434       0.88      0.78      0.82         9
         435       1.00      0.89      0.94         9
         436       0.56      1.00      0.72         9
         437       0.80      0.80      0.80         5
         438       0.80      1.00      0.89         4
         439       1.00      1.00      1.00         4
         440       0.14      0.25      0.18         4
         441       1.00      1.00      1.00         5
         442       0.50      0.89      0.64         9
         443       1.00      0.75      0.86         4
         444       1.00      0.75      0.86         4
         445       0.40      0.50      0.44         4
         446       1.00      0.50      0.67         4
         447       0.73      0.89      0.80         9
         448       0.80      1.00      0.89         4
         449       0.00      0.00      0.00         9
         450       0.67      1.00      0.80         4
         451       0.50      0.75      0.60         4
         452       0.33      0.40      0.36         5
         453       1.00      1.00      1.00         5
         454       1.00      1.00      1.00         4
         455       1.00      0.50      0.67         4
         456       1.00      1.00      1.00         5
         457       1.00      1.00      1.00         4
         458       0.82      1.00      0.90         9
         459       1.00      1.00      1.00         5
         460       0.86      0.67      0.75         9
         461       1.00      0.88      0.93         8
         462       0.67      0.89      0.76         9
         463       0.40      0.22      0.29         9
         464       0.75      0.75      0.75         4
         465       1.00      0.80      0.89         5
         466       1.00      0.89      0.94         9
         467       0.75      0.75      0.75         4
         468       0.67      1.00      0.80         4
         469       0.80      1.00      0.89         4
         470       0.80      1.00      0.89         4
         471       1.00      0.50      0.67         4
         472       0.00      0.00      0.00         4
         473       0.62      1.00      0.77         5
         474       0.80      1.00      0.89         4
         475       1.00      1.00      1.00         5
         476       0.50      0.75      0.60         4
         477       0.89      0.89      0.89         9
         478       0.75      0.75      0.75         4
         479       1.00      0.75      0.86         4
         480       0.73      0.89      0.80         9
         481       0.64      0.78      0.70         9
         482       0.44      0.44      0.44         9
         483       0.80      1.00      0.89         4
         484       0.67      1.00      0.80         4
         485       0.75      0.75      0.75         4
         486       0.00      0.00      0.00         4
         487       1.00      0.25      0.40         4
         488       1.00      1.00      1.00         4
         489       1.00      0.50      0.67         4
         490       1.00      1.00      1.00         5
         491       0.14      0.50      0.22         4
         492       1.00      0.80      0.89         5
         493       0.67      0.50      0.57         4
         494       1.00      1.00      1.00         9
         495       0.20      0.22      0.21         9
         496       0.75      0.75      0.75         4
         497       1.00      0.75      0.86         4
         498       0.00      0.00      0.00         4
         499       1.00      1.00      1.00         9
         500       1.00      1.00      1.00         4
         501       1.00      0.89      0.94         9
         502       1.00      0.50      0.67         4
         503       0.82      1.00      0.90         9
         504       0.75      0.75      0.75         4
         505       1.00      1.00      1.00         4
         506       1.00      0.89      0.94         9
         507       1.00      0.50      0.67         4
         508       0.80      1.00      0.89         4
         509       0.90      1.00      0.95         9
         510       1.00      1.00      1.00         4
         511       0.80      1.00      0.89         4
         512       1.00      0.50      0.67         4
         513       0.80      0.89      0.84         9
         514       1.00      0.50      0.67         4
         515       1.00      0.25      0.40         4
         516       0.80      0.80      0.80         5
         517       0.67      0.89      0.76         9
         518       0.00      0.00      0.00         4
         519       0.83      0.56      0.67         9
         520       1.00      0.75      0.86         4
         521       1.00      1.00      1.00         4
         522       0.60      0.75      0.67         4
         523       1.00      1.00      1.00         9
         524       0.00      0.00      0.00         4
         525       0.00      0.00      0.00         4
         526       0.80      0.89      0.84         9
         527       1.00      1.00      1.00         5
         528       1.00      0.25      0.40         4
         529       0.00      0.00      0.00         4
         530       0.00      0.00      0.00         4
         531       1.00      1.00      1.00         4
         532       1.00      1.00      1.00         4
         533       0.89      0.89      0.89         9
         534       0.67      1.00      0.80         4
         535       1.00      0.78      0.88         9
         536       1.00      0.50      0.67         4
         537       0.00      0.00      0.00         9
         538       0.75      0.75      0.75         4
         539       0.00      0.00      0.00         4
         540       0.80      1.00      0.89         4
         541       1.00      1.00      1.00         4
         542       0.80      0.89      0.84         9
         543       0.67      0.50      0.57         4
         544       0.00      0.00      0.00         4
         545       1.00      0.60      0.75         5
         546       1.00      1.00      1.00         9
         547       0.00      0.00      0.00         4
         548       0.00      0.00      0.00         4
         549       0.75      0.75      0.75         4
         550       1.00      0.89      0.94         9
         551       0.55      0.67      0.60         9
         552       0.40      0.40      0.40         5
         553       0.00      0.00      0.00         4
         554       0.75      0.75      0.75         4
         555       0.80      1.00      0.89         4
         556       0.00      0.00      0.00         4
         557       0.00      0.00      0.00         4
         558       0.33      0.25      0.29         4
         559       0.67      1.00      0.80         4
         560       0.75      0.43      0.55         7
         561       0.11      0.25      0.15         4
         562       0.86      0.67      0.75         9
         563       0.67      0.50      0.57         4
         564       1.00      1.00      1.00         4
         565       0.80      1.00      0.89         4
         566       1.00      1.00      1.00         9
         567       1.00      1.00      1.00         4
         568       0.75      1.00      0.86         9
         569       0.60      0.67      0.63         9
         570       0.80      1.00      0.89         4
         571       0.80      1.00      0.89         4
         572       0.45      0.56      0.50         9
         573       0.00      0.00      0.00         4
         574       0.00      0.00      0.00         4
         575       1.00      0.75      0.86         4
         576       0.33      0.25      0.29         4
         577       0.70      0.78      0.74         9
         578       1.00      1.00      1.00         4
         579       1.00      1.00      1.00         4
         580       0.50      0.50      0.50         4
         581       1.00      1.00      1.00         4
         582       1.00      1.00      1.00         5
         583       0.62      0.56      0.59         9
         584       0.67      0.50      0.57         4
         585       1.00      0.75      0.86         4
         586       0.89      0.89      0.89         9
         587       0.50      0.75      0.60         4
         588       0.67      0.80      0.73         5
         589       0.00      0.00      0.00         5
         590       0.75      0.75      0.75         4
         591       0.80      1.00      0.89         4
         592       0.75      0.75      0.75         4
         593       0.50      1.00      0.67         4
         594       1.00      0.56      0.71         9
         595       0.89      0.89      0.89         9
         596       0.50      0.75      0.60         4
         597       0.78      0.78      0.78         9
         598       1.00      1.00      1.00         9
         599       0.89      0.89      0.89         9
         600       1.00      1.00      1.00         9
         601       1.00      0.50      0.67         4
         602       0.11      0.25      0.15         4
         603       1.00      1.00      1.00         4
         604       0.00      0.00      0.00         4
         605       1.00      1.00      1.00         5
         606       0.75      0.75      0.75         4
         607       0.67      0.80      0.73         5
         608       0.80      1.00      0.89         4
         609       0.00      0.00      0.00         4
         610       1.00      0.75      0.86         4
         611       0.60      0.75      0.67         4
         612       0.83      1.00      0.91         5
         613       0.50      0.56      0.53         9
         614       1.00      0.80      0.89         5
         615       0.71      1.00      0.83         5
         616       0.83      0.56      0.67         9
         617       0.00      0.00      0.00         4
         618       0.80      1.00      0.89         4
         619       0.75      0.60      0.67         5
         620       0.80      1.00      0.89         4
         621       0.75      0.60      0.67         5
         622       0.43      0.75      0.55         4
         623       0.00      0.00      0.00         4
         624       1.00      0.80      0.89         5
         625       1.00      1.00      1.00         9
         626       1.00      0.80      0.89         5
         627       0.86      0.67      0.75         9
         628       0.50      0.25      0.33         4
         629       1.00      0.78      0.88         9
         630       0.40      0.50      0.44         4
         631       0.33      0.25      0.29         4
         632       0.00      0.00      0.00         4
         633       0.82      1.00      0.90         9
         634       0.67      1.00      0.80         4
         635       1.00      1.00      1.00         4
         636       0.67      0.80      0.73         5
         637       0.60      0.75      0.67         4
         638       0.00      0.00      0.00         4
         639       0.00      0.00      0.00         4
         640       0.88      0.78      0.82         9
         641       1.00      1.00      1.00         4
         642       0.00      0.00      0.00         9
         643       1.00      0.50      0.67         4
         644       0.73      0.89      0.80         9
         645       1.00      1.00      1.00         5
         646       0.50      0.50      0.50         4
         647       1.00      1.00      1.00         4
         648       0.07      0.25      0.11         4
         649       0.78      0.78      0.78         9
         650       1.00      0.50      0.67         4
         651       0.75      0.75      0.75         4
         652       0.80      0.80      0.80         5
         653       1.00      1.00      1.00         4
         654       0.00      0.00      0.00         4
         655       0.73      0.89      0.80         9
         656       0.50      0.50      0.50         4
         657       0.80      1.00      0.89         4
         658       0.75      0.67      0.71         9
         659       0.43      0.33      0.38         9
         660       1.00      1.00      1.00         9
         661       0.00      0.00      0.00         4
         662       1.00      1.00      1.00         4
         663       0.00      0.00      0.00         4
         664       1.00      0.89      0.94         9
         665       0.75      0.75      0.75         4
         666       1.00      1.00      1.00         4
         667       0.60      0.75      0.67         4
         668       1.00      1.00      1.00         4
         669       0.00      0.00      0.00         4
         670       0.00      0.00      0.00         9
         671       0.83      1.00      0.91         5
         672       1.00      0.80      0.89         5
         673       0.80      1.00      0.89         4
         674       0.60      0.75      0.67         4
         675       0.89      0.89      0.89         9
         676       1.00      0.75      0.86         4
         677       1.00      1.00      1.00         9
         678       0.80      1.00      0.89         4
         679       1.00      1.00      1.00         9
         680       0.80      1.00      0.89         4
         681       0.00      0.00      0.00         9
         682       1.00      1.00      1.00         9
         683       0.00      0.00      0.00         4
         684       0.67      0.44      0.53         9
         685       1.00      0.75      0.86         4
         686       0.50      0.75      0.60         4
         687       1.00      0.60      0.75         5
         688       0.67      0.67      0.67         9
         689       0.00      0.00      0.00         4
         690       1.00      0.80      0.89         5
         691       1.00      0.89      0.94         9
         692       0.78      0.78      0.78         9
         693       1.00      1.00      1.00         4
         694       0.67      1.00      0.80         4
         695       0.57      0.80      0.67         5
         696       0.00      0.00      0.00         4
         697       1.00      0.89      0.94         9
         698       0.80      1.00      0.89         4
         699       1.00      1.00      1.00         4
         700       1.00      0.50      0.67         4
         701       0.00      0.00      0.00         4
         702       0.70      0.78      0.74         9
         703       0.00      0.00      0.00         4
         704       0.00      0.00      0.00         4
         705       0.00      0.00      0.00         4
         706       0.80      0.89      0.84         9
         707       1.00      0.89      0.94         9
         708       0.00      0.00      0.00         4
         709       1.00      1.00      1.00         4
         710       0.78      0.78      0.78         9
         711       1.00      0.67      0.80         9
         712       1.00      0.50      0.67         4
         713       0.71      1.00      0.83         5
         714       0.62      1.00      0.77         5
         715       0.80      1.00      0.89         4
         716       1.00      0.50      0.67         4
         717       0.75      0.75      0.75         4
         718       1.00      0.75      0.86         4
         719       0.00      0.00      0.00         9
         720       0.55      0.67      0.60         9
         721       0.75      0.60      0.67         5
         722       1.00      0.80      0.89         5
         723       0.71      1.00      0.83         5
         724       1.00      0.75      0.86         4
         725       1.00      0.60      0.75         5
         726       0.60      0.60      0.60         5
         727       0.67      0.50      0.57         4
         728       1.00      1.00      1.00         9
         729       1.00      0.75      0.86         4
         730       1.00      1.00      1.00         5
         731       0.83      1.00      0.91         5
         732       0.67      1.00      0.80         4
         733       0.33      0.25      0.29         4
         734       0.80      1.00      0.89         4
         735       0.75      0.67      0.71         9
         736       1.00      0.75      0.86         4
         737       0.75      0.75      0.75         4
         738       0.60      0.75      0.67         4
         739       0.90      1.00      0.95         9
         740       1.00      0.89      0.94         9
         741       0.40      0.50      0.44         4
         742       0.89      0.89      0.89         9
         743       0.00      0.00      0.00         4
         744       0.67      0.67      0.67         9
         745       0.50      0.40      0.44         5
         746       1.00      1.00      1.00         4
         747       1.00      1.00      1.00         4
         748       0.00      0.00      0.00         4
         749       0.71      1.00      0.83         5
         750       0.11      0.25      0.15         4
         751       0.80      0.80      0.80         5
         752       0.69      1.00      0.82         9
         753       0.75      0.67      0.71         9
         754       0.80      1.00      0.89         4
         755       1.00      0.50      0.67         4
         756       0.00      0.00      0.00         4
         757       0.09      0.25      0.13         4
         758       1.00      0.80      0.89         5
         759       0.56      1.00      0.71         5
         760       1.00      1.00      1.00         4
         761       1.00      1.00      1.00         4
         762       0.75      0.60      0.67         5
         763       0.00      0.00      0.00         4
         764       0.75      1.00      0.86         9
         765       0.00      0.00      0.00         4
         766       1.00      0.75      0.86         4
         767       0.83      1.00      0.91         5
         768       1.00      0.75      0.86         4
         769       1.00      0.89      0.94         9
         770       1.00      0.50      0.67         4
         771       0.67      0.50      0.57         4
         772       1.00      1.00      1.00         9
         773       1.00      0.25      0.40         4
         774       1.00      0.67      0.80         9
         775       1.00      0.50      0.67         4
         776       1.00      0.78      0.88         9
         777       0.60      0.75      0.67         4
         778       0.67      1.00      0.80         4
         779       1.00      0.75      0.86         4
         780       0.83      0.56      0.67         9
         781       0.80      1.00      0.89         4
         782       0.75      0.75      0.75         4
         783       0.80      1.00      0.89         4
         784       1.00      0.88      0.93         8
         785       1.00      0.89      0.94         9
         786       1.00      1.00      1.00         4
         787       0.89      0.89      0.89         9
         788       0.90      1.00      0.95         9
         789       1.00      0.50      0.67         4
         790       1.00      0.25      0.40         4
         791       0.00      0.00      0.00         4
         792       0.75      1.00      0.86         9
         793       1.00      0.75      0.86         4
         794       0.80      1.00      0.89         4
         795       1.00      1.00      1.00         4
         796       0.75      0.67      0.71         9
         797       1.00      0.50      0.67         4
         798       0.60      0.75      0.67         4
         799       1.00      0.89      0.94         9
         800       1.00      0.80      0.89         5
         801       0.80      1.00      0.89         4
         802       0.75      0.75      0.75         4
         803       0.83      1.00      0.91         5
         804       0.90      1.00      0.95         9
         805       0.75      0.75      0.75         4
         806       0.75      0.75      0.75         4
         807       1.00      0.78      0.88         9
         808       0.82      1.00      0.90         9
         809       0.83      1.00      0.91         5
         810       0.00      0.00      0.00         9
         811       0.67      1.00      0.80         4
         812       0.75      0.75      0.75         4
         813       1.00      0.80      0.89         5
         814       0.00      0.00      0.00         4
         815       1.00      0.89      0.94         9
         816       0.80      1.00      0.89         4
         817       1.00      1.00      1.00         4
         818       0.67      1.00      0.80         4
         819       1.00      1.00      1.00         5
         820       1.00      1.00      1.00         4
         821       0.50      0.56      0.53         9
         822       0.83      1.00      0.91         5
         823       0.90      1.00      0.95         9
         824       1.00      1.00      1.00         4
         825       1.00      1.00      1.00         4
         826       1.00      1.00      1.00         5
         827       1.00      0.89      0.94         9
         828       1.00      1.00      1.00         5
         829       1.00      1.00      1.00         9
         830       1.00      1.00      1.00         9
         831       1.00      1.00      1.00         4
         832       1.00      0.25      0.40         4
         833       1.00      0.25      0.40         4
         834       1.00      0.89      0.94         9
         835       1.00      1.00      1.00         4
         836       0.75      0.75      0.75         4
         837       0.60      0.75      0.67         4
         838       1.00      0.40      0.57         5
         839       0.80      1.00      0.89         4
         840       0.60      0.67      0.63         9
         841       0.00      0.00      0.00         4
         842       1.00      0.89      0.94         9
         843       0.80      1.00      0.89         4
         844       0.90      1.00      0.95         9
         845       0.00      0.00      0.00         4
         846       1.00      1.00      1.00         4
         847       0.00      0.00      0.00         4
         848       0.69      1.00      0.82         9
         849       0.75      1.00      0.86         9
         850       0.50      0.33      0.40         6
         851       0.00      0.00      0.00         4
         852       0.00      0.00      0.00         9
         853       0.00      0.00      0.00         4
         854       0.88      0.78      0.82         9
         855       0.33      0.50      0.40         4
         856       0.00      0.00      0.00         4
         857       0.80      0.89      0.84         9
         858       0.67      1.00      0.80         4
         859       0.00      0.00      0.00         4
         860       0.00      0.00      0.00         4
         861       0.67      1.00      0.80         4
         862       0.00      0.00      0.00         4
         863       0.67      1.00      0.80         4
         864       0.67      0.50      0.57         4
         865       1.00      0.80      0.89         5
         866       0.40      0.50      0.44         4
         867       0.80      0.80      0.80         5
         868       0.67      0.50      0.57         4
         869       0.75      0.60      0.67         5
         870       0.50      0.25      0.33         4
         871       0.00      0.00      0.00         4
         872       1.00      1.00      1.00         5
         873       1.00      0.75      0.86         4
         874       0.33      0.25      0.29         4
         875       0.90      1.00      0.95         9
         876       1.00      1.00      1.00         4
         877       0.50      0.25      0.33         4
         878       0.00      0.00      0.00         4
         879       1.00      0.75      0.86         4
         880       1.00      0.89      0.94         9
         881       0.67      1.00      0.80         4
         882       0.67      1.00      0.80         4
         883       0.75      0.75      0.75         4
         884       0.80      1.00      0.89         4
         885       0.50      0.75      0.60         4
         886       0.00      0.00      0.00         9
         887       0.80      0.89      0.84         9
         888       0.33      0.20      0.25         5
         889       0.78      0.78      0.78         9
         890       1.00      0.56      0.71         9
         891       0.80      1.00      0.89         4
         892       1.00      0.89      0.94         9
         893       0.90      1.00      0.95         9

    accuracy                           0.71      4917
   macro avg       0.71      0.69      0.68      4917
weighted avg       0.72      0.71      0.70      4917

task_train_time: {0: 0.12288825599999953, 1: 0.04001507999999987, 2: 0.03862597700000059, 3: 0.03251910500000044, 4: 0.031190866000001094, 5: 0.034852834999998805, 6: 0.027293721999999576, 7: 0.026357823999999752, 8: 0.03235679800000035, 9: 0.028884809999999206, 10: 0.028135422000000077, 11: 0.033787544000000835, 12: 0.03809196399999948, 13: 0.02780346099999953, 14: 0.031945569999999535, 15: 0.03001057100000004, 16: 0.033052472999999694, 17: 0.0322781550000002, 18: 0.03286225899999984, 19: 0.03769607199999925, 20: 0.03153572099999913, 21: 0.029789425999998898, 22: 0.028780584999999803, 23: 0.0315723090000013, 24: 0.03104437200000021, 25: 0.03398652999999996, 26: 0.03318302700000153, 27: 0.03332333100000007, 28: 0.030873656999999, 29: 0.03645471199999939, 30: 0.034578143999999256, 31: 0.03249998999999981, 32: 0.03419634500000157, 33: 0.038915820999999795, 34: 0.03407206700000032, 35: 0.029845111000000202, 36: 0.036007955000000536, 37: 0.0297104939999997, 38: 0.03465125700000016, 39: 0.03368459200000018, 40: 0.03298810400000107, 41: 0.03465573300000102, 42: 0.02743058400000109, 43: 0.03805121899999975}
prediction_time: 0.00030250799999009814
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
