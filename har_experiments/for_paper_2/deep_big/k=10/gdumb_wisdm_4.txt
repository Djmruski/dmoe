Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='e0f7d24c-34dd-424d-8f1b-1d0277e94316', conf_timestamp='2023-08-13 15:37:33.082634', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 80.21 % 	 [Task-IL]: 50.52 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 55.7 % 	 [Task-IL]: 39.06 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 47.9 % 	 [Task-IL]: 35.7 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 35.44 % 	 [Task-IL]: 33.0 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 22.55 % 	 [Task-IL]: 31.91 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 25.8 % 	 [Task-IL]: 29.72 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 27.78 % 	 [Task-IL]: 28.48 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 21.98 % 	 [Task-IL]: 28.49 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 20.41 % 	 [Task-IL]: 28.33 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.83 % 	 [Task-IL]: 28.51 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 15.89 % 	 [Task-IL]: 28.39 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 12.64 % 	 [Task-IL]: 28.0 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 13.81 % 	 [Task-IL]: 27.69 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 13.38 % 	 [Task-IL]: 27.63 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.22 % 	 [Task-IL]: 26.75 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 14.54 % 	 [Task-IL]: 27.14 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 8.11 % 	 [Task-IL]: 27.18 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.15 % 	 [Task-IL]: 26.67 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 6.72 % 	 [Task-IL]: 26.78 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 8.78 % 	 [Task-IL]: 25.91 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.87 % 	 [Task-IL]: 25.92 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.7 % 	 [Task-IL]: 25.52 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.41 % 	 [Task-IL]: 24.95 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.49 % 	 [Task-IL]: 25.23 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.08 % 	 [Task-IL]: 25.56 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.17 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.95 % 	 [Task-IL]: 26.36 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.24 % 	 [Task-IL]: 26.65 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.21 % 	 [Task-IL]: 26.61 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.6 % 	 [Task-IL]: 26.13 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.83 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.09 % 	 [Task-IL]: 26.06 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 4.72 % 	 [Task-IL]: 26.28 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.4 % 	 [Task-IL]: 26.2 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.21 % 	 [Task-IL]: 26.25 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.0 % 	 [Task-IL]: 26.28 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.58 % 	 [Task-IL]: 26.14 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.86 % 	 [Task-IL]: 25.84 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.78 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.51 % 	 [Task-IL]: 25.43 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.55 % 	 [Task-IL]: 25.56 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.56 % 	 [Task-IL]: 25.86 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.88 % 	 [Task-IL]: 25.96 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({696: 28, 306: 27, 409: 26, 657: 24, 655: 24, 217: 24, 771: 23, 883: 23, 652: 23, 67: 23, 194: 23, 240: 23, 376: 23, 557: 22, 802: 22, 47: 22, 765: 22, 641: 22, 870: 22, 596: 22, 246: 22, 12: 21, 743: 21, 773: 21, 659: 21, 628: 21, 893: 21, 734: 21, 788: 21, 133: 21, 160: 21, 302: 21, 339: 21, 390: 21, 498: 21, 10: 20, 7: 20, 25: 20, 586: 20, 590: 20, 793: 20, 569: 20, 644: 20, 836: 20, 556: 20, 766: 20, 56: 20, 594: 20, 106: 20, 244: 20, 262: 20, 338: 20, 371: 20, 377: 20, 426: 20, 489: 20, 14: 19, 868: 19, 840: 19, 563: 19, 732: 19, 834: 19, 677: 19, 889: 19, 71: 19, 91: 19, 837: 19, 126: 19, 161: 19, 188: 19, 387: 19, 407: 19, 418: 19, 422: 19, 467: 19, 513: 19, 505: 19, 538: 19, 534: 19, 544: 19, 736: 18, 687: 18, 822: 18, 752: 18, 832: 18, 555: 18, 609: 18, 881: 18, 668: 18, 875: 18, 835: 18, 693: 18, 774: 18, 64: 18, 108: 18, 94: 18, 113: 18, 159: 18, 172: 18, 182: 18, 208: 18, 197: 18, 348: 18, 352: 18, 368: 18, 381: 18, 386: 18, 402: 18, 484: 18, 480: 18, 491: 18, 502: 18, 494: 18, 499: 18, 528: 18, 11: 17, 24: 17, 818: 17, 700: 17, 789: 17, 824: 17, 762: 17, 787: 17, 819: 17, 34: 17, 591: 17, 855: 17, 799: 17, 783: 17, 630: 17, 665: 17, 606: 17, 654: 17, 100: 17, 581: 17, 115: 17, 152: 17, 134: 17, 179: 17, 346: 17, 408: 17, 453: 17, 449: 17, 532: 17, 536: 17, 547: 17, 562: 16, 867: 16, 564: 16, 585: 16, 589: 16, 622: 16, 614: 16, 52: 16, 554: 16, 61: 16, 826: 16, 99: 16, 105: 16, 123: 16, 121: 16, 145: 16, 206: 16, 256: 16, 267: 16, 270: 16, 291: 16, 328: 16, 327: 16, 340: 16, 337: 16, 379: 16, 399: 16, 423: 16, 424: 16, 471: 16, 456: 16, 537: 16, 546: 16, 9: 15, 805: 15, 603: 15, 44: 15, 746: 15, 62: 15, 761: 15, 90: 15, 684: 15, 670: 15, 110: 15, 122: 15, 153: 15, 190: 15, 195: 15, 364: 15, 403: 15, 472: 15, 518: 15, 520: 15, 28: 14, 816: 14, 666: 14, 808: 14, 877: 14, 618: 14, 750: 14, 725: 14, 851: 14, 48: 14, 663: 14, 103: 14, 116: 14, 170: 14, 224: 14, 232: 14, 247: 14, 275: 14, 288: 14, 344: 14, 366: 14, 398: 14, 487: 14, 739: 13, 656: 13, 853: 13, 849: 13, 695: 13, 219: 13, 350: 13, 383: 13, 429: 13, 441: 13, 478: 13, 501: 13, 782: 12, 791: 12, 647: 12, 43: 12, 692: 12, 686: 12, 96: 12, 107: 12, 796: 12, 173: 12, 154: 12, 276: 12, 280: 12, 286: 12, 359: 12, 362: 12, 479: 12, 549: 12, 1: 11, 31: 11, 26: 11, 637: 11, 828: 11, 768: 11, 729: 11, 640: 11, 708: 11, 643: 11, 567: 11, 820: 11, 164: 11, 165: 11, 178: 11, 624: 11, 226: 11, 248: 11, 268: 11, 265: 11, 260: 11, 380: 11, 450: 11, 463: 11, 526: 11, 531: 11, 6: 10, 676: 10, 3: 10, 30: 10, 19: 10, 605: 10, 22: 10, 767: 10, 850: 10, 653: 10, 742: 10, 599: 10, 572: 10, 886: 10, 772: 10, 878: 10, 809: 10, 587: 10, 66: 10, 801: 10, 807: 10, 717: 10, 748: 10, 716: 10, 82: 10, 619: 10, 600: 10, 97: 10, 838: 10, 125: 10, 130: 10, 648: 10, 671: 10, 722: 10, 176: 10, 200: 10, 209: 10, 218: 10, 243: 10, 235: 10, 266: 10, 279: 10, 292: 10, 297: 10, 319: 10, 401: 10, 397: 10, 438: 10, 470: 10, 486: 10, 495: 10, 530: 10, 514: 10, 545: 10, 8: 9, 682: 9, 23: 9, 756: 9, 645: 9, 785: 9, 830: 9, 720: 9, 823: 9, 888: 9, 733: 9, 639: 9, 568: 9, 813: 9, 649: 9, 634: 9, 726: 9, 821: 9, 55: 9, 593: 9, 675: 9, 560: 9, 776: 9, 89: 9, 719: 9, 92: 9, 845: 9, 779: 9, 790: 9, 95: 9, 757: 9, 114: 9, 132: 9, 137: 9, 141: 9, 625: 9, 721: 9, 162: 9, 155: 9, 189: 9, 181: 9, 669: 9, 213: 9, 221: 9, 215: 9, 233: 9, 236: 9, 252: 9, 253: 9, 251: 9, 249: 9, 255: 9, 284: 9, 283: 9, 277: 9, 324: 9, 330: 9, 349: 9, 336: 9, 363: 9, 354: 9, 361: 9, 378: 9, 447: 9, 458: 9, 468: 9, 473: 9, 482: 9, 483: 9, 512: 9, 515: 9, 533: 9, 516: 9, 673: 8, 29: 8, 775: 8, 2: 8, 781: 8, 27: 8, 607: 8, 16: 8, 848: 8, 800: 8, 680: 8, 754: 8, 713: 8, 803: 8, 632: 8, 866: 8, 860: 8, 707: 8, 584: 8, 53: 8, 36: 8, 577: 8, 728: 8, 863: 8, 583: 8, 612: 8, 57: 8, 54: 8, 68: 8, 69: 8, 579: 8, 841: 8, 631: 8, 566: 8, 712: 8, 79: 8, 77: 8, 84: 8, 626: 8, 697: 8, 679: 8, 817: 8, 104: 8, 111: 8, 112: 8, 737: 8, 602: 8, 815: 8, 847: 8, 127: 8, 129: 8, 744: 8, 117: 8, 131: 8, 672: 8, 142: 8, 148: 8, 147: 8, 157: 8, 167: 8, 876: 8, 859: 8, 187: 8, 193: 8, 199: 8, 203: 8, 223: 8, 229: 8, 231: 8, 237: 8, 273: 8, 281: 8, 289: 8, 287: 8, 305: 8, 310: 8, 303: 8, 296: 8, 318: 8, 321: 8, 323: 8, 317: 8, 320: 8, 335: 8, 342: 8, 351: 8, 642: 8, 360: 8, 365: 8, 356: 8, 367: 8, 369: 8, 382: 8, 374: 8, 405: 8, 396: 8, 406: 8, 414: 8, 432: 8, 416: 8, 419: 8, 420: 8, 425: 8, 427: 8, 446: 8, 439: 8, 440: 8, 466: 8, 459: 8, 457: 8, 469: 8, 509: 8, 497: 8, 503: 8, 519: 8, 521: 8, 527: 8, 529: 8, 542: 8, 541: 8, 617: 7, 578: 7, 592: 7, 15: 7, 780: 7, 854: 7, 690: 7, 32: 7, 731: 7, 582: 7, 646: 7, 784: 7, 608: 7, 890: 7, 777: 7, 865: 7, 792: 7, 41: 7, 35: 7, 39: 7, 45: 7, 884: 7, 50: 7, 795: 7, 611: 7, 839: 7, 829: 7, 738: 7, 588: 7, 638: 7, 794: 7, 72: 7, 60: 7, 63: 7, 580: 7, 597: 7, 872: 7, 575: 7, 620: 7, 87: 7, 570: 7, 650: 7, 627: 7, 81: 7, 730: 7, 98: 7, 102: 7, 109: 7, 723: 7, 811: 7, 879: 7, 658: 7, 120: 7, 661: 7, 135: 7, 138: 7, 151: 7, 144: 7, 797: 7, 140: 7, 146: 7, 827: 7, 156: 7, 158: 7, 171: 7, 651: 7, 183: 7, 185: 7, 191: 7, 210: 7, 198: 7, 207: 7, 228: 7, 214: 7, 220: 7, 227: 7, 225: 7, 239: 7, 238: 7, 257: 7, 261: 7, 258: 7, 274: 7, 293: 7, 285: 7, 308: 7, 295: 7, 301: 7, 298: 7, 294: 7, 304: 7, 299: 7, 322: 7, 325: 7, 315: 7, 333: 7, 314: 7, 332: 7, 316: 7, 353: 7, 345: 7, 334: 7, 372: 7, 358: 7, 391: 7, 385: 7, 392: 7, 413: 7, 404: 7, 430: 7, 417: 7, 428: 7, 436: 7, 452: 7, 443: 7, 462: 7, 464: 7, 454: 7, 477: 7, 481: 7, 496: 7, 511: 7, 522: 7, 548: 7, 550: 7, 543: 7, 551: 7, 552: 7, 13: 6, 610: 6, 21: 6, 17: 6, 613: 6, 4: 6, 664: 6, 18: 6, 843: 6, 633: 6, 595: 6, 565: 6, 683: 6, 674: 6, 862: 6, 703: 6, 702: 6, 558: 6, 704: 6, 869: 6, 871: 6, 759: 6, 844: 6, 688: 6, 814: 6, 46: 6, 49: 6, 806: 6, 629: 6, 846: 6, 701: 6, 694: 6, 740: 6, 70: 6, 58: 6, 59: 6, 73: 6, 709: 6, 873: 6, 559: 6, 685: 6, 78: 6, 80: 6, 74: 6, 93: 6, 714: 6, 804: 6, 76: 6, 852: 6, 864: 6, 681: 6, 623: 6, 571: 6, 753: 6, 718: 6, 825: 6, 128: 6, 118: 6, 124: 6, 705: 6, 710: 6, 770: 6, 601: 6, 150: 6, 887: 6, 149: 6, 169: 6, 751: 6, 574: 6, 880: 6, 699: 6, 186: 6, 180: 6, 678: 6, 724: 6, 211: 6, 204: 6, 689: 6, 763: 6, 230: 6, 241: 6, 269: 6, 272: 6, 727: 6, 812: 6, 278: 6, 313: 6, 309: 6, 311: 6, 300: 6, 326: 6, 331: 6, 341: 6, 373: 6, 355: 6, 389: 6, 384: 6, 410: 6, 394: 6, 412: 6, 433: 6, 415: 6, 437: 6, 448: 6, 451: 6, 444: 6, 442: 6, 435: 6, 455: 6, 461: 6, 474: 6, 490: 6, 488: 6, 475: 6, 493: 6, 508: 6, 506: 6, 523: 6, 535: 6, 5: 5, 33: 5, 0: 5, 755: 5, 691: 5, 604: 5, 858: 5, 764: 5, 561: 5, 735: 5, 778: 5, 662: 5, 711: 5, 42: 5, 51: 5, 573: 5, 40: 5, 37: 5, 842: 5, 786: 5, 749: 5, 769: 5, 831: 5, 86: 5, 798: 5, 85: 5, 75: 5, 83: 5, 758: 5, 88: 5, 715: 5, 576: 5, 892: 5, 810: 5, 885: 5, 616: 5, 136: 5, 139: 5, 598: 5, 177: 5, 174: 5, 615: 5, 196: 5, 856: 5, 242: 5, 250: 5, 234: 5, 245: 5, 857: 5, 254: 5, 271: 5, 282: 5, 290: 5, 312: 5, 343: 5, 375: 5, 395: 5, 411: 5, 421: 5, 445: 5, 485: 5, 492: 5, 476: 5, 507: 5, 504: 5, 517: 5, 524: 5, 540: 5, 553: 5, 20: 4, 833: 4, 706: 4, 741: 4, 621: 4, 38: 4, 891: 4, 65: 4, 636: 4, 882: 4, 745: 4, 698: 4, 660: 4, 101: 4, 119: 4, 143: 4, 874: 4, 168: 4, 163: 4, 166: 4, 747: 4, 175: 4, 192: 4, 184: 4, 861: 4, 212: 4, 202: 4, 201: 4, 222: 4, 216: 4, 635: 4, 263: 4, 259: 4, 264: 4, 667: 4, 329: 4, 347: 4, 357: 4, 370: 4, 388: 4, 393: 4, 400: 4, 431: 4, 434: 4, 460: 4, 510: 4, 539: 4, 205: 3, 760: 3, 307: 3, 500: 3, 465: 2, 525: 1})
Total buffer: 8940
fit_time: 77.57935836

Accuracy for 44 task(s): 	 [Class-IL]: 71.17 % 	 [Task-IL]: 30.54 %

CLASS_IL_ACC: 
	[70.3125, 79.62962962962963, 74.31192660550458, 78.94736842105263, 85.60606060606061, 76.47058823529412, 71.56862745098039, 60.71428571428571, 57.28155339805825, 71.96261682242991, 67.3469387755102, 68.86792452830188, 75.23809523809524, 74.10714285714286, 76.34408602150538, 60.0, 80.95238095238095, 62.03703703703704, 66.39344262295081, 61.016949152542374, 63.96396396396396, 70.0, 88.23529411764706, 60.86956521739131, 75.0, 61.32075471698113, 78.99159663865547, 71.07438016528926, 61.94690265486725, 73.83177570093457, 68.22429906542055, 72.38095238095238, 58.64661654135338, 76.47058823529412, 67.3469387755102, 64.28571428571429, 76.10619469026548, 72.56637168141593, 74.78991596638656, 81.73076923076923, 68.0672268907563, 78.04878048780488, 71.84466019417476, 76.78571428571429]
TASK_IL_ACC: 
	[57.291666666666664, 28.703703703703702, 24.770642201834864, 25.263157894736842, 29.545454545454547, 27.73109243697479, 29.411764705882355, 21.428571428571427, 28.155339805825243, 32.71028037383177, 27.55102040816326, 23.58490566037736, 27.61904761904762, 32.142857142857146, 24.731182795698924, 28.421052631578945, 30.952380952380953, 23.14814814814815, 24.59016393442623, 26.27118644067797, 25.225225225225223, 26.0, 28.431372549019606, 27.82608695652174, 36.607142857142854, 28.30188679245283, 36.134453781512605, 36.36363636363637, 20.353982300884958, 31.775700934579437, 29.906542056074763, 26.666666666666668, 30.82706766917293, 28.431372549019606, 34.69387755102041, 23.46938775510204, 33.6283185840708, 22.123893805309734, 24.369747899159663, 27.884615384615387, 31.932773109243694, 35.77235772357724, 28.155339805825243, 94.64285714285714]
f1_micro: 71.2019524100061
f1_macro: 68.25071575629276
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         4
           1       0.71      1.00      0.83         5
           2       0.83      1.00      0.91         5
           3       1.00      1.00      1.00         4
           4       0.75      0.75      0.75         4
           5       1.00      0.25      0.40         4
           6       0.00      0.00      0.00         4
           7       1.00      0.89      0.94         9
           8       0.75      0.60      0.67         5
           9       0.67      0.44      0.53         9
          10       0.82      1.00      0.90         9
          11       0.82      1.00      0.90         9
          12       0.90      1.00      0.95         9
          13       0.80      1.00      0.89         4
          14       1.00      0.89      0.94         9
          15       0.00      0.00      0.00         4
          16       1.00      1.00      1.00         4
          17       0.67      1.00      0.80         4
          18       0.80      1.00      0.89         4
          19       0.00      0.00      0.00         4
          20       0.00      0.00      0.00         4
          21       1.00      1.00      1.00         5
          22       1.00      0.60      0.75         5
          23       0.67      0.40      0.50         5
          24       1.00      0.89      0.94         9
          25       0.00      0.00      0.00         9
          26       1.00      0.86      0.92         7
          27       0.00      0.00      0.00         4
          28       0.88      0.78      0.82         9
          29       1.00      1.00      1.00         4
          30       0.00      0.00      0.00         4
          31       0.67      0.80      0.73         5
          32       0.50      0.75      0.60         4
          33       1.00      1.00      1.00         5
          34       0.90      1.00      0.95         9
          35       0.60      0.75      0.67         4
          36       1.00      0.75      0.86         4
          37       1.00      0.80      0.89         5
          38       1.00      0.75      0.86         4
          39       0.83      1.00      0.91         5
          40       1.00      0.75      0.86         4
          41       1.00      0.80      0.89         5
          42       1.00      0.60      0.75         5
          43       0.67      0.80      0.73         5
          44       0.78      0.78      0.78         9
          45       0.83      1.00      0.91         5
          46       1.00      0.75      0.86         4
          47       0.62      0.56      0.59         9
          48       1.00      0.80      0.89         5
          49       0.80      1.00      0.89         4
          50       1.00      1.00      1.00         4
          51       0.00      0.00      0.00         4
          52       0.75      1.00      0.86         9
          53       1.00      0.80      0.89         5
          54       0.00      0.00      0.00         4
          55       0.00      0.00      0.00         4
          56       1.00      0.89      0.94         9
          57       0.80      1.00      0.89         4
          58       0.75      0.75      0.75         4
          59       0.75      0.75      0.75         4
          60       1.00      1.00      1.00         4
          61       0.80      0.57      0.67         7
          62       1.00      1.00      1.00         9
          63       0.80      1.00      0.89         4
          64       1.00      1.00      1.00         9
          65       1.00      0.75      0.86         4
          66       0.11      0.50      0.18         4
          67       0.88      0.78      0.82         9
          68       0.00      0.00      0.00         4
          69       0.00      0.00      0.00         4
          70       1.00      1.00      1.00         4
          71       1.00      1.00      1.00         9
          72       1.00      0.80      0.89         5
          73       1.00      1.00      1.00         4
          74       1.00      0.75      0.86         4
          75       1.00      1.00      1.00         4
          76       1.00      1.00      1.00         4
          77       0.33      0.40      0.36         5
          78       0.50      0.50      0.50         4
          79       1.00      0.80      0.89         5
          80       1.00      0.80      0.89         5
          81       0.60      0.75      0.67         4
          82       1.00      0.75      0.86         4
          83       0.67      1.00      0.80         4
          84       1.00      1.00      1.00         5
          85       1.00      1.00      1.00         4
          86       1.00      0.50      0.67         4
          87       1.00      1.00      1.00         5
          88       0.80      1.00      0.89         4
          89       0.80      1.00      0.89         4
          90       0.89      0.89      0.89         9
          91       0.90      1.00      0.95         9
          92       0.00      0.00      0.00         4
          93       0.33      0.25      0.29         4
          94       0.71      0.56      0.63         9
          95       0.71      1.00      0.83         5
          96       0.90      1.00      0.95         9
          97       0.33      0.50      0.40         4
          98       0.50      0.50      0.50         4
          99       0.67      0.67      0.67         9
         100       0.56      1.00      0.72         9
         101       1.00      1.00      1.00         4
         102       0.80      1.00      0.89         4
         103       1.00      1.00      1.00         9
         104       0.80      1.00      0.89         4
         105       0.90      1.00      0.95         9
         106       0.67      0.89      0.76         9
         107       0.83      1.00      0.91         5
         108       0.82      1.00      0.90         9
         109       0.00      0.00      0.00         4
         110       1.00      1.00      1.00         9
         111       0.60      0.75      0.67         4
         112       0.40      0.50      0.44         4
         113       0.90      1.00      0.95         9
         114       0.67      1.00      0.80         4
         115       0.78      0.88      0.82         8
         116       0.90      1.00      0.95         9
         117       1.00      0.75      0.86         4
         118       0.00      0.00      0.00         4
         119       0.50      0.25      0.33         4
         120       0.67      0.50      0.57         4
         121       1.00      0.89      0.94         9
         122       0.57      0.44      0.50         9
         123       1.00      1.00      1.00         9
         124       1.00      1.00      1.00         4
         125       0.75      0.86      0.80         7
         126       0.58      0.78      0.67         9
         127       0.75      0.75      0.75         4
         128       0.00      0.00      0.00         4
         129       0.57      1.00      0.73         4
         130       1.00      1.00      1.00         5
         131       1.00      1.00      1.00         4
         132       1.00      0.80      0.89         5
         133       1.00      0.78      0.88         9
         134       0.89      0.89      0.89         9
         135       0.50      0.75      0.60         4
         136       0.75      0.75      0.75         4
         137       0.67      0.50      0.57         4
         138       0.50      0.75      0.60         4
         139       0.33      0.20      0.25         5
         140       0.60      0.75      0.67         4
         141       0.71      1.00      0.83         5
         142       0.00      0.00      0.00         4
         143       1.00      0.75      0.86         4
         144       0.80      1.00      0.89         4
         145       1.00      0.78      0.88         9
         146       0.80      1.00      0.89         4
         147       0.00      0.00      0.00         4
         148       0.80      1.00      0.89         4
         149       0.67      0.50      0.57         4
         150       1.00      0.75      0.86         4
         151       0.80      1.00      0.89         4
         152       0.90      1.00      0.95         9
         153       0.83      0.56      0.67         9
         154       0.89      0.89      0.89         9
         155       0.00      0.00      0.00         4
         156       0.67      0.50      0.57         4
         157       1.00      1.00      1.00         4
         158       1.00      0.75      0.86         4
         159       0.00      0.00      0.00         9
         160       0.78      0.78      0.78         9
         161       0.50      0.67      0.57         9
         162       0.00      0.00      0.00         4
         163       0.00      0.00      0.00         4
         164       1.00      0.80      0.89         5
         165       0.67      1.00      0.80         4
         166       0.80      1.00      0.89         4
         167       0.50      0.50      0.50         4
         168       0.00      0.00      0.00         4
         169       1.00      0.75      0.86         4
         170       1.00      0.89      0.94         9
         171       0.00      0.00      0.00         4
         172       1.00      1.00      1.00         9
         173       0.80      0.80      0.80         5
         174       0.00      0.00      0.00         4
         175       1.00      0.40      0.57         5
         176       0.60      0.75      0.67         4
         177       0.75      0.75      0.75         4
         178       1.00      1.00      1.00         4
         179       0.33      0.33      0.33         9
         180       0.67      0.50      0.57         4
         181       1.00      1.00      1.00         5
         182       1.00      0.89      0.94         9
         183       0.60      0.75      0.67         4
         184       1.00      0.75      0.86         4
         185       0.67      0.80      0.73         5
         186       0.00      0.00      0.00         4
         187       1.00      0.50      0.67         4
         188       0.82      1.00      0.90         9
         189       0.00      0.00      0.00         4
         190       0.80      0.89      0.84         9
         191       0.00      0.00      0.00         4
         192       0.00      0.00      0.00         4
         193       0.00      0.00      0.00         4
         194       1.00      0.89      0.94         9
         195       0.73      0.89      0.80         9
         196       0.80      1.00      0.89         4
         197       1.00      0.44      0.62         9
         198       1.00      1.00      1.00         4
         199       0.60      0.75      0.67         4
         200       0.80      0.80      0.80         5
         201       1.00      0.75      0.86         4
         202       1.00      0.50      0.67         4
         203       0.67      0.50      0.57         4
         204       1.00      0.75      0.86         4
         205       1.00      0.50      0.67         4
         206       1.00      0.89      0.94         9
         207       0.50      0.75      0.60         4
         208       0.89      0.89      0.89         9
         209       0.71      1.00      0.83         5
         210       0.00      0.00      0.00         4
         211       1.00      0.75      0.86         4
         212       0.00      0.00      0.00         4
         213       0.75      0.75      0.75         4
         214       0.00      0.00      0.00         4
         215       0.00      0.00      0.00         4
         216       0.00      0.00      0.00         4
         217       0.78      0.78      0.78         9
         218       0.00      0.00      0.00         4
         219       0.80      0.80      0.80         5
         220       1.00      0.75      0.86         4
         221       1.00      0.80      0.89         5
         222       0.40      0.50      0.44         4
         223       0.80      1.00      0.89         4
         224       1.00      0.89      0.94         9
         225       1.00      1.00      1.00         4
         226       0.67      0.40      0.50         5
         227       1.00      0.75      0.86         4
         228       0.80      1.00      0.89         4
         229       0.80      1.00      0.89         4
         230       0.00      0.00      0.00         4
         231       0.80      1.00      0.89         4
         232       1.00      1.00      1.00         9
         233       0.80      1.00      0.89         4
         234       0.00      0.00      0.00         4
         235       0.75      0.75      0.75         4
         236       1.00      1.00      1.00         5
         237       0.60      0.75      0.67         4
         238       1.00      1.00      1.00         4
         239       0.00      0.00      0.00         4
         240       0.80      0.89      0.84         9
         241       0.00      0.00      0.00         4
         242       1.00      0.50      0.67         4
         243       0.57      0.80      0.67         5
         244       0.60      0.67      0.63         9
         245       1.00      1.00      1.00         4
         246       0.89      0.89      0.89         9
         247       0.67      0.67      0.67         9
         248       1.00      1.00      1.00         5
         249       0.80      1.00      0.89         4
         250       0.00      0.00      0.00         4
         251       1.00      0.67      0.80         6
         252       0.75      0.60      0.67         5
         253       0.33      1.00      0.50         4
         254       1.00      0.50      0.67         4
         255       0.80      1.00      0.89         4
         256       1.00      1.00      1.00         9
         257       0.43      0.75      0.55         4
         258       0.00      0.00      0.00         5
         259       0.75      0.75      0.75         4
         260       0.62      1.00      0.77         5
         261       0.60      0.75      0.67         4
         262       0.82      1.00      0.90         9
         263       0.33      0.50      0.40         4
         264       1.00      0.75      0.86         4
         265       1.00      1.00      1.00         4
         266       1.00      0.60      0.75         5
         267       0.78      0.78      0.78         9
         268       1.00      1.00      1.00         5
         269       0.00      0.00      0.00         5
         270       0.90      1.00      0.95         9
         271       0.00      0.00      0.00         4
         272       1.00      1.00      1.00         4
         273       1.00      1.00      1.00         4
         274       1.00      1.00      1.00         5
         275       0.00      0.00      0.00         9
         276       0.90      1.00      0.95         9
         277       0.17      0.20      0.18         5
         278       0.75      0.75      0.75         4
         279       0.67      0.50      0.57         4
         280       1.00      0.80      0.89         5
         281       0.60      0.60      0.60         5
         282       1.00      1.00      1.00         4
         283       0.60      0.60      0.60         5
         284       1.00      1.00      1.00         4
         285       0.57      1.00      0.73         4
         286       1.00      1.00      1.00         9
         287       1.00      1.00      1.00         4
         288       1.00      0.78      0.88         9
         289       0.00      0.00      0.00         4
         290       0.57      0.80      0.67         5
         291       0.89      0.89      0.89         9
         292       0.83      1.00      0.91         5
         293       0.80      1.00      0.89         4
         294       1.00      0.75      0.86         4
         295       1.00      0.40      0.57         5
         296       0.33      0.50      0.40         4
         297       1.00      0.25      0.40         4
         298       0.80      1.00      0.89         4
         299       0.75      0.75      0.75         4
         300       1.00      0.75      0.86         4
         301       1.00      1.00      1.00         5
         302       1.00      1.00      1.00         9
         303       0.50      1.00      0.67         4
         304       0.67      0.50      0.57         4
         305       0.60      0.75      0.67         4
         306       0.90      1.00      0.95         9
         307       1.00      0.75      0.86         4
         308       0.60      0.75      0.67         4
         309       0.00      0.00      0.00         4
         310       1.00      0.75      0.86         4
         311       0.57      1.00      0.73         4
         312       0.80      0.80      0.80         5
         313       1.00      1.00      1.00         4
         314       1.00      1.00      1.00         4
         315       0.67      0.40      0.50         5
         316       0.80      1.00      0.89         4
         317       0.00      0.00      0.00         4
         318       0.83      1.00      0.91         5
         319       0.57      0.80      0.67         5
         320       1.00      1.00      1.00         4
         321       1.00      1.00      1.00         5
         322       0.00      0.00      0.00         4
         323       0.57      1.00      0.73         4
         324       0.00      0.00      0.00         4
         325       0.80      1.00      0.89         4
         326       0.50      0.50      0.50         4
         327       0.60      0.33      0.43         9
         328       1.00      1.00      1.00         9
         329       1.00      0.75      0.86         4
         330       1.00      0.60      0.75         5
         331       0.00      0.00      0.00         4
         332       0.11      0.25      0.15         4
         333       0.00      0.00      0.00         4
         334       1.00      1.00      1.00         4
         335       1.00      1.00      1.00         4
         336       0.75      0.60      0.67         5
         337       1.00      0.89      0.94         9
         338       0.82      1.00      0.90         9
         339       0.64      0.78      0.70         9
         340       0.88      0.78      0.82         9
         341       1.00      1.00      1.00         4
         342       0.57      1.00      0.73         4
         343       0.50      0.40      0.44         5
         344       0.73      0.89      0.80         9
         345       1.00      0.60      0.75         5
         346       0.82      1.00      0.90         9
         347       0.00      0.00      0.00         4
         348       0.73      0.89      0.80         9
         349       1.00      0.60      0.75         5
         350       1.00      0.40      0.57         5
         351       1.00      1.00      1.00         5
         352       1.00      0.89      0.94         9
         353       1.00      1.00      1.00         4
         354       1.00      1.00      1.00         4
         355       0.00      0.00      0.00         4
         356       0.80      1.00      0.89         4
         357       1.00      0.75      0.86         4
         358       1.00      1.00      1.00         4
         359       0.67      0.80      0.73         5
         360       0.00      0.00      0.00         4
         361       1.00      1.00      1.00         4
         362       0.90      1.00      0.95         9
         363       0.67      1.00      0.80         4
         364       1.00      0.89      0.94         9
         365       0.00      0.00      0.00         4
         366       0.00      0.00      0.00         9
         367       0.75      0.60      0.67         5
         368       1.00      0.89      0.94         9
         369       1.00      0.25      0.40         4
         370       0.75      0.75      0.75         4
         371       0.00      0.00      0.00         9
         372       1.00      1.00      1.00         5
         373       0.50      0.75      0.60         4
         374       1.00      1.00      1.00         4
         375       0.00      0.00      0.00         4
         376       0.00      0.00      0.00         9
         377       0.73      0.89      0.80         9
         378       1.00      1.00      1.00         4
         379       0.88      0.78      0.82         9
         380       0.83      1.00      0.91         5
         381       1.00      1.00      1.00         9
         382       0.00      0.00      0.00         4
         383       0.78      0.78      0.78         9
         384       1.00      0.75      0.86         4
         385       0.00      0.00      0.00         4
         386       1.00      0.89      0.94         9
         387       0.80      0.44      0.57         9
         388       1.00      0.50      0.67         4
         389       1.00      0.80      0.89         5
         390       1.00      0.67      0.80         9
         391       0.75      0.75      0.75         4
         392       0.50      0.75      0.60         4
         393       1.00      1.00      1.00         4
         394       0.75      0.75      0.75         4
         395       0.00      0.00      0.00         4
         396       1.00      0.80      0.89         5
         397       0.00      0.00      0.00         4
         398       0.67      0.22      0.33         9
         399       1.00      1.00      1.00         9
         400       1.00      1.00      1.00         4
         401       1.00      1.00      1.00         4
         402       0.00      0.00      0.00         9
         403       0.86      0.67      0.75         9
         404       0.00      0.00      0.00         4
         405       1.00      0.60      0.75         5
         406       1.00      0.80      0.89         5
         407       0.73      0.89      0.80         9
         408       0.88      0.78      0.82         9
         409       0.70      0.78      0.74         9
         410       0.50      0.25      0.33         4
         411       0.80      1.00      0.89         4
         412       1.00      0.75      0.86         4
         413       1.00      0.75      0.86         4
         414       0.75      0.75      0.75         4
         415       1.00      0.75      0.86         4
         416       1.00      1.00      1.00         4
         417       0.80      1.00      0.89         4
         418       1.00      1.00      1.00         9
         419       0.00      0.00      0.00         4
         420       0.08      0.25      0.12         4
         421       0.75      0.75      0.75         4
         422       0.67      0.22      0.33         9
         423       0.09      0.11      0.10         9
         424       1.00      0.89      0.94         9
         425       0.60      0.60      0.60         5
         426       0.73      0.89      0.80         9
         427       0.67      1.00      0.80         4
         428       1.00      1.00      1.00         4
         429       0.82      1.00      0.90         9
         430       0.00      0.00      0.00         4
         431       0.25      0.25      0.25         4
         432       0.50      0.75      0.60         4
         433       0.20      0.25      0.22         4
         434       0.75      0.60      0.67         5
         435       0.33      0.25      0.29         4
         436       0.17      0.25      0.20         4
         437       0.00      0.00      0.00         4
         438       1.00      0.75      0.86         4
         439       0.83      1.00      0.91         5
         440       0.50      0.50      0.50         4
         441       0.83      0.56      0.67         9
         442       1.00      1.00      1.00         4
         443       1.00      1.00      1.00         5
         444       0.80      1.00      0.89         4
         445       0.00      0.00      0.00         4
         446       1.00      0.75      0.86         4
         447       0.80      1.00      0.89         4
         448       0.00      0.00      0.00         4
         449       1.00      0.89      0.94         9
         450       0.83      1.00      0.91         5
         451       1.00      1.00      1.00         4
         452       0.57      0.80      0.67         5
         453       1.00      1.00      1.00         9
         454       0.67      1.00      0.80         4
         455       1.00      1.00      1.00         4
         456       0.53      0.89      0.67         9
         457       0.75      0.75      0.75         4
         458       1.00      1.00      1.00         5
         459       1.00      0.75      0.86         4
         460       0.75      0.75      0.75         4
         461       1.00      1.00      1.00         4
         462       1.00      1.00      1.00         4
         463       0.33      0.25      0.29         4
         464       1.00      1.00      1.00         5
         465       0.67      0.50      0.57         4
         466       1.00      1.00      1.00         4
         467       0.73      0.89      0.80         9
         468       1.00      1.00      1.00         4
         469       0.80      1.00      0.89         4
         470       1.00      1.00      1.00         4
         471       1.00      0.89      0.94         9
         472       0.89      0.89      0.89         9
         473       1.00      1.00      1.00         4
         474       0.60      0.75      0.67         4
         475       0.33      0.25      0.29         4
         476       1.00      0.50      0.67         4
         477       1.00      1.00      1.00         4
         478       0.00      0.00      0.00         9
         479       0.40      0.22      0.29         9
         480       0.88      0.78      0.82         9
         481       1.00      0.75      0.86         4
         482       0.75      0.75      0.75         4
         483       0.75      0.75      0.75         4
         484       0.89      1.00      0.94         8
         485       0.00      0.00      0.00         4
         486       0.71      1.00      0.83         5
         487       0.88      0.78      0.82         9
         488       0.50      0.25      0.33         4
         489       1.00      0.89      0.94         9
         490       0.00      0.00      0.00         4
         491       0.56      0.56      0.56         9
         492       1.00      1.00      1.00         4
         493       0.80      1.00      0.89         4
         494       0.83      0.56      0.67         9
         495       0.80      0.80      0.80         5
         496       0.83      1.00      0.91         5
         497       0.00      0.00      0.00         4
         498       1.00      1.00      1.00         9
         499       1.00      0.89      0.94         9
         500       1.00      1.00      1.00         4
         501       0.75      0.75      0.75         4
         502       0.88      0.88      0.88         8
         503       0.57      1.00      0.73         4
         504       1.00      0.50      0.67         4
         505       0.89      0.89      0.89         9
         506       0.20      0.25      0.22         4
         507       1.00      0.25      0.40         4
         508       0.80      1.00      0.89         4
         509       1.00      1.00      1.00         4
         510       0.67      1.00      0.80         4
         511       0.00      0.00      0.00         4
         512       1.00      0.40      0.57         5
         513       1.00      1.00      1.00         9
         514       0.80      1.00      0.89         4
         515       0.67      0.50      0.57         4
         516       1.00      1.00      1.00         5
         517       1.00      0.75      0.86         4
         518       0.50      0.56      0.53         9
         519       0.83      1.00      0.91         5
         520       0.80      0.44      0.57         9
         521       0.00      0.00      0.00         4
         522       0.00      0.00      0.00         4
         523       0.00      0.00      0.00         4
         524       0.40      0.50      0.44         4
         525       0.00      0.00      0.00         4
         526       1.00      1.00      1.00         5
         527       0.00      0.00      0.00         4
         528       1.00      0.89      0.94         9
         529       1.00      0.75      0.86         4
         530       0.71      1.00      0.83         5
         531       0.43      0.60      0.50         5
         532       0.88      0.78      0.82         9
         533       0.67      0.80      0.73         5
         534       1.00      1.00      1.00         9
         535       1.00      1.00      1.00         4
         536       0.80      0.89      0.84         9
         537       0.60      0.33      0.43         9
         538       0.80      0.89      0.84         9
         539       0.50      0.75      0.60         4
         540       1.00      0.25      0.40         4
         541       0.00      0.00      0.00         4
         542       1.00      1.00      1.00         4
         543       0.80      1.00      0.89         4
         544       0.62      0.89      0.73         9
         545       1.00      1.00      1.00         5
         546       0.89      0.89      0.89         9
         547       0.80      0.89      0.84         9
         548       0.80      0.80      0.80         5
         549       1.00      1.00      1.00         5
         550       0.60      0.75      0.67         4
         551       1.00      1.00      1.00         4
         552       0.20      0.20      0.20         5
         553       0.80      1.00      0.89         4
         554       0.90      1.00      0.95         9
         555       0.04      0.11      0.06         9
         556       1.00      1.00      1.00         9
         557       0.80      0.89      0.84         9
         558       1.00      1.00      1.00         4
         559       0.67      1.00      0.80         4
         560       0.60      0.75      0.67         4
         561       0.50      0.25      0.33         4
         562       0.89      0.89      0.89         9
         563       0.89      0.89      0.89         9
         564       0.50      0.11      0.18         9
         565       0.75      0.75      0.75         4
         566       1.00      0.75      0.86         4
         567       1.00      1.00      1.00         5
         568       1.00      1.00      1.00         4
         569       0.80      0.89      0.84         9
         570       0.67      1.00      0.80         4
         571       1.00      0.50      0.67         4
         572       0.06      0.25      0.10         4
         573       0.00      0.00      0.00         4
         574       0.00      0.00      0.00         4
         575       0.00      0.00      0.00         4
         576       0.33      0.25      0.29         4
         577       1.00      1.00      1.00         4
         578       0.00      0.00      0.00         4
         579       1.00      0.60      0.75         5
         580       0.71      1.00      0.83         5
         581       0.80      0.89      0.84         9
         582       0.75      0.75      0.75         4
         583       0.33      0.50      0.40         4
         584       0.43      0.75      0.55         4
         585       0.71      0.56      0.63         9
         586       0.89      0.89      0.89         9
         587       0.80      0.80      0.80         5
         588       0.50      0.25      0.33         4
         589       1.00      0.89      0.94         9
         590       0.00      0.00      0.00         9
         591       0.82      1.00      0.90         9
         592       0.75      0.75      0.75         4
         593       0.15      0.75      0.25         4
         594       1.00      0.56      0.71         9
         595       0.60      0.75      0.67         4
         596       1.00      1.00      1.00         9
         597       1.00      0.25      0.40         4
         598       1.00      1.00      1.00         4
         599       0.57      1.00      0.73         4
         600       0.43      0.75      0.55         4
         601       1.00      0.75      0.86         4
         602       0.80      0.80      0.80         5
         603       0.88      0.78      0.82         9
         604       0.67      0.80      0.73         5
         605       1.00      0.75      0.86         4
         606       0.71      0.56      0.63         9
         607       1.00      1.00      1.00         4
         608       1.00      1.00      1.00         4
         609       0.80      0.44      0.57         9
         610       1.00      1.00      1.00         4
         611       1.00      1.00      1.00         4
         612       0.50      0.25      0.33         4
         613       1.00      0.75      0.86         4
         614       1.00      1.00      1.00         9
         615       0.80      1.00      0.89         4
         616       1.00      0.60      0.75         5
         617       1.00      0.75      0.86         4
         618       0.44      0.44      0.44         9
         619       0.67      1.00      0.80         4
         620       0.00      0.00      0.00         4
         621       1.00      0.50      0.67         4
         622       0.78      0.78      0.78         9
         623       1.00      0.75      0.86         4
         624       0.57      1.00      0.73         4
         625       0.75      0.75      0.75         4
         626       0.50      0.40      0.44         5
         627       0.00      0.00      0.00         4
         628       1.00      1.00      1.00         9
         629       1.00      1.00      1.00         4
         630       1.00      1.00      1.00         9
         631       0.75      0.75      0.75         4
         632       0.00      0.00      0.00         4
         633       0.00      0.00      0.00         4
         634       1.00      0.75      0.86         4
         635       1.00      0.75      0.86         4
         636       1.00      0.50      0.67         4
         637       1.00      0.89      0.94         9
         638       1.00      1.00      1.00         4
         639       0.25      0.25      0.25         4
         640       1.00      0.40      0.57         5
         641       0.06      0.11      0.08         9
         642       0.33      0.75      0.46         4
         643       0.71      1.00      0.83         5
         644       0.89      0.89      0.89         9
         645       1.00      0.75      0.86         4
         646       0.33      0.25      0.29         4
         647       1.00      1.00      1.00         5
         648       1.00      0.80      0.89         5
         649       1.00      0.75      0.86         4
         650       0.67      0.80      0.73         5
         651       0.43      0.75      0.55         4
         652       0.90      1.00      0.95         9
         653       1.00      1.00      1.00         4
         654       0.00      0.00      0.00         9
         655       0.50      0.89      0.64         9
         656       0.89      0.89      0.89         9
         657       0.78      0.78      0.78         9
         658       0.67      0.40      0.50         5
         659       0.73      0.89      0.80         9
         660       1.00      1.00      1.00         4
         661       0.33      0.25      0.29         4
         662       0.80      1.00      0.89         4
         663       0.90      1.00      0.95         9
         664       0.11      0.25      0.15         4
         665       0.69      1.00      0.82         9
         666       0.00      0.00      0.00         9
         667       0.71      1.00      0.83         5
         668       0.00      0.00      0.00         9
         669       0.40      0.50      0.44         4
         670       0.71      0.56      0.63         9
         671       0.00      0.00      0.00         4
         672       0.75      0.60      0.67         5
         673       1.00      0.50      0.67         4
         674       1.00      1.00      1.00         4
         675       1.00      1.00      1.00         5
         676       0.50      0.50      0.50         4
         677       1.00      1.00      1.00         9
         678       1.00      1.00      1.00         4
         679       1.00      0.75      0.86         4
         680       0.50      0.75      0.60         4
         681       1.00      1.00      1.00         4
         682       1.00      1.00      1.00         4
         683       0.00      0.00      0.00         4
         684       0.70      0.78      0.74         9
         685       1.00      0.50      0.67         4
         686       1.00      0.60      0.75         5
         687       1.00      1.00      1.00         9
         688       0.33      0.25      0.29         4
         689       1.00      0.75      0.86         4
         690       0.00      0.00      0.00         4
         691       1.00      0.75      0.86         4
         692       0.14      1.00      0.25         4
         693       0.80      0.89      0.84         9
         694       1.00      0.75      0.86         4
         695       1.00      0.89      0.94         9
         696       0.78      0.78      0.78         9
         697       0.67      0.40      0.50         5
         698       1.00      1.00      1.00         4
         699       0.67      1.00      0.80         4
         700       0.88      0.78      0.82         9
         701       0.50      0.75      0.60         4
         702       0.67      0.50      0.57         4
         703       1.00      0.50      0.67         4
         704       0.00      0.00      0.00         4
         705       0.40      0.50      0.44         4
         706       1.00      1.00      1.00         4
         707       0.40      0.50      0.44         4
         708       1.00      0.80      0.89         5
         709       0.50      0.50      0.50         4
         710       0.00      0.00      0.00         4
         711       1.00      0.50      0.67         4
         712       1.00      0.80      0.89         5
         713       0.67      1.00      0.80         4
         714       0.80      1.00      0.89         4
         715       0.00      0.00      0.00         4
         716       1.00      1.00      1.00         5
         717       0.00      0.00      0.00         4
         718       0.33      0.25      0.29         4
         719       1.00      0.80      0.89         5
         720       1.00      0.75      0.86         4
         721       0.67      1.00      0.80         4
         722       0.67      0.80      0.73         5
         723       0.00      0.00      0.00         4
         724       1.00      0.75      0.86         4
         725       0.00      0.00      0.00         9
         726       1.00      0.75      0.86         4
         727       1.00      1.00      1.00         4
         728       0.80      1.00      0.89         4
         729       0.71      0.56      0.63         9
         730       0.60      0.75      0.67         4
         731       1.00      1.00      1.00         4
         732       0.73      0.89      0.80         9
         733       0.80      1.00      0.89         4
         734       0.78      0.78      0.78         9
         735       1.00      0.75      0.86         4
         736       0.89      0.89      0.89         9
         737       0.75      0.75      0.75         4
         738       0.50      0.25      0.33         4
         739       1.00      0.89      0.94         9
         740       0.00      0.00      0.00         4
         741       0.50      0.50      0.50         4
         742       0.67      0.80      0.73         5
         743       0.64      1.00      0.78         9
         744       1.00      1.00      1.00         4
         745       0.80      1.00      0.89         4
         746       1.00      0.78      0.88         9
         747       0.00      0.00      0.00         4
         748       1.00      1.00      1.00         5
         749       0.75      0.75      0.75         4
         750       0.80      0.80      0.80         5
         751       0.80      1.00      0.89         4
         752       1.00      0.67      0.80         9
         753       1.00      1.00      1.00         4
         754       0.83      1.00      0.91         5
         755       1.00      1.00      1.00         4
         756       0.75      0.75      0.75         4
         757       1.00      0.75      0.86         4
         758       0.00      0.00      0.00         4
         759       1.00      0.80      0.89         5
         760       1.00      0.50      0.67         4
         761       0.00      0.00      0.00         9
         762       1.00      1.00      1.00         9
         763       1.00      0.25      0.40         4
         764       1.00      1.00      1.00         4
         765       0.70      0.78      0.74         9
         766       0.69      1.00      0.82         9
         767       1.00      0.50      0.67         4
         768       0.80      1.00      0.89         4
         769       0.67      0.50      0.57         4
         770       0.57      1.00      0.73         4
         771       1.00      0.67      0.80         9
         772       1.00      1.00      1.00         5
         773       0.89      0.89      0.89         9
         774       1.00      0.89      0.94         9
         775       1.00      1.00      1.00         4
         776       0.43      0.60      0.50         5
         777       0.00      0.00      0.00         4
         778       1.00      0.75      0.86         4
         779       0.80      1.00      0.89         4
         780       0.75      0.60      0.67         5
         781       0.05      0.25      0.08         4
         782       0.88      0.78      0.82         9
         783       0.88      0.78      0.82         9
         784       0.00      0.00      0.00         4
         785       1.00      1.00      1.00         5
         786       0.80      1.00      0.89         4
         787       0.80      0.89      0.84         9
         788       0.50      0.56      0.53         9
         789       0.69      1.00      0.82         9
         790       0.57      0.80      0.67         5
         791       0.60      0.75      0.67         4
         792       1.00      1.00      1.00         4
         793       1.00      0.78      0.88         9
         794       1.00      1.00      1.00         5
         795       1.00      0.50      0.67         4
         796       0.00      0.00      0.00         4
         797       0.50      0.75      0.60         4
         798       0.00      0.00      0.00         4
         799       0.90      1.00      0.95         9
         800       0.62      1.00      0.77         5
         801       1.00      0.75      0.86         4
         802       0.90      1.00      0.95         9
         803       1.00      1.00      1.00         5
         804       1.00      1.00      1.00         4
         805       1.00      0.89      0.94         9
         806       1.00      1.00      1.00         4
         807       1.00      1.00      1.00         5
         808       0.89      0.89      0.89         9
         809       0.50      0.75      0.60         4
         810       0.50      0.50      0.50         4
         811       1.00      0.75      0.86         4
         812       1.00      1.00      1.00         4
         813       1.00      0.75      0.86         4
         814       0.00      0.00      0.00         4
         815       0.00      0.00      0.00         4
         816       0.46      0.67      0.55         9
         817       0.50      0.60      0.55         5
         818       0.75      0.67      0.71         9
         819       1.00      0.67      0.80         9
         820       1.00      1.00      1.00         4
         821       1.00      0.75      0.86         4
         822       1.00      1.00      1.00         9
         823       0.00      0.00      0.00         4
         824       0.88      0.78      0.82         9
         825       0.57      1.00      0.73         4
         826       1.00      0.89      0.94         9
         827       1.00      0.50      0.67         4
         828       0.40      0.80      0.53         5
         829       0.71      1.00      0.83         5
         830       1.00      0.60      0.75         5
         831       1.00      0.50      0.67         4
         832       0.90      1.00      0.95         9
         833       0.00      0.00      0.00         4
         834       1.00      1.00      1.00         9
         835       1.00      1.00      1.00         9
         836       1.00      1.00      1.00         9
         837       1.00      0.78      0.88         9
         838       0.33      0.25      0.29         4
         839       1.00      1.00      1.00         4
         840       1.00      1.00      1.00         9
         841       1.00      1.00      1.00         4
         842       1.00      0.75      0.86         4
         843       1.00      1.00      1.00         4
         844       0.00      0.00      0.00         4
         845       1.00      0.25      0.40         4
         846       1.00      1.00      1.00         4
         847       0.80      0.80      0.80         5
         848       1.00      0.40      0.57         5
         849       0.89      0.89      0.89         9
         850       0.73      0.89      0.80         9
         851       1.00      0.67      0.80         9
         852       0.00      0.00      0.00         4
         853       0.67      0.80      0.73         5
         854       0.80      1.00      0.89         4
         855       0.10      0.22      0.14         9
         856       1.00      1.00      1.00         4
         857       0.00      0.00      0.00         4
         858       0.67      0.50      0.57         4
         859       0.75      0.75      0.75         4
         860       0.45      1.00      0.62         5
         861       1.00      1.00      1.00         5
         862       1.00      1.00      1.00         4
         863       0.00      0.00      0.00         4
         864       1.00      1.00      1.00         5
         865       1.00      1.00      1.00         4
         866       1.00      1.00      1.00         4
         867       1.00      0.89      0.94         9
         868       1.00      0.89      0.94         9
         869       1.00      0.75      0.86         4
         870       0.80      0.89      0.84         9
         871       0.08      0.25      0.12         4
         872       1.00      1.00      1.00         4
         873       0.00      0.00      0.00         4
         874       0.80      1.00      0.89         4
         875       1.00      1.00      1.00         9
         876       1.00      1.00      1.00         5
         877       0.09      0.11      0.10         9
         878       1.00      1.00      1.00         4
         879       1.00      0.75      0.86         4
         880       1.00      1.00      1.00         4
         881       1.00      1.00      1.00         9
         882       1.00      0.75      0.86         4
         883       1.00      1.00      1.00         9
         884       1.00      1.00      1.00         4
         885       1.00      1.00      1.00         4
         886       0.80      0.80      0.80         5
         887       1.00      0.75      0.86         4
         888       1.00      0.75      0.86         4
         889       0.06      0.11      0.07         9
         890       1.00      0.75      0.86         4
         891       0.80      1.00      0.89         4
         892       0.75      0.75      0.75         4
         893       0.86      0.67      0.75         9

    accuracy                           0.71      4917
   macro avg       0.71      0.69      0.68      4917
weighted avg       0.73      0.71      0.71      4917

task_train_time: {0: 0.13148161300000005, 1: 0.026686650000000256, 2: 0.026319216999999284, 3: 0.026230323000000055, 4: 0.03447762599999926, 5: 0.027295690999999067, 6: 0.024769090999999577, 7: 0.03083818500000035, 8: 0.03312347800000026, 9: 0.030361490999998964, 10: 0.030476882999998622, 11: 0.032359888000000225, 12: 0.029900902000001395, 13: 0.032471417, 14: 0.027527209000000497, 15: 0.028544491999999977, 16: 0.03682837400000061, 17: 0.03394138300000016, 18: 0.035158032000000006, 19: 0.03569293099999982, 20: 0.03412176500000008, 21: 0.032048471999999606, 22: 0.029167390999999654, 23: 0.03398829200000009, 24: 0.03459528899999853, 25: 0.0307440029999988, 26: 0.036656624000000804, 27: 0.04090084400000116, 28: 0.03652290299999983, 29: 0.03232527000000118, 30: 0.03187089199999882, 31: 0.03424907899999852, 32: 0.04240929799999904, 33: 0.02918286699999939, 34: 0.031331860000001654, 35: 0.031277534999997414, 36: 0.037799067000001685, 37: 0.03455772199999885, 38: 0.03739427600000056, 39: 0.033874216000000956, 40: 0.03533763900000153, 41: 0.03664222500000136, 42: 0.03132036299999896, 43: 0.028045776999999106}
prediction_time: 0.0004070830000131309
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
