Namespace(alpha=0.3, backbone_type='whole', batch_size=20, buffer_size=10, dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', ignore_other_metrics=0, load_data='', lr=0.0001, minibatch_size=20, model='der_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(alpha=0.3, backbone_type='whole', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='1e2ce7eb-f27e-4893-b0aa-a607dcf2880c', conf_timestamp='2023-08-09 14:01:57.724043', dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', ignore_other_metrics=0, load_data='', lr=0.0001, minibatch_size=20, model='der_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 11.11 % 	 [Task-IL]: 11.11 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 9.65 % 	 [Task-IL]: 16.11 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 11.2 % 	 [Task-IL]: 20.05 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 9.97 % 	 [Task-IL]: 21.25 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 6.83 % 	 [Task-IL]: 19.31 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 4.31 % 	 [Task-IL]: 16.83 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 3.33 % 	 [Task-IL]: 15.56 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 3.12 % 	 [Task-IL]: 16.13 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 3.89 % 	 [Task-IL]: 16.45 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 3.75 % 	 [Task-IL]: 15.57 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 2.8 % 	 [Task-IL]: 15.33 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 2.99 % 	 [Task-IL]: 16.49 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 4.42 % 	 [Task-IL]: 17.79 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 3.51 % 	 [Task-IL]: 16.94 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 3.72 % 	 [Task-IL]: 16.67 %

CLASS_IL_ACC: 
	[0.0, 0.0, 1.6666666666666667, 0.0, 0.0, 0.0, 0.0, 10.0, 1.6666666666666667, 0.0, 0.0, 0.0, 16.666666666666664, 12.5, 13.333333333333334]
TASK_IL_ACC: 
	[12.5, 19.166666666666668, 26.666666666666668, 15.833333333333332, 18.333333333333332, 14.166666666666666, 15.0, 21.666666666666668, 12.5, 12.5, 16.666666666666664, 25.833333333333336, 19.166666666666668, 5.0, 15.0]
f1_micro: 3.673245614035088
f1_macro: 1.1949875180089091
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.00      0.00      0.00        12
           2       0.00      0.00      0.00        12
           3       0.00      0.00      0.00        12
           4       0.00      0.00      0.00        12
           5       0.00      0.00      0.00        12
           6       0.00      0.00      0.00        12
           7       0.00      0.00      0.00        12
           8       0.00      0.00      0.00        12
           9       0.00      0.00      0.00        12
          10       0.00      0.00      0.00        12
          11       0.00      0.00      0.00        12
          12       0.00      0.00      0.00        12
          13       0.00      0.00      0.00        12
          14       0.00      0.00      0.00        12
          15       0.00      0.00      0.00        12
          16       0.00      0.00      0.00        12
          17       0.00      0.00      0.00        12
          18       0.00      0.00      0.00        12
          19       0.00      0.00      0.00        12
          20       0.00      0.00      0.00        12
          21       0.00      0.00      0.00        12
          22       0.00      0.00      0.00        12
          23       0.20      0.08      0.12        12
          24       0.00      0.00      0.00        12
          25       0.00      0.00      0.00        12
          26       0.33      0.08      0.13        12
          27       0.00      0.00      0.00        12
          28       0.00      0.00      0.00        12
          29       0.00      0.00      0.00        12
          30       0.00      0.00      0.00        12
          31       0.00      0.00      0.00        12
          32       0.00      0.00      0.00        12
          33       0.00      0.00      0.00        12
          34       0.00      0.00      0.00        12
          35       0.00      0.00      0.00        12
          36       0.00      0.00      0.00        12
          37       0.00      0.00      0.00        12
          38       0.00      0.00      0.00        12
          39       0.00      0.00      0.00        12
          40       0.00      0.00      0.00        12
          41       0.00      0.00      0.00        12
          42       0.00      0.00      0.00        12
          43       0.00      0.00      0.00        12
          44       0.00      0.00      0.00        12
          45       0.00      0.00      0.00        12
          46       0.00      0.00      0.00        12
          47       0.00      0.00      0.00        12
          48       0.00      0.00      0.00        12
          49       0.00      0.00      0.00        12
          50       0.00      0.00      0.00        12
          51       0.00      0.00      0.00        12
          52       0.00      0.00      0.00        12
          53       0.00      0.00      0.00        12
          54       0.00      0.00      0.00        12
          55       0.00      0.00      0.00        12
          56       0.00      0.00      0.00        12
          57       0.00      0.00      0.00        12
          58       0.00      0.00      0.00        12
          59       0.00      0.00      0.00        12
          60       0.00      0.00      0.00        12
          61       0.00      0.00      0.00        12
          62       0.00      0.00      0.00        12
          63       0.00      0.00      0.00        12
          64       0.00      0.00      0.00        12
          65       0.00      0.00      0.00        12
          66       0.00      0.00      0.00        12
          67       0.00      0.00      0.00        12
          68       0.00      0.00      0.00        12
          69       0.00      0.00      0.00        12
          70       0.00      0.00      0.00        12
          71       0.00      0.00      0.00        12
          72       0.00      0.00      0.00        12
          73       0.00      0.00      0.00        12
          74       0.14      1.00      0.24        12
          75       0.00      0.00      0.00        12
          76       0.00      0.00      0.00        12
          77       0.00      0.00      0.00        12
          78       0.00      0.00      0.00        12
          79       0.00      0.00      0.00        12
          80       0.00      0.00      0.00        12
          81       0.00      0.00      0.00        12
          82       0.00      0.00      0.00        12
          83       0.00      0.00      0.00        12
          84       0.00      0.00      0.00        12
          85       0.00      0.00      0.00        12
          86       0.00      0.00      0.00        12
          87       0.12      0.17      0.14        12
          88       0.00      0.00      0.00        12
          89       0.00      0.00      0.00        12
          90       0.00      0.00      0.00        12
          91       0.00      0.00      0.00        12
          92       0.00      0.00      0.00        12
          93       0.00      0.00      0.00        12
          94       0.00      0.00      0.00        12
          95       0.00      0.00      0.00        12
          96       0.00      0.00      0.00        12
          97       0.00      0.00      0.00        12
          98       0.00      0.00      0.00        12
          99       0.00      0.00      0.00        12
         100       0.00      0.00      0.00        12
         101       0.00      0.00      0.00        12
         102       0.00      0.00      0.00        12
         103       0.00      0.00      0.00        12
         104       0.00      0.00      0.00        12
         105       0.00      0.00      0.00        12
         106       0.00      0.00      0.00        12
         107       0.00      0.00      0.00        12
         108       0.00      0.00      0.00        12
         109       0.00      0.00      0.00        12
         110       0.00      0.00      0.00        12
         111       0.00      0.00      0.00        12
         112       0.00      0.00      0.00        12
         113       0.00      0.00      0.00        12
         114       0.00      0.00      0.00        12
         115       0.00      0.00      0.00        12
         116       0.00      0.00      0.00        12
         117       0.00      0.00      0.00        12
         118       0.00      0.00      0.00        12
         119       0.00      0.00      0.00        12
         120       0.00      0.00      0.00        12
         121       0.00      0.00      0.00        12
         122       0.10      0.50      0.16        12
         123       0.00      0.00      0.00        12
         124       0.00      0.00      0.00        12
         125       0.00      0.00      0.00        12
         126       0.17      0.08      0.11        12
         127       0.00      0.00      0.00        12
         128       0.02      0.08      0.03        12
         129       0.00      0.00      0.00        12
         130       0.07      0.67      0.13        12
         131       0.12      0.33      0.17        12
         132       0.00      0.00      0.00        12
         133       0.00      0.00      0.00        12
         134       0.00      0.00      0.00        12
         135       0.00      0.00      0.00        12
         136       0.00      0.00      0.00        12
         137       0.00      0.00      0.00        12
         138       0.00      0.00      0.00        12
         139       0.00      0.00      0.00        12
         140       0.21      1.00      0.34        12
         141       0.09      0.25      0.13        12
         142       0.01      1.00      0.02        12
         143       0.00      0.00      0.00        12
         144       0.00      0.00      0.00        12
         145       0.00      0.00      0.00        12
         146       0.00      0.00      0.00        12
         147       0.04      0.33      0.07        12
         148       0.00      0.00      0.00        12
         149       0.00      0.00      0.00        12
         150       0.00      0.00      0.00        12
         151       0.00      0.00      0.00        12

    accuracy                           0.04      1824
   macro avg       0.01      0.04      0.01      1824
weighted avg       0.01      0.04      0.01      1824

task_train_time: {0: 12.002657223999998, 1: 9.816694221000002, 2: 10.124042217, 3: 9.992254179999996, 4: 9.800137637000006, 5: 9.936295519000005, 6: 10.186295551, 7: 9.832735869999993, 8: 10.075860488999993, 9: 9.750511927999995, 10: 9.905955186, 11: 9.738546324000012, 12: 10.109842710999999, 13: 9.950281953000001, 14: 9.805915909999982}
prediction_time: 0.00025808399999505127
Parameters: 558152
Task parameters: {0: 558152, 1: 558152, 2: 558152, 3: 558152, 4: 558152, 5: 558152, 6: 558152, 7: 558152, 8: 558152, 9: 558152, 10: 558152, 11: 558152, 12: 558152, 13: 558152, 14: 558152}
