Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.01, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='83f17bbc-8b25-4eaa-93f4-15aa0fd4d8d7', conf_timestamp='2023-08-09 12:42:31.544089', cutmix_alpha=None, dataid=4, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.01, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=15, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=12, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=12, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=12, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 97.92 % 	 [Task-IL]: 81.25 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=22, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=22, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=22, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 49.17 % 	 [Task-IL]: 78.75 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=32, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=32, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=32, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 31.67 % 	 [Task-IL]: 77.92 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=42, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=42, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=42, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 29.79 % 	 [Task-IL]: 75.62 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=52, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=52, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=52, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 20.33 % 	 [Task-IL]: 75.58 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=62, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=62, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=62, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 16.67 % 	 [Task-IL]: 74.93 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=72, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=72, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=72, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 14.52 % 	 [Task-IL]: 76.88 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=82, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=82, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=82, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 12.5 % 	 [Task-IL]: 77.41 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=92, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=92, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=92, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 11.02 % 	 [Task-IL]: 75.66 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=102, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=102, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=102, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 9.92 % 	 [Task-IL]: 76.67 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=112, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=112, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=112, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 8.48 % 	 [Task-IL]: 72.13 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=122, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=122, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=122, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 8.19 % 	 [Task-IL]: 70.74 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=132, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=132, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=132, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 7.63 % 	 [Task-IL]: 69.26 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=142, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=142, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=142, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 7.38 % 	 [Task-IL]: 72.47 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=405, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=152, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=405, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=152, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=405, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=152, bias=True)
    )
  )
)
torch.Size([1520, 405])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151]	Counter({117: 20, 73: 18, 40: 17, 106: 17, 93: 16, 85: 16, 41: 16, 16: 16, 23: 16, 144: 16, 131: 15, 141: 15, 34: 15, 19: 15, 58: 15, 6: 15, 142: 14, 70: 14, 59: 14, 102: 14, 4: 14, 134: 14, 76: 14, 114: 14, 116: 13, 137: 13, 151: 13, 8: 13, 138: 13, 43: 13, 100: 13, 121: 13, 130: 13, 78: 13, 47: 12, 97: 12, 46: 12, 92: 12, 65: 12, 113: 12, 29: 12, 9: 12, 56: 12, 123: 12, 122: 12, 24: 12, 124: 12, 36: 12, 88: 11, 33: 11, 5: 11, 15: 11, 25: 11, 80: 11, 52: 11, 67: 11, 61: 11, 38: 11, 150: 11, 21: 11, 90: 11, 110: 11, 104: 11, 108: 11, 27: 11, 87: 11, 101: 11, 129: 11, 2: 11, 83: 10, 12: 10, 55: 10, 66: 10, 143: 10, 112: 10, 0: 10, 145: 10, 82: 10, 39: 10, 53: 10, 17: 10, 105: 10, 119: 10, 62: 10, 57: 10, 81: 10, 120: 9, 11: 9, 35: 9, 99: 9, 149: 9, 125: 9, 148: 9, 96: 9, 69: 9, 37: 9, 135: 9, 77: 9, 136: 9, 44: 9, 146: 9, 84: 9, 30: 8, 45: 8, 115: 8, 32: 8, 133: 8, 31: 8, 51: 8, 63: 8, 91: 7, 111: 7, 107: 7, 75: 7, 140: 7, 103: 7, 71: 7, 13: 7, 28: 7, 139: 7, 14: 6, 94: 6, 109: 6, 50: 6, 60: 6, 86: 6, 74: 6, 72: 6, 126: 6, 68: 6, 3: 6, 128: 6, 26: 6, 7: 6, 64: 6, 147: 6, 127: 6, 132: 6, 95: 5, 18: 5, 48: 5, 42: 5, 79: 5, 20: 5, 118: 5, 89: 5, 49: 5, 22: 4, 98: 4, 1: 4, 54: 4, 10: 4})
fit_time: 4.7683096370000015

Accuracy for 15 task(s): 	 [Class-IL]: 73.22 % 	 [Task-IL]: 76.69 %

CLASS_IL_ACC: 
	[58.333333333333336, 76.66666666666667, 65.83333333333333, 88.33333333333333, 75.83333333333333, 79.16666666666666, 70.0, 66.66666666666666, 73.33333333333333, 67.5, 60.0, 78.33333333333333, 75.0, 80.0, 83.33333333333334]
TASK_IL_ACC: 
	[77.08333333333334, 73.33333333333333, 66.66666666666666, 76.66666666666667, 80.0, 78.33333333333333, 76.66666666666667, 80.0, 74.16666666666667, 73.33333333333333, 64.16666666666667, 78.33333333333333, 78.33333333333333, 76.66666666666667, 96.66666666666667]
f1_micro: 73.02631578947368
f1_macro: 70.54116191764666
              precision    recall  f1-score   support

           0       0.28      0.58      0.38        12
           1       0.00      0.00      0.00        12
           2       0.60      1.00      0.75        12
           3       0.10      0.08      0.09        12
           4       1.00      1.00      1.00        12
           5       1.00      1.00      1.00        12
           6       0.28      0.58      0.38        12
           7       1.00      0.17      0.29        12
           8       0.50      0.42      0.45        12
           9       1.00      0.92      0.96        12
          10       1.00      0.25      0.40        12
          11       1.00      1.00      1.00        12
          12       1.00      1.00      1.00        12
          13       0.38      0.25      0.30        12
          14       0.71      0.42      0.53        12
          15       0.90      0.75      0.82        12
          16       0.67      1.00      0.80        12
          17       0.48      1.00      0.65        12
          18       0.80      0.33      0.47        12
          19       0.67      1.00      0.80        12
          20       0.79      0.92      0.85        12
          21       1.00      1.00      1.00        12
          22       0.80      0.33      0.47        12
          23       0.60      1.00      0.75        12
          24       0.38      1.00      0.55        12
          25       0.92      1.00      0.96        12
          26       0.07      0.08      0.07        12
          27       1.00      1.00      1.00        12
          28       0.00      0.00      0.00        12
          29       0.50      0.25      0.33        12
          30       1.00      0.92      0.96        12
          31       1.00      1.00      1.00        12
          32       0.91      0.83      0.87        12
          33       0.80      1.00      0.89        12
          34       1.00      0.92      0.96        12
          35       0.92      1.00      0.96        12
          36       1.00      1.00      1.00        12
          37       1.00      0.08      0.15        12
          38       1.00      1.00      1.00        12
          39       1.00      1.00      1.00        12
          40       0.92      1.00      0.96        12
          41       1.00      1.00      1.00        12
          42       0.92      1.00      0.96        12
          43       0.92      1.00      0.96        12
          44       0.58      0.92      0.71        12
          45       1.00      1.00      1.00        12
          46       0.92      0.92      0.92        12
          47       1.00      0.67      0.80        12
          48       1.00      0.17      0.29        12
          49       1.00      0.83      0.91        12
          50       0.67      0.33      0.44        12
          51       0.90      0.75      0.82        12
          52       0.48      1.00      0.65        12
          53       0.00      0.00      0.00        12
          54       0.50      1.00      0.67        12
          55       0.79      0.92      0.85        12
          56       1.00      0.92      0.96        12
          57       0.64      0.58      0.61        12
          58       0.77      0.83      0.80        12
          59       0.62      0.83      0.71        12
          60       0.77      0.83      0.80        12
          61       1.00      1.00      1.00        12
          62       1.00      0.58      0.74        12
          63       1.00      0.92      0.96        12
          64       1.00      0.58      0.74        12
          65       0.43      1.00      0.60        12
          66       0.92      1.00      0.96        12
          67       0.47      0.58      0.52        12
          68       0.33      0.08      0.13        12
          69       0.57      0.67      0.62        12
          70       1.00      0.75      0.86        12
          71       1.00      0.83      0.91        12
          72       0.92      1.00      0.96        12
          73       1.00      1.00      1.00        12
          74       1.00      0.58      0.74        12
          75       0.00      0.00      0.00        12
          76       1.00      1.00      1.00        12
          77       0.77      0.83      0.80        12
          78       0.75      0.25      0.38        12
          79       0.00      0.00      0.00        12
          80       1.00      1.00      1.00        12
          81       0.92      1.00      0.96        12
          82       0.50      1.00      0.67        12
          83       1.00      1.00      1.00        12
          84       0.30      0.67      0.41        12
          85       0.00      0.00      0.00        12
          86       0.92      1.00      0.96        12
          87       0.47      0.67      0.55        12
          88       1.00      1.00      1.00        12
          89       1.00      0.08      0.15        12
          90       0.48      0.92      0.63        12
          91       0.92      1.00      0.96        12
          92       1.00      0.92      0.96        12
          93       0.55      1.00      0.71        12
          94       0.67      0.67      0.67        12
          95       1.00      0.08      0.15        12
          96       1.00      1.00      1.00        12
          97       0.67      1.00      0.80        12
          98       1.00      0.17      0.29        12
          99       0.69      0.75      0.72        12
         100       0.92      0.92      0.92        12
         101       0.23      0.25      0.24        12
         102       0.55      1.00      0.71        12
         103       1.00      0.58      0.74        12
         104       1.00      0.25      0.40        12
         105       0.50      0.33      0.40        12
         106       1.00      1.00      1.00        12
         107       0.43      0.25      0.32        12
         108       0.67      0.67      0.67        12
         109       1.00      0.50      0.67        12
         110       0.34      1.00      0.51        12
         111       0.83      0.42      0.56        12
         112       1.00      0.75      0.86        12
         113       0.37      0.58      0.45        12
         114       0.38      0.50      0.43        12
         115       1.00      1.00      1.00        12
         116       0.67      0.67      0.67        12
         117       1.00      0.92      0.96        12
         118       0.71      0.42      0.53        12
         119       1.00      1.00      1.00        12
         120       0.92      1.00      0.96        12
         121       1.00      1.00      1.00        12
         122       1.00      1.00      1.00        12
         123       1.00      0.92      0.96        12
         124       0.80      0.33      0.47        12
         125       1.00      1.00      1.00        12
         126       0.83      0.42      0.56        12
         127       1.00      1.00      1.00        12
         128       0.78      0.58      0.67        12
         129       0.50      1.00      0.67        12
         130       0.30      0.25      0.27        12
         131       0.80      1.00      0.89        12
         132       0.67      0.67      0.67        12
         133       0.75      1.00      0.86        12
         134       0.77      0.83      0.80        12
         135       1.00      0.08      0.15        12
         136       1.00      0.75      0.86        12
         137       0.92      1.00      0.96        12
         138       0.92      1.00      0.96        12
         139       1.00      1.00      1.00        12
         140       0.64      0.75      0.69        12
         141       0.61      0.92      0.73        12
         142       1.00      1.00      1.00        12
         143       0.77      0.83      0.80        12
         144       0.92      1.00      0.96        12
         145       1.00      1.00      1.00        12
         146       0.67      0.50      0.57        12
         147       1.00      0.92      0.96        12
         148       0.37      0.58      0.45        12
         149       0.67      0.50      0.57        12
         150       0.80      1.00      0.89        12
         151       0.67      1.00      0.80        12

    accuracy                           0.73      1824
   macro avg       0.76      0.73      0.71      1824
weighted avg       0.76      0.73      0.71      1824

task_train_time: {0: 8.076640959999999, 1: 6.293224824999999, 2: 6.545855016999997, 3: 6.038613602999998, 4: 5.971433537999999, 5: 6.435212225000001, 6: 6.446873594000003, 7: 6.379561620000004, 8: 6.441865486999994, 9: 6.443255558999994, 10: 6.4348909590000005, 11: 6.551307213000001, 12: 6.366355568999992, 13: 6.48993478300001, 14: 6.4351286339999945}
prediction_time: 0.00027430400000127975
Parameters: 558152
Task parameters: {0: 418012, 1: 428022, 2: 438032, 3: 448042, 4: 458052, 5: 468062, 6: 478072, 7: 488082, 8: 498092, 9: 508102, 10: 518112, 11: 528122, 12: 538132, 13: 548142, 14: 558152}
