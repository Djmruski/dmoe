Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='b511fcb5-87dd-421e-b9f3-9fff09478fa6', conf_timestamp='2023-08-09 12:58:00.364143', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 93.4 % 	 [Task-IL]: 55.33 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 59.09 % 	 [Task-IL]: 42.07 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 52.52 % 	 [Task-IL]: 37.83 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 36.58 % 	 [Task-IL]: 35.31 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 28.6 % 	 [Task-IL]: 33.88 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 24.4 % 	 [Task-IL]: 35.06 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 20.02 % 	 [Task-IL]: 34.21 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 17.91 % 	 [Task-IL]: 33.55 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 20.31 % 	 [Task-IL]: 33.35 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 16.88 % 	 [Task-IL]: 33.17 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 13.68 % 	 [Task-IL]: 32.32 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 14.92 % 	 [Task-IL]: 31.84 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 11.66 % 	 [Task-IL]: 31.5 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.51 % 	 [Task-IL]: 30.94 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 11.82 % 	 [Task-IL]: 30.85 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 9.27 % 	 [Task-IL]: 30.82 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 8.98 % 	 [Task-IL]: 30.85 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.49 % 	 [Task-IL]: 30.56 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.02 % 	 [Task-IL]: 30.2 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 6.22 % 	 [Task-IL]: 29.8 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 6.44 % 	 [Task-IL]: 29.45 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.75 % 	 [Task-IL]: 29.52 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 6.89 % 	 [Task-IL]: 29.3 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.61 % 	 [Task-IL]: 29.24 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.77 % 	 [Task-IL]: 29.57 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.01 % 	 [Task-IL]: 29.68 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.48 % 	 [Task-IL]: 29.64 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 4.95 % 	 [Task-IL]: 29.78 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.11 % 	 [Task-IL]: 29.74 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.47 % 	 [Task-IL]: 29.55 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.33 % 	 [Task-IL]: 29.71 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 4.77 % 	 [Task-IL]: 29.54 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 4.35 % 	 [Task-IL]: 29.38 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.92 % 	 [Task-IL]: 28.8 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.59 % 	 [Task-IL]: 28.78 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.19 % 	 [Task-IL]: 28.73 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.28 % 	 [Task-IL]: 28.79 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.4 % 	 [Task-IL]: 28.79 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.27 % 	 [Task-IL]: 28.68 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.08 % 	 [Task-IL]: 28.59 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.35 % 	 [Task-IL]: 28.98 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 3.81 % 	 [Task-IL]: 28.68 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.33 % 	 [Task-IL]: 28.81 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594
 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612
 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630
 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648
 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666
 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684
 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702
 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720
 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738
 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756
 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774
 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792
 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810
 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828
 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846
 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864
 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882
 883 884 885 886 887 888 889 890 891 892 893]	Counter({853: 32, 709: 30, 707: 28, 751: 28, 786: 27, 561: 27, 8: 27, 367: 27, 319: 27, 222: 27, 395: 26, 692: 26, 350: 26, 712: 25, 471: 25, 54: 25, 25: 24, 299: 24, 772: 24, 884: 24, 314: 24, 346: 24, 37: 24, 572: 24, 523: 24, 479: 23, 265: 23, 780: 23, 151: 23, 178: 23, 155: 23, 389: 23, 457: 23, 381: 23, 880: 23, 94: 23, 469: 22, 337: 22, 135: 22, 683: 22, 72: 22, 383: 22, 313: 22, 654: 22, 144: 22, 512: 21, 49: 21, 831: 21, 195: 21, 116: 21, 859: 21, 616: 21, 589: 21, 306: 21, 107: 21, 822: 21, 210: 21, 205: 20, 61: 20, 224: 20, 857: 20, 26: 20, 815: 20, 249: 20, 796: 20, 544: 20, 594: 20, 717: 20, 403: 20, 851: 19, 198: 19, 260: 19, 619: 19, 119: 19, 696: 19, 749: 19, 621: 19, 366: 19, 283: 19, 145: 19, 432: 19, 4: 19, 463: 19, 705: 19, 423: 18, 331: 18, 801: 18, 765: 18, 230: 18, 465: 18, 455: 18, 806: 18, 255: 18, 511: 18, 728: 18, 114: 18, 782: 18, 34: 18, 227: 18, 100: 18, 257: 18, 311: 18, 374: 18, 93: 18, 467: 17, 197: 17, 45: 17, 409: 17, 42: 17, 810: 17, 75: 17, 848: 17, 377: 17, 161: 17, 541: 17, 768: 17, 293: 17, 390: 17, 879: 17, 360: 17, 501: 17, 579: 17, 489: 17, 871: 17, 267: 17, 297: 17, 516: 17, 623: 17, 330: 17, 211: 17, 118: 17, 122: 17, 425: 17, 587: 17, 735: 16, 538: 16, 495: 16, 631: 16, 680: 16, 472: 16, 226: 16, 189: 16, 186: 16, 143: 16, 559: 16, 30: 16, 166: 16, 406: 16, 638: 16, 442: 16, 551: 16, 711: 16, 2: 16, 404: 16, 671: 16, 842: 16, 433: 16, 185: 16, 855: 15, 861: 15, 562: 15, 451: 15, 878: 15, 13: 15, 629: 15, 304: 15, 539: 15, 687: 15, 263: 15, 583: 15, 3: 15, 375: 15, 175: 15, 478: 15, 307: 15, 475: 15, 641: 15, 563: 15, 264: 15, 543: 15, 152: 15, 802: 15, 47: 15, 700: 15, 80: 15, 437: 15, 499: 14, 336: 14, 362: 14, 558: 14, 419: 14, 405: 14, 657: 14, 333: 14, 170: 14, 574: 14, 382: 14, 203: 14, 27: 14, 117: 14, 177: 14, 354: 14, 401: 14, 365: 14, 856: 14, 689: 14, 663: 14, 223: 14, 460: 14, 101: 14, 525: 14, 91: 14, 821: 14, 697: 14, 610: 13, 418: 13, 324: 13, 169: 13, 424: 13, 660: 13, 760: 13, 763: 13, 312: 13, 87: 13, 200: 13, 817: 13, 391: 13, 670: 13, 601: 13, 493: 13, 690: 13, 745: 13, 308: 13, 738: 13, 85: 13, 681: 13, 28: 13, 466: 13, 502: 13, 694: 12, 627: 12, 393: 12, 759: 12, 427: 12, 739: 12, 723: 12, 633: 12, 32: 12, 392: 12, 64: 12, 566: 12, 643: 12, 139: 12, 727: 12, 814: 12, 699: 12, 742: 12, 44: 12, 428: 12, 77: 12, 737: 12, 891: 12, 445: 12, 645: 12, 278: 12, 67: 12, 14: 12, 282: 12, 287: 12, 661: 12, 440: 12, 527: 12, 514: 12, 582: 12, 321: 12, 82: 12, 688: 12, 620: 12, 553: 12, 132: 11, 618: 11, 557: 11, 585: 11, 134: 11, 254: 11, 490: 11, 339: 11, 291: 11, 838: 11, 673: 11, 704: 11, 826: 11, 317: 11, 636: 11, 327: 11, 323: 11, 606: 11, 703: 11, 849: 11, 351: 11, 352: 11, 446: 11, 747: 11, 298: 11, 626: 11, 334: 11, 386: 11, 399: 11, 356: 10, 824: 10, 788: 10, 444: 10, 12: 10, 246: 10, 225: 10, 355: 10, 518: 10, 743: 10, 296: 10, 40: 10, 684: 10, 149: 10, 578: 10, 652: 10, 777: 10, 731: 10, 397: 10, 863: 10, 138: 10, 740: 10, 758: 10, 716: 10, 830: 10, 84: 10, 818: 10, 229: 10, 536: 10, 305: 10, 865: 10, 301: 10, 669: 10, 245: 10, 698: 10, 775: 10, 277: 10, 625: 10, 591: 10, 79: 10, 497: 10, 592: 10, 725: 10, 462: 10, 702: 10, 555: 10, 458: 10, 123: 10, 106: 10, 888: 10, 776: 10, 651: 10, 605: 10, 498: 10, 800: 10, 757: 10, 447: 10, 655: 10, 88: 10, 882: 10, 515: 10, 250: 9, 216: 9, 59: 9, 29: 9, 567: 9, 303: 9, 482: 9, 402: 9, 522: 9, 244: 9, 713: 9, 593: 9, 280: 9, 829: 9, 228: 9, 533: 9, 770: 9, 580: 9, 36: 9, 781: 9, 188: 9, 89: 9, 565: 9, 396: 9, 1: 9, 504: 9, 194: 9, 252: 9, 436: 9, 31: 9, 412: 9, 764: 9, 180: 9, 429: 9, 481: 9, 421: 9, 353: 9, 870: 9, 48: 9, 873: 9, 176: 9, 434: 9, 129: 9, 546: 9, 105: 9, 167: 9, 171: 9, 607: 9, 400: 9, 600: 9, 202: 9, 693: 9, 68: 9, 843: 9, 548: 9, 332: 9, 596: 9, 78: 9, 519: 9, 730: 9, 335: 9, 570: 9, 766: 9, 454: 9, 76: 9, 510: 9, 373: 9, 534: 9, 35: 9, 174: 9, 746: 9, 165: 9, 613: 8, 532: 8, 125: 8, 674: 8, 58: 8, 542: 8, 236: 8, 199: 8, 156: 8, 414: 8, 804: 8, 370: 8, 7: 8, 513: 8, 163: 8, 624: 8, 309: 8, 17: 8, 803: 8, 162: 8, 649: 8, 215: 8, 785: 8, 426: 8, 137: 8, 528: 8, 820: 8, 115: 8, 240: 8, 431: 8, 201: 8, 218: 8, 147: 8, 154: 8, 464: 8, 710: 8, 597: 8, 150: 8, 272: 8, 576: 8, 488: 8, 376: 8, 893: 8, 756: 8, 509: 8, 274: 8, 70: 8, 887: 8, 872: 8, 714: 8, 564: 8, 494: 8, 602: 8, 62: 8, 741: 8, 160: 8, 869: 8, 834: 8, 102: 8, 816: 8, 368: 8, 846: 8, 666: 8, 862: 8, 284: 8, 474: 8, 531: 8, 575: 8, 461: 8, 611: 8, 181: 8, 545: 8, 261: 8, 892: 8, 316: 8, 111: 8, 443: 8, 840: 8, 20: 8, 158: 8, 153: 8, 517: 8, 325: 8, 21: 8, 622: 8, 706: 8, 789: 8, 675: 8, 484: 8, 500: 8, 868: 8, 835: 8, 644: 8, 634: 8, 867: 8, 234: 8, 614: 7, 207: 7, 130: 7, 790: 7, 242: 7, 410: 7, 16: 7, 456: 7, 289: 7, 52: 7, 811: 7, 507: 7, 63: 7, 136: 7, 241: 7, 604: 7, 310: 7, 695: 7, 812: 7, 748: 7, 24: 7, 615: 7, 141: 7, 315: 7, 560: 7, 269: 7, 416: 7, 302: 7, 290: 7, 468: 7, 664: 7, 83: 7, 647: 7, 668: 7, 608: 7, 342: 7, 415: 7, 505: 7, 281: 7, 833: 7, 787: 7, 348: 7, 187: 7, 349: 7, 450: 7, 448: 7, 51: 7, 340: 7, 127: 7, 220: 7, 491: 7, 420: 7, 388: 7, 550: 7, 295: 7, 238: 7, 676: 7, 126: 7, 275: 7, 66: 7, 556: 7, 173: 7, 537: 7, 371: 7, 813: 7, 212: 7, 5: 7, 577: 7, 581: 7, 659: 7, 480: 7, 108: 7, 836: 7, 883: 7, 256: 7, 595: 7, 55: 7, 247: 7, 43: 7, 422: 7, 328: 7, 271: 7, 131: 7, 208: 7, 793: 7, 819: 7, 783: 7, 96: 7, 387: 6, 33: 6, 784: 6, 809: 6, 808: 6, 828: 6, 259: 6, 662: 6, 630: 6, 146: 6, 854: 6, 779: 6, 262: 6, 326: 6, 508: 6, 95: 6, 57: 6, 588: 6, 103: 6, 598: 6, 206: 6, 204: 6, 734: 6, 726: 6, 590: 6, 773: 6, 183: 6, 380: 6, 682: 6, 866: 6, 850: 6, 535: 6, 413: 6, 584: 6, 648: 6, 347: 6, 22: 6, 237: 6, 11: 6, 686: 6, 292: 6, 408: 6, 552: 6, 9: 6, 53: 6, 379: 6, 733: 6, 438: 6, 109: 6, 140: 6, 56: 6, 640: 6, 722: 6, 38: 6, 10: 6, 839: 6, 459: 6, 435: 6, 411: 6, 253: 6, 795: 6, 214: 6, 845: 6, 586: 6, 794: 6, 679: 6, 881: 6, 453: 6, 0: 6, 74: 6, 837: 6, 860: 6, 232: 6, 667: 6, 744: 6, 363: 6, 720: 6, 732: 6, 721: 6, 98: 6, 646: 6, 632: 5, 69: 5, 485: 5, 279: 5, 540: 5, 110: 5, 322: 5, 124: 5, 656: 5, 875: 5, 60: 5, 678: 5, 285: 5, 65: 5, 172: 5, 685: 5, 81: 5, 248: 5, 184: 5, 258: 5, 359: 5, 86: 5, 273: 5, 718: 5, 128: 5, 104: 5, 571: 5, 486: 5, 858: 5, 665: 5, 827: 5, 148: 5, 890: 5, 364: 5, 650: 5, 864: 5, 219: 5, 473: 5, 112: 5, 526: 5, 18: 5, 774: 5, 487: 5, 847: 5, 762: 5, 286: 5, 384: 5, 378: 5, 761: 5, 341: 5, 39: 5, 708: 5, 807: 5, 832: 5, 642: 5, 270: 5, 372: 5, 357: 5, 778: 5, 658: 5, 182: 5, 294: 5, 755: 5, 179: 5, 521: 5, 503: 5, 719: 5, 617: 5, 701: 5, 407: 5, 874: 5, 639: 5, 797: 5, 496: 5, 477: 5, 825: 5, 338: 5, 164: 5, 221: 4, 506: 4, 233: 4, 120: 4, 73: 4, 266: 4, 344: 4, 190: 4, 715: 4, 876: 4, 15: 4, 476: 4, 889: 4, 877: 4, 569: 4, 191: 4, 398: 4, 6: 4, 217: 4, 753: 4, 771: 4, 547: 4, 441: 4, 452: 4, 791: 4, 209: 4, 142: 4, 653: 4, 628: 4, 345: 4, 844: 4, 530: 4, 573: 4, 329: 4, 231: 4, 300: 4, 524: 4, 736: 4, 672: 4, 691: 4, 823: 4, 121: 4, 724: 4, 113: 4, 805: 4, 637: 4, 23: 4, 520: 4, 71: 4, 449: 4, 243: 4, 394: 4, 320: 3, 251: 3, 798: 3, 885: 3, 729: 3, 677: 3, 193: 3, 168: 3, 439: 3, 369: 3, 612: 3, 385: 3, 50: 3, 417: 3, 239: 3, 97: 3, 90: 3, 769: 3, 792: 3, 799: 3, 750: 3, 268: 3, 196: 3, 41: 3, 599: 3, 276: 3, 430: 3, 886: 3, 609: 3, 318: 3, 752: 3, 358: 3, 99: 3, 343: 3, 470: 3, 361: 3, 288: 3, 529: 2, 754: 2, 767: 2, 235: 2, 568: 2, 852: 2, 841: 2, 192: 2, 549: 2, 133: 2, 492: 2, 635: 2, 159: 2, 554: 2, 213: 2, 603: 2, 92: 1, 19: 1, 46: 1, 157: 1})
fit_time: 27.307915896999987

Accuracy for 44 task(s): 	 [Class-IL]: 65.73 % 	 [Task-IL]: 30.51 %

CLASS_IL_ACC: 
	[68.02030456852792, 61.206896551724135, 52.083333333333336, 66.38655462184873, 70.47619047619048, 50.89285714285714, 69.23076923076923, 64.76190476190476, 66.66666666666666, 61.94690265486725, 57.6271186440678, 58.06451612903226, 75.0, 55.434782608695656, 84.49612403100775, 73.83177570093457, 52.475247524752476, 69.1588785046729, 75.21367521367522, 60.3448275862069, 66.38655462184873, 61.61616161616161, 72.3076923076923, 61.53846153846154, 68.51851851851852, 73.14814814814815, 67.82608695652173, 56.88073394495413, 77.19298245614034, 64.35643564356435, 60.86956521739131, 55.00000000000001, 61.53846153846154, 75.42372881355932, 74.10071942446042, 75.24752475247524, 58.252427184466015, 71.02803738317756, 63.46153846153846, 62.38532110091744, 88.39285714285714, 51.92307692307693, 71.69811320754717, 59.61538461538461]
TASK_IL_ACC: 
	[53.299492385786806, 27.586206896551722, 23.958333333333336, 22.689075630252102, 24.761904761904763, 43.75, 30.76923076923077, 27.61904761904762, 32.407407407407405, 34.51327433628318, 18.64406779661017, 26.881720430107524, 29.310344827586203, 25.0, 29.457364341085274, 31.775700934579437, 30.693069306930692, 24.299065420560748, 23.931623931623932, 24.137931034482758, 25.210084033613445, 30.303030303030305, 25.384615384615383, 32.69230769230769, 31.48148148148148, 31.48148148148148, 30.434782608695656, 31.19266055045872, 30.701754385964914, 29.7029702970297, 31.30434782608696, 32.0, 30.76923076923077, 20.33898305084746, 30.215827338129497, 29.7029702970297, 27.184466019417474, 23.364485981308412, 26.923076923076923, 23.853211009174313, 29.464285714285715, 22.115384615384613, 40.56603773584906, 90.38461538461539]
f1_micro: 66.11755135245068
f1_macro: 62.06611605169685
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       1.00      1.00      1.00         5
           2       0.47      0.89      0.62         9
           3       1.00      0.78      0.88         9
           4       1.00      1.00      1.00         9
           5       0.00      0.00      0.00         4
           6       0.67      0.50      0.57         4
           7       0.75      0.60      0.67         5
           8       0.00      0.00      0.00         9
           9       0.57      1.00      0.73         4
          10       1.00      0.75      0.86         4
          11       1.00      1.00      1.00         4
          12       0.75      0.75      0.75         4
          13       0.71      0.56      0.63         9
          14       0.89      0.89      0.89         9
          15       0.75      0.75      0.75         4
          16       0.18      1.00      0.31         4
          17       1.00      0.60      0.75         5
          18       0.75      0.75      0.75         4
          19       1.00      0.25      0.40         4
          20       0.83      1.00      0.91         5
          21       1.00      0.40      0.57         5
          22       1.00      0.75      0.86         4
          23       0.00      0.00      0.00         4
          24       0.00      0.00      0.00         4
          25       0.67      0.67      0.67         9
          26       0.43      0.67      0.52         9
          27       0.90      1.00      0.95         9
          28       1.00      1.00      1.00         9
          29       0.18      0.75      0.29         4
          30       0.67      0.89      0.76         9
          31       0.56      1.00      0.71         5
          32       0.00      0.00      0.00         4
          33       1.00      0.75      0.86         4
          34       1.00      1.00      1.00         9
          35       1.00      1.00      1.00         4
          36       1.00      1.00      1.00         4
          37       0.73      0.89      0.80         9
          38       0.33      0.50      0.40         4
          39       1.00      0.25      0.40         4
          40       0.80      1.00      0.89         4
          41       0.50      0.50      0.50         4
          42       0.83      0.56      0.67         9
          43       0.00      0.00      0.00         4
          44       0.67      0.44      0.53         9
          45       1.00      0.78      0.88         9
          46       1.00      0.25      0.40         4
          47       0.86      0.67      0.75         9
          48       1.00      0.75      0.86         4
          49       0.88      0.78      0.82         9
          50       0.00      0.00      0.00         4
          51       1.00      0.80      0.89         5
          52       0.00      0.00      0.00         4
          53       0.00      0.00      0.00         4
          54       0.82      1.00      0.90         9
          55       1.00      1.00      1.00         4
          56       1.00      0.25      0.40         4
          57       0.00      0.00      0.00         4
          58       0.00      0.00      0.00         4
          59       0.50      0.75      0.60         4
          60       0.67      0.50      0.57         4
          61       0.00      0.00      0.00         9
          62       0.08      0.25      0.12         4
          63       0.00      0.00      0.00         4
          64       1.00      0.80      0.89         5
          65       1.00      1.00      1.00         4
          66       0.33      0.25      0.29         4
          67       0.33      0.50      0.40         4
          68       1.00      0.25      0.40         4
          69       0.00      0.00      0.00         4
          70       0.80      1.00      0.89         4
          71       1.00      0.75      0.86         4
          72       0.70      0.78      0.74         9
          73       1.00      1.00      1.00         4
          74       0.57      1.00      0.73         4
          75       0.00      0.00      0.00         9
          76       1.00      1.00      1.00         4
          77       1.00      1.00      1.00         5
          78       0.83      1.00      0.91         5
          79       0.80      0.80      0.80         5
          80       0.78      0.78      0.78         9
          81       1.00      0.75      0.86         4
          82       0.75      0.75      0.75         4
          83       0.00      0.00      0.00         4
          84       1.00      1.00      1.00         5
          85       1.00      1.00      1.00         4
          86       0.00      0.00      0.00         4
          87       1.00      0.89      0.94         9
          88       0.82      1.00      0.90         9
          89       0.00      0.00      0.00         9
          90       1.00      0.50      0.67         4
          91       1.00      0.78      0.88         9
          92       1.00      0.25      0.40         4
          93       0.67      0.89      0.76         9
          94       0.90      1.00      0.95         9
          95       1.00      0.80      0.89         5
          96       0.62      1.00      0.77         5
          97       0.00      0.00      0.00         4
          98       1.00      1.00      1.00         4
          99       1.00      0.75      0.86         4
         100       1.00      1.00      1.00         9
         101       0.30      0.33      0.32         9
         102       0.83      1.00      0.91         5
         103       1.00      0.75      0.86         4
         104       1.00      0.75      0.86         4
         105       1.00      1.00      1.00         4
         106       1.00      1.00      1.00         5
         107       0.82      1.00      0.90         9
         108       0.60      0.75      0.67         4
         109       0.00      0.00      0.00         5
         110       1.00      1.00      1.00         4
         111       0.00      0.00      0.00         4
         112       0.00      0.00      0.00         4
         113       1.00      0.25      0.40         4
         114       0.00      0.00      0.00         9
         115       0.10      0.25      0.14         4
         116       1.00      0.89      0.94         9
         117       1.00      1.00      1.00         9
         118       0.80      0.89      0.84         9
         119       0.00      0.00      0.00         9
         120       0.67      0.50      0.57         4
         121       0.67      0.50      0.57         4
         122       0.50      0.44      0.47         9
         123       0.00      0.00      0.00         5
         124       1.00      1.00      1.00         4
         125       0.80      1.00      0.89         4
         126       0.50      0.25      0.33         4
         127       1.00      0.25      0.40         4
         128       0.00      0.00      0.00         4
         129       1.00      1.00      1.00         4
         130       0.00      0.00      0.00         4
         131       1.00      1.00      1.00         4
         132       1.00      1.00      1.00         5
         133       0.00      0.00      0.00         4
         134       0.88      0.78      0.82         9
         135       0.82      1.00      0.90         9
         136       0.67      0.50      0.57         4
         137       0.67      0.80      0.73         5
         138       0.00      0.00      0.00         4
         139       0.56      1.00      0.71         5
         140       0.00      0.00      0.00         4
         141       1.00      0.75      0.86         4
         142       1.00      0.50      0.67         4
         143       0.73      0.89      0.80         9
         144       0.90      1.00      0.95         9
         145       1.00      0.67      0.80         9
         146       1.00      1.00      1.00         4
         147       1.00      1.00      1.00         4
         148       0.00      0.00      0.00         4
         149       0.00      0.00      0.00         4
         150       1.00      1.00      1.00         4
         151       0.89      0.89      0.89         9
         152       1.00      0.56      0.71         9
         153       0.14      0.25      0.18         4
         154       1.00      0.60      0.75         5
         155       1.00      1.00      1.00         9
         156       1.00      0.75      0.86         4
         157       0.00      0.00      0.00         4
         158       1.00      0.50      0.67         4
         159       0.25      0.25      0.25         4
         160       0.67      0.50      0.57         4
         161       1.00      0.56      0.71         9
         162       0.80      1.00      0.89         4
         163       0.00      0.00      0.00         4
         164       0.50      0.75      0.60         4
         165       0.75      0.60      0.67         5
         166       0.50      0.67      0.57         9
         167       0.71      1.00      0.83         5
         168       0.80      1.00      0.89         4
         169       0.71      0.56      0.63         9
         170       0.24      1.00      0.38         5
         171       1.00      0.80      0.89         5
         172       1.00      0.75      0.86         4
         173       0.50      0.25      0.33         4
         174       0.80      1.00      0.89         4
         175       0.30      0.60      0.40         5
         176       1.00      0.50      0.67         4
         177       0.88      0.78      0.82         9
         178       0.90      1.00      0.95         9
         179       0.50      0.75      0.60         4
         180       0.50      0.75      0.60         4
         181       0.60      0.75      0.67         4
         182       0.00      0.00      0.00         4
         183       1.00      1.00      1.00         4
         184       0.80      1.00      0.89         4
         185       0.69      1.00      0.82         9
         186       0.83      1.00      0.91         5
         187       0.36      0.80      0.50         5
         188       0.00      0.00      0.00         9
         189       1.00      0.89      0.94         9
         190       0.00      0.00      0.00         4
         191       1.00      0.50      0.67         4
         192       0.00      0.00      0.00         4
         193       0.33      0.50      0.40         4
         194       1.00      0.75      0.86         4
         195       0.80      0.44      0.57         9
         196       0.67      1.00      0.80         4
         197       1.00      0.78      0.88         9
         198       1.00      1.00      1.00         9
         199       0.67      0.80      0.73         5
         200       0.10      0.75      0.18         4
         201       0.08      0.25      0.12         4
         202       1.00      1.00      1.00         5
         203       0.67      0.40      0.50         5
         204       0.00      0.00      0.00         4
         205       0.67      0.44      0.53         9
         206       0.00      0.00      0.00         4
         207       0.00      0.00      0.00         4
         208       1.00      0.50      0.67         4
         209       1.00      0.75      0.86         4
         210       0.69      1.00      0.82         9
         211       0.80      0.89      0.84         9
         212       0.25      0.50      0.33         4
         213       0.00      0.00      0.00         4
         214       0.00      0.00      0.00         4
         215       0.00      0.00      0.00         5
         216       0.50      0.40      0.44         5
         217       1.00      0.40      0.57         5
         218       1.00      0.50      0.67         4
         219       1.00      0.50      0.67         4
         220       0.50      0.50      0.50         4
         221       0.00      0.00      0.00         4
         222       1.00      1.00      1.00         9
         223       0.88      0.78      0.82         9
         224       0.06      0.22      0.10         9
         225       0.67      1.00      0.80         4
         226       1.00      0.56      0.71         9
         227       0.69      1.00      0.82         9
         228       0.80      1.00      0.89         4
         229       0.00      0.00      0.00         4
         230       1.00      1.00      1.00         9
         231       0.00      0.00      0.00         4
         232       1.00      0.67      0.80         9
         233       1.00      0.75      0.86         4
         234       0.00      0.00      0.00         4
         235       0.00      0.00      0.00         4
         236       1.00      0.80      0.89         5
         237       1.00      1.00      1.00         4
         238       0.80      1.00      0.89         4
         239       1.00      0.75      0.86         4
         240       1.00      0.75      0.86         4
         241       1.00      0.78      0.88         9
         242       0.00      0.00      0.00         4
         243       1.00      0.75      0.86         4
         244       1.00      1.00      1.00         4
         245       1.00      0.75      0.86         4
         246       0.50      0.50      0.50         4
         247       1.00      0.75      0.86         4
         248       0.67      1.00      0.80         4
         249       0.07      0.22      0.11         9
         250       0.00      0.00      0.00         4
         251       1.00      1.00      1.00         4
         252       0.60      0.60      0.60         5
         253       1.00      0.20      0.33         5
         254       1.00      0.50      0.67         4
         255       0.75      1.00      0.86         9
         256       1.00      0.75      0.86         4
         257       0.00      0.00      0.00         9
         258       0.50      0.25      0.33         4
         259       1.00      0.75      0.86         4
         260       1.00      1.00      1.00         9
         261       1.00      0.75      0.86         4
         262       1.00      0.80      0.89         5
         263       0.53      0.89      0.67         9
         264       0.89      0.89      0.89         9
         265       1.00      0.89      0.94         9
         266       1.00      0.50      0.67         4
         267       0.89      0.89      0.89         9
         268       1.00      0.75      0.86         4
         269       0.80      1.00      0.89         4
         270       0.80      1.00      0.89         4
         271       0.40      0.50      0.44         4
         272       1.00      0.75      0.86         4
         273       0.60      0.75      0.67         4
         274       0.00      0.00      0.00         4
         275       0.67      1.00      0.80         4
         276       0.57      1.00      0.73         4
         277       1.00      1.00      1.00         4
         278       0.60      0.60      0.60         5
         279       0.80      1.00      0.89         4
         280       0.67      1.00      0.80         4
         281       0.00      0.00      0.00         4
         282       0.00      0.00      0.00         4
         283       0.67      0.75      0.71         8
         284       0.00      0.00      0.00         4
         285       1.00      1.00      1.00         4
         286       0.60      0.75      0.67         4
         287       0.33      0.80      0.47         5
         288       1.00      1.00      1.00         4
         289       0.00      0.00      0.00         4
         290       0.67      0.40      0.50         5
         291       0.25      0.25      0.25         4
         292       1.00      0.50      0.67         4
         293       1.00      0.22      0.36         9
         294       0.50      0.75      0.60         4
         295       1.00      1.00      1.00         4
         296       0.50      0.75      0.60         4
         297       1.00      0.89      0.94         9
         298       1.00      1.00      1.00         9
         299       0.80      0.89      0.84         9
         300       1.00      1.00      1.00         4
         301       1.00      1.00      1.00         4
         302       0.67      0.80      0.73         5
         303       0.00      0.00      0.00         4
         304       1.00      0.89      0.94         9
         305       1.00      0.80      0.89         5
         306       0.69      1.00      0.82         9
         307       0.50      1.00      0.67         5
         308       0.80      0.89      0.84         9
         309       0.33      0.25      0.29         4
         310       0.83      1.00      0.91         5
         311       0.58      0.78      0.67         9
         312       0.88      0.78      0.82         9
         313       1.00      0.89      0.94         9
         314       1.00      0.89      0.94         9
         315       1.00      0.80      0.89         5
         316       0.60      0.75      0.67         4
         317       0.57      1.00      0.73         4
         318       0.75      0.75      0.75         4
         319       0.80      0.89      0.84         9
         320       0.75      0.75      0.75         4
         321       0.33      0.40      0.36         5
         322       0.80      1.00      0.89         4
         323       1.00      0.40      0.57         5
         324       0.62      1.00      0.77         5
         325       0.50      0.25      0.33         4
         326       0.33      0.25      0.29         4
         327       1.00      0.40      0.57         5
         328       0.33      0.80      0.47         5
         329       0.00      0.00      0.00         4
         330       0.90      1.00      0.95         9
         331       0.67      0.89      0.76         9
         332       1.00      1.00      1.00         4
         333       0.80      0.80      0.80         5
         334       0.00      0.00      0.00         4
         335       0.00      0.00      0.00         4
         336       0.50      0.50      0.50         4
         337       0.00      0.00      0.00         9
         338       1.00      0.75      0.86         4
         339       0.89      0.89      0.89         9
         340       0.67      0.50      0.57         4
         341       1.00      0.50      0.67         4
         342       0.00      0.00      0.00         4
         343       0.50      0.25      0.33         4
         344       1.00      0.75      0.86         4
         345       1.00      0.50      0.67         4
         346       0.88      0.78      0.82         9
         347       1.00      1.00      1.00         4
         348       0.40      0.50      0.44         4
         349       0.00      0.00      0.00         4
         350       0.73      0.89      0.80         9
         351       0.67      1.00      0.80         4
         352       0.71      1.00      0.83         5
         353       0.00      0.00      0.00         4
         354       0.78      0.78      0.78         9
         355       0.00      0.00      0.00         4
         356       0.67      0.50      0.57         4
         357       0.60      0.75      0.67         4
         358       0.67      0.50      0.57         4
         359       0.67      0.50      0.57         4
         360       0.70      0.78      0.74         9
         361       0.75      0.75      0.75         4
         362       0.50      0.60      0.55         5
         363       0.00      0.00      0.00         4
         364       1.00      1.00      1.00         4
         365       1.00      1.00      1.00         9
         366       1.00      1.00      1.00         9
         367       1.00      0.78      0.88         9
         368       0.00      0.00      0.00         4
         369       0.75      0.75      0.75         4
         370       0.57      1.00      0.73         4
         371       1.00      0.60      0.75         5
         372       0.75      0.75      0.75         4
         373       0.50      0.75      0.60         4
         374       0.80      0.80      0.80         5
         375       0.13      0.75      0.22         4
         376       1.00      0.75      0.86         4
         377       0.62      0.89      0.73         9
         378       0.50      0.25      0.33         4
         379       1.00      1.00      1.00         5
         380       1.00      1.00      1.00         4
         381       0.38      0.56      0.45         9
         382       0.88      0.78      0.82         9
         383       1.00      1.00      1.00         9
         384       0.00      0.00      0.00         4
         385       1.00      1.00      1.00         4
         386       0.00      0.00      0.00         4
         387       0.20      0.25      0.22         4
         388       0.50      0.75      0.60         4
         389       0.89      0.89      0.89         9
         390       0.90      1.00      0.95         9
         391       0.89      0.89      0.89         9
         392       0.50      0.50      0.50         4
         393       0.80      1.00      0.89         4
         394       1.00      0.75      0.86         4
         395       0.00      0.00      0.00         9
         396       1.00      1.00      1.00         4
         397       1.00      0.75      0.86         4
         398       1.00      1.00      1.00         4
         399       1.00      0.75      0.86         4
         400       0.50      0.75      0.60         4
         401       1.00      0.89      0.94         9
         402       0.00      0.00      0.00         4
         403       0.78      0.78      0.78         9
         404       0.90      1.00      0.95         9
         405       1.00      0.67      0.80         9
         406       1.00      0.89      0.94         9
         407       0.00      0.00      0.00         5
         408       1.00      0.50      0.67         4
         409       0.00      0.00      0.00         9
         410       0.50      0.50      0.50         4
         411       1.00      0.50      0.67         4
         412       0.50      0.50      0.50         4
         413       0.67      1.00      0.80         4
         414       0.83      1.00      0.91         5
         415       0.75      0.60      0.67         5
         416       0.57      1.00      0.73         4
         417       1.00      1.00      1.00         4
         418       0.71      0.56      0.63         9
         419       0.75      0.75      0.75         4
         420       1.00      1.00      1.00         4
         421       1.00      1.00      1.00         4
         422       0.67      0.80      0.73         5
         423       0.58      0.78      0.67         9
         424       0.60      0.67      0.63         9
         425       0.58      0.78      0.67         9
         426       0.80      1.00      0.89         4
         427       0.44      0.44      0.44         9
         428       1.00      1.00      1.00         5
         429       0.80      1.00      0.89         4
         430       1.00      0.75      0.86         4
         431       1.00      0.75      0.86         4
         432       0.00      0.00      0.00         9
         433       0.00      0.00      0.00         9
         434       1.00      0.50      0.67         4
         435       0.80      0.80      0.80         5
         436       0.75      0.75      0.75         4
         437       0.00      0.00      0.00         9
         438       1.00      1.00      1.00         4
         439       1.00      1.00      1.00         4
         440       0.80      0.80      0.80         5
         441       0.00      0.00      0.00         4
         442       0.67      0.89      0.76         9
         443       0.67      1.00      0.80         4
         444       1.00      0.75      0.86         4
         445       0.60      0.75      0.67         4
         446       0.20      0.20      0.20         5
         447       1.00      1.00      1.00         4
         448       0.00      0.00      0.00         4
         449       1.00      0.25      0.40         4
         450       0.80      0.80      0.80         5
         451       0.57      0.89      0.70         9
         452       0.00      0.00      0.00         4
         453       1.00      1.00      1.00         4
         454       0.75      0.75      0.75         4
         455       0.64      0.78      0.70         9
         456       1.00      0.75      0.86         4
         457       0.86      0.67      0.75         9
         458       0.13      0.75      0.22         4
         459       0.50      0.25      0.33         4
         460       0.75      0.67      0.71         9
         461       0.75      0.75      0.75         4
         462       1.00      0.75      0.86         4
         463       0.64      0.78      0.70         9
         464       0.67      1.00      0.80         4
         465       1.00      1.00      1.00         9
         466       0.86      0.67      0.75         9
         467       0.62      0.56      0.59         9
         468       1.00      0.75      0.86         4
         469       0.38      0.56      0.45         9
         470       1.00      1.00      1.00         4
         471       0.89      0.89      0.89         9
         472       0.80      0.44      0.57         9
         473       1.00      1.00      1.00         4
         474       0.80      1.00      0.89         4
         475       1.00      0.78      0.88         9
         476       1.00      1.00      1.00         5
         477       0.60      0.75      0.67         4
         478       0.00      0.00      0.00         5
         479       1.00      1.00      1.00         9
         480       0.08      0.25      0.12         4
         481       0.00      0.00      0.00         4
         482       1.00      0.75      0.86         4
         483       0.00      0.00      0.00         4
         484       1.00      0.75      0.86         4
         485       1.00      1.00      1.00         5
         486       0.00      0.00      0.00         4
         487       0.10      0.50      0.17         4
         488       1.00      1.00      1.00         4
         489       0.64      0.78      0.70         9
         490       1.00      1.00      1.00         5
         491       0.00      0.00      0.00         4
         492       1.00      0.50      0.67         4
         493       1.00      0.44      0.62         9
         494       1.00      1.00      1.00         4
         495       0.90      1.00      0.95         9
         496       0.50      0.75      0.60         4
         497       0.50      0.25      0.33         4
         498       1.00      1.00      1.00         5
         499       0.71      0.56      0.63         9
         500       1.00      1.00      1.00         4
         501       0.18      0.22      0.20         9
         502       1.00      1.00      1.00         5
         503       1.00      0.75      0.86         4
         504       0.00      0.00      0.00         4
         505       1.00      0.75      0.86         4
         506       1.00      0.25      0.40         4
         507       0.00      0.00      0.00         4
         508       1.00      0.80      0.89         5
         509       1.00      1.00      1.00         4
         510       1.00      0.50      0.67         4
         511       0.89      0.89      0.89         9
         512       1.00      1.00      1.00         9
         513       0.29      0.50      0.36         4
         514       0.58      0.78      0.67         9
         515       0.50      0.50      0.50         4
         516       1.00      0.89      0.94         9
         517       0.75      0.75      0.75         4
         518       1.00      1.00      1.00         4
         519       0.75      0.75      0.75         4
         520       0.00      0.00      0.00         4
         521       0.00      0.00      0.00         4
         522       0.80      1.00      0.89         4
         523       0.90      1.00      0.95         9
         524       1.00      1.00      1.00         5
         525       1.00      0.56      0.71         9
         526       0.33      1.00      0.50         4
         527       0.83      1.00      0.91         5
         528       0.60      0.75      0.67         4
         529       0.00      0.00      0.00         4
         530       1.00      0.75      0.86         4
         531       0.33      0.75      0.46         4
         532       0.86      0.67      0.75         9
         533       0.83      1.00      0.91         5
         534       0.43      0.50      0.46         6
         535       0.33      0.75      0.46         4
         536       1.00      1.00      1.00         5
         537       1.00      0.75      0.86         4
         538       0.00      0.00      0.00         9
         539       0.50      0.33      0.40         9
         540       0.00      0.00      0.00         4
         541       1.00      1.00      1.00         9
         542       1.00      1.00      1.00         4
         543       0.89      0.89      0.89         9
         544       0.80      0.89      0.84         9
         545       0.50      0.25      0.33         4
         546       1.00      1.00      1.00         5
         547       1.00      0.25      0.40         4
         548       0.80      1.00      0.89         4
         549       0.60      0.75      0.67         4
         550       0.57      1.00      0.73         4
         551       0.75      0.67      0.71         9
         552       1.00      1.00      1.00         4
         553       1.00      0.80      0.89         5
         554       0.00      0.00      0.00         4
         555       0.83      1.00      0.91         5
         556       1.00      0.60      0.75         5
         557       0.00      0.00      0.00         4
         558       0.70      0.78      0.74         9
         559       0.50      0.67      0.57         9
         560       0.00      0.00      0.00         4
         561       1.00      1.00      1.00         9
         562       0.00      0.00      0.00         4
         563       1.00      0.11      0.20         9
         564       1.00      1.00      1.00         4
         565       1.00      0.80      0.89         5
         566       0.50      0.20      0.29         5
         567       0.29      0.50      0.36         4
         568       0.50      0.50      0.50         4
         569       0.80      1.00      0.89         4
         570       1.00      0.75      0.86         4
         571       0.50      0.25      0.33         4
         572       0.69      1.00      0.82         9
         573       0.50      0.25      0.33         4
         574       0.67      0.89      0.76         9
         575       0.50      0.60      0.55         5
         576       1.00      0.80      0.89         5
         577       0.75      0.75      0.75         4
         578       1.00      0.80      0.89         5
         579       1.00      1.00      1.00         9
         580       1.00      1.00      1.00         4
         581       0.80      1.00      0.89         4
         582       0.50      0.75      0.60         4
         583       0.89      0.89      0.89         9
         584       0.80      1.00      0.89         4
         585       0.60      0.75      0.67         4
         586       0.80      1.00      0.89         4
         587       0.82      1.00      0.90         9
         588       1.00      0.25      0.40         4
         589       0.00      0.00      0.00         9
         590       0.00      0.00      0.00         4
         591       0.80      0.80      0.80         5
         592       0.82      1.00      0.90         9
         593       1.00      1.00      1.00         4
         594       0.89      0.89      0.89         9
         595       1.00      1.00      1.00         4
         596       0.80      1.00      0.89         4
         597       1.00      1.00      1.00         5
         598       0.00      0.00      0.00         4
         599       0.80      1.00      0.89         4
         600       0.75      0.75      0.75         4
         601       0.88      0.78      0.82         9
         602       0.00      0.00      0.00         4
         603       1.00      0.25      0.40         4
         604       0.25      0.25      0.25         4
         605       0.50      0.20      0.29         5
         606       0.33      0.25      0.29         4
         607       1.00      0.80      0.89         5
         608       0.67      0.80      0.73         5
         609       0.57      0.80      0.67         5
         610       0.75      0.67      0.71         9
         611       0.00      0.00      0.00         4
         612       1.00      1.00      1.00         4
         613       0.67      0.80      0.73         5
         614       1.00      1.00      1.00         4
         615       0.00      0.00      0.00         4
         616       0.82      1.00      0.90         9
         617       1.00      1.00      1.00         5
         618       0.44      0.80      0.57         5
         619       1.00      1.00      1.00         9
         620       0.83      1.00      0.91         5
         621       0.56      0.56      0.56         9
         622       0.22      0.50      0.31         4
         623       0.00      0.00      0.00         9
         624       1.00      0.20      0.33         5
         625       1.00      0.50      0.67         4
         626       0.78      0.78      0.78         9
         627       1.00      0.80      0.89         5
         628       0.75      0.75      0.75         4
         629       0.29      1.00      0.44         4
         630       0.00      0.00      0.00         4
         631       1.00      0.56      0.71         9
         632       0.00      0.00      0.00         4
         633       0.11      0.25      0.15         4
         634       0.00      0.00      0.00         4
         635       0.00      0.00      0.00         4
         636       1.00      0.89      0.94         9
         637       1.00      1.00      1.00         4
         638       1.00      1.00      1.00         7
         639       0.50      0.25      0.33         4
         640       0.60      0.75      0.67         4
         641       0.40      0.50      0.44         4
         642       0.00      0.00      0.00         4
         643       0.86      0.67      0.75         9
         644       0.75      0.60      0.67         5
         645       1.00      0.78      0.88         9
         646       0.33      0.25      0.29         4
         647       0.67      0.40      0.50         5
         648       0.00      0.00      0.00         4
         649       0.00      0.00      0.00         4
         650       0.80      1.00      0.89         4
         651       0.38      0.75      0.50         4
         652       0.80      1.00      0.89         4
         653       0.00      0.00      0.00         4
         654       0.90      1.00      0.95         9
         655       0.00      0.00      0.00         4
         656       0.38      0.60      0.46         5
         657       0.41      1.00      0.58         7
         658       1.00      1.00      1.00         4
         659       0.33      0.75      0.46         4
         660       0.45      0.56      0.50         9
         661       0.67      0.80      0.73         5
         662       0.00      0.00      0.00         4
         663       1.00      0.20      0.33         5
         664       0.00      0.00      0.00         4
         665       0.50      0.75      0.60         4
         666       0.00      0.00      0.00         4
         667       1.00      0.25      0.40         4
         668       0.11      0.75      0.19         4
         669       0.75      0.60      0.67         5
         670       0.67      1.00      0.80         4
         671       1.00      1.00      1.00         9
         672       1.00      0.60      0.75         5
         673       1.00      0.40      0.57         5
         674       1.00      1.00      1.00         4
         675       0.50      0.75      0.60         4
         676       0.67      1.00      0.80         4
         677       0.00      0.00      0.00         4
         678       0.67      0.40      0.50         5
         679       0.17      0.25      0.20         4
         680       1.00      1.00      1.00         9
         681       0.90      1.00      0.95         9
         682       1.00      1.00      1.00         4
         683       1.00      0.67      0.80         9
         684       1.00      0.25      0.40         4
         685       0.00      0.00      0.00         4
         686       0.50      0.50      0.50         4
         687       0.89      0.89      0.89         9
         688       0.25      0.50      0.33         4
         689       1.00      0.89      0.94         9
         690       0.90      1.00      0.95         9
         691       1.00      1.00      1.00         5
         692       0.90      1.00      0.95         9
         693       1.00      0.60      0.75         5
         694       1.00      0.89      0.94         9
         695       1.00      0.75      0.86         4
         696       0.33      0.44      0.38         9
         697       0.60      0.33      0.43         9
         698       0.44      0.80      0.57         5
         699       0.35      0.78      0.48         9
         700       1.00      0.44      0.62         9
         701       0.00      0.00      0.00         4
         702       1.00      1.00      1.00         5
         703       0.60      1.00      0.75         9
         704       0.78      0.78      0.78         9
         705       1.00      0.89      0.94         9
         706       1.00      0.75      0.86         4
         707       0.78      0.78      0.78         9
         708       1.00      0.75      0.86         4
         709       0.90      1.00      0.95         9
         710       0.80      1.00      0.89         4
         711       1.00      0.80      0.89         5
         712       0.80      0.89      0.84         9
         713       0.75      0.60      0.67         5
         714       0.83      1.00      0.91         5
         715       1.00      0.50      0.67         4
         716       0.19      0.75      0.30         4
         717       0.78      0.78      0.78         9
         718       1.00      1.00      1.00         5
         719       1.00      0.75      0.86         4
         720       0.67      0.80      0.73         5
         721       0.57      1.00      0.73         4
         722       0.38      0.75      0.50         4
         723       0.83      1.00      0.91         5
         724       0.00      0.00      0.00         4
         725       0.43      0.75      0.55         4
         726       1.00      0.75      0.86         4
         727       0.89      0.89      0.89         9
         728       0.90      1.00      0.95         9
         729       0.00      0.00      0.00         4
         730       0.43      0.60      0.50         5
         731       0.83      1.00      0.91         5
         732       0.00      0.00      0.00         4
         733       1.00      1.00      1.00         4
         734       0.40      0.50      0.44         4
         735       0.60      0.33      0.43         9
         736       0.00      0.00      0.00         4
         737       0.57      1.00      0.73         4
         738       0.89      0.89      0.89         9
         739       0.33      0.50      0.40         4
         740       1.00      1.00      1.00         4
         741       0.67      1.00      0.80         4
         742       0.00      0.00      0.00         4
         743       0.00      0.00      0.00         4
         744       0.30      0.60      0.40         5
         745       0.38      0.75      0.50         4
         746       0.71      1.00      0.83         5
         747       0.80      1.00      0.89         4
         748       0.20      0.25      0.22         4
         749       0.50      0.56      0.53         9
         750       0.00      0.00      0.00         4
         751       1.00      0.89      0.94         9
         752       1.00      0.25      0.40         4
         753       0.75      0.60      0.67         5
         754       1.00      0.75      0.86         4
         755       1.00      1.00      1.00         5
         756       1.00      1.00      1.00         4
         757       0.00      0.00      0.00         4
         758       0.71      1.00      0.83         5
         759       0.00      0.00      0.00         4
         760       0.44      0.57      0.50         7
         761       0.80      1.00      0.89         4
         762       1.00      1.00      1.00         4
         763       1.00      1.00      1.00         9
         764       0.50      1.00      0.67         4
         765       0.62      0.56      0.59         9
         766       1.00      1.00      1.00         5
         767       0.00      0.00      0.00         4
         768       0.67      0.89      0.76         9
         769       1.00      0.60      0.75         5
         770       1.00      0.25      0.40         4
         771       0.50      0.25      0.33         4
         772       0.78      0.78      0.78         9
         773       0.80      1.00      0.89         4
         774       1.00      0.50      0.67         4
         775       1.00      0.75      0.86         4
         776       0.44      0.80      0.57         5
         777       0.70      0.88      0.78         8
         778       0.50      0.25      0.33         4
         779       1.00      1.00      1.00         4
         780       0.12      0.33      0.17         9
         781       0.67      0.40      0.50         5
         782       0.62      0.56      0.59         9
         783       1.00      0.80      0.89         5
         784       1.00      0.80      0.89         5
         785       1.00      0.75      0.86         4
         786       0.80      0.89      0.84         9
         787       1.00      0.75      0.86         4
         788       0.67      0.40      0.50         5
         789       1.00      0.50      0.67         4
         790       0.75      0.75      0.75         4
         791       0.00      0.00      0.00         4
         792       1.00      1.00      1.00         4
         793       0.50      0.50      0.50         4
         794       0.11      0.25      0.15         4
         795       1.00      0.50      0.67         4
         796       0.67      0.67      0.67         9
         797       0.08      0.25      0.12         4
         798       0.00      0.00      0.00         4
         799       0.50      0.20      0.29         5
         800       0.75      0.60      0.67         5
         801       1.00      0.78      0.88         9
         802       0.67      0.89      0.76         9
         803       1.00      0.50      0.67         4
         804       1.00      0.25      0.40         4
         805       0.67      0.50      0.57         4
         806       0.89      0.89      0.89         9
         807       1.00      1.00      1.00         4
         808       1.00      1.00      1.00         4
         809       0.75      0.75      0.75         4
         810       0.86      0.67      0.75         9
         811       0.71      1.00      0.83         5
         812       0.00      0.00      0.00         4
         813       0.57      0.80      0.67         5
         814       0.60      0.60      0.60         5
         815       0.64      1.00      0.78         9
         816       0.80      1.00      0.89         4
         817       1.00      1.00      1.00         8
         818       0.71      1.00      0.83         5
         819       0.12      0.50      0.19         4
         820       1.00      1.00      1.00         4
         821       0.89      0.89      0.89         9
         822       0.75      1.00      0.86         9
         823       0.75      0.75      0.75         4
         824       0.90      1.00      0.95         9
         825       1.00      1.00      1.00         4
         826       0.67      1.00      0.80         4
         827       0.44      1.00      0.62         4
         828       1.00      0.80      0.89         5
         829       0.27      0.75      0.40         4
         830       1.00      1.00      1.00         4
         831       0.55      0.67      0.60         9
         832       1.00      1.00      1.00         4
         833       0.67      0.50      0.57         4
         834       1.00      0.50      0.67         4
         835       1.00      1.00      1.00         4
         836       1.00      0.20      0.33         5
         837       0.80      1.00      0.89         4
         838       0.50      0.50      0.50         4
         839       0.00      0.00      0.00         4
         840       1.00      1.00      1.00         5
         841       1.00      0.75      0.86         4
         842       1.00      0.44      0.62         9
         843       0.50      0.80      0.62         5
         844       0.57      1.00      0.73         4
         845       0.67      0.50      0.57         4
         846       1.00      1.00      1.00         4
         847       1.00      0.75      0.86         4
         848       0.50      0.33      0.40         9
         849       0.67      1.00      0.80         4
         850       0.80      0.80      0.80         5
         851       0.00      0.00      0.00         9
         852       1.00      0.25      0.40         4
         853       0.00      0.00      0.00         9
         854       0.80      1.00      0.89         4
         855       0.67      0.67      0.67         9
         856       1.00      0.33      0.50         9
         857       0.64      0.78      0.70         9
         858       1.00      1.00      1.00         4
         859       0.90      1.00      0.95         9
         860       0.33      0.25      0.29         4
         861       0.88      0.78      0.82         9
         862       0.80      1.00      0.89         4
         863       0.83      1.00      0.91         5
         864       0.06      0.25      0.10         4
         865       0.80      1.00      0.89         4
         866       0.33      1.00      0.50         4
         867       0.80      1.00      0.89         4
         868       0.80      1.00      0.89         4
         869       1.00      1.00      1.00         4
         870       1.00      1.00      1.00         4
         871       0.00      0.00      0.00         4
         872       1.00      0.25      0.40         4
         873       0.00      0.00      0.00         4
         874       0.00      0.00      0.00         4
         875       0.00      0.00      0.00         4
         876       1.00      1.00      1.00         4
         877       0.67      1.00      0.80         4
         878       0.00      0.00      0.00         4
         879       0.53      0.89      0.67         9
         880       0.50      0.67      0.57         9
         881       0.83      1.00      0.91         5
         882       0.50      0.20      0.29         5
         883       0.75      0.75      0.75         4
         884       1.00      0.44      0.62         9
         885       0.00      0.00      0.00         4
         886       0.00      0.00      0.00         4
         887       1.00      1.00      1.00         4
         888       1.00      0.40      0.57         5
         889       1.00      1.00      1.00         4
         890       0.80      1.00      0.89         4
         891       1.00      0.56      0.71         9
         892       0.75      0.75      0.75         4
         893       0.83      1.00      0.91         5

    accuracy                           0.66      4917
   macro avg       0.65      0.64      0.62      4917
weighted avg       0.68      0.66      0.65      4917

task_train_time: {0: 10.046124808999998, 1: 5.498118765000001, 2: 4.308803571000002, 3: 5.651023469999998, 4: 5.231202674999999, 5: 5.229951704000001, 6: 5.605860733, 7: 4.962255390999999, 8: 5.0260892469999945, 9: 5.233286278999998, 10: 5.59051456200001, 11: 4.3439317440000025, 12: 5.577552320999999, 13: 4.416854909999998, 14: 6.399223140000004, 15: 5.132681445000003, 16: 4.660581372999999, 17: 5.035306180000006, 18: 5.612789495000001, 19: 5.536574081999987, 20: 5.593540771999997, 21: 4.733284913999995, 22: 6.139155733999985, 23: 4.99891218800002, 24: 4.872829548999988, 25: 5.208634504999992, 26: 5.745167272000003, 27: 5.437736744000006, 28: 5.352867572000008, 29: 4.709504442999986, 30: 5.720588608000014, 31: 4.824244061000002, 32: 4.905217375999996, 33: 5.642893729999997, 34: 7.090893550000004, 35: 4.688398489000008, 36: 5.165887190999996, 37: 5.368826917000007, 38: 5.033659003999986, 39: 5.279379818999985, 40: 5.366547002000004, 41: 5.248241153000009, 42: 5.090018332, 43: 5.040904931}
prediction_time: 0.0003089090000116812
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
