Namespace(backbone_type=None, batch_size=20, buffer_size=10, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=10, conf_host='elquinto', conf_jobnum='9983aa03-4041-464f-9a55-89f874445f66', conf_timestamp='2023-08-09 13:12:35.208821', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=200, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 95.11 % 	 [Task-IL]: 57.07 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 61.44 % 	 [Task-IL]: 43.45 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 47.28 % 	 [Task-IL]: 39.96 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 32.86 % 	 [Task-IL]: 38.32 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 31.92 % 	 [Task-IL]: 36.34 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 25.62 % 	 [Task-IL]: 34.41 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.22 % 	 [Task-IL]: 33.98 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 15.66 % 	 [Task-IL]: 33.79 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 16.54 % 	 [Task-IL]: 32.76 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 15.85 % 	 [Task-IL]: 32.84 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.61 % 	 [Task-IL]: 32.75 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 12.49 % 	 [Task-IL]: 32.3 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 11.9 % 	 [Task-IL]: 31.87 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 10.48 % 	 [Task-IL]: 31.19 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 9.54 % 	 [Task-IL]: 31.21 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 9.41 % 	 [Task-IL]: 30.97 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 9.84 % 	 [Task-IL]: 30.5 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.3 % 	 [Task-IL]: 30.56 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 7.27 % 	 [Task-IL]: 30.05 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 7.46 % 	 [Task-IL]: 30.03 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 6.64 % 	 [Task-IL]: 29.82 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.99 % 	 [Task-IL]: 29.91 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 6.96 % 	 [Task-IL]: 29.71 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 6.3 % 	 [Task-IL]: 29.51 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 6.72 % 	 [Task-IL]: 29.64 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.77 % 	 [Task-IL]: 29.54 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.4 % 	 [Task-IL]: 29.09 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.69 % 	 [Task-IL]: 29.18 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 5.92 % 	 [Task-IL]: 29.09 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.25 % 	 [Task-IL]: 29.49 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.35 % 	 [Task-IL]: 29.21 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 5.68 % 	 [Task-IL]: 29.07 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.42 % 	 [Task-IL]: 29.45 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 5.3 % 	 [Task-IL]: 29.47 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 4.23 % 	 [Task-IL]: 29.29 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.02 % 	 [Task-IL]: 29.42 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.33 % 	 [Task-IL]: 29.05 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 3.52 % 	 [Task-IL]: 28.89 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.43 % 	 [Task-IL]: 28.75 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 3.98 % 	 [Task-IL]: 28.98 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 3.95 % 	 [Task-IL]: 28.82 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.18 % 	 [Task-IL]: 28.75 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 3.18 % 	 [Task-IL]: 28.66 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([8940, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378
 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396
 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414
 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432
 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450
 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468
 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486
 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504
 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522
 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540
 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558
 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576
 577 578 579 580 581 582 583 584 585 586 587 588 589 590 592 593 594 595
 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613
 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631
 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649
 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667
 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685
 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703
 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721
 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739
 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757
 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775
 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793
 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811
 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829
 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847
 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865
 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883
 884 885 886 887 888 889 890 891 892 893]	Counter({543: 30, 886: 30, 472: 29, 93: 29, 854: 29, 772: 29, 766: 28, 834: 28, 166: 28, 262: 27, 826: 26, 165: 26, 528: 25, 859: 24, 229: 24, 173: 24, 454: 24, 316: 24, 553: 24, 542: 24, 429: 24, 722: 24, 293: 23, 633: 23, 216: 23, 864: 23, 64: 23, 325: 23, 764: 23, 77: 23, 159: 22, 152: 22, 879: 22, 467: 22, 194: 22, 211: 22, 809: 22, 748: 22, 753: 22, 857: 22, 533: 21, 839: 21, 793: 21, 43: 21, 515: 21, 685: 21, 698: 21, 559: 21, 7: 21, 780: 21, 295: 21, 880: 21, 531: 21, 304: 21, 335: 21, 11: 21, 324: 20, 389: 20, 431: 20, 583: 20, 128: 20, 607: 20, 853: 20, 421: 20, 805: 20, 728: 20, 690: 20, 532: 20, 208: 20, 497: 20, 39: 20, 411: 20, 227: 19, 486: 19, 117: 19, 301: 19, 479: 19, 788: 19, 815: 19, 179: 19, 844: 19, 406: 19, 285: 19, 8: 19, 25: 19, 427: 19, 501: 19, 526: 18, 872: 18, 134: 18, 68: 18, 641: 18, 81: 18, 200: 18, 228: 18, 796: 18, 544: 18, 363: 18, 825: 18, 423: 18, 397: 18, 484: 18, 393: 18, 458: 18, 587: 18, 760: 18, 619: 18, 341: 18, 188: 17, 539: 17, 718: 17, 204: 17, 502: 17, 627: 17, 40: 17, 230: 17, 426: 17, 290: 17, 351: 17, 621: 17, 163: 17, 617: 17, 727: 17, 127: 17, 185: 17, 618: 17, 376: 17, 432: 17, 327: 17, 259: 17, 581: 17, 560: 17, 34: 17, 889: 17, 514: 16, 540: 16, 38: 16, 308: 16, 345: 16, 645: 16, 564: 16, 29: 16, 237: 16, 710: 16, 743: 16, 599: 16, 713: 16, 317: 16, 383: 16, 750: 16, 563: 16, 394: 16, 371: 16, 66: 16, 843: 16, 296: 16, 822: 16, 251: 15, 459: 15, 33: 15, 807: 15, 694: 15, 31: 15, 50: 15, 105: 15, 57: 15, 883: 15, 498: 15, 838: 15, 675: 15, 642: 15, 513: 15, 322: 15, 464: 15, 306: 15, 354: 15, 495: 15, 1: 15, 761: 15, 817: 15, 408: 15, 704: 15, 827: 15, 298: 15, 863: 15, 58: 15, 249: 15, 74: 15, 217: 15, 198: 15, 375: 15, 654: 15, 73: 14, 754: 14, 592: 14, 104: 14, 181: 14, 588: 14, 247: 14, 548: 14, 483: 14, 823: 14, 489: 14, 518: 14, 490: 14, 379: 14, 860: 14, 245: 14, 628: 14, 785: 14, 226: 14, 629: 14, 17: 14, 875: 14, 415: 13, 779: 13, 413: 13, 356: 13, 541: 13, 75: 13, 192: 13, 191: 13, 669: 13, 78: 13, 746: 13, 332: 13, 795: 13, 5: 13, 866: 13, 739: 13, 697: 13, 709: 13, 131: 13, 189: 13, 90: 13, 342: 13, 400: 13, 265: 13, 414: 13, 54: 13, 139: 12, 811: 12, 274: 12, 307: 12, 392: 12, 44: 12, 156: 12, 323: 12, 292: 12, 818: 12, 890: 12, 689: 12, 111: 12, 602: 12, 665: 12, 885: 12, 390: 12, 380: 12, 118: 12, 328: 12, 401: 12, 433: 12, 575: 12, 808: 12, 744: 12, 225: 12, 688: 12, 656: 12, 471: 12, 699: 12, 738: 12, 196: 12, 209: 12, 391: 12, 740: 12, 631: 12, 650: 12, 417: 12, 364: 12, 184: 12, 331: 12, 424: 11, 151: 11, 195: 11, 275: 11, 616: 11, 199: 11, 49: 11, 504: 11, 683: 11, 344: 11, 678: 11, 309: 11, 242: 11, 657: 11, 878: 11, 835: 11, 460: 11, 482: 11, 521: 11, 203: 11, 485: 11, 453: 11, 362: 11, 410: 11, 334: 11, 819: 11, 881: 11, 190: 11, 605: 11, 436: 11, 577: 11, 422: 11, 873: 11, 712: 11, 762: 11, 357: 11, 435: 11, 114: 11, 538: 11, 836: 10, 570: 10, 346: 10, 789: 10, 86: 10, 22: 10, 319: 10, 48: 10, 404: 10, 99: 10, 115: 10, 144: 10, 257: 10, 359: 10, 667: 10, 664: 10, 751: 10, 634: 10, 260: 10, 470: 10, 547: 10, 291: 10, 550: 10, 775: 10, 37: 10, 658: 10, 18: 10, 840: 10, 59: 10, 439: 10, 220: 10, 445: 10, 492: 10, 176: 10, 3: 10, 305: 10, 447: 10, 269: 10, 487: 10, 12: 10, 530: 10, 124: 10, 829: 10, 360: 10, 123: 10, 597: 10, 545: 10, 451: 10, 103: 10, 45: 10, 56: 10, 684: 9, 742: 9, 142: 9, 781: 9, 343: 9, 816: 9, 604: 9, 714: 9, 729: 9, 703: 9, 418: 9, 523: 9, 430: 9, 312: 9, 387: 9, 747: 9, 24: 9, 842: 9, 403: 9, 246: 9, 509: 9, 555: 9, 586: 9, 197: 9, 232: 9, 756: 9, 13: 9, 2: 9, 752: 9, 566: 9, 686: 9, 355: 9, 696: 9, 169: 9, 314: 9, 373: 9, 153: 9, 214: 9, 841: 9, 474: 9, 529: 9, 882: 9, 318: 9, 443: 9, 147: 9, 221: 9, 787: 9, 677: 9, 437: 9, 399: 9, 580: 9, 494: 9, 26: 9, 178: 9, 444: 9, 736: 9, 125: 9, 610: 9, 661: 9, 476: 9, 85: 9, 442: 9, 441: 9, 378: 9, 871: 9, 652: 9, 330: 9, 757: 9, 148: 9, 536: 9, 717: 9, 60: 9, 646: 8, 299: 8, 800: 8, 51: 8, 88: 8, 129: 8, 500: 8, 510: 8, 52: 8, 76: 8, 867: 8, 122: 8, 851: 8, 377: 8, 83: 8, 723: 8, 248: 8, 505: 8, 813: 8, 601: 8, 313: 8, 644: 8, 463: 8, 702: 8, 366: 8, 651: 8, 361: 8, 478: 8, 593: 8, 224: 8, 507: 8, 790: 8, 812: 8, 615: 8, 741: 8, 174: 8, 449: 8, 794: 8, 160: 8, 136: 8, 110: 8, 155: 8, 119: 8, 402: 8, 126: 8, 506: 8, 861: 8, 367: 8, 263: 8, 824: 8, 300: 8, 386: 8, 321: 8, 84: 8, 107: 8, 108: 8, 382: 8, 42: 8, 673: 8, 719: 8, 206: 8, 759: 8, 326: 8, 671: 8, 692: 8, 219: 8, 347: 8, 320: 8, 94: 8, 412: 8, 705: 8, 425: 8, 405: 8, 384: 8, 847: 8, 396: 8, 798: 7, 440: 7, 792: 7, 778: 7, 534: 7, 273: 7, 175: 7, 381: 7, 810: 7, 193: 7, 32: 7, 63: 7, 369: 7, 803: 7, 434: 7, 372: 7, 352: 7, 804: 7, 672: 7, 468: 7, 624: 7, 682: 7, 201: 7, 511: 7, 286: 7, 491: 7, 786: 7, 612: 7, 420: 7, 623: 7, 338: 7, 680: 7, 215: 7, 578: 7, 771: 7, 158: 7, 183: 7, 620: 7, 488: 7, 582: 7, 466: 7, 855: 7, 726: 7, 769: 7, 234: 7, 477: 7, 270: 7, 749: 7, 603: 7, 571: 7, 797: 7, 23: 7, 768: 7, 315: 7, 187: 7, 236: 7, 837: 7, 279: 7, 832: 7, 613: 7, 626: 7, 594: 7, 241: 7, 893: 7, 16: 7, 670: 7, 653: 7, 398: 7, 643: 7, 572: 7, 858: 7, 799: 7, 182: 7, 154: 7, 244: 7, 551: 7, 140: 7, 676: 7, 333: 7, 388: 7, 590: 7, 46: 7, 258: 7, 535: 7, 294: 7, 238: 7, 452: 7, 278: 7, 569: 7, 349: 7, 264: 7, 724: 7, 311: 7, 41: 7, 783: 7, 791: 7, 55: 6, 407: 6, 774: 6, 186: 6, 745: 6, 877: 6, 207: 6, 557: 6, 116: 6, 777: 6, 288: 6, 801: 6, 277: 6, 0: 6, 135: 6, 524: 6, 462: 6, 830: 6, 15: 6, 231: 6, 457: 6, 450: 6, 681: 6, 210: 6, 716: 6, 385: 6, 416: 6, 109: 6, 556: 6, 679: 6, 121: 6, 493: 6, 70: 6, 888: 6, 589: 6, 254: 6, 584: 6, 365: 6, 598: 6, 281: 6, 146: 6, 112: 6, 4: 6, 666: 6, 272: 6, 735: 6, 776: 6, 870: 6, 874: 6, 852: 6, 561: 6, 614: 6, 503: 6, 707: 6, 674: 6, 100: 6, 419: 6, 568: 6, 213: 6, 67: 6, 649: 6, 700: 6, 802: 6, 519: 6, 720: 6, 370: 6, 821: 6, 576: 6, 758: 6, 517: 6, 481: 6, 91: 6, 574: 6, 180: 6, 465: 6, 846: 6, 522: 6, 711: 6, 170: 6, 62: 6, 28: 6, 865: 6, 240: 6, 280: 6, 9: 6, 887: 6, 625: 6, 636: 6, 20: 6, 409: 6, 850: 6, 655: 6, 828: 5, 205: 5, 271: 5, 648: 5, 585: 5, 721: 5, 806: 5, 95: 5, 368: 5, 516: 5, 496: 5, 96: 5, 253: 5, 611: 5, 268: 5, 715: 5, 337: 5, 283: 5, 102: 5, 101: 5, 339: 5, 82: 5, 508: 5, 635: 5, 608: 5, 632: 5, 92: 5, 499: 5, 336: 5, 133: 5, 79: 5, 461: 5, 609: 5, 784: 5, 106: 5, 770: 5, 250: 5, 876: 5, 161: 5, 255: 5, 212: 5, 297: 5, 374: 5, 261: 5, 884: 5, 150: 5, 765: 5, 218: 5, 480: 5, 755: 5, 565: 5, 731: 5, 456: 5, 773: 5, 512: 5, 554: 5, 549: 5, 98: 5, 446: 5, 552: 5, 132: 5, 862: 5, 19: 5, 782: 5, 448: 5, 833: 5, 820: 5, 737: 5, 284: 5, 36: 5, 27: 5, 638: 5, 596: 5, 143: 5, 660: 5, 177: 5, 595: 4, 428: 4, 537: 4, 831: 4, 573: 4, 525: 4, 164: 4, 80: 4, 701: 4, 891: 4, 848: 4, 706: 4, 892: 4, 732: 4, 647: 4, 734: 4, 21: 4, 455: 4, 693: 4, 14: 4, 469: 4, 687: 4, 120: 4, 473: 4, 138: 4, 708: 4, 546: 4, 438: 4, 695: 4, 172: 4, 622: 4, 637: 4, 579: 4, 47: 4, 302: 4, 252: 4, 856: 4, 239: 4, 61: 4, 662: 4, 256: 4, 329: 4, 222: 4, 340: 4, 691: 4, 149: 4, 130: 4, 358: 4, 72: 4, 567: 4, 849: 4, 558: 4, 814: 4, 113: 4, 97: 4, 167: 4, 71: 4, 30: 4, 243: 4, 395: 4, 10: 3, 287: 3, 141: 3, 733: 3, 310: 3, 527: 3, 145: 3, 725: 3, 520: 3, 763: 3, 87: 3, 69: 3, 235: 3, 89: 3, 289: 3, 168: 3, 475: 3, 53: 3, 640: 3, 137: 3, 350: 3, 267: 3, 767: 3, 171: 3, 663: 3, 668: 3, 282: 3, 348: 3, 868: 3, 223: 3, 606: 3, 845: 2, 600: 2, 233: 2, 276: 2, 639: 2, 6: 2, 869: 2, 630: 2, 659: 2, 157: 2, 303: 2, 730: 2, 202: 2, 266: 2, 353: 1, 65: 1, 562: 1, 35: 1})
fit_time: 27.161823842000018

Accuracy for 44 task(s): 	 [Class-IL]: 66.46 % 	 [Task-IL]: 30.1 %

CLASS_IL_ACC: 
	[68.47826086956522, 71.7741935483871, 72.26890756302521, 67.85714285714286, 57.95454545454546, 70.47619047619048, 52.12765957446809, 65.48672566371681, 77.31092436974791, 67.1875, 38.93805309734513, 71.42857142857143, 70.2127659574468, 70.37037037037037, 65.54621848739495, 84.61538461538461, 74.31192660550458, 71.84466019417476, 66.66666666666666, 68.33333333333333, 74.01574803149606, 64.70588235294117, 46.55172413793103, 58.65384615384615, 65.34653465346535, 73.68421052631578, 76.06837606837607, 58.252427184466015, 70.79646017699115, 62.365591397849464, 57.85123966942148, 69.0, 63.725490196078425, 58.55855855855856, 66.66666666666666, 74.52830188679245, 61.86440677966102, 67.79661016949152, 68.62745098039215, 71.55963302752293, 59.32203389830508, 58.92857142857143, 78.125, 64.15094339622641]
TASK_IL_ACC: 
	[54.891304347826086, 25.806451612903224, 30.252100840336134, 32.142857142857146, 26.136363636363637, 26.666666666666668, 29.78723404255319, 29.20353982300885, 23.52941176470588, 30.46875, 24.778761061946902, 27.61904761904762, 32.97872340425532, 22.22222222222222, 27.73109243697479, 29.914529914529915, 27.522935779816514, 26.21359223300971, 23.076923076923077, 30.0, 21.25984251968504, 31.76470588235294, 31.03448275862069, 27.884615384615387, 31.683168316831683, 30.701754385964914, 24.786324786324787, 29.126213592233007, 21.238938053097346, 26.881720430107524, 28.09917355371901, 26.0, 37.254901960784316, 30.630630630630627, 29.411764705882355, 29.245283018867923, 26.27118644067797, 28.8135593220339, 26.47058823529412, 22.018348623853214, 27.966101694915253, 32.142857142857146, 27.34375, 95.28301886792453]
f1_micro: 66.66666666666666
f1_macro: 62.22382962936466
              precision    recall  f1-score   support

           0       0.75      0.75      0.75         4
           1       1.00      0.89      0.94         9
           2       0.80      0.80      0.80         5
           3       0.00      0.00      0.00         4
           4       0.60      0.75      0.67         4
           5       0.90      1.00      0.95         9
           6       0.75      0.75      0.75         4
           7       0.90      1.00      0.95         9
           8       0.86      0.67      0.75         9
           9       0.00      0.00      0.00         4
          10       0.44      1.00      0.62         4
          11       0.60      0.67      0.63         9
          12       1.00      0.60      0.75         5
          13       1.00      0.80      0.89         5
          14       0.50      1.00      0.67         4
          15       0.50      0.40      0.44         5
          16       1.00      0.80      0.89         5
          17       0.43      0.60      0.50         5
          18       0.75      0.75      0.75         4
          19       1.00      1.00      1.00         4
          20       1.00      1.00      1.00         4
          21       0.00      0.00      0.00         4
          22       1.00      0.75      0.86         4
          23       0.00      0.00      0.00         4
          24       0.80      0.80      0.80         5
          25       1.00      0.88      0.93         8
          26       0.67      0.40      0.50         5
          27       1.00      0.75      0.86         4
          28       0.00      0.00      0.00         4
          29       0.50      0.50      0.50         4
          30       1.00      0.40      0.57         5
          31       0.88      0.78      0.82         9
          32       1.00      1.00      1.00         4
          33       1.00      0.67      0.80         9
          34       1.00      0.44      0.62         9
          35       1.00      0.50      0.67         4
          36       0.00      0.00      0.00         4
          37       1.00      1.00      1.00         5
          38       0.14      0.22      0.17         9
          39       0.73      0.89      0.80         9
          40       0.80      0.80      0.80         5
          41       0.57      0.80      0.67         5
          42       1.00      0.75      0.86         4
          43       0.80      0.89      0.84         9
          44       0.78      0.78      0.78         9
          45       1.00      0.89      0.94         9
          46       1.00      1.00      1.00         5
          47       1.00      0.25      0.40         4
          48       0.50      1.00      0.67         4
          49       1.00      0.89      0.94         9
          50       0.39      0.78      0.52         9
          51       0.80      1.00      0.89         4
          52       0.43      0.75      0.55         4
          53       1.00      0.50      0.67         4
          54       1.00      1.00      1.00         5
          55       1.00      0.25      0.40         4
          56       0.71      1.00      0.83         5
          57       0.00      0.00      0.00         9
          58       1.00      1.00      1.00         9
          59       0.80      0.80      0.80         5
          60       1.00      1.00      1.00         4
          61       1.00      1.00      1.00         4
          62       0.25      0.75      0.38         4
          63       1.00      0.33      0.50         9
          64       0.82      1.00      0.90         9
          65       1.00      1.00      1.00         4
          66       1.00      1.00      1.00         9
          67       0.00      0.00      0.00         4
          68       0.73      0.89      0.80         9
          69       0.67      0.50      0.57         4
          70       0.71      1.00      0.83         5
          71       1.00      1.00      1.00         4
          72       1.00      0.75      0.86         4
          73       0.80      0.44      0.57         9
          74       1.00      0.89      0.94         9
          75       0.78      0.78      0.78         9
          76       0.00      0.00      0.00         4
          77       0.70      0.78      0.74         9
          78       0.33      0.25      0.29         4
          79       0.80      1.00      0.89         4
          80       0.00      0.00      0.00         4
          81       0.89      0.89      0.89         9
          82       0.00      0.00      0.00         4
          83       0.33      1.00      0.50         4
          84       0.80      0.80      0.80         5
          85       0.43      0.75      0.55         4
          86       0.80      1.00      0.89         4
          87       0.00      0.00      0.00         4
          88       0.80      1.00      0.89         4
          89       0.00      0.00      0.00         4
          90       0.88      0.78      0.82         9
          91       0.67      1.00      0.80         4
          92       1.00      0.40      0.57         5
          93       0.90      1.00      0.95         9
          94       0.83      1.00      0.91         5
          95       1.00      0.50      0.67         4
          96       1.00      0.75      0.86         4
          97       1.00      1.00      1.00         4
          98       0.50      0.75      0.60         4
          99       0.00      0.00      0.00         4
         100       0.10      0.75      0.18         4
         101       0.00      0.00      0.00         4
         102       0.80      1.00      0.89         4
         103       1.00      0.25      0.40         4
         104       0.57      0.80      0.67         5
         105       0.89      0.89      0.89         9
         106       1.00      0.75      0.86         4
         107       1.00      0.75      0.86         4
         108       0.00      0.00      0.00         4
         109       0.10      0.25      0.14         4
         110       0.00      0.00      0.00         4
         111       1.00      1.00      1.00         5
         112       0.67      0.50      0.57         4
         113       0.00      0.00      0.00         4
         114       0.29      1.00      0.44         4
         115       0.83      1.00      0.91         5
         116       0.80      1.00      0.89         4
         117       1.00      0.67      0.80         9
         118       0.62      1.00      0.77         5
         119       0.75      0.75      0.75         4
         120       1.00      1.00      1.00         4
         121       0.33      0.25      0.29         4
         122       0.27      0.60      0.37         5
         123       0.60      0.75      0.67         4
         124       0.62      1.00      0.77         5
         125       0.00      0.00      0.00         4
         126       1.00      0.80      0.89         5
         127       0.69      1.00      0.82         9
         128       0.00      0.00      0.00         9
         129       0.60      0.75      0.67         4
         130       0.67      0.50      0.57         4
         131       0.67      0.89      0.76         9
         132       0.44      1.00      0.62         4
         133       0.50      0.25      0.33         4
         134       0.78      0.78      0.78         9
         135       0.33      0.50      0.40         4
         136       0.50      0.50      0.50         4
         137       0.00      0.00      0.00         4
         138       1.00      0.60      0.75         5
         139       1.00      1.00      1.00         5
         140       0.00      0.00      0.00         4
         141       1.00      0.50      0.67         4
         142       0.80      1.00      0.89         4
         143       0.25      0.25      0.25         4
         144       1.00      1.00      1.00         4
         145       0.50      0.50      0.50         4
         146       0.00      0.00      0.00         4
         147       0.00      0.00      0.00         4
         148       1.00      0.25      0.40         4
         149       1.00      1.00      1.00         4
         150       0.00      0.00      0.00         4
         151       0.60      0.60      0.60         5
         152       0.42      0.56      0.48         9
         153       1.00      0.80      0.89         5
         154       1.00      1.00      1.00         5
         155       0.00      0.00      0.00         4
         156       0.78      0.78      0.78         9
         157       1.00      0.75      0.86         4
         158       0.83      1.00      0.91         5
         159       0.82      1.00      0.90         9
         160       1.00      0.75      0.86         4
         161       1.00      1.00      1.00         4
         162       0.00      0.00      0.00         4
         163       0.71      0.56      0.63         9
         164       0.00      0.00      0.00         4
         165       1.00      1.00      1.00         9
         166       1.00      0.78      0.88         9
         167       0.40      0.50      0.44         4
         168       0.00      0.00      0.00         4
         169       0.75      0.75      0.75         4
         170       0.40      0.40      0.40         5
         171       0.00      0.00      0.00         4
         172       0.67      0.50      0.57         4
         173       0.38      0.89      0.53         9
         174       0.14      0.50      0.22         4
         175       0.43      0.60      0.50         5
         176       0.00      0.00      0.00         4
         177       1.00      0.75      0.86         4
         178       0.50      0.25      0.33         4
         179       1.00      1.00      1.00         9
         180       1.00      1.00      1.00         4
         181       1.00      1.00      1.00         9
         182       0.50      0.25      0.33         4
         183       0.75      0.75      0.75         4
         184       1.00      1.00      1.00         9
         185       0.78      0.78      0.78         9
         186       0.09      0.25      0.13         4
         187       0.62      1.00      0.77         5
         188       0.89      0.89      0.89         9
         189       0.82      1.00      0.90         9
         190       0.62      1.00      0.77         5
         191       1.00      1.00      1.00         9
         192       0.40      0.80      0.53         5
         193       0.00      0.00      0.00         4
         194       1.00      0.44      0.62         9
         195       0.20      0.22      0.21         9
         196       0.67      0.44      0.53         9
         197       0.75      0.75      0.75         4
         198       0.90      1.00      0.95         9
         199       1.00      0.40      0.57         5
         200       0.80      0.89      0.84         9
         201       0.67      1.00      0.80         4
         202       1.00      0.75      0.86         4
         203       1.00      1.00      1.00         9
         204       1.00      0.89      0.94         9
         205       0.57      1.00      0.73         4
         206       0.50      0.40      0.44         5
         207       0.00      0.00      0.00         4
         208       0.86      0.67      0.75         9
         209       0.80      1.00      0.89         4
         210       1.00      0.25      0.40         4
         211       1.00      1.00      1.00         9
         212       1.00      0.75      0.86         4
         213       1.00      0.20      0.33         5
         214       0.75      0.75      0.75         4
         215       1.00      0.25      0.40         4
         216       1.00      1.00      1.00         9
         217       0.60      0.33      0.43         9
         218       0.00      0.00      0.00         4
         219       0.33      0.20      0.25         5
         220       0.00      0.00      0.00         4
         221       0.50      0.50      0.50         4
         222       0.00      0.00      0.00         4
         223       0.00      0.00      0.00         4
         224       0.50      0.50      0.50         4
         225       0.00      0.00      0.00         4
         226       0.62      1.00      0.77         5
         227       0.00      0.00      0.00         9
         228       0.00      0.00      0.00         9
         229       0.75      0.67      0.71         9
         230       1.00      0.44      0.62         9
         231       1.00      1.00      1.00         5
         232       0.75      0.75      0.75         4
         233       0.00      0.00      0.00         4
         234       0.67      1.00      0.80         4
         235       1.00      1.00      1.00         4
         236       0.00      0.00      0.00         4
         237       1.00      1.00      1.00         9
         238       1.00      1.00      1.00         4
         239       1.00      1.00      1.00         4
         240       0.67      1.00      0.80         4
         241       1.00      1.00      1.00         4
         242       0.60      0.75      0.67         4
         243       1.00      0.25      0.40         4
         244       0.00      0.00      0.00         4
         245       0.00      0.00      0.00         9
         246       1.00      1.00      1.00         4
         247       0.82      1.00      0.90         9
         248       1.00      1.00      1.00         4
         249       0.75      0.67      0.71         9
         250       1.00      0.25      0.40         4
         251       1.00      1.00      1.00         9
         252       0.20      0.50      0.29         4
         253       0.75      0.75      0.75         4
         254       0.00      0.00      0.00         4
         255       0.00      0.00      0.00         4
         256       1.00      1.00      1.00         5
         257       1.00      0.80      0.89         5
         258       0.60      0.75      0.67         4
         259       0.47      0.89      0.62         9
         260       1.00      0.50      0.67         4
         261       1.00      1.00      1.00         4
         262       0.90      1.00      0.95         9
         263       0.75      0.75      0.75         4
         264       0.67      0.50      0.57         4
         265       1.00      1.00      1.00         4
         266       1.00      0.50      0.67         4
         267       0.00      0.00      0.00         4
         268       0.75      0.60      0.67         5
         269       1.00      1.00      1.00         5
         270       1.00      1.00      1.00         4
         271       1.00      0.25      0.40         4
         272       1.00      0.75      0.86         4
         273       0.80      1.00      0.89         4
         274       0.56      1.00      0.71         5
         275       0.67      0.40      0.50         5
         276       1.00      0.50      0.67         4
         277       0.80      1.00      0.89         4
         278       0.67      0.50      0.57         4
         279       1.00      0.50      0.67         4
         280       0.50      0.25      0.33         4
         281       0.75      0.75      0.75         4
         282       1.00      1.00      1.00         4
         283       0.50      0.20      0.29         5
         284       0.38      0.75      0.50         4
         285       0.78      0.78      0.78         9
         286       0.43      0.75      0.55         4
         287       1.00      0.44      0.62         9
         288       1.00      0.75      0.86         4
         289       1.00      1.00      1.00         4
         290       0.89      0.89      0.89         9
         291       0.00      0.00      0.00         4
         292       0.53      1.00      0.69         9
         293       0.69      1.00      0.82         9
         294       0.75      0.75      0.75         4
         295       0.80      0.89      0.84         9
         296       0.67      0.89      0.76         9
         297       0.00      0.00      0.00         4
         298       0.14      0.33      0.20         9
         299       0.40      0.50      0.44         4
         300       0.13      0.75      0.22         4
         301       0.90      1.00      0.95         9
         302       0.00      0.00      0.00         4
         303       0.00      0.00      0.00         4
         304       1.00      1.00      1.00         9
         305       0.50      0.20      0.29         5
         306       1.00      0.89      0.94         9
         307       0.67      0.50      0.57         4
         308       0.80      0.44      0.57         9
         309       1.00      0.80      0.89         5
         310       1.00      0.75      0.86         4
         311       0.75      0.75      0.75         4
         312       0.75      0.60      0.67         5
         313       0.71      1.00      0.83         5
         314       0.57      1.00      0.73         4
         315       1.00      1.00      1.00         4
         316       0.82      1.00      0.90         9
         317       1.00      0.56      0.71         9
         318       1.00      0.75      0.86         4
         319       1.00      0.80      0.89         5
         320       0.80      1.00      0.89         4
         321       0.14      0.25      0.18         4
         322       0.88      0.78      0.82         9
         323       0.75      0.75      0.75         4
         324       1.00      1.00      1.00         9
         325       0.90      1.00      0.95         9
         326       0.50      0.50      0.50         4
         327       0.80      1.00      0.89         4
         328       1.00      0.75      0.86         4
         329       0.50      0.75      0.60         4
         330       0.71      1.00      0.83         5
         331       0.90      1.00      0.95         9
         332       1.00      1.00      1.00         9
         333       0.67      0.50      0.57         4
         334       1.00      0.40      0.57         5
         335       0.41      1.00      0.58         9
         336       1.00      1.00      1.00         4
         337       1.00      0.50      0.67         4
         338       0.13      0.75      0.22         4
         339       1.00      0.25      0.40         4
         340       0.80      1.00      0.89         4
         341       0.88      0.78      0.82         9
         342       0.50      1.00      0.67         4
         343       0.57      1.00      0.73         4
         344       1.00      0.80      0.89         5
         345       0.00      0.00      0.00         9
         346       0.64      1.00      0.78         9
         347       0.80      1.00      0.89         4
         348       0.80      1.00      0.89         4
         349       0.83      1.00      0.91         5
         350       1.00      0.75      0.86         4
         351       0.90      1.00      0.95         9
         352       0.50      0.40      0.44         5
         353       1.00      0.25      0.40         4
         354       0.67      0.80      0.73         5
         355       0.00      0.00      0.00         4
         356       0.90      1.00      0.95         9
         357       0.60      0.75      0.67         4
         358       0.00      0.00      0.00         4
         359       0.83      1.00      0.91         5
         360       0.60      0.75      0.67         4
         361       0.75      0.75      0.75         4
         362       1.00      0.78      0.88         9
         363       1.00      1.00      1.00         9
         364       0.80      1.00      0.89         4
         365       0.00      0.00      0.00         4
         366       0.33      0.75      0.46         4
         367       0.60      0.75      0.67         4
         368       1.00      0.75      0.86         4
         369       1.00      1.00      1.00         4
         370       0.00      0.00      0.00         4
         371       1.00      1.00      1.00         9
         372       0.50      1.00      0.67         5
         373       0.00      0.00      0.00         4
         374       0.00      0.00      0.00         4
         375       0.67      0.67      0.67         9
         376       0.50      0.33      0.40         9
         377       0.67      0.40      0.50         5
         378       0.80      0.80      0.80         5
         379       0.11      0.75      0.19         4
         380       0.00      0.00      0.00         4
         381       1.00      1.00      1.00         4
         382       1.00      1.00      1.00         4
         383       0.54      0.78      0.64         9
         384       1.00      1.00      1.00         5
         385       1.00      1.00      1.00         5
         386       0.67      1.00      0.80         4
         387       0.33      0.50      0.40         6
         388       0.80      1.00      0.89         4
         389       0.29      0.44      0.35         9
         390       1.00      0.75      0.86         4
         391       0.50      1.00      0.67         5
         392       0.88      0.78      0.82         9
         393       0.38      0.56      0.45         9
         394       0.82      1.00      0.90         9
         395       0.00      0.00      0.00         4
         396       1.00      0.89      0.94         9
         397       1.00      0.67      0.80         9
         398       0.00      0.00      0.00         4
         399       0.00      0.00      0.00         4
         400       1.00      1.00      1.00         8
         401       0.75      0.75      0.75         4
         402       0.67      1.00      0.80         4
         403       1.00      0.75      0.86         4
         404       1.00      0.75      0.86         4
         405       0.00      0.00      0.00         4
         406       0.90      1.00      0.95         9
         407       0.75      0.75      0.75         4
         408       0.89      0.89      0.89         9
         409       0.60      0.75      0.67         4
         410       1.00      0.60      0.75         5
         411       0.62      0.89      0.73         9
         412       0.80      1.00      0.89         4
         413       0.00      0.00      0.00         9
         414       0.20      0.20      0.20         5
         415       0.83      1.00      0.91         5
         416       1.00      0.20      0.33         5
         417       0.88      0.78      0.82         9
         418       0.00      0.00      0.00         4
         419       1.00      1.00      1.00         5
         420       0.50      0.75      0.60         4
         421       0.67      0.89      0.76         9
         422       0.50      0.60      0.55         5
         423       0.82      1.00      0.90         9
         424       0.75      0.75      0.75         4
         425       0.00      0.00      0.00         4
         426       0.75      1.00      0.86         9
         427       1.00      0.89      0.94         9
         428       0.00      0.00      0.00         4
         429       0.86      0.86      0.86         7
         430       1.00      0.75      0.86         4
         431       0.62      0.89      0.73         9
         432       0.89      0.89      0.89         9
         433       0.70      0.88      0.78         8
         434       0.00      0.00      0.00         4
         435       1.00      1.00      1.00         5
         436       1.00      1.00      1.00         4
         437       1.00      0.60      0.75         5
         438       1.00      1.00      1.00         4
         439       0.83      1.00      0.91         5
         440       0.25      0.25      0.25         4
         441       0.00      0.00      0.00         4
         442       0.75      0.75      0.75         4
         443       0.80      1.00      0.89         4
         444       1.00      1.00      1.00         5
         445       0.60      0.75      0.67         4
         446       1.00      1.00      1.00         4
         447       0.33      0.60      0.43         5
         448       0.00      0.00      0.00         4
         449       0.00      0.00      0.00         4
         450       0.00      0.00      0.00         4
         451       0.36      1.00      0.53         4
         452       1.00      1.00      1.00         4
         453       1.00      0.75      0.86         4
         454       0.00      0.00      0.00         9
         455       0.25      0.50      0.33         4
         456       0.00      0.00      0.00         4
         457       1.00      1.00      1.00         4
         458       0.86      0.67      0.75         9
         459       1.00      0.11      0.20         9
         460       0.83      1.00      0.91         5
         461       0.80      1.00      0.89         4
         462       1.00      0.25      0.40         4
         463       0.00      0.00      0.00         4
         464       0.88      0.78      0.82         9
         465       0.00      0.00      0.00         4
         466       0.50      0.25      0.33         4
         467       0.80      0.89      0.84         9
         468       1.00      0.50      0.67         4
         469       0.00      0.00      0.00         4
         470       0.00      0.00      0.00         4
         471       1.00      0.67      0.80         9
         472       0.78      0.78      0.78         9
         473       0.00      0.00      0.00         4
         474       0.67      0.50      0.57         4
         475       1.00      0.50      0.67         4
         476       1.00      0.75      0.86         4
         477       1.00      0.75      0.86         4
         478       1.00      1.00      1.00         4
         479       0.50      1.00      0.67         9
         480       0.00      0.00      0.00         4
         481       0.80      1.00      0.89         4
         482       1.00      1.00      1.00         4
         483       0.33      0.20      0.25         5
         484       0.00      0.00      0.00         9
         485       0.00      0.00      0.00         4
         486       0.69      1.00      0.82         9
         487       0.67      0.50      0.57         4
         488       0.14      0.20      0.17         5
         489       0.80      0.80      0.80         5
         490       1.00      0.56      0.71         9
         491       1.00      0.80      0.89         5
         492       0.60      0.75      0.67         4
         493       1.00      0.25      0.40         4
         494       1.00      1.00      1.00         4
         495       0.00      0.00      0.00         4
         496       0.00      0.00      0.00         4
         497       0.78      0.78      0.78         9
         498       0.83      0.56      0.67         9
         499       0.00      0.00      0.00         4
         500       0.80      0.80      0.80         5
         501       0.83      0.56      0.67         9
         502       1.00      0.89      0.94         9
         503       1.00      1.00      1.00         4
         504       1.00      1.00      1.00         4
         505       0.43      0.75      0.55         4
         506       1.00      0.50      0.67         4
         507       0.44      1.00      0.62         4
         508       0.29      0.50      0.36         4
         509       0.00      0.00      0.00         4
         510       0.80      1.00      0.89         4
         511       0.67      0.50      0.57         4
         512       1.00      1.00      1.00         4
         513       1.00      1.00      1.00         4
         514       0.86      0.67      0.75         9
         515       1.00      0.78      0.88         9
         516       0.67      1.00      0.80         4
         517       1.00      0.75      0.86         4
         518       1.00      1.00      1.00         5
         519       0.33      0.25      0.29         4
         520       1.00      0.50      0.67         4
         521       0.80      1.00      0.89         4
         522       0.00      0.00      0.00         4
         523       0.00      0.00      0.00         4
         524       0.80      1.00      0.89         4
         525       1.00      1.00      1.00         4
         526       0.71      0.71      0.71         7
         527       1.00      0.75      0.86         4
         528       0.73      0.89      0.80         9
         529       0.75      0.75      0.75         4
         530       0.50      0.75      0.60         4
         531       0.89      0.89      0.89         9
         532       1.00      0.89      0.94         9
         533       1.00      0.67      0.80         9
         534       0.67      1.00      0.80         4
         535       1.00      0.75      0.86         4
         536       1.00      1.00      1.00         5
         537       1.00      0.75      0.86         4
         538       1.00      1.00      1.00         4
         539       1.00      1.00      1.00         9
         540       0.50      0.44      0.47         9
         541       1.00      0.44      0.62         9
         542       0.73      0.89      0.80         9
         543       0.80      0.89      0.84         9
         544       0.78      0.78      0.78         9
         545       0.75      0.75      0.75         4
         546       0.00      0.00      0.00         4
         547       0.80      1.00      0.89         4
         548       0.57      1.00      0.73         4
         549       1.00      0.75      0.86         4
         550       0.60      0.60      0.60         5
         551       0.75      0.75      0.75         4
         552       0.33      0.50      0.40         4
         553       1.00      0.89      0.94         9
         554       1.00      0.75      0.86         4
         555       0.80      0.80      0.80         5
         556       0.83      1.00      0.91         5
         557       0.75      0.75      0.75         4
         558       1.00      0.75      0.86         4
         559       1.00      0.89      0.94         9
         560       0.70      0.78      0.74         9
         561       0.00      0.00      0.00         4
         562       0.00      0.00      0.00         4
         563       1.00      1.00      1.00         9
         564       0.70      0.78      0.74         9
         565       0.00      0.00      0.00         4
         566       0.50      0.20      0.29         5
         567       0.50      0.25      0.33         4
         568       0.00      0.00      0.00         4
         569       0.60      0.75      0.67         4
         570       1.00      0.75      0.86         4
         571       0.00      0.00      0.00         4
         572       0.27      0.75      0.40         4
         573       0.00      0.00      0.00         4
         574       0.00      0.00      0.00         4
         575       1.00      0.67      0.80         9
         576       1.00      0.75      0.86         4
         577       1.00      1.00      1.00         4
         578       0.00      0.00      0.00         4
         579       1.00      1.00      1.00         4
         580       1.00      1.00      1.00         4
         581       1.00      0.89      0.94         9
         582       0.00      0.00      0.00         4
         583       1.00      0.89      0.94         9
         584       0.11      0.25      0.15         4
         585       0.80      0.80      0.80         5
         586       1.00      1.00      1.00         5
         587       0.62      0.56      0.59         9
         588       0.70      0.78      0.74         9
         589       1.00      1.00      1.00         4
         590       0.67      1.00      0.80         4
         591       0.00      0.00      0.00         4
         592       0.80      0.89      0.84         9
         593       0.56      1.00      0.71         5
         594       0.60      0.75      0.67         4
         595       0.00      0.00      0.00         4
         596       0.00      0.00      0.00         4
         597       0.00      0.00      0.00         4
         598       0.33      0.20      0.25         5
         599       1.00      0.89      0.94         9
         600       0.00      0.00      0.00         4
         601       0.80      1.00      0.89         4
         602       0.75      0.75      0.75         4
         603       1.00      0.80      0.89         5
         604       0.67      1.00      0.80         4
         605       1.00      1.00      1.00         5
         606       1.00      0.75      0.86         4
         607       0.78      0.78      0.78         9
         608       0.67      0.50      0.57         4
         609       1.00      0.75      0.86         4
         610       1.00      1.00      1.00         4
         611       0.00      0.00      0.00         4
         612       1.00      1.00      1.00         4
         613       1.00      0.75      0.86         4
         614       0.33      0.40      0.36         5
         615       0.80      1.00      0.89         4
         616       0.00      0.00      0.00         4
         617       0.29      0.40      0.33         5
         618       0.88      0.78      0.82         9
         619       0.80      0.89      0.84         9
         620       0.67      0.80      0.73         5
         621       1.00      1.00      1.00         9
         622       1.00      0.75      0.86         4
         623       1.00      1.00      1.00         4
         624       0.00      0.00      0.00         4
         625       0.00      0.00      0.00         5
         626       1.00      0.60      0.75         5
         627       0.75      0.75      0.75         4
         628       0.67      0.44      0.53         9
         629       1.00      0.44      0.62         9
         630       0.00      0.00      0.00         4
         631       1.00      0.89      0.94         9
         632       1.00      1.00      1.00         5
         633       0.00      0.00      0.00         9
         634       0.62      1.00      0.77         5
         635       0.50      0.50      0.50         4
         636       0.07      0.25      0.11         4
         637       0.44      0.80      0.57         5
         638       0.00      0.00      0.00         4
         639       0.00      0.00      0.00         5
         640       1.00      1.00      1.00         5
         641       0.78      0.78      0.78         9
         642       0.82      1.00      0.90         9
         643       0.80      1.00      0.89         4
         644       0.00      0.00      0.00         4
         645       0.73      0.89      0.80         9
         646       0.40      1.00      0.57         4
         647       1.00      0.75      0.86         4
         648       0.00      0.00      0.00         4
         649       1.00      1.00      1.00         4
         650       1.00      1.00      1.00         4
         651       0.67      0.50      0.57         4
         652       1.00      0.50      0.67         4
         653       1.00      1.00      1.00         5
         654       1.00      0.89      0.94         9
         655       0.75      0.60      0.67         5
         656       0.00      0.00      0.00         4
         657       1.00      1.00      1.00         9
         658       0.55      0.86      0.67         7
         659       0.50      0.75      0.60         4
         660       0.83      1.00      0.91         5
         661       1.00      0.75      0.86         4
         662       1.00      0.25      0.40         4
         663       0.00      0.00      0.00         4
         664       0.83      1.00      0.91         5
         665       1.00      0.44      0.62         9
         666       1.00      0.75      0.86         4
         667       0.17      0.75      0.27         4
         668       0.00      0.00      0.00         4
         669       0.40      1.00      0.57         4
         670       1.00      0.75      0.86         4
         671       0.40      0.40      0.40         5
         672       0.00      0.00      0.00         4
         673       0.60      0.75      0.67         4
         674       1.00      0.40      0.57         5
         675       1.00      0.78      0.88         9
         676       0.00      0.00      0.00         4
         677       0.82      1.00      0.90         9
         678       1.00      1.00      1.00         4
         679       1.00      0.75      0.86         4
         680       1.00      0.80      0.89         5
         681       1.00      0.75      0.86         4
         682       1.00      0.25      0.40         4
         683       0.00      0.00      0.00         9
         684       1.00      1.00      1.00         4
         685       0.67      0.67      0.67         9
         686       0.18      0.50      0.27         4
         687       0.00      0.00      0.00         4
         688       1.00      0.80      0.89         5
         689       0.80      0.80      0.80         5
         690       0.71      0.56      0.63         9
         691       1.00      0.40      0.57         5
         692       0.83      1.00      0.91         5
         693       0.00      0.00      0.00         4
         694       0.80      0.89      0.84         9
         695       0.67      0.50      0.57         4
         696       1.00      1.00      1.00         4
         697       0.08      0.25      0.12         4
         698       1.00      0.78      0.88         9
         699       0.50      0.25      0.33         4
         700       1.00      1.00      1.00         4
         701       1.00      1.00      1.00         4
         702       1.00      0.75      0.86         4
         703       0.50      0.80      0.62         5
         704       0.75      0.67      0.71         9
         705       1.00      1.00      1.00         4
         706       0.00      0.00      0.00         4
         707       0.22      0.50      0.31         4
         708       0.00      0.00      0.00         4
         709       0.00      0.00      0.00         4
         710       0.50      0.80      0.62         5
         711       0.44      1.00      0.62         4
         712       1.00      0.50      0.67         4
         713       1.00      0.89      0.94         9
         714       1.00      1.00      1.00         5
         715       1.00      0.25      0.40         4
         716       1.00      1.00      1.00         4
         717       1.00      1.00      1.00         4
         718       0.90      1.00      0.95         9
         719       0.57      0.80      0.67         5
         720       1.00      1.00      1.00         5
         721       1.00      0.50      0.67         4
         722       0.82      1.00      0.90         9
         723       1.00      0.60      0.75         5
         724       1.00      1.00      1.00         4
         725       1.00      0.25      0.40         4
         726       0.75      0.75      0.75         4
         727       0.62      0.56      0.59         9
         728       1.00      0.89      0.94         9
         729       1.00      0.80      0.89         5
         730       0.00      0.00      0.00         4
         731       1.00      0.25      0.40         4
         732       0.75      0.60      0.67         5
         733       0.50      1.00      0.67         4
         734       1.00      0.25      0.40         4
         735       0.60      0.75      0.67         4
         736       1.00      0.89      0.94         9
         737       0.00      0.00      0.00         4
         738       1.00      0.80      0.89         5
         739       0.50      0.60      0.55         5
         740       0.86      0.67      0.75         9
         741       1.00      0.75      0.86         4
         742       1.00      1.00      1.00         4
         743       1.00      0.78      0.88         9
         744       0.67      1.00      0.80         4
         745       0.44      0.80      0.57         5
         746       0.80      0.44      0.57         9
         747       0.80      1.00      0.89         4
         748       1.00      1.00      1.00         9
         749       0.00      0.00      0.00         4
         750       0.36      0.44      0.40         9
         751       1.00      0.25      0.40         4
         752       0.80      1.00      0.89         4
         753       0.00      0.00      0.00         9
         754       1.00      1.00      1.00         9
         755       1.00      1.00      1.00         5
         756       0.50      0.50      0.50         4
         757       1.00      0.11      0.20         9
         758       1.00      0.75      0.86         4
         759       0.00      0.00      0.00         4
         760       0.73      0.89      0.80         9
         761       0.82      1.00      0.90         9
         762       0.12      0.75      0.21         4
         763       0.80      0.80      0.80         5
         764       0.89      0.89      0.89         9
         765       1.00      1.00      1.00         4
         766       0.04      0.11      0.06         9
         767       0.67      1.00      0.80         4
         768       1.00      1.00      1.00         5
         769       1.00      0.25      0.40         4
         770       0.10      0.25      0.14         4
         771       1.00      0.75      0.86         4
         772       1.00      0.89      0.94         9
         773       0.20      0.25      0.22         4
         774       1.00      0.50      0.67         4
         775       0.80      1.00      0.89         4
         776       0.75      0.75      0.75         4
         777       0.75      0.75      0.75         4
         778       0.00      0.00      0.00         4
         779       1.00      0.89      0.94         9
         780       1.00      0.89      0.94         9
         781       1.00      1.00      1.00         4
         782       0.14      0.25      0.18         4
         783       0.80      1.00      0.89         4
         784       0.67      1.00      0.80         4
         785       0.30      0.75      0.43         4
         786       0.75      0.75      0.75         4
         787       1.00      1.00      1.00         5
         788       0.09      0.11      0.10         9
         789       1.00      0.40      0.57         5
         790       1.00      1.00      1.00         4
         791       0.00      0.00      0.00         4
         792       0.67      0.50      0.57         4
         793       0.82      1.00      0.90         9
         794       0.50      0.50      0.50         4
         795       0.00      0.00      0.00         9
         796       0.90      1.00      0.95         9
         797       1.00      0.25      0.40         4
         798       1.00      1.00      1.00         5
         799       0.50      0.25      0.33         4
         800       0.67      1.00      0.80         4
         801       1.00      0.75      0.86         4
         802       1.00      0.75      0.86         4
         803       0.00      0.00      0.00         4
         804       0.80      1.00      0.89         4
         805       1.00      0.89      0.94         9
         806       0.67      1.00      0.80         4
         807       0.88      0.78      0.82         9
         808       0.57      1.00      0.73         4
         809       0.88      0.78      0.82         9
         810       0.17      0.25      0.20         4
         811       0.62      1.00      0.77         5
         812       1.00      1.00      1.00         5
         813       1.00      1.00      1.00         5
         814       0.75      0.60      0.67         5
         815       0.78      0.78      0.78         9
         816       0.83      1.00      0.91         5
         817       0.67      0.44      0.53         9
         818       1.00      1.00      1.00         4
         819       1.00      1.00      1.00         4
         820       0.00      0.00      0.00         4
         821       0.00      0.00      0.00         4
         822       0.75      1.00      0.86         9
         823       0.43      0.33      0.38         9
         824       0.14      0.25      0.18         4
         825       1.00      0.89      0.94         9
         826       0.86      0.67      0.75         9
         827       0.05      0.11      0.07         9
         828       0.75      0.75      0.75         4
         829       1.00      0.80      0.89         5
         830       0.75      0.75      0.75         4
         831       1.00      0.50      0.67         4
         832       0.60      0.75      0.67         4
         833       0.00      0.00      0.00         4
         834       0.80      0.89      0.84         9
         835       0.67      1.00      0.80         4
         836       0.00      0.00      0.00         4
         837       0.75      0.75      0.75         4
         838       1.00      1.00      1.00         9
         839       1.00      0.33      0.50         9
         840       0.75      0.75      0.75         4
         841       0.50      0.40      0.44         5
         842       0.80      1.00      0.89         4
         843       0.00      0.00      0.00         9
         844       0.82      1.00      0.90         9
         845       1.00      1.00      1.00         4
         846       0.50      0.25      0.33         4
         847       1.00      0.40      0.57         5
         848       1.00      0.50      0.67         4
         849       0.80      1.00      0.89         4
         850       0.67      1.00      0.80         4
         851       0.00      0.00      0.00         4
         852       0.67      1.00      0.80         4
         853       0.00      0.00      0.00         9
         854       0.90      1.00      0.95         9
         855       0.00      0.00      0.00         4
         856       1.00      0.75      0.86         4
         857       1.00      1.00      1.00         9
         858       0.62      1.00      0.77         5
         859       0.47      0.78      0.58         9
         860       0.83      0.56      0.67         9
         861       1.00      1.00      1.00         5
         862       0.00      0.00      0.00         4
         863       0.57      0.44      0.50         9
         864       0.41      0.78      0.54         9
         865       0.60      0.75      0.67         4
         866       0.64      0.78      0.70         9
         867       1.00      1.00      1.00         4
         868       0.57      1.00      0.73         4
         869       1.00      1.00      1.00         4
         870       0.67      1.00      0.80         4
         871       0.83      1.00      0.91         5
         872       0.90      1.00      0.95         9
         873       0.55      0.67      0.60         9
         874       1.00      0.50      0.67         4
         875       0.58      0.78      0.67         9
         876       1.00      0.50      0.67         4
         877       0.00      0.00      0.00         4
         878       0.50      0.50      0.50         4
         879       0.89      0.89      0.89         9
         880       0.67      0.67      0.67         9
         881       1.00      1.00      1.00         4
         882       0.67      1.00      0.80         4
         883       1.00      1.00      1.00         5
         884       0.50      0.25      0.33         4
         885       1.00      1.00      1.00         4
         886       0.07      0.11      0.09         9
         887       0.00      0.00      0.00         4
         888       0.50      1.00      0.67         4
         889       1.00      1.00      1.00         9
         890       1.00      1.00      1.00         4
         891       1.00      1.00      1.00         4
         892       0.17      0.25      0.20         4
         893       0.00      0.00      0.00         4

    accuracy                           0.67      4917
   macro avg       0.65      0.64      0.62      4917
weighted avg       0.68      0.67      0.65      4917

task_train_time: {0: 9.053083175, 1: 6.095366028000001, 2: 5.6653375960000005, 3: 5.157988994, 4: 4.113051221999996, 5: 5.161403532999998, 6: 4.318455741999998, 7: 5.313585766999999, 8: 5.605526672000003, 9: 6.1438134109999964, 10: 5.198058364999994, 11: 5.109025121000002, 12: 4.462429109000013, 13: 4.970301712000008, 14: 5.55145259999999, 15: 5.6590599650000115, 16: 5.297219828999999, 17: 4.616675231000002, 18: 5.623148107999995, 19: 5.761946469999998, 20: 6.189790469999991, 21: 4.1679166849999945, 22: 5.560354001999997, 23: 4.892128463999995, 24: 4.625316361999978, 25: 5.210797569000022, 26: 5.776766643000002, 27: 5.181287422999986, 28: 5.213932324000012, 29: 4.386337836999985, 30: 5.890835082999985, 31: 4.696072241000024, 32: 4.664913086000013, 33: 5.335790704000004, 34: 4.9197593840000025, 35: 5.072613236999985, 36: 5.874174195000023, 37: 5.869882501999996, 38: 4.705944132000013, 39: 5.060319420000013, 40: 5.886774064000008, 41: 5.477540097000002, 42: 6.517580758999998, 43: 5.196054201999999}
prediction_time: 0.0004412769999930788
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
