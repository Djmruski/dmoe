Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='ea9a0aba-6ebc-4989-b670-552bb7db7eb4', conf_timestamp='2023-08-13 15:26:28.003545', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 60.98 % 	 [Task-IL]: 47.56 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 41.27 % 	 [Task-IL]: 37.92 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 40.6 % 	 [Task-IL]: 35.21 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 33.86 % 	 [Task-IL]: 33.02 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 29.18 % 	 [Task-IL]: 31.45 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 27.85 % 	 [Task-IL]: 30.9 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 20.82 % 	 [Task-IL]: 30.04 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 17.48 % 	 [Task-IL]: 29.46 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 16.36 % 	 [Task-IL]: 29.0 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.73 % 	 [Task-IL]: 28.43 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 19.67 % 	 [Task-IL]: 27.34 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 16.01 % 	 [Task-IL]: 27.74 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 17.45 % 	 [Task-IL]: 27.36 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 17.42 % 	 [Task-IL]: 28.03 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 11.53 % 	 [Task-IL]: 28.38 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 11.73 % 	 [Task-IL]: 27.69 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 11.13 % 	 [Task-IL]: 27.48 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 10.29 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.11 % 	 [Task-IL]: 27.32 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.7 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 9.36 % 	 [Task-IL]: 27.49 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.92 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 7.54 % 	 [Task-IL]: 27.19 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.26 % 	 [Task-IL]: 26.78 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.6 % 	 [Task-IL]: 26.69 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.09 % 	 [Task-IL]: 27.05 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 9.58 % 	 [Task-IL]: 27.31 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.01 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.95 % 	 [Task-IL]: 27.16 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.03 % 	 [Task-IL]: 27.5 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.3 % 	 [Task-IL]: 27.22 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 5.5 % 	 [Task-IL]: 27.02 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.51 % 	 [Task-IL]: 26.64 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 7.03 % 	 [Task-IL]: 26.67 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.57 % 	 [Task-IL]: 26.27 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.48 % 	 [Task-IL]: 25.96 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.39 % 	 [Task-IL]: 25.92 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 6.36 % 	 [Task-IL]: 25.9 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.23 % 	 [Task-IL]: 25.98 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.18 % 	 [Task-IL]: 25.8 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.31 % 	 [Task-IL]: 25.5 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.98 % 	 [Task-IL]: 25.74 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.12 % 	 [Task-IL]: 25.35 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74885, 646: 35, 726: 35, 35: 34, 307: 34, 21: 33, 122: 33, 156: 33, 323: 33, 443: 33, 668: 33, 802: 33, 7: 32, 70: 32, 88: 32, 113: 32, 140: 32, 161: 32, 205: 32, 251: 32, 374: 32, 435: 32, 512: 32, 624: 32, 866: 32, 71: 31, 56: 31, 91: 31, 85: 31, 173: 31, 195: 31, 201: 31, 229: 31, 328: 31, 343: 31, 359: 31, 393: 31, 381: 31, 411: 31, 395: 31, 452: 31, 453: 31, 469: 31, 492: 31, 507: 31, 514: 31, 548: 31, 572: 31, 567: 31, 587: 31, 595: 31, 753: 31, 755: 31, 789: 31, 871: 31, 5: 30, 34: 30, 143: 30, 185: 30, 175: 30, 181: 30, 230: 30, 360: 30, 355: 30, 385: 30, 429: 30, 433: 30, 475: 30, 517: 30, 537: 30, 590: 30, 585: 30, 593: 30, 579: 30, 604: 30, 609: 30, 613: 30, 677: 30, 747: 30, 768: 30, 760: 30, 807: 30, 803: 30, 843: 30, 863: 30, 888: 30, 52: 29, 68: 29, 63: 29, 93: 29, 108: 29, 97: 29, 105: 29, 100: 29, 126: 29, 120: 29, 166: 29, 180: 29, 268: 29, 264: 29, 275: 29, 299: 29, 366: 29, 373: 29, 364: 29, 438: 29, 501: 29, 502: 29, 532: 29, 558: 29, 563: 29, 559: 29, 606: 29, 605: 29, 645: 29, 669: 29, 674: 29, 697: 29, 704: 29, 707: 29, 745: 29, 762: 29, 777: 29, 800: 29, 856: 29, 883: 29, 884: 29, 78: 28, 95: 28, 159: 28, 174: 28, 183: 28, 194: 28, 252: 28, 245: 28, 303: 28, 335: 28, 336: 28, 353: 28, 383: 28, 388: 28, 401: 28, 410: 28, 485: 28, 496: 28, 516: 28, 524: 28, 527: 28, 565: 28, 554: 28, 556: 28, 619: 28, 626: 28, 630: 28, 641: 28, 655: 28, 716: 28, 744: 28, 750: 28, 809: 28, 801: 28, 823: 28, 820: 28, 846: 28, 43: 27, 75: 27, 149: 27, 210: 27, 249: 27, 276: 27, 330: 27, 414: 27, 426: 27, 436: 27, 525: 27, 571: 27, 616: 27, 650: 27, 663: 27, 680: 27, 705: 27, 761: 27, 790: 27, 813: 27, 839: 27, 892: 27, 14: 26, 11: 26, 64: 26, 163: 26, 165: 26, 204: 26, 221: 26, 236: 26, 277: 26, 332: 26, 408: 26, 673: 26, 691: 26, 723: 26, 721: 26, 731: 26, 729: 26, 775: 26, 796: 26, 51: 25, 48: 25, 62: 25, 73: 25, 118: 25, 134: 25, 190: 25, 200: 25, 302: 25, 375: 25, 415: 25, 461: 25, 513: 25, 582: 25, 574: 25, 692: 25, 701: 25, 55: 24, 182: 24, 329: 24, 342: 24, 361: 24, 423: 24, 505: 24, 678: 24, 111: 23, 362: 23, 379: 23, 478: 23, 545: 23, 671: 22, 253: 21, 735: 21, 634: 20, 854: 20, 538: 18, 865: 18, 107: 17, 119: 17, 177: 17, 308: 17, 331: 17, 363: 17, 465: 17, 493: 17, 500: 17, 575: 17, 596: 17, 623: 17, 714: 17, 736: 17, 811: 17, 112: 16, 160: 16, 188: 16, 209: 16, 216: 16, 240: 16, 235: 16, 247: 16, 266: 16, 274: 16, 284: 16, 428: 16, 446: 16, 454: 16, 487: 16, 491: 16, 482: 16, 499: 16, 562: 16, 627: 16, 689: 16, 880: 16, 38: 15, 42: 15, 54: 15, 139: 15, 151: 15, 157: 15, 189: 15, 186: 15, 213: 15, 228: 15, 218: 15, 244: 15, 246: 15, 258: 15, 259: 15, 265: 15, 296: 15, 322: 15, 344: 15, 351: 15, 345: 15, 369: 15, 417: 15, 462: 15, 657: 15, 703: 15, 776: 15, 791: 15, 794: 15, 832: 15, 836: 15, 834: 15, 15: 14, 9: 14, 67: 14, 90: 14, 94: 14, 104: 14, 102: 14, 96: 14, 136: 14, 184: 14, 178: 14, 222: 14, 286: 14, 278: 14, 282: 14, 304: 14, 297: 14, 339: 14, 354: 14, 372: 14, 392: 14, 437: 14, 542: 14, 552: 14, 566: 14, 569: 14, 594: 14, 654: 14, 684: 14, 700: 14, 712: 14, 706: 14, 695: 14, 722: 14, 748: 14, 752: 14, 759: 14, 758: 14, 779: 14, 783: 14, 829: 14, 822: 14, 842: 14, 841: 14, 855: 14, 859: 14, 870: 14, 876: 14, 28: 13, 18: 13, 23: 13, 19: 13, 37: 13, 46: 13, 69: 13, 103: 13, 98: 13, 132: 13, 116: 13, 133: 13, 147: 13, 138: 13, 170: 13, 158: 13, 187: 13, 203: 13, 197: 13, 198: 13, 225: 13, 220: 13, 238: 13, 260: 13, 267: 13, 257: 13, 272: 13, 291: 13, 285: 13, 309: 13, 311: 13, 324: 13, 333: 13, 314: 13, 349: 13, 357: 13, 377: 13, 389: 13, 386: 13, 404: 13, 409: 13, 402: 13, 407: 13, 422: 13, 431: 13, 424: 13, 430: 13, 468: 13, 470: 13, 456: 13, 457: 13, 483: 13, 481: 13, 486: 13, 510: 13, 528: 13, 523: 13, 549: 13, 560: 13, 576: 13, 592: 13, 612: 13, 608: 13, 618: 13, 629: 13, 628: 13, 639: 13, 660: 13, 682: 13, 676: 13, 708: 13, 746: 13, 741: 13, 766: 13, 757: 13, 785: 13, 781: 13, 818: 13, 824: 13, 827: 13, 847: 13, 850: 13, 860: 13, 6: 12, 22: 12, 26: 12, 31: 12, 17: 12, 3: 12, 41: 12, 65: 12, 57: 12, 58: 12, 59: 12, 60: 12, 86: 12, 84: 12, 79: 12, 89: 12, 106: 12, 101: 12, 128: 12, 123: 12, 117: 12, 124: 12, 114: 12, 146: 12, 150: 12, 135: 12, 137: 12, 162: 12, 193: 12, 208: 12, 219: 12, 226: 12, 239: 12, 254: 12, 273: 12, 270: 12, 256: 12, 279: 12, 280: 12, 294: 12, 320: 12, 319: 12, 327: 12, 316: 12, 337: 12, 338: 12, 356: 12, 371: 12, 387: 12, 380: 12, 400: 12, 397: 12, 399: 12, 418: 12, 421: 12, 419: 12, 416: 12, 441: 12, 439: 12, 440: 12, 472: 12, 459: 12, 476: 12, 488: 12, 490: 12, 504: 12, 497: 12, 495: 12, 511: 12, 503: 12, 520: 12, 531: 12, 533: 12, 551: 12, 534: 12, 573: 12, 564: 12, 577: 12, 580: 12, 581: 12, 589: 12, 603: 12, 598: 12, 615: 12, 621: 12, 647: 12, 643: 12, 636: 12, 659: 12, 672: 12, 683: 12, 681: 12, 687: 12, 693: 12, 679: 12, 685: 12, 686: 12, 696: 12, 699: 12, 713: 12, 702: 12, 732: 12, 719: 12, 733: 12, 749: 12, 737: 12, 771: 12, 767: 12, 773: 12, 772: 12, 756: 12, 788: 12, 784: 12, 787: 12, 797: 12, 795: 12, 806: 12, 808: 12, 821: 12, 815: 12, 828: 12, 825: 12, 844: 12, 835: 12, 845: 12, 849: 12, 837: 12, 851: 12, 852: 12, 867: 12, 868: 12, 873: 12, 862: 12, 891: 12, 889: 12, 882: 12, 885: 12, 877: 12, 878: 12, 20: 11, 25: 11, 27: 11, 29: 11, 24: 11, 16: 11, 40: 11, 45: 11, 39: 11, 72: 11, 66: 11, 77: 11, 82: 11, 87: 11, 92: 11, 109: 11, 110: 11, 121: 11, 125: 11, 129: 11, 145: 11, 141: 11, 142: 11, 148: 11, 154: 11, 164: 11, 202: 11, 211: 11, 206: 11, 207: 11, 223: 11, 233: 11, 217: 11, 231: 11, 241: 11, 248: 11, 242: 11, 237: 11, 250: 11, 263: 11, 261: 11, 262: 11, 283: 11, 289: 11, 288: 11, 293: 11, 281: 11, 290: 11, 313: 11, 306: 11, 298: 11, 318: 11, 315: 11, 321: 11, 317: 11, 326: 11, 340: 11, 346: 11, 350: 11, 352: 11, 358: 11, 367: 11, 365: 11, 384: 11, 376: 11, 382: 11, 378: 11, 413: 11, 403: 11, 420: 11, 432: 11, 425: 11, 448: 11, 463: 11, 464: 11, 460: 11, 477: 11, 479: 11, 509: 11, 508: 11, 498: 11, 494: 11, 529: 11, 518: 11, 521: 11, 544: 11, 546: 11, 543: 11, 539: 11, 541: 11, 540: 11, 535: 11, 536: 11, 547: 11, 607: 11, 599: 11, 601: 11, 600: 11, 631: 11, 620: 11, 632: 11, 633: 11, 622: 11, 638: 11, 651: 11, 642: 11, 662: 11, 664: 11, 665: 11, 661: 11, 667: 11, 688: 11, 675: 11, 709: 11, 698: 11, 710: 11, 728: 11, 718: 11, 725: 11, 730: 11, 717: 11, 715: 11, 738: 11, 751: 11, 734: 11, 763: 11, 769: 11, 770: 11, 786: 11, 793: 11, 774: 11, 780: 11, 804: 11, 810: 11, 830: 11, 819: 11, 826: 11, 848: 11, 840: 11, 858: 11, 869: 11, 874: 11, 887: 11, 890: 11, 875: 11, 893: 11, 30: 10, 1: 10, 10: 10, 4: 10, 33: 10, 2: 10, 49: 10, 36: 10, 47: 10, 50: 10, 53: 10, 61: 10, 76: 10, 80: 10, 99: 10, 127: 10, 115: 10, 144: 10, 168: 10, 171: 10, 167: 10, 155: 10, 191: 10, 176: 10, 199: 10, 212: 10, 196: 10, 232: 10, 227: 10, 215: 10, 214: 10, 234: 10, 255: 10, 287: 10, 301: 10, 305: 10, 310: 10, 325: 10, 348: 10, 341: 10, 368: 10, 370: 10, 390: 10, 391: 10, 394: 10, 412: 10, 396: 10, 398: 10, 406: 10, 450: 10, 447: 10, 458: 10, 455: 10, 467: 10, 466: 10, 473: 10, 480: 10, 506: 10, 515: 10, 522: 10, 553: 10, 570: 10, 555: 10, 568: 10, 583: 10, 586: 10, 578: 10, 611: 10, 610: 10, 602: 10, 617: 10, 649: 10, 635: 10, 652: 10, 644: 10, 653: 10, 637: 10, 640: 10, 648: 10, 656: 10, 690: 10, 711: 10, 720: 10, 724: 10, 727: 10, 739: 10, 740: 10, 742: 10, 764: 10, 778: 10, 799: 10, 831: 10, 814: 10, 817: 10, 864: 10, 857: 10, 881: 10, 886: 10, 879: 10, 32: 9, 13: 9, 12: 9, 8: 9, 44: 9, 81: 9, 74: 9, 130: 9, 153: 9, 152: 9, 172: 9, 169: 9, 179: 9, 192: 9, 224: 9, 300: 9, 334: 9, 347: 9, 405: 9, 442: 9, 445: 9, 434: 9, 451: 9, 471: 9, 489: 9, 484: 9, 519: 9, 530: 9, 526: 9, 550: 9, 561: 9, 591: 9, 658: 9, 670: 9, 666: 9, 743: 9, 765: 9, 754: 9, 792: 9, 798: 9, 805: 9, 812: 9, 816: 9, 872: 9, 861: 9, 83: 8, 131: 8, 243: 8, 269: 8, 292: 8, 295: 8, 312: 8, 427: 8, 444: 8, 449: 8, 474: 8, 557: 8, 584: 8, 625: 8, 694: 8, 782: 8, 833: 8, 838: 8, 271: 7, 588: 7, 614: 7, 853: 7, 597: 6})
Total buffer: 89400
fit_time: 123.75982378600001

Accuracy for 44 task(s): 	 [Class-IL]: 73.93 % 	 [Task-IL]: 29.93 %

CLASS_IL_ACC: 
	[70.73170731707317, 76.78571428571429, 85.9375, 66.66666666666666, 68.54838709677419, 76.69902912621359, 75.96153846153845, 73.72881355932203, 88.09523809523809, 81.35593220338984, 75.0, 69.56521739130434, 79.38144329896907, 74.0, 75.72815533980582, 74.77477477477478, 75.0, 76.0, 71.31147540983606, 61.32075471698113, 78.57142857142857, 65.17857142857143, 68.42105263157895, 60.952380952380956, 78.15126050420169, 77.39130434782608, 72.44897959183673, 77.34375, 76.72413793103449, 63.47826086956522, 70.37037037037037, 73.7864077669903, 79.0909090909091, 76.78571428571429, 72.72727272727273, 75.67567567567568, 68.75, 85.3211009174312, 75.0, 68.29268292682927, 64.51612903225806, 73.0, 80.73394495412845, 73.7864077669903]
TASK_IL_ACC: 
	[57.92682926829268, 31.25, 23.4375, 26.126126126126124, 27.419354838709676, 28.155339805825243, 23.076923076923077, 27.966101694915253, 28.57142857142857, 22.88135593220339, 22.0, 26.08695652173913, 25.773195876288657, 41.0, 29.126213592233007, 17.117117117117118, 29.629629629629626, 27.200000000000003, 31.967213114754102, 25.471698113207548, 31.25, 33.035714285714285, 26.31578947368421, 29.523809523809526, 23.52941176470588, 33.04347826086956, 30.612244897959183, 33.59375, 28.448275862068968, 27.82608695652174, 31.48148148148148, 25.24271844660194, 27.27272727272727, 32.142857142857146, 25.454545454545453, 26.126126126126124, 23.214285714285715, 28.440366972477065, 33.65384615384615, 25.203252032520325, 22.58064516129032, 27.0, 31.19266055045872, 88.3495145631068]
f1_micro: 74.02887939800692
f1_macro: 71.29097713324818
              precision    recall  f1-score   support

           0       1.00      0.80      0.89         5
           1       1.00      0.50      0.67         4
           2       0.00      0.00      0.00         4
           3       1.00      1.00      1.00         4
           4       1.00      0.75      0.86         4
           5       0.90      1.00      0.95         9
           6       0.50      0.50      0.50         4
           7       0.75      1.00      0.86         9
           8       0.00      0.00      0.00         4
           9       0.83      1.00      0.91         5
          10       0.00      0.00      0.00         4
          11       0.00      0.00      0.00         9
          12       0.75      0.75      0.75         4
          13       0.80      1.00      0.89         4
          14       0.90      1.00      0.95         9
          15       0.75      0.75      0.75         4
          16       1.00      0.75      0.86         4
          17       1.00      0.75      0.86         4
          18       0.75      0.75      0.75         4
          19       1.00      0.75      0.86         4
          20       1.00      1.00      1.00         4
          21       0.82      1.00      0.90         9
          22       0.75      0.75      0.75         4
          23       0.00      0.00      0.00         4
          24       0.40      0.50      0.44         4
          25       0.60      0.75      0.67         4
          26       1.00      0.80      0.89         5
          27       0.50      0.75      0.60         4
          28       1.00      0.75      0.86         4
          29       1.00      1.00      1.00         4
          30       0.80      1.00      0.89         4
          31       0.00      0.00      0.00         4
          32       1.00      1.00      1.00         4
          33       1.00      1.00      1.00         4
          34       1.00      1.00      1.00         9
          35       1.00      1.00      1.00         9
          36       1.00      1.00      1.00         4
          37       0.50      1.00      0.67         4
          38       1.00      1.00      1.00         5
          39       0.80      1.00      0.89         4
          40       0.00      0.00      0.00         4
          41       0.14      0.25      0.18         4
          42       0.80      0.80      0.80         5
          43       1.00      1.00      1.00         9
          44       1.00      0.75      0.86         4
          45       1.00      0.75      0.86         4
          46       1.00      0.75      0.86         4
          47       0.50      0.75      0.60         4
          48       0.88      0.78      0.82         9
          49       0.80      1.00      0.89         4
          50       0.00      0.00      0.00         4
          51       0.60      0.33      0.43         9
          52       0.88      0.78      0.82         9
          53       1.00      1.00      1.00         4
          54       1.00      1.00      1.00         5
          55       0.75      1.00      0.86         9
          56       0.89      0.89      0.89         9
          57       0.80      1.00      0.89         4
          58       0.50      0.50      0.50         4
          59       0.00      0.00      0.00         4
          60       1.00      1.00      1.00         4
          61       1.00      0.75      0.86         4
          62       1.00      1.00      1.00         9
          63       0.89      0.89      0.89         9
          64       0.90      1.00      0.95         9
          65       1.00      0.80      0.89         5
          66       1.00      1.00      1.00         4
          67       0.00      0.00      0.00         4
          68       1.00      1.00      1.00         9
          69       1.00      0.80      0.89         5
          70       0.70      0.78      0.74         9
          71       1.00      1.00      1.00         9
          72       0.67      1.00      0.80         4
          73       1.00      0.89      0.94         9
          74       0.75      0.75      0.75         4
          75       0.05      0.22      0.08         9
          76       0.80      1.00      0.89         4
          77       0.00      0.00      0.00         4
          78       0.88      0.78      0.82         9
          79       0.80      1.00      0.89         4
          80       0.67      1.00      0.80         4
          81       0.00      0.00      0.00         4
          82       1.00      0.75      0.86         4
          83       0.00      0.00      0.00         4
          84       1.00      1.00      1.00         4
          85       1.00      1.00      1.00         9
          86       1.00      1.00      1.00         4
          87       0.50      0.75      0.60         4
          88       0.04      0.11      0.05         9
          89       0.00      0.00      0.00         4
          90       1.00      0.80      0.89         5
          91       0.90      1.00      0.95         9
          92       0.80      1.00      0.89         4
          93       1.00      1.00      1.00         9
          94       1.00      0.80      0.89         5
          95       0.40      0.22      0.29         9
          96       0.83      1.00      0.91         5
          97       0.00      0.00      0.00         9
          98       1.00      0.75      0.86         4
          99       1.00      1.00      1.00         4
         100       1.00      0.89      0.94         9
         101       1.00      0.80      0.89         5
         102       1.00      0.80      0.89         5
         103       0.80      0.80      0.80         5
         104       0.83      1.00      0.91         5
         105       0.00      0.00      0.00         9
         106       1.00      1.00      1.00         4
         107       1.00      1.00      1.00         5
         108       1.00      1.00      1.00         9
         109       1.00      0.20      0.33         5
         110       1.00      0.75      0.86         4
         111       0.88      0.78      0.82         9
         112       1.00      1.00      1.00         5
         113       0.73      0.89      0.80         9
         114       1.00      1.00      1.00         4
         115       1.00      0.75      0.86         4
         116       1.00      0.75      0.86         4
         117       1.00      1.00      1.00         4
         118       0.78      0.78      0.78         9
         119       1.00      1.00      1.00         5
         120       0.71      0.56      0.63         9
         121       1.00      0.75      0.86         4
         122       0.67      0.44      0.53         9
         123       0.00      0.00      0.00         4
         124       1.00      1.00      1.00         5
         125       0.00      0.00      0.00         4
         126       0.90      1.00      0.95         9
         127       0.75      0.75      0.75         4
         128       0.75      0.75      0.75         4
         129       1.00      1.00      1.00         4
         130       1.00      1.00      1.00         4
         131       0.67      1.00      0.80         4
         132       0.71      1.00      0.83         5
         133       0.80      1.00      0.89         4
         134       0.78      0.78      0.78         9
         135       1.00      1.00      1.00         4
         136       0.80      1.00      0.89         4
         137       0.00      0.00      0.00         4
         138       0.80      1.00      0.89         4
         139       0.40      0.40      0.40         5
         140       0.80      0.44      0.57         9
         141       1.00      1.00      1.00         4
         142       1.00      1.00      1.00         4
         143       0.89      0.89      0.89         9
         144       1.00      0.75      0.86         4
         145       0.80      1.00      0.89         4
         146       0.67      1.00      0.80         4
         147       0.67      0.80      0.73         5
         148       0.67      0.50      0.57         4
         149       1.00      1.00      1.00         9
         150       0.00      0.00      0.00         4
         151       1.00      0.80      0.89         5
         152       1.00      1.00      1.00         5
         153       1.00      0.75      0.86         4
         154       1.00      0.50      0.67         4
         155       1.00      0.50      0.67         4
         156       0.67      0.67      0.67         9
         157       0.80      0.80      0.80         5
         158       1.00      1.00      1.00         4
         159       0.90      1.00      0.95         9
         160       1.00      1.00      1.00         5
         161       0.70      0.78      0.74         9
         162       0.67      0.40      0.50         5
         163       1.00      0.67      0.80         9
         164       1.00      1.00      1.00         4
         165       1.00      0.78      0.88         9
         166       1.00      0.56      0.71         9
         167       1.00      1.00      1.00         4
         168       1.00      0.75      0.86         4
         169       0.57      1.00      0.73         4
         170       1.00      0.75      0.86         4
         171       0.00      0.00      0.00         4
         172       1.00      0.75      0.86         4
         173       0.88      0.78      0.82         9
         174       1.00      0.89      0.94         9
         175       1.00      1.00      1.00         9
         176       0.75      0.75      0.75         4
         177       0.71      1.00      0.83         5
         178       1.00      1.00      1.00         5
         179       1.00      0.50      0.67         4
         180       0.70      0.78      0.74         9
         181       1.00      0.89      0.94         9
         182       0.73      0.89      0.80         9
         183       1.00      0.78      0.88         9
         184       1.00      1.00      1.00         5
         185       0.90      1.00      0.95         9
         186       1.00      0.80      0.89         5
         187       1.00      0.50      0.67         4
         188       0.83      1.00      0.91         5
         189       1.00      1.00      1.00         5
         190       0.89      0.89      0.89         9
         191       1.00      1.00      1.00         4
         192       0.80      1.00      0.89         4
         193       0.75      0.75      0.75         4
         194       0.83      0.56      0.67         9
         195       1.00      1.00      1.00         9
         196       0.67      0.50      0.57         4
         197       1.00      0.75      0.86         4
         198       0.00      0.00      0.00         4
         199       1.00      1.00      1.00         4
         200       0.82      1.00      0.90         9
         201       0.90      1.00      0.95         9
         202       0.00      0.00      0.00         4
         203       0.38      0.60      0.46         5
         204       1.00      1.00      1.00         9
         205       0.64      0.78      0.70         9
         206       1.00      0.75      0.86         4
         207       1.00      0.50      0.67         4
         208       1.00      1.00      1.00         4
         209       0.71      1.00      0.83         5
         210       0.90      1.00      0.95         9
         211       0.80      1.00      0.89         4
         212       1.00      1.00      1.00         4
         213       1.00      1.00      1.00         5
         214       1.00      0.50      0.67         4
         215       1.00      1.00      1.00         4
         216       0.67      0.40      0.50         5
         217       0.50      0.75      0.60         4
         218       0.75      0.60      0.67         5
         219       1.00      0.75      0.86         4
         220       0.75      0.75      0.75         4
         221       0.54      0.78      0.64         9
         222       1.00      0.60      0.75         5
         223       0.67      0.50      0.57         4
         224       0.80      1.00      0.89         4
         225       0.80      1.00      0.89         4
         226       0.75      0.60      0.67         5
         227       1.00      0.25      0.40         4
         228       0.83      1.00      0.91         5
         229       0.82      1.00      0.90         9
         230       0.86      0.67      0.75         9
         231       1.00      1.00      1.00         4
         232       1.00      1.00      1.00         4
         233       0.75      0.75      0.75         4
         234       0.50      0.25      0.33         4
         235       1.00      1.00      1.00         5
         236       0.00      0.00      0.00         9
         237       1.00      0.75      0.86         4
         238       1.00      1.00      1.00         4
         239       0.67      0.50      0.57         4
         240       0.67      0.40      0.50         5
         241       0.50      0.50      0.50         4
         242       0.80      1.00      0.89         4
         243       1.00      1.00      1.00         4
         244       0.43      0.60      0.50         5
         245       1.00      1.00      1.00         9
         246       0.67      0.40      0.50         5
         247       1.00      0.80      0.89         5
         248       1.00      1.00      1.00         4
         249       1.00      0.78      0.88         9
         250       1.00      0.75      0.86         4
         251       1.00      0.78      0.88         9
         252       0.60      0.67      0.63         9
         253       0.89      0.89      0.89         9
         254       1.00      0.75      0.86         4
         255       0.00      0.00      0.00         4
         256       0.00      0.00      0.00         4
         257       1.00      0.75      0.86         4
         258       1.00      1.00      1.00         5
         259       0.83      1.00      0.91         5
         260       0.80      0.80      0.80         5
         261       1.00      1.00      1.00         4
         262       1.00      1.00      1.00         5
         263       0.00      0.00      0.00         4
         264       1.00      1.00      1.00         9
         265       1.00      1.00      1.00         5
         266       0.83      1.00      0.91         5
         267       0.67      0.50      0.57         4
         268       0.90      1.00      0.95         9
         269       1.00      1.00      1.00         4
         270       1.00      1.00      1.00         4
         271       0.75      0.75      0.75         4
         272       1.00      1.00      1.00         4
         273       0.75      0.60      0.67         5
         274       1.00      1.00      1.00         5
         275       1.00      0.78      0.88         9
         276       1.00      1.00      1.00         9
         277       0.80      0.89      0.84         9
         278       1.00      1.00      1.00         5
         279       0.00      0.00      0.00         4
         280       0.60      0.75      0.67         4
         281       0.60      0.75      0.67         4
         282       1.00      0.80      0.89         5
         283       0.09      0.50      0.15         4
         284       1.00      0.80      0.89         5
         285       1.00      0.25      0.40         4
         286       1.00      0.80      0.89         5
         287       0.00      0.00      0.00         4
         288       1.00      1.00      1.00         4
         289       1.00      1.00      1.00         4
         290       0.80      1.00      0.89         4
         291       0.80      1.00      0.89         4
         292       1.00      0.75      0.86         4
         293       0.00      0.00      0.00         4
         294       0.67      1.00      0.80         4
         295       0.75      0.75      0.75         4
         296       1.00      0.60      0.75         5
         297       0.83      1.00      0.91         5
         298       0.80      1.00      0.89         4
         299       0.67      0.89      0.76         9
         300       0.00      0.00      0.00         4
         301       0.60      0.75      0.67         4
         302       1.00      0.67      0.80         9
         303       0.82      1.00      0.90         9
         304       0.80      1.00      0.89         4
         305       0.00      0.00      0.00         4
         306       1.00      1.00      1.00         4
         307       0.90      1.00      0.95         9
         308       1.00      1.00      1.00         5
         309       1.00      1.00      1.00         4
         310       0.67      0.50      0.57         4
         311       0.80      1.00      0.89         4
         312       0.50      0.25      0.33         4
         313       0.00      0.00      0.00         4
         314       1.00      1.00      1.00         5
         315       1.00      1.00      1.00         4
         316       0.00      0.00      0.00         4
         317       0.67      1.00      0.80         4
         318       1.00      0.50      0.67         4
         319       0.00      0.00      0.00         4
         320       0.83      1.00      0.91         5
         321       0.00      0.00      0.00         4
         322       1.00      0.80      0.89         5
         323       1.00      1.00      1.00         9
         324       1.00      0.40      0.57         5
         325       0.40      0.50      0.44         4
         326       0.67      0.50      0.57         4
         327       1.00      1.00      1.00         4
         328       0.90      1.00      0.95         9
         329       0.86      0.67      0.75         9
         330       1.00      0.89      0.94         9
         331       0.80      0.80      0.80         5
         332       0.80      0.89      0.84         9
         333       1.00      1.00      1.00         5
         334       1.00      1.00      1.00         4
         335       1.00      0.56      0.71         9
         336       1.00      1.00      1.00         9
         337       0.75      0.75      0.75         4
         338       1.00      1.00      1.00         4
         339       1.00      1.00      1.00         4
         340       0.75      0.75      0.75         4
         341       0.67      1.00      0.80         4
         342       1.00      0.67      0.80         9
         343       0.00      0.00      0.00         9
         344       1.00      0.60      0.75         5
         345       0.71      1.00      0.83         5
         346       1.00      1.00      1.00         4
         347       0.00      0.00      0.00         4
         348       1.00      0.25      0.40         4
         349       0.80      1.00      0.89         4
         350       1.00      1.00      1.00         4
         351       1.00      1.00      1.00         5
         352       1.00      1.00      1.00         4
         353       1.00      1.00      1.00         9
         354       0.80      0.80      0.80         5
         355       0.90      1.00      0.95         9
         356       1.00      1.00      1.00         4
         357       1.00      0.75      0.86         4
         358       1.00      0.75      0.86         4
         359       0.88      0.78      0.82         9
         360       0.00      0.00      0.00         9
         361       1.00      1.00      1.00         9
         362       0.67      0.44      0.53         9
         363       0.50      0.60      0.55         5
         364       1.00      1.00      1.00         9
         365       1.00      0.50      0.67         4
         366       0.82      1.00      0.90         9
         367       0.80      1.00      0.89         4
         368       1.00      0.25      0.40         4
         369       1.00      1.00      1.00         5
         370       1.00      0.75      0.86         4
         371       0.60      0.60      0.60         5
         372       1.00      1.00      1.00         5
         373       0.80      0.89      0.84         9
         374       0.89      0.89      0.89         9
         375       0.00      0.00      0.00         9
         376       1.00      1.00      1.00         4
         377       0.50      0.50      0.50         4
         378       0.00      0.00      0.00         4
         379       0.90      1.00      0.95         9
         380       0.00      0.00      0.00         4
         381       0.78      0.78      0.78         9
         382       0.20      0.20      0.20         5
         383       0.62      0.89      0.73         9
         384       0.60      0.75      0.67         4
         385       0.80      0.89      0.84         9
         386       0.50      0.50      0.50         4
         387       0.33      0.25      0.29         4
         388       1.00      0.89      0.94         9
         389       0.80      1.00      0.89         4
         390       0.80      1.00      0.89         4
         391       0.80      1.00      0.89         4
         392       0.83      1.00      0.91         5
         393       1.00      1.00      1.00         9
         394       1.00      1.00      1.00         4
         395       0.80      0.44      0.57         9
         396       0.00      0.00      0.00         4
         397       1.00      0.80      0.89         5
         398       0.67      1.00      0.80         4
         399       0.80      1.00      0.89         4
         400       1.00      1.00      1.00         4
         401       0.82      1.00      0.90         9
         402       0.75      0.75      0.75         4
         403       0.00      0.00      0.00         4
         404       0.00      0.00      0.00         4
         405       0.57      1.00      0.73         4
         406       0.67      0.50      0.57         4
         407       0.30      0.75      0.43         4
         408       0.00      0.00      0.00         9
         409       0.80      1.00      0.89         4
         410       0.43      0.33      0.38         9
         411       0.70      0.78      0.74         9
         412       0.67      0.50      0.57         4
         413       0.80      1.00      0.89         4
         414       1.00      1.00      1.00         9
         415       0.80      0.89      0.84         9
         416       0.67      0.50      0.57         4
         417       1.00      1.00      1.00         5
         418       1.00      1.00      1.00         4
         419       0.80      1.00      0.89         4
         420       0.00      0.00      0.00         4
         421       0.80      1.00      0.89         4
         422       0.75      0.75      0.75         4
         423       0.00      0.00      0.00         9
         424       0.40      0.50      0.44         4
         425       0.75      0.75      0.75         4
         426       0.90      1.00      0.95         9
         427       1.00      0.75      0.86         4
         428       0.83      1.00      0.91         5
         429       0.88      0.78      0.82         9
         430       1.00      1.00      1.00         4
         431       1.00      1.00      1.00         4
         432       0.80      1.00      0.89         4
         433       1.00      0.89      0.94         9
         434       0.00      0.00      0.00         4
         435       0.90      1.00      0.95         9
         436       0.00      0.00      0.00         9
         437       1.00      0.60      0.75         5
         438       1.00      1.00      1.00         9
         439       0.33      0.25      0.29         4
         440       1.00      1.00      1.00         4
         441       1.00      0.75      0.86         4
         442       0.33      0.75      0.46         4
         443       0.90      1.00      0.95         9
         444       0.75      0.75      0.75         4
         445       0.50      0.50      0.50         4
         446       1.00      0.80      0.89         5
         447       0.29      0.50      0.36         4
         448       1.00      0.75      0.86         4
         449       1.00      0.75      0.86         4
         450       1.00      1.00      1.00         4
         451       0.80      1.00      0.89         4
         452       0.00      0.00      0.00         9
         453       0.78      0.78      0.78         9
         454       0.80      0.80      0.80         5
         455       1.00      1.00      1.00         4
         456       0.80      1.00      0.89         4
         457       0.00      0.00      0.00         4
         458       1.00      1.00      1.00         4
         459       0.00      0.00      0.00         4
         460       0.80      1.00      0.89         4
         461       1.00      1.00      1.00         9
         462       1.00      0.80      0.89         5
         463       1.00      0.75      0.86         4
         464       0.00      0.00      0.00         4
         465       0.75      0.50      0.60         6
         466       0.00      0.00      0.00         4
         467       0.50      0.50      0.50         4
         468       1.00      0.80      0.89         5
         469       1.00      1.00      1.00         9
         470       1.00      1.00      1.00         4
         471       1.00      0.75      0.86         4
         472       1.00      1.00      1.00         4
         473       0.00      0.00      0.00         4
         474       0.75      0.75      0.75         4
         475       0.78      0.78      0.78         9
         476       1.00      1.00      1.00         4
         477       0.67      0.50      0.57         4
         478       0.90      1.00      0.95         9
         479       1.00      1.00      1.00         4
         480       1.00      0.75      0.86         4
         481       0.00      0.00      0.00         4
         482       0.80      0.80      0.80         5
         483       0.00      0.00      0.00         4
         484       0.00      0.00      0.00         4
         485       1.00      1.00      1.00         9
         486       0.71      1.00      0.83         5
         487       0.67      0.40      0.50         5
         488       0.75      0.75      0.75         4
         489       0.00      0.00      0.00         4
         490       1.00      0.75      0.86         4
         491       0.50      0.80      0.62         5
         492       0.00      0.00      0.00         9
         493       0.67      0.40      0.50         5
         494       0.50      0.50      0.50         4
         495       0.67      1.00      0.80         4
         496       0.89      0.89      0.89         9
         497       0.75      0.75      0.75         4
         498       1.00      1.00      1.00         4
         499       0.83      1.00      0.91         5
         500       1.00      1.00      1.00         5
         501       1.00      1.00      1.00         9
         502       0.62      0.56      0.59         9
         503       0.00      0.00      0.00         4
         504       0.80      1.00      0.89         4
         505       1.00      0.89      0.94         9
         506       0.67      0.50      0.57         4
         507       0.90      1.00      0.95         9
         508       0.67      1.00      0.80         4
         509       1.00      0.80      0.89         5
         510       0.71      1.00      0.83         5
         511       1.00      1.00      1.00         4
         512       0.89      0.89      0.89         9
         513       0.00      0.00      0.00         9
         514       1.00      0.78      0.88         9
         515       0.80      1.00      0.89         4
         516       0.90      1.00      0.95         9
         517       1.00      1.00      1.00         9
         518       1.00      0.75      0.86         4
         519       1.00      0.25      0.40         4
         520       0.67      1.00      0.80         4
         521       0.00      0.00      0.00         4
         522       1.00      0.50      0.67         4
         523       1.00      0.75      0.86         4
         524       0.89      0.89      0.89         9
         525       0.75      1.00      0.86         9
         526       1.00      0.75      0.86         4
         527       0.88      0.78      0.82         9
         528       0.00      0.00      0.00         4
         529       0.80      1.00      0.89         4
         530       0.75      0.75      0.75         4
         531       1.00      0.75      0.86         4
         532       1.00      1.00      1.00         9
         533       0.50      0.25      0.33         4
         534       0.60      0.75      0.67         4
         535       0.50      1.00      0.67         4
         536       1.00      0.75      0.86         4
         537       1.00      0.89      0.94         9
         538       1.00      0.80      0.89         5
         539       1.00      1.00      1.00         4
         540       0.80      1.00      0.89         4
         541       1.00      0.50      0.67         4
         542       0.00      0.00      0.00         4
         543       1.00      0.75      0.86         4
         544       1.00      1.00      1.00         4
         545       0.62      0.56      0.59         9
         546       0.67      0.50      0.57         4
         547       1.00      1.00      1.00         4
         548       1.00      0.89      0.94         9
         549       0.50      0.25      0.33         4
         550       0.00      0.00      0.00         4
         551       0.67      0.80      0.73         5
         552       1.00      0.80      0.89         5
         553       0.67      1.00      0.80         4
         554       0.90      1.00      0.95         9
         555       0.80      1.00      0.89         4
         556       0.86      0.67      0.75         9
         557       1.00      0.75      0.86         4
         558       0.00      0.00      0.00         9
         559       1.00      0.89      0.94         9
         560       1.00      1.00      1.00         5
         561       1.00      1.00      1.00         4
         562       1.00      1.00      1.00         5
         563       0.90      1.00      0.95         9
         564       1.00      0.75      0.86         4
         565       0.90      1.00      0.95         9
         566       0.80      1.00      0.89         4
         567       1.00      0.89      0.94         9
         568       0.50      0.75      0.60         4
         569       0.56      1.00      0.71         5
         570       0.07      0.25      0.11         4
         571       0.00      0.00      0.00         9
         572       0.82      1.00      0.90         9
         573       0.80      1.00      0.89         4
         574       0.83      0.56      0.67         9
         575       0.71      1.00      0.83         5
         576       1.00      0.75      0.86         4
         577       0.00      0.00      0.00         4
         578       1.00      1.00      1.00         4
         579       1.00      0.78      0.88         9
         580       0.75      0.75      0.75         4
         581       1.00      0.75      0.86         4
         582       1.00      1.00      1.00         9
         583       1.00      1.00      1.00         4
         584       0.00      0.00      0.00         4
         585       0.82      1.00      0.90         9
         586       1.00      1.00      1.00         4
         587       0.89      0.89      0.89         9
         588       0.00      0.00      0.00         4
         589       1.00      0.75      0.86         4
         590       1.00      1.00      1.00         9
         591       0.67      0.50      0.57         4
         592       1.00      0.75      0.86         4
         593       1.00      0.89      0.94         9
         594       0.80      1.00      0.89         4
         595       0.90      1.00      0.95         9
         596       0.75      0.86      0.80         7
         597       1.00      1.00      1.00         4
         598       0.00      0.00      0.00         4
         599       0.00      0.00      0.00         4
         600       0.50      1.00      0.67         4
         601       1.00      1.00      1.00         4
         602       0.75      0.75      0.75         4
         603       0.00      0.00      0.00         4
         604       0.75      0.67      0.71         9
         605       0.89      0.89      0.89         9
         606       0.00      0.00      0.00         9
         607       0.00      0.00      0.00         4
         608       0.67      0.80      0.73         5
         609       0.60      0.67      0.63         9
         610       1.00      0.50      0.67         4
         611       0.00      0.00      0.00         4
         612       1.00      1.00      1.00         5
         613       1.00      0.89      0.94         9
         614       1.00      0.50      0.67         4
         615       0.00      0.00      0.00         4
         616       0.90      1.00      0.95         9
         617       0.60      0.75      0.67         4
         618       0.25      0.20      0.22         5
         619       0.58      0.78      0.67         9
         620       1.00      0.75      0.86         4
         621       0.67      1.00      0.80         4
         622       1.00      1.00      1.00         4
         623       0.83      1.00      0.91         5
         624       1.00      1.00      1.00         9
         625       0.50      0.50      0.50         4
         626       1.00      0.89      0.94         9
         627       0.83      1.00      0.91         5
         628       0.60      0.75      0.67         4
         629       0.00      0.00      0.00         4
         630       0.90      1.00      0.95         9
         631       0.67      0.50      0.57         4
         632       0.00      0.00      0.00         4
         633       0.00      0.00      0.00         4
         634       1.00      0.86      0.92         7
         635       1.00      0.75      0.86         4
         636       1.00      1.00      1.00         4
         637       1.00      0.75      0.86         4
         638       1.00      1.00      1.00         4
         639       0.08      0.25      0.12         4
         640       1.00      0.75      0.86         4
         641       1.00      0.78      0.88         9
         642       0.50      0.50      0.50         4
         643       0.50      0.50      0.50         4
         644       1.00      0.50      0.67         4
         645       0.88      0.78      0.82         9
         646       0.50      0.56      0.53         9
         647       1.00      0.75      0.86         4
         648       1.00      1.00      1.00         4
         649       0.80      1.00      0.89         4
         650       1.00      0.89      0.94         9
         651       1.00      0.75      0.86         4
         652       1.00      1.00      1.00         4
         653       0.33      0.25      0.29         4
         654       0.50      0.60      0.55         5
         655       0.89      1.00      0.94         8
         656       0.75      0.75      0.75         4
         657       0.67      0.80      0.73         5
         658       1.00      1.00      1.00         4
         659       1.00      1.00      1.00         4
         660       0.75      0.60      0.67         5
         661       0.75      0.75      0.75         4
         662       0.00      0.00      0.00         4
         663       0.88      0.78      0.82         9
         664       0.00      0.00      0.00         4
         665       0.80      1.00      0.89         4
         666       0.00      0.00      0.00         4
         667       0.57      1.00      0.73         4
         668       0.82      1.00      0.90         9
         669       0.90      1.00      0.95         9
         670       1.00      1.00      1.00         4
         671       0.86      0.75      0.80         8
         672       0.80      1.00      0.89         4
         673       0.80      1.00      0.89         8
         674       1.00      1.00      1.00         9
         675       0.67      1.00      0.80         4
         676       0.57      1.00      0.73         4
         677       1.00      0.89      0.94         9
         678       1.00      0.78      0.88         9
         679       1.00      1.00      1.00         4
         680       0.88      0.78      0.82         9
         681       0.00      0.00      0.00         4
         682       0.75      0.75      0.75         4
         683       1.00      1.00      1.00         4
         684       0.80      0.80      0.80         5
         685       1.00      0.75      0.86         4
         686       0.00      0.00      0.00         4
         687       0.00      0.00      0.00         4
         688       0.40      0.50      0.44         4
         689       1.00      1.00      1.00         5
         690       0.80      1.00      0.89         4
         691       0.90      1.00      0.95         9
         692       1.00      0.56      0.71         9
         693       0.80      1.00      0.89         4
         694       0.00      0.00      0.00         4
         695       0.50      1.00      0.67         4
         696       0.00      0.00      0.00         4
         697       1.00      0.89      0.94         9
         698       1.00      1.00      1.00         4
         699       0.33      0.25      0.29         4
         700       1.00      1.00      1.00         5
         701       1.00      1.00      1.00         9
         702       1.00      1.00      1.00         4
         703       1.00      0.80      0.89         5
         704       1.00      0.78      0.88         9
         705       0.78      0.78      0.78         9
         706       1.00      1.00      1.00         5
         707       1.00      0.89      0.94         9
         708       1.00      0.60      0.75         5
         709       0.00      0.00      0.00         4
         710       1.00      1.00      1.00         4
         711       0.80      1.00      0.89         4
         712       0.67      0.40      0.50         5
         713       0.33      0.25      0.29         4
         714       0.83      1.00      0.91         5
         715       1.00      1.00      1.00         4
         716       0.00      0.00      0.00         9
         717       1.00      0.50      0.67         4
         718       1.00      0.75      0.86         4
         719       1.00      1.00      1.00         4
         720       0.80      1.00      0.89         4
         721       1.00      0.89      0.94         9
         722       1.00      1.00      1.00         4
         723       1.00      1.00      1.00         9
         724       1.00      1.00      1.00         4
         725       0.60      0.75      0.67         4
         726       0.60      1.00      0.75         9
         727       0.67      0.50      0.57         4
         728       1.00      0.75      0.86         4
         729       0.67      0.89      0.76         9
         730       0.00      0.00      0.00         4
         731       1.00      1.00      1.00         9
         732       1.00      0.75      0.86         4
         733       0.00      0.00      0.00         4
         734       1.00      1.00      1.00         4
         735       0.00      0.00      0.00         9
         736       0.56      1.00      0.71         5
         737       1.00      1.00      1.00         4
         738       0.00      0.00      0.00         4
         739       1.00      0.75      0.86         4
         740       0.00      0.00      0.00         4
         741       1.00      1.00      1.00         4
         742       0.50      0.25      0.33         4
         743       0.75      0.75      0.75         4
         744       0.80      0.89      0.84         9
         745       0.90      1.00      0.95         9
         746       0.00      0.00      0.00         4
         747       1.00      0.89      0.94         9
         748       1.00      0.75      0.86         4
         749       1.00      1.00      1.00         4
         750       0.38      0.33      0.35         9
         751       1.00      1.00      1.00         4
         752       1.00      1.00      1.00         5
         753       0.90      1.00      0.95         9
         754       0.60      0.75      0.67         4
         755       1.00      1.00      1.00         9
         756       1.00      0.60      0.75         5
         757       0.80      1.00      0.89         4
         758       1.00      1.00      1.00         5
         759       0.67      0.80      0.73         5
         760       1.00      0.89      0.94         9
         761       0.82      1.00      0.90         9
         762       0.90      1.00      0.95         9
         763       1.00      1.00      1.00         5
         764       0.00      0.00      0.00         4
         765       1.00      1.00      1.00         4
         766       1.00      1.00      1.00         4
         767       0.50      0.75      0.60         4
         768       0.88      0.78      0.82         9
         769       0.80      1.00      0.89         4
         770       0.80      1.00      0.89         4
         771       0.80      1.00      0.89         4
         772       0.60      0.75      0.67         4
         773       1.00      0.25      0.40         4
         774       0.00      0.00      0.00         4
         775       0.90      1.00      0.95         9
         776       0.00      0.00      0.00         4
         777       1.00      1.00      1.00         9
         778       0.00      0.00      0.00         4
         779       0.83      1.00      0.91         5
         780       0.50      0.50      0.50         4
         781       0.00      0.00      0.00         4
         782       0.60      0.75      0.67         4
         783       0.75      0.60      0.67         5
         784       0.80      1.00      0.89         4
         785       1.00      0.80      0.89         5
         786       0.67      1.00      0.80         4
         787       1.00      1.00      1.00         4
         788       0.67      0.50      0.57         4
         789       0.89      0.89      0.89         9
         790       1.00      1.00      1.00         9
         791       0.67      0.80      0.73         5
         792       1.00      1.00      1.00         4
         793       1.00      1.00      1.00         4
         794       1.00      1.00      1.00         5
         795       0.80      1.00      0.89         4
         796       1.00      0.89      0.94         9
         797       1.00      1.00      1.00         5
         798       1.00      0.25      0.40         4
         799       0.00      0.00      0.00         4
         800       1.00      0.89      0.94         9
         801       0.80      0.89      0.84         9
         802       0.75      1.00      0.86         9
         803       0.00      0.00      0.00         9
         804       1.00      1.00      1.00         4
         805       1.00      0.25      0.40         4
         806       0.00      0.00      0.00         4
         807       0.89      0.89      0.89         9
         808       0.60      0.75      0.67         4
         809       0.67      0.89      0.76         9
         810       0.00      0.00      0.00         4
         811       0.80      0.80      0.80         5
         812       0.60      0.75      0.67         4
         813       0.62      0.56      0.59         9
         814       0.00      0.00      0.00         4
         815       0.75      0.75      0.75         4
         816       1.00      1.00      1.00         4
         817       0.20      0.25      0.22         4
         818       0.04      0.25      0.07         4
         819       1.00      1.00      1.00         4
         820       0.43      0.67      0.52         9
         821       0.00      0.00      0.00         4
         822       1.00      1.00      1.00         4
         823       1.00      1.00      1.00         9
         824       0.80      0.80      0.80         5
         825       1.00      1.00      1.00         4
         826       0.67      0.50      0.57         4
         827       0.00      0.00      0.00         4
         828       0.75      0.75      0.75         4
         829       0.75      0.75      0.75         4
         830       0.33      0.40      0.36         5
         831       1.00      1.00      1.00         4
         832       1.00      0.80      0.89         5
         833       0.50      0.50      0.50         4
         834       1.00      0.80      0.89         5
         835       0.50      1.00      0.67         4
         836       0.71      1.00      0.83         5
         837       0.00      0.00      0.00         4
         838       1.00      1.00      1.00         4
         839       1.00      1.00      1.00         9
         840       1.00      0.75      0.86         4
         841       1.00      1.00      1.00         5
         842       1.00      1.00      1.00         5
         843       1.00      1.00      1.00         9
         844       0.80      1.00      0.89         4
         845       0.00      0.00      0.00         4
         846       1.00      0.89      0.94         9
         847       0.00      0.00      0.00         4
         848       0.67      1.00      0.80         4
         849       0.00      0.00      0.00         4
         850       0.75      0.60      0.67         5
         851       0.75      0.75      0.75         4
         852       0.75      0.75      0.75         4
         853       0.00      0.00      0.00         4
         854       1.00      0.71      0.83         7
         855       1.00      1.00      1.00         5
         856       0.80      0.89      0.84         9
         857       1.00      0.75      0.86         4
         858       1.00      1.00      1.00         5
         859       0.83      1.00      0.91         5
         860       0.08      0.25      0.12         4
         861       0.75      0.75      0.75         4
         862       0.12      0.25      0.17         4
         863       0.88      0.78      0.82         9
         864       1.00      0.75      0.86         4
         865       0.56      1.00      0.71         5
         866       1.00      1.00      1.00         9
         867       0.67      1.00      0.80         4
         868       0.57      0.80      0.67         5
         869       0.80      1.00      0.89         4
         870       1.00      1.00      1.00         5
         871       0.88      0.78      0.82         9
         872       0.80      1.00      0.89         4
         873       0.00      0.00      0.00         4
         874       1.00      1.00      1.00         4
         875       1.00      0.50      0.67         4
         876       1.00      0.75      0.86         4
         877       1.00      1.00      1.00         4
         878       1.00      0.75      0.86         4
         879       0.80      0.80      0.80         5
         880       0.71      1.00      0.83         5
         881       0.00      0.00      0.00         4
         882       1.00      1.00      1.00         4
         883       0.75      0.67      0.71         9
         884       1.00      1.00      1.00         9
         885       0.00      0.00      0.00         4
         886       0.75      0.75      0.75         4
         887       0.17      0.25      0.20         4
         888       0.75      1.00      0.86         9
         889       1.00      1.00      1.00         4
         890       0.06      0.25      0.09         4
         891       0.71      1.00      0.83         5
         892       1.00      0.78      0.88         9
         893       1.00      0.50      0.67         4

    accuracy                           0.74      4917
   macro avg       0.73      0.72      0.71      4917
weighted avg       0.75      0.74      0.74      4917

task_train_time: {0: 0.11010765900000052, 1: 0.031611205999999115, 2: 0.03272786800000027, 3: 0.026087581000000526, 4: 0.0313694610000006, 5: 0.026268234999999862, 6: 0.029991514000000663, 7: 0.027807263999999776, 8: 0.030748983000000507, 9: 0.03033021899999966, 10: 0.028193681999999498, 11: 0.033409404000000364, 12: 0.029001698000000076, 13: 0.030226026000001127, 14: 0.030762168000000756, 15: 0.03200347900000011, 16: 0.030676630000000316, 17: 0.03577957999999981, 18: 0.03577739400000013, 19: 0.030318009000000146, 20: 0.03500213300000077, 21: 0.03393331800000077, 22: 0.027575182999999726, 23: 0.03076217899999989, 24: 0.03590335800000055, 25: 0.035791033999998945, 26: 0.02975104500000114, 27: 0.04169187200000124, 28: 0.03825800700000137, 29: 0.03269250099999965, 30: 0.030699802000000886, 31: 0.03127253499999938, 32: 0.03296968900000152, 33: 0.03339375700000069, 34: 0.03269842499999953, 35: 0.0334416829999995, 36: 0.03368468100000044, 37: 0.03420320499999896, 38: 0.0328354080000004, 39: 0.0387993790000003, 40: 0.023648498000000018, 41: 0.02311562699999925, 42: 0.03250381699999849, 43: 0.032495491999998904}
prediction_time: 0.00022015300001498872
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
