	dataset_config: {'path': '/home/fr27/Documents/pyscript/wisdm/dataset/arff_files/phone/accel/all.csv', 'path_test': '/home/fr27/Documents/pyscript/wisdm/dataset/arff_files/phone/accel/all.csv', 'resize': None, 'pad': None, 'crop': None, 'normalize': None, 'class_order': None, 'extend_channel': None, 'flip': False}
CLASS_ORDER: [40, 657, 613, 122, 758, 99, 589, 744, 409, 567, 692, 305, 873, 506, 833, 3, 275, 391, 520, 460, 280, 563, 123, 206, 825, 476, 186, 763, 377, 61, 427, 585, 574, 19, 663, 369, 309, 222, 629, 286, 593, 371, 886, 627, 775, 338, 736, 141, 20, 196, 690, 493, 851, 704, 605, 303, 449, 333, 621, 609, 91, 339, 617, 892, 854, 784, 147, 42, 375, 865, 297, 219, 625, 812, 712, 403, 655, 649, 724, 582, 23, 134, 619, 839, 259, 445, 308, 513, 482, 121, 849, 588, 860, 421, 207, 749, 707, 499, 592, 596, 557, 55, 172, 684, 448, 319, 4, 247, 21, 888, 543, 300, 36, 248, 711, 641, 168, 462, 393, 786, 756, 142, 889, 891, 54, 816, 553, 127, 870, 473, 572, 768, 424, 193, 603, 149, 216, 109, 69, 547, 809, 17, 71, 161, 35, 471, 770, 266, 37, 577, 174, 594, 705, 253, 810, 290, 2, 518, 301, 233, 664, 402, 783, 407, 245, 289, 197, 171, 539, 162, 112, 669, 218, 620, 115, 378, 430, 78, 855, 569, 796, 510, 125, 262, 656, 640, 323, 608, 400, 771, 24, 766, 302, 549, 342, 82, 5, 114, 521, 7, 401, 637, 701, 884, 591, 10, 96, 752, 691, 722, 60, 490, 41, 330, 843, 893, 67, 470, 118, 698, 156, 310, 829, 426, 797, 776, 552, 314, 519, 390, 368, 500, 777, 824, 706, 349, 883, 244, 747, 111, 246, 720, 433, 179, 496, 648, 434, 361, 129, 650, 102, 188, 542, 357, 74, 31, 866, 677, 537, 235, 367, 800, 277, 602, 458, 586, 879, 418, 769, 740, 505, 806, 95, 341, 287, 170, 801, 616, 764, 173, 140, 696, 451, 90, 675, 66, 106, 231, 817, 660, 491, 754, 511, 128, 321, 312, 92, 15, 405, 331, 16, 146, 394, 674, 788, 646, 778, 739, 639, 828, 550, 295, 202, 199, 623, 515, 187, 814, 87, 746, 527, 335, 14, 240, 265, 269, 370, 387, 419, 249, 734, 260, 466, 792, 808, 8, 885, 681, 601, 89, 524, 76, 104, 97, 365, 795, 226, 293, 845, 428, 351, 191, 431, 626, 180, 145, 214, 514, 285, 575, 581, 64, 480, 599, 151, 366, 742, 169, 209, 43, 486, 404, 798, 234, 678, 731, 243, 232, 488, 565, 541, 159, 863, 26, 160, 628, 306, 379, 425, 702, 818, 94, 360, 713, 761, 504, 413, 288, 853, 359, 356, 282, 871, 284, 86, 113, 850, 267, 452, 195, 1, 212, 533, 326, 805, 841, 772, 237, 790, 228, 457, 545, 184, 46, 444, 395, 327, 606, 450, 154, 868, 551, 263, 353, 68, 723, 644, 93, 229, 607, 329, 685, 738, 642, 447, 176, 210, 373, 47, 773, 782, 88, 98, 155, 479, 730, 477, 136, 630, 561, 217, 415, 615, 304, 862, 687, 531, 528, 311, 826, 382, 334, 80, 700, 410, 454, 492, 653, 75, 534, 495, 556, 63, 580, 438, 832, 667, 437, 372, 178, 717, 745, 185, 307, 548, 635, 205, 554, 890, 670, 807, 417, 759, 564, 254, 523, 852, 847, 680, 238, 201, 877, 869, 163, 858, 345, 611, 166, 671, 117, 714, 56, 241, 472, 562, 679, 494, 291, 57, 328, 380, 276, 27, 838, 659, 432, 633, 643, 158, 785, 255, 793, 573, 735, 544, 638, 526, 781, 332, 748, 126, 0, 242, 840, 741, 501, 59, 558, 272, 498, 686, 794, 595, 414, 348, 465, 737, 399, 107, 317, 315, 566, 110, 85, 376, 622, 324, 658, 281, 79, 570, 464, 463, 502, 157, 299, 774, 108, 729, 489, 194, 279, 856, 584, 350, 65, 386, 101, 571, 503, 697, 381, 177, 167, 236, 525, 25, 689, 32, 270, 135, 516, 51, 760, 175, 803, 264, 716, 388, 52, 83, 389, 875, 397, 459, 44, 559, 138, 859, 682, 271, 811, 53, 22, 469, 204, 632, 578, 604, 804, 283, 468, 119, 512, 661, 709, 429, 881, 268, 139, 846, 487, 364, 70, 830, 483, 343, 423, 384, 662, 33, 478, 153, 392, 58, 296, 374, 757, 532, 673, 131, 474, 733, 822, 439, 81, 536, 192, 278, 842, 813, 864, 647, 137, 732, 583, 827, 440, 257, 133, 12, 72, 446, 765, 28, 780, 130, 872, 251, 844, 837, 220, 396, 211, 84, 45, 668, 200, 30, 743, 751, 721, 208, 227, 435, 874, 150, 455, 215, 292, 77, 672, 636, 294, 436, 522, 600, 182, 878, 347, 412, 318, 725, 634, 755, 50, 676, 100, 762, 420, 693, 258, 579, 715, 508, 665, 198, 273, 726, 654, 224, 383, 481, 213, 29, 880, 336, 406, 223, 298, 105, 398, 49, 683, 274, 791, 831, 443, 802, 354, 456, 152, 507, 861, 699, 694, 116, 789, 225, 815, 484, 13, 485, 18, 708, 362, 422, 779, 703, 568, 598, 848, 835, 313, 6, 836, 467, 823, 727, 239, 408, 322, 799, 688, 203, 834, 509, 256, 614, 344, 38, 576, 190, 497, 819, 124, 753, 517, 666, 143, 39, 337, 103, 442, 183, 453, 645, 529, 261, 540, 441, 787, 587, 325, 144, 340, 48, 651, 132, 230, 358, 73, 652, 618, 355, 34, 352, 538, 120, 461, 250, 148, 363, 416, 346, 719, 411, 718, 555, 316, 882, 560, 767, 530, 750, 9, 710, 535, 320, 252, 189, 624, 164, 597, 612, 867, 820, 728, 695, 181, 876, 221, 546, 475, 385, 857, 62, 887, 610, 821, 165, 11, 631, 590]
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList()
)
======

************************************************************************************************************
Task  0
************************************************************************************************************
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.792, TAw acc= 42.4% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.324, TAw acc= 52.8% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.972, TAw acc= 59.2% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.700, TAw acc= 69.6% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.486, TAw acc= 84.0% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.309, TAw acc= 88.0% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.166, TAw acc= 89.6% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.044, TAw acc= 92.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
| Selected 353 train exemplars, time=  0.0s
353
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.004 | TAw acc= 94.7%, forg=  0.0%| TAg acc= 94.7%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
  )
)
======

************************************************************************************************************
Task  1
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=3.241, TAw acc= 50.5% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.441, TAw acc= 63.2% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.964, TAw acc= 72.6% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.656, TAw acc= 82.1% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.438, TAw acc= 87.4% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.259, TAw acc= 88.4% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.131, TAw acc= 90.5% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.023, TAw acc= 90.5% | *
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.022, TAw acc= 90.5% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.021, TAw acc= 90.5% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.020, TAw acc= 90.5% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.019, TAw acc= 90.5% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.018, TAw acc= 90.5% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
| Selected 533 train exemplars, time=  0.0s
533
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.901 | TAw acc= 94.2%, forg=  0.6%| TAg acc= 90.6%, forg=  4.1% <<<
>>> Test on task  1 : loss=1.068 | TAw acc= 89.0%, forg=  0.0%| TAg acc= 86.6%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  2
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.398, TAw acc= 17.4% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.632, TAw acc= 44.6% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.187, TAw acc= 73.9% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.846, TAw acc= 78.3% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.607, TAw acc= 80.4% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.424, TAw acc= 81.5% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.289, TAw acc= 84.8% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.139, TAw acc= 82.6% | *
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.138, TAw acc= 82.6% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.137, TAw acc= 82.6% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.136, TAw acc= 82.6% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.134, TAw acc= 82.6% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.133, TAw acc= 82.6% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
| Selected 713 train exemplars, time=  0.0s
713
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.731 | TAw acc= 95.3%, forg= -0.6%| TAg acc= 90.6%, forg=  4.1% <<<
>>> Test on task  1 : loss=1.239 | TAw acc= 95.3%, forg= -6.3%| TAg acc= 71.7%, forg= 15.0% <<<
>>> Test on task  2 : loss=1.115 | TAw acc= 83.7%, forg=  0.0%| TAg acc= 80.5%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  3
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=4.173, TAw acc= 35.4% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.294, TAw acc= 39.0% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.758, TAw acc= 46.3% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.421, TAw acc= 65.9% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.144, TAw acc= 73.2% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.928, TAw acc= 78.0% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.759, TAw acc= 82.9% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.622, TAw acc= 82.9% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.621, TAw acc= 82.9% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.3s loss=1.620, TAw acc= 82.9% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.4s loss=1.619, TAw acc= 82.9% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.4s loss=1.618, TAw acc= 82.9% | *
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.3s loss=1.617, TAw acc= 82.9% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 845 train exemplars, time=  0.0s
845
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.706 | TAw acc= 95.3%, forg=  0.0%| TAg acc= 83.0%, forg= 11.7% <<<
>>> Test on task  1 : loss=1.081 | TAw acc= 95.3%, forg=  0.0%| TAg acc= 81.1%, forg=  5.5% <<<
>>> Test on task  2 : loss=1.174 | TAw acc= 89.4%, forg= -5.7%| TAg acc= 81.3%, forg= -0.8% <<<
>>> Test on task  3 : loss=1.504 | TAw acc= 83.8%, forg=  0.0%| TAg acc= 64.0%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  4
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.853, TAw acc= 47.9% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.250, TAw acc= 62.8% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.595, TAw acc= 83.0% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.243, TAw acc= 89.4% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.051, TAw acc= 90.4% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=0.919, TAw acc= 94.7% | *
| Epoch   7, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.858, TAw acc= 95.7% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.783, TAw acc= 95.7% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.782, TAw acc= 95.7% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.782, TAw acc= 95.7% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.781, TAw acc= 95.7% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.780, TAw acc= 95.7% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=0.780, TAw acc= 95.7% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 965 train exemplars, time=  0.0s
965
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.679 | TAw acc= 95.3%, forg=  0.0%| TAg acc= 84.8%, forg=  9.9% <<<
>>> Test on task  1 : loss=1.062 | TAw acc= 95.3%, forg=  0.0%| TAg acc= 78.0%, forg=  8.7% <<<
>>> Test on task  2 : loss=0.996 | TAw acc= 86.2%, forg=  3.3%| TAg acc= 80.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=1.829 | TAw acc= 91.9%, forg= -8.1%| TAg acc= 42.3%, forg= 21.6% <<<
>>> Test on task  4 : loss=0.858 | TAw acc= 95.2%, forg=  0.0%| TAg acc= 88.0%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  5
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=4.280, TAw acc= 51.5% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.911, TAw acc= 58.4% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.207, TAw acc= 68.3% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.783, TAw acc= 78.2% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.561, TAw acc= 82.2% | *
| Epoch   6, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.394, TAw acc= 81.2% | *
| Epoch   7, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.285, TAw acc= 85.1% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.216, TAw acc= 82.2% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.215, TAw acc= 82.2% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.214, TAw acc= 82.2% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.213, TAw acc= 82.2% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.211, TAw acc= 82.2% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.210, TAw acc= 82.2% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1085 train exemplars, time=  0.0s
1085
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.627 | TAw acc= 96.5%, forg= -1.2%| TAg acc= 90.6%, forg=  4.1% <<<
>>> Test on task  1 : loss=0.919 | TAw acc= 96.1%, forg= -0.8%| TAg acc= 81.9%, forg=  4.7% <<<
>>> Test on task  2 : loss=0.972 | TAw acc= 89.4%, forg=  0.0%| TAg acc= 80.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=1.665 | TAw acc= 93.7%, forg= -1.8%| TAg acc= 47.7%, forg= 16.2% <<<
>>> Test on task  4 : loss=1.266 | TAw acc= 95.2%, forg=  0.0%| TAg acc= 72.0%, forg= 16.0% <<<
>>> Test on task  5 : loss=1.050 | TAw acc= 88.0%, forg=  0.0%| TAg acc= 74.4%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  6
************************************************************************************************************
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=4.566, TAw acc= 43.5% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.693, TAw acc= 63.5% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.849, TAw acc= 83.5% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.497, TAw acc= 90.6% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.241, TAw acc= 91.8% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.147, TAw acc= 92.9% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.007, TAw acc= 96.5% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.930, TAw acc= 96.5% | *
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.929, TAw acc= 96.5% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.929, TAw acc= 96.5% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.928, TAw acc= 96.5% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.928, TAw acc= 96.5% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=0.927, TAw acc= 96.5% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1205 train exemplars, time=  0.0s
1205
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.574 | TAw acc= 96.5%, forg=  0.0%| TAg acc= 94.2%, forg=  0.6% <<<
>>> Test on task  1 : loss=0.888 | TAw acc= 96.9%, forg= -0.8%| TAg acc= 84.3%, forg=  2.4% <<<
>>> Test on task  2 : loss=0.925 | TAw acc= 87.8%, forg=  1.6%| TAg acc= 80.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=1.489 | TAw acc= 95.5%, forg= -1.8%| TAg acc= 57.7%, forg=  6.3% <<<
>>> Test on task  4 : loss=1.336 | TAw acc= 96.0%, forg= -0.8%| TAg acc= 63.2%, forg= 24.8% <<<
>>> Test on task  5 : loss=1.428 | TAw acc= 94.7%, forg= -6.8%| TAg acc= 64.7%, forg=  9.8% <<<
>>> Test on task  6 : loss=0.807 | TAw acc= 96.5%, forg=  0.0%| TAg acc= 92.2%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  7
************************************************************************************************************
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=5.083, TAw acc= 50.0% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=3.217, TAw acc= 61.3% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.208, TAw acc= 83.8% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.765, TAw acc= 92.5% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.479, TAw acc= 92.5% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.322, TAw acc= 92.5% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.192, TAw acc= 92.5% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.089, TAw acc= 91.2% | *
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.088, TAw acc= 91.2% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.087, TAw acc= 91.2% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.087, TAw acc= 91.2% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.086, TAw acc= 91.2% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.085, TAw acc= 91.2% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1325 train exemplars, time=  0.0s
1325
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.611 | TAw acc= 96.5%, forg=  0.0%| TAg acc= 93.0%, forg=  1.8% <<<
>>> Test on task  1 : loss=0.807 | TAw acc= 97.6%, forg= -0.8%| TAg acc= 90.6%, forg= -3.9% <<<
>>> Test on task  2 : loss=0.913 | TAw acc= 89.4%, forg=  0.0%| TAg acc= 84.6%, forg= -3.3% <<<
>>> Test on task  3 : loss=1.365 | TAw acc= 96.4%, forg= -0.9%| TAg acc= 59.5%, forg=  4.5% <<<
>>> Test on task  4 : loss=1.154 | TAw acc= 96.0%, forg=  0.0%| TAg acc= 68.0%, forg= 20.0% <<<
>>> Test on task  5 : loss=1.410 | TAw acc= 95.5%, forg= -0.8%| TAg acc= 59.4%, forg= 15.0% <<<
>>> Test on task  6 : loss=1.355 | TAw acc= 99.1%, forg= -2.6%| TAg acc= 55.7%, forg= 36.5% <<<
>>> Test on task  7 : loss=1.061 | TAw acc= 93.5%, forg=  0.0%| TAg acc= 83.3%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
    (7): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  8
************************************************************************************************************
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=5.292, TAw acc= 49.4% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=3.463, TAw acc= 62.7% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.492, TAw acc= 69.9% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.045, TAw acc= 77.1% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.720, TAw acc= 86.7% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.562, TAw acc= 92.8% | *
| Epoch   7, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.405, TAw acc= 94.0% | *
| Epoch   8, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.343, TAw acc= 95.2% | *
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.342, TAw acc= 95.2% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.340, TAw acc= 95.2% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.339, TAw acc= 95.2% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.338, TAw acc= 95.2% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.337, TAw acc= 95.2% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1445 train exemplars, time=  0.0s
1445
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.617 | TAw acc= 97.1%, forg= -0.6%| TAg acc= 85.4%, forg=  9.4% <<<
>>> Test on task  1 : loss=0.791 | TAw acc= 97.6%, forg=  0.0%| TAg acc= 86.6%, forg=  3.9% <<<
>>> Test on task  2 : loss=0.969 | TAw acc= 89.4%, forg=  0.0%| TAg acc= 74.8%, forg=  9.8% <<<
>>> Test on task  3 : loss=1.408 | TAw acc= 95.5%, forg=  0.9%| TAg acc= 63.1%, forg=  0.9% <<<
>>> Test on task  4 : loss=1.201 | TAw acc= 96.8%, forg= -0.8%| TAg acc= 65.6%, forg= 22.4% <<<
>>> Test on task  5 : loss=1.358 | TAw acc= 94.7%, forg=  0.8%| TAg acc= 63.2%, forg= 11.3% <<<
>>> Test on task  6 : loss=1.229 | TAw acc= 99.1%, forg=  0.0%| TAg acc= 67.8%, forg= 24.3% <<<
>>> Test on task  7 : loss=1.403 | TAw acc= 91.7%, forg=  1.9%| TAg acc= 62.0%, forg= 21.3% <<<
>>> Test on task  8 : loss=1.201 | TAw acc= 95.5%, forg=  0.0%| TAg acc= 70.5%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
    (7): Linear(in_features=1000, out_features=20, bias=True)
    (8): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task  9
************************************************************************************************************
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=4.216, TAw acc= 43.0% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.591, TAw acc= 66.7% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.907, TAw acc= 73.1% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.597, TAw acc= 74.2% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.425, TAw acc= 83.9% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.274, TAw acc= 90.3% | *
| Epoch   7, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.233, TAw acc= 87.1% | *
| Epoch   8, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.140, TAw acc= 90.3% | *
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.140, TAw acc= 91.4% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.139, TAw acc= 91.4% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.139, TAw acc= 91.4% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.138, TAw acc= 91.4% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.138, TAw acc= 91.4% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1565 train exemplars, time=  0.0s
1565
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.614 | TAw acc= 97.1%, forg=  0.0%| TAg acc= 93.6%, forg=  1.2% <<<
>>> Test on task  1 : loss=0.787 | TAw acc= 97.6%, forg=  0.0%| TAg acc= 89.0%, forg=  1.6% <<<
>>> Test on task  2 : loss=0.939 | TAw acc= 88.6%, forg=  0.8%| TAg acc= 82.9%, forg=  1.6% <<<
>>> Test on task  3 : loss=1.361 | TAw acc= 95.5%, forg=  0.9%| TAg acc= 63.1%, forg=  0.9% <<<
>>> Test on task  4 : loss=1.166 | TAw acc= 96.8%, forg=  0.0%| TAg acc= 70.4%, forg= 17.6% <<<
>>> Test on task  5 : loss=1.362 | TAw acc= 96.2%, forg= -0.8%| TAg acc= 60.9%, forg= 13.5% <<<
>>> Test on task  6 : loss=1.117 | TAw acc= 99.1%, forg=  0.0%| TAg acc= 71.3%, forg= 20.9% <<<
>>> Test on task  7 : loss=1.338 | TAw acc= 92.6%, forg=  0.9%| TAg acc= 60.2%, forg= 23.1% <<<
>>> Test on task  8 : loss=1.729 | TAw acc= 95.5%, forg=  0.0%| TAg acc= 33.0%, forg= 37.5% <<<
>>> Test on task  9 : loss=0.861 | TAw acc= 96.8%, forg=  0.0%| TAg acc= 89.5%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
    (7): Linear(in_features=1000, out_features=20, bias=True)
    (8): Linear(in_features=1000, out_features=20, bias=True)
    (9): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task 10
************************************************************************************************************
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=5.679, TAw acc= 31.9% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=3.708, TAw acc= 45.8% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.615, TAw acc= 66.7% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.947, TAw acc= 77.8% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.4s loss=1.643, TAw acc= 77.8% | *
| Epoch   6, time=  1.1s | Train: skip eval | Valid: time=  0.3s loss=1.433, TAw acc= 80.6% | *
| Epoch   7, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.329, TAw acc= 87.5% | *
| Epoch   8, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.252, TAw acc= 90.3% | *
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.250, TAw acc= 90.3% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.249, TAw acc= 90.3% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.248, TAw acc= 90.3% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.246, TAw acc= 90.3% | *
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.245, TAw acc= 90.3% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1685 train exemplars, time=  0.0s
1685
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.558 | TAw acc= 97.1%, forg=  0.0%| TAg acc= 93.6%, forg=  1.2% <<<
>>> Test on task  1 : loss=0.765 | TAw acc= 97.6%, forg=  0.0%| TAg acc= 91.3%, forg= -0.8% <<<
>>> Test on task  2 : loss=0.906 | TAw acc= 89.4%, forg=  0.0%| TAg acc= 82.9%, forg=  1.6% <<<
>>> Test on task  3 : loss=1.279 | TAw acc= 95.5%, forg=  0.9%| TAg acc= 67.6%, forg= -3.6% <<<
>>> Test on task  4 : loss=1.104 | TAw acc= 96.0%, forg=  0.8%| TAg acc= 75.2%, forg= 12.8% <<<
>>> Test on task  5 : loss=1.275 | TAw acc= 95.5%, forg=  0.8%| TAg acc= 70.7%, forg=  3.8% <<<
>>> Test on task  6 : loss=1.107 | TAw acc= 99.1%, forg=  0.0%| TAg acc= 71.3%, forg= 20.9% <<<
>>> Test on task  7 : loss=1.224 | TAw acc= 92.6%, forg=  0.9%| TAg acc= 70.4%, forg= 13.0% <<<
>>> Test on task  8 : loss=1.690 | TAw acc= 95.5%, forg=  0.0%| TAg acc= 33.0%, forg= 37.5% <<<
>>> Test on task  9 : loss=1.182 | TAw acc= 96.8%, forg=  0.0%| TAg acc= 76.6%, forg= 12.9% <<<
>>> Test on task 10 : loss=1.250 | TAw acc= 89.9%, forg=  0.0%| TAg acc= 68.7%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
    (7): Linear(in_features=1000, out_features=20, bias=True)
    (8): Linear(in_features=1000, out_features=20, bias=True)
    (9): Linear(in_features=1000, out_features=20, bias=True)
    (10): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task 11
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=5.004, TAw acc= 43.9% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=3.016, TAw acc= 53.7% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.130, TAw acc= 73.2% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.776, TAw acc= 81.7% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.573, TAw acc= 86.6% | *
| Epoch   6, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.496, TAw acc= 86.6% | *
| Epoch   7, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.423, TAw acc= 82.9% | *
| Epoch   8, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.316, TAw acc= 90.2% | *
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.315, TAw acc= 90.2% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.314, TAw acc= 90.2% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.313, TAw acc= 90.2% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.312, TAw acc= 90.2% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.311, TAw acc= 90.2% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 30
Not enough samples to store. Select all samples instead.	Needed: 27
Not enough samples to store. Select all samples instead.	Needed: 16
Not enough samples to store. Select all samples instead.	Needed: 10
Not enough samples to store. Select all samples instead.	Needed: 9
| Selected 1805 train exemplars, time=  0.0s
1805
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.590 | TAw acc= 97.1%, forg=  0.0%| TAg acc= 93.0%, forg=  1.8% <<<
>>> Test on task  1 : loss=0.781 | TAw acc= 97.6%, forg=  0.0%| TAg acc= 83.5%, forg=  7.9% <<<
>>> Test on task  2 : loss=0.911 | TAw acc= 89.4%, forg=  0.0%| TAg acc= 82.9%, forg=  1.6% <<<
>>> Test on task  3 : loss=1.268 | TAw acc= 95.5%, forg=  0.9%| TAg acc= 66.7%, forg=  0.9% <<<
>>> Test on task  4 : loss=1.279 | TAw acc= 96.8%, forg=  0.0%| TAg acc= 67.2%, forg= 20.8% <<<
>>> Test on task  5 : loss=1.158 | TAw acc= 95.5%, forg=  0.8%| TAg acc= 77.4%, forg= -3.0% <<<
>>> Test on task  6 : loss=1.108 | TAw acc= 99.1%, forg=  0.0%| TAg acc= 77.4%, forg= 14.8% <<<
>>> Test on task  7 : loss=1.118 | TAw acc= 92.6%, forg=  0.9%| TAg acc= 69.4%, forg= 13.9% <<<
>>> Test on task  8 : loss=1.624 | TAw acc= 95.5%, forg=  0.0%| TAg acc= 38.4%, forg= 32.1% <<<
>>> Test on task  9 : loss=1.156 | TAw acc= 96.0%, forg=  0.8%| TAg acc= 79.0%, forg= 10.5% <<<
>>> Test on task 10 : loss=1.456 | TAw acc= 89.9%, forg=  0.0%| TAg acc= 66.7%, forg=  2.0% <<<
>>> Test on task 11 : loss=1.132 | TAw acc= 83.0%, forg=  0.0%| TAg acc= 69.6%, forg=  0.0% <<<
Save at k=100/eeil_e20_wisdm_3/wisdm_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=91, out_features=1000, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=1000, out_features=34, bias=True)
    (1): Linear(in_features=1000, out_features=20, bias=True)
    (2): Linear(in_features=1000, out_features=20, bias=True)
    (3): Linear(in_features=1000, out_features=20, bias=True)
    (4): Linear(in_features=1000, out_features=20, bias=True)
    (5): Linear(in_features=1000, out_features=20, bias=True)
    (6): Linear(in_features=1000, out_features=20, bias=True)
    (7): Linear(in_features=1000, out_features=20, bias=True)
    (8): Linear(in_features=1000, out_features=20, bias=True)
    (9): Linear(in_features=1000, out_features=20, bias=True)
    (10): Linear(in_features=1000, out_features=20, bias=True)
    (11): Linear(in_features=1000, out_features=20, bias=True)
  )
)
======

************************************************************************************************************
Task 12
************************************************************************************************************
