	dataset_config: {'path': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'path_test': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'resize': None, 'pad': None, 'crop': None, 'normalize': None, 'class_order': None, 'extend_channel': None, 'flip': False}
CLASS_ORDER: [80, 27, 53, 101, 48, 76, 42, 72, 51, 10, 47, 115, 111, 11, 99, 122, 43, 74, 105, 68, 3, 46, 19, 119, 112, 132, 90, 84, 67, 108, 126, 71, 133, 104, 58, 38, 66, 138, 8, 118, 130, 148, 59, 52, 100, 49, 81, 142, 109, 69, 17, 34, 110, 60, 77, 18, 57, 150, 16, 63, 134, 147, 95, 24, 15, 128, 121, 91, 13, 96, 83, 14, 7, 64, 40, 78, 30, 36, 94, 75, 32, 116, 139, 124, 22, 41, 55, 1, 79, 4, 120, 62, 143, 93, 82, 35, 23, 129, 70, 29, 140, 92, 102, 31, 21, 151, 135, 50, 26, 97, 149, 88, 127, 9, 86, 44, 65, 106, 85, 6, 146, 125, 113, 145, 45, 20, 2, 87, 114, 136, 137, 123, 61, 25, 141, 33, 89, 73, 12, 5, 144, 28, 131, 54, 107, 117, 0, 98, 39, 103, 37, 56]
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList()
)
======

************************************************************************************************************
Task  0
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=2.484, TAw acc=  7.0% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.467, TAw acc=  9.6% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.451, TAw acc= 18.3% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.434, TAw acc= 20.9% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.423, TAw acc= 24.3% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.391, TAw acc= 23.5% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.372, TAw acc= 30.4% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.350, TAw acc= 28.7% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.337, TAw acc= 14.8% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.296, TAw acc= 24.3% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.267, TAw acc= 34.8% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.237, TAw acc= 44.3% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.203, TAw acc= 39.1% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.182, TAw acc= 25.2% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.144, TAw acc= 37.4% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.097, TAw acc= 38.3% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.045, TAw acc= 45.2% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.014, TAw acc= 49.6% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.959, TAw acc= 46.1% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.907, TAw acc= 49.6% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 419 train exemplars, time=  0.0s
419
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.882 | TAw acc= 53.5%, forg=  0.0%| TAg acc= 53.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
  )
)
======

************************************************************************************************************
Task  1
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=3.108, TAw acc= 19.8% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=3.022, TAw acc= 27.1% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.937, TAw acc= 28.1% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.872, TAw acc= 28.1% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.785, TAw acc= 29.2% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.725, TAw acc= 25.0% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.636, TAw acc= 29.2% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.587, TAw acc= 28.1% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.494, TAw acc= 43.8% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.461, TAw acc= 55.2% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.404, TAw acc= 56.2% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.326, TAw acc= 46.9% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.290, TAw acc= 47.9% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.274, TAw acc= 45.8% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.205, TAw acc= 55.2% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.123, TAw acc= 55.2% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.047, TAw acc= 63.5% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.024, TAw acc= 70.8% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.938, TAw acc= 72.9% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.894, TAw acc= 75.0% | *
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.894, TAw acc= 75.0% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.894, TAw acc= 75.0% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.894, TAw acc= 75.0% |
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.894, TAw acc= 75.0% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.894, TAw acc= 75.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 759 train exemplars, time=  0.0s
759
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.727 | TAw acc= 81.9%, forg=-28.5%| TAg acc= 67.4%, forg=-13.9% <<<
>>> Test on task  1 : loss=1.831 | TAw acc= 85.0%, forg=  0.0%| TAg acc= 65.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  2
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.417, TAw acc= 26.0% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.121, TAw acc= 26.0% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.902, TAw acc= 35.4% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.780, TAw acc= 47.9% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.628, TAw acc= 46.9% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.466, TAw acc= 67.7% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.407, TAw acc= 67.7% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.284, TAw acc= 79.2% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.157, TAw acc= 81.2% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.099, TAw acc= 75.0% | *
| Epoch  11, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.963, TAw acc= 85.4% | *
| Epoch  12, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.826, TAw acc= 88.5% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.810, TAw acc= 92.7% | *
| Epoch  14, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.766, TAw acc= 86.5% | *
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.619, TAw acc= 94.8% | *
| Epoch  16, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.530, TAw acc= 96.9% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.482, TAw acc= 87.5% | *
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.454, TAw acc= 75.0% | *
| Epoch  19, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.342, TAw acc= 85.4% | *
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.317, TAw acc= 86.5% | *
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.316, TAw acc= 86.5% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.315, TAw acc= 86.5% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.313, TAw acc= 86.5% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.312, TAw acc= 87.5% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.311, TAw acc= 87.5% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 1099 train exemplars, time=  0.0s
1099
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.349 | TAw acc= 86.8%, forg= -4.9%| TAg acc= 79.2%, forg=-11.8% <<<
>>> Test on task  1 : loss=1.429 | TAw acc= 93.3%, forg= -8.3%| TAg acc= 87.5%, forg=-22.5% <<<
>>> Test on task  2 : loss=1.294 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 82.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  3
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.501, TAw acc= 35.4% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.955, TAw acc= 49.0% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.809, TAw acc= 52.1% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.596, TAw acc= 70.8% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=2.410, TAw acc= 79.2% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.289, TAw acc= 84.4% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.129, TAw acc= 75.0% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.039, TAw acc= 81.2% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.892, TAw acc= 93.8% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.888, TAw acc= 84.4% | *
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.858, TAw acc= 83.3% | *
| Epoch  12, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.647, TAw acc= 93.8% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.654, TAw acc= 93.8% |
| Epoch  14, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 84.4% | *
| Epoch  15, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.629, TAw acc= 87.5% |
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.483, TAw acc= 88.5% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.522, TAw acc= 84.4% |
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.388, TAw acc= 85.4% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.342, TAw acc= 95.8% | *
| Epoch  20, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.269, TAw acc= 89.6% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.268, TAw acc= 89.6% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.267, TAw acc= 89.6% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.267, TAw acc= 89.6% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.267, TAw acc= 89.6% |
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.267, TAw acc= 89.6% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 1439 train exemplars, time=  0.0s
1439
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.087 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 78.5%, forg=  0.7% <<<
>>> Test on task  1 : loss=1.082 | TAw acc= 95.8%, forg= -2.5%| TAg acc= 85.0%, forg=  2.5% <<<
>>> Test on task  2 : loss=0.906 | TAw acc= 97.5%, forg= -3.3%| TAg acc= 86.7%, forg= -4.2% <<<
>>> Test on task  3 : loss=1.244 | TAw acc= 93.3%, forg=  0.0%| TAg acc= 74.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  4
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=4.213, TAw acc= 27.1% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.287, TAw acc= 39.6% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.881, TAw acc= 40.6% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.640, TAw acc= 50.0% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.365, TAw acc= 60.4% | *
| Epoch   6, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.293, TAw acc= 68.8% | *
| Epoch   7, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.145, TAw acc= 72.9% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.835, TAw acc= 81.2% | *
| Epoch   9, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.873, TAw acc= 82.3% |
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.880, TAw acc= 89.6% |
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.727, TAw acc= 80.2% | *
| Epoch  12, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.663, TAw acc= 88.5% | *
| Epoch  13, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.579, TAw acc= 87.5% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.589, TAw acc= 81.2% |
| Epoch  15, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.514, TAw acc= 81.2% | *
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.537, TAw acc= 88.5% |
| Epoch  17, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.456, TAw acc= 88.5% | *
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.378, TAw acc= 89.6% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.479, TAw acc= 84.4% |
| Epoch  20, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.316, TAw acc= 83.3% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.317, TAw acc= 83.3% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.318, TAw acc= 84.4% |
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.318, TAw acc= 84.4% |
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.319, TAw acc= 84.4% |
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.320, TAw acc= 84.4% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 1779 train exemplars, time=  0.0s
1779
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.047 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 79.2%, forg=  0.0% <<<
>>> Test on task  1 : loss=0.872 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 89.2%, forg= -1.7% <<<
>>> Test on task  2 : loss=0.633 | TAw acc= 99.2%, forg= -1.7%| TAg acc= 93.3%, forg= -6.7% <<<
>>> Test on task  3 : loss=1.047 | TAw acc= 99.2%, forg= -5.8%| TAg acc= 86.7%, forg=-12.5% <<<
>>> Test on task  4 : loss=1.344 | TAw acc= 85.8%, forg=  0.0%| TAg acc= 62.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  5
************************************************************************************************************
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=4.467, TAw acc= 33.3% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=3.167, TAw acc= 51.0% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.680, TAw acc= 63.5% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=2.443, TAw acc= 67.7% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=2.215, TAw acc= 65.6% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.103, TAw acc= 71.9% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.073, TAw acc= 74.0% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.945, TAw acc= 71.9% | *
| Epoch   9, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.888, TAw acc= 77.1% | *
| Epoch  10, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.810, TAw acc= 79.2% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.659, TAw acc= 77.1% | *
| Epoch  12, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.618, TAw acc= 79.2% | *
| Epoch  13, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.633, TAw acc= 80.2% |
| Epoch  14, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.508, TAw acc= 87.5% | *
| Epoch  15, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.566, TAw acc= 81.2% |
| Epoch  16, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.438, TAw acc= 86.5% | *
| Epoch  17, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% | *
| Epoch  18, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.412, TAw acc= 84.4% |
| Epoch  19, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.351, TAw acc= 83.3% | *
| Epoch  20, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.326, TAw acc= 71.9% | *
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.324, TAw acc= 72.9% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.322, TAw acc= 76.0% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.322, TAw acc= 76.0% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.321, TAw acc= 77.1% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.322, TAw acc= 78.1% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 2119 train exemplars, time=  0.0s
2119
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.985 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 77.8%, forg=  1.4% <<<
>>> Test on task  1 : loss=0.775 | TAw acc= 94.2%, forg=  1.7%| TAg acc= 88.3%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.528 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.8%, forg=  2.5% <<<
>>> Test on task  3 : loss=0.992 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 72.5%, forg= 14.2% <<<
>>> Test on task  4 : loss=1.260 | TAw acc= 88.3%, forg= -2.5%| TAg acc= 65.0%, forg= -2.5% <<<
>>> Test on task  5 : loss=1.207 | TAw acc= 80.0%, forg=  0.0%| TAg acc= 69.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  6
************************************************************************************************************
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=3.776, TAw acc= 39.6% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.535, TAw acc= 50.0% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=2.025, TAw acc= 60.4% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.932, TAw acc= 69.8% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.787, TAw acc= 86.5% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.672, TAw acc= 84.4% | *
| Epoch   7, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.625, TAw acc= 88.5% | *
| Epoch   8, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.476, TAw acc= 86.5% | *
| Epoch   9, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.472, TAw acc= 82.3% | *
| Epoch  10, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.453, TAw acc= 71.9% | *
| Epoch  11, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.454, TAw acc= 91.7% |
| Epoch  12, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.378, TAw acc= 85.4% | *
| Epoch  13, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.305, TAw acc= 88.5% | *
| Epoch  14, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.179, TAw acc= 93.8% | *
| Epoch  15, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.201, TAw acc= 81.2% |
| Epoch  16, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.187, TAw acc= 93.8% |
| Epoch  17, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.212, TAw acc= 88.5% |
| Epoch  18, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.059, TAw acc= 93.8% | *
| Epoch  19, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.141, TAw acc= 92.7% |
| Epoch  20, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.061, TAw acc= 94.8% |
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.053, TAw acc= 93.8% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.047, TAw acc= 94.8% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.043, TAw acc= 95.8% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.041, TAw acc= 95.8% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.039, TAw acc= 95.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 2459 train exemplars, time=  0.0s
2459
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.882 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 78.5%, forg=  0.7% <<<
>>> Test on task  1 : loss=0.774 | TAw acc= 98.3%, forg= -2.5%| TAg acc= 85.8%, forg=  3.3% <<<
>>> Test on task  2 : loss=0.506 | TAw acc=100.0%, forg= -0.8%| TAg acc= 93.3%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.782 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 89.2%, forg= -2.5% <<<
>>> Test on task  4 : loss=1.043 | TAw acc= 85.8%, forg=  2.5%| TAg acc= 71.7%, forg= -6.7% <<<
>>> Test on task  5 : loss=1.167 | TAw acc= 90.8%, forg=-10.8%| TAg acc= 70.0%, forg= -0.8% <<<
>>> Test on task  6 : loss=1.078 | TAw acc= 90.8%, forg=  0.0%| TAg acc= 71.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  7
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=4.376, TAw acc= 47.9% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.904, TAw acc= 72.9% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.045, TAw acc= 77.1% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.747, TAw acc= 85.4% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.482, TAw acc= 84.4% | *
| Epoch   6, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.489, TAw acc= 84.4% |
| Epoch   7, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.262, TAw acc= 86.5% | *
| Epoch   8, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.181, TAw acc= 97.9% | *
| Epoch   9, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.120, TAw acc= 93.8% | *
| Epoch  10, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.173, TAw acc= 86.5% |
| Epoch  11, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.901, TAw acc= 99.0% | *
| Epoch  12, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.990, TAw acc= 86.5% |
| Epoch  13, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.801, TAw acc= 96.9% | *
| Epoch  14, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.966, TAw acc=100.0% |
| Epoch  15, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.879, TAw acc= 95.8% |
| Epoch  16, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.832, TAw acc= 99.0% |
| Epoch  17, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=0.768, TAw acc= 99.0% | *
| Epoch  18, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.728, TAw acc= 99.0% | *
| Epoch  19, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.591, TAw acc= 99.0% | *
| Epoch  20, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.679, TAw acc= 99.0% |
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.597, TAw acc= 99.0% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.603, TAw acc= 99.0% |
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=0.608, TAw acc= 99.0% |
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.614, TAw acc= 99.0% |
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.618, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
| Selected 2799 train exemplars, time=  0.0s
2799
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.837 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 80.6%, forg= -1.4% <<<
>>> Test on task  1 : loss=0.700 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 85.0%, forg=  4.2% <<<
>>> Test on task  2 : loss=0.453 | TAw acc=100.0%, forg=  0.0%| TAg acc= 92.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.571 | TAw acc=100.0%, forg= -0.8%| TAg acc= 91.7%, forg= -2.5% <<<
>>> Test on task  4 : loss=1.003 | TAw acc= 89.2%, forg= -0.8%| TAg acc= 73.3%, forg= -1.7% <<<
>>> Test on task  5 : loss=1.078 | TAw acc= 94.2%, forg= -3.3%| TAg acc= 70.8%, forg= -0.8% <<<
>>> Test on task  6 : loss=0.980 | TAw acc= 93.3%, forg= -2.5%| TAg acc= 66.7%, forg=  5.0% <<<
>>> Test on task  7 : loss=0.579 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 98.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  8
************************************************************************************************************
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=5.133, TAw acc= 32.3% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=2.999, TAw acc= 45.8% | *
| Epoch   3, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.540, TAw acc= 64.6% | *
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.357, TAw acc= 66.7% | *
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=2.189, TAw acc= 69.8% | *
| Epoch   6, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.873, TAw acc= 64.6% | *
| Epoch   7, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.903, TAw acc= 82.3% |
| Epoch   8, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.845, TAw acc= 80.2% | *
| Epoch   9, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.682, TAw acc= 90.6% | *
| Epoch  10, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.520, TAw acc= 94.8% | *
| Epoch  11, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.676, TAw acc= 81.2% |
| Epoch  12, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.541, TAw acc= 85.4% |
| Epoch  13, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.642, TAw acc= 93.8% |
| Epoch  14, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.610, TAw acc= 94.8% |
| Epoch  15, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.474, TAw acc= 94.8% | *
| Epoch  16, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.431, TAw acc= 93.8% | *
| Epoch  17, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.388, TAw acc= 94.8% | *
| Epoch  18, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.327, TAw acc= 94.8% | *
| Epoch  19, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.160, TAw acc= 96.9% | *
| Epoch  20, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.192, TAw acc= 95.8% |
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.153, TAw acc= 96.9% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.150, TAw acc= 96.9% | *
| Epoch   3, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.150, TAw acc= 96.9% | *
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.152, TAw acc= 96.9% |
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.154, TAw acc= 96.9% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3118 train exemplars, time=  0.0s
3118
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.892 | TAw acc= 86.8%, forg=  0.0%| TAg acc= 78.5%, forg=  2.1% <<<
>>> Test on task  1 : loss=0.614 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 87.5%, forg=  1.7% <<<
>>> Test on task  2 : loss=0.413 | TAw acc=100.0%, forg=  0.0%| TAg acc= 92.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.604 | TAw acc=100.0%, forg=  0.0%| TAg acc= 90.0%, forg=  1.7% <<<
>>> Test on task  4 : loss=0.949 | TAw acc= 90.0%, forg= -0.8%| TAg acc= 75.0%, forg= -1.7% <<<
>>> Test on task  5 : loss=0.867 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 84.2%, forg=-13.3% <<<
>>> Test on task  6 : loss=0.728 | TAw acc= 97.5%, forg= -4.2%| TAg acc= 88.3%, forg=-16.7% <<<
>>> Test on task  7 : loss=0.525 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 95.8%, forg=  2.5% <<<
>>> Test on task  8 : loss=1.232 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 75.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  9
************************************************************************************************************
| Epoch   1, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=3.440, TAw acc= 41.7% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.390, TAw acc= 78.1% | *
| Epoch   3, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.910, TAw acc= 86.5% | *
| Epoch   4, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 96.9% | *
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.418, TAw acc= 95.8% | *
| Epoch   6, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.375, TAw acc= 96.9% | *
| Epoch   7, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.360, TAw acc= 97.9% | *
| Epoch   8, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.127, TAw acc= 99.0% | *
| Epoch   9, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.993, TAw acc= 97.9% | *
| Epoch  10, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.105, TAw acc= 97.9% |
| Epoch  11, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.916, TAw acc= 90.6% | *
| Epoch  12, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.926, TAw acc=100.0% |
| Epoch  13, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.842, TAw acc= 99.0% | *
| Epoch  14, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.920, TAw acc=100.0% |
| Epoch  15, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.777, TAw acc= 99.0% | *
| Epoch  16, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.774, TAw acc=100.0% | *
| Epoch  17, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.677, TAw acc=100.0% | *
| Epoch  18, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.675, TAw acc=100.0% | *
| Epoch  19, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.611, TAw acc=100.0% | *
| Epoch  20, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.564, TAw acc=100.0% | *
| Epoch   1, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.570, TAw acc=100.0% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.576, TAw acc=100.0% |
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.581, TAw acc=100.0% |
| Epoch   4, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.587, TAw acc=100.0% |
| Epoch   5, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.591, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3428 train exemplars, time=  0.0s
3428
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.755 | TAw acc= 86.8%, forg=  0.0%| TAg acc= 81.2%, forg= -0.7% <<<
>>> Test on task  1 : loss=0.493 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.8%, forg= -1.7% <<<
>>> Test on task  2 : loss=0.310 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg= -4.2% <<<
>>> Test on task  3 : loss=0.534 | TAw acc=100.0%, forg=  0.0%| TAg acc= 89.2%, forg=  2.5% <<<
>>> Test on task  4 : loss=0.874 | TAw acc= 89.2%, forg=  0.8%| TAg acc= 75.0%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.838 | TAw acc= 95.0%, forg= -0.8%| TAg acc= 80.8%, forg=  3.3% <<<
>>> Test on task  6 : loss=0.626 | TAw acc=100.0%, forg= -2.5%| TAg acc= 87.5%, forg=  0.8% <<<
>>> Test on task  7 : loss=0.406 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 95.0%, forg=  3.3% <<<
>>> Test on task  8 : loss=1.314 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 66.7%, forg=  8.3% <<<
>>> Test on task  9 : loss=0.571 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 10
************************************************************************************************************
| Epoch   1, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=4.083, TAw acc= 49.0% | *
| Epoch   2, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.765, TAw acc= 74.0% | *
| Epoch   3, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.271, TAw acc= 88.5% | *
| Epoch   4, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.011, TAw acc= 87.5% | *
| Epoch   5, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.734, TAw acc= 88.5% | *
| Epoch   6, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.765, TAw acc= 90.6% |
| Epoch   7, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.511, TAw acc= 93.8% | *
| Epoch   8, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.626, TAw acc= 95.8% |
| Epoch   9, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.464, TAw acc= 95.8% | *
| Epoch  10, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.530, TAw acc= 92.7% |
| Epoch  11, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.449, TAw acc= 95.8% | *
| Epoch  12, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=1.421, TAw acc= 96.9% | *
| Epoch  13, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.236, TAw acc= 97.9% | *
| Epoch  14, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.307, TAw acc= 95.8% |
| Epoch  15, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.195, TAw acc= 97.9% | *
| Epoch  16, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.137, TAw acc= 96.9% | *
| Epoch  17, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.986, TAw acc= 96.9% | *
| Epoch  18, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.976, TAw acc= 96.9% | *
| Epoch  19, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.054, TAw acc= 96.9% |
| Epoch  20, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.014, TAw acc= 96.9% |
| Epoch   1, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.977, TAw acc= 96.9% | *
| Epoch   2, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.979, TAw acc= 96.9% |
| Epoch   3, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.980, TAw acc= 96.9% |
| Epoch   4, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.982, TAw acc= 96.9% |
| Epoch   5, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.983, TAw acc= 96.9% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3738 train exemplars, time=  0.0s
3738
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.757 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 79.2%, forg=  2.1% <<<
>>> Test on task  1 : loss=0.521 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.0%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.274 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.487 | TAw acc=100.0%, forg=  0.0%| TAg acc= 88.3%, forg=  3.3% <<<
>>> Test on task  4 : loss=0.866 | TAw acc= 90.8%, forg= -0.8%| TAg acc= 75.0%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.966 | TAw acc= 95.8%, forg= -0.8%| TAg acc= 75.0%, forg=  9.2% <<<
>>> Test on task  6 : loss=0.600 | TAw acc= 98.3%, forg=  1.7%| TAg acc= 90.0%, forg= -1.7% <<<
>>> Test on task  7 : loss=0.353 | TAw acc=100.0%, forg= -0.8%| TAg acc= 94.2%, forg=  4.2% <<<
>>> Test on task  8 : loss=1.173 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 72.5%, forg=  2.5% <<<
>>> Test on task  9 : loss=0.541 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 83.3%, forg= 11.7% <<<
>>> Test on task 10 : loss=1.044 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 71.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 11
************************************************************************************************************
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=3.782, TAw acc= 40.6% | *
| Epoch   2, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=2.853, TAw acc= 83.3% | *
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=2.267, TAw acc= 76.0% | *
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.993, TAw acc= 79.2% | *
| Epoch   5, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.695, TAw acc= 71.9% | *
| Epoch   6, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.710, TAw acc= 89.6% |
| Epoch   7, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.571, TAw acc= 69.8% | *
| Epoch   8, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.521, TAw acc= 81.2% | *
| Epoch   9, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.376, TAw acc= 92.7% | *
| Epoch  10, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.328, TAw acc= 80.2% | *
| Epoch  11, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.340, TAw acc= 89.6% |
| Epoch  12, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.282, TAw acc= 90.6% | *
| Epoch  13, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.218, TAw acc= 95.8% | *
| Epoch  14, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.202, TAw acc= 97.9% | *
| Epoch  15, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.141, TAw acc= 92.7% | *
| Epoch  16, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.253, TAw acc= 95.8% |
| Epoch  17, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.112, TAw acc= 96.9% | *
| Epoch  18, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.138, TAw acc= 93.8% |
| Epoch  19, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.063, TAw acc= 95.8% | *
| Epoch  20, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.977, TAw acc= 94.8% | *
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.977, TAw acc= 94.8% | *
| Epoch   2, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.977, TAw acc= 94.8% |
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=0.977, TAw acc= 95.8% |
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=0.977, TAw acc= 95.8% | *
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.976, TAw acc= 95.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4048 train exemplars, time=  0.0s
4048
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.779 | TAw acc= 86.1%, forg=  0.7%| TAg acc= 79.9%, forg=  1.4% <<<
>>> Test on task  1 : loss=0.463 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.0%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.259 | TAw acc=100.0%, forg=  0.0%| TAg acc= 99.2%, forg= -1.7% <<<
>>> Test on task  3 : loss=0.477 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg=  4.2% <<<
>>> Test on task  4 : loss=0.749 | TAw acc= 91.7%, forg= -0.8%| TAg acc= 80.8%, forg= -5.8% <<<
>>> Test on task  5 : loss=0.821 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 79.2%, forg=  5.0% <<<
>>> Test on task  6 : loss=0.453 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 93.3%, forg= -3.3% <<<
>>> Test on task  7 : loss=0.336 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  2.5% <<<
>>> Test on task  8 : loss=1.171 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 72.5%, forg=  2.5% <<<
>>> Test on task  9 : loss=0.468 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg=  7.5% <<<
>>> Test on task 10 : loss=0.959 | TAw acc= 97.5%, forg= -2.5%| TAg acc= 74.2%, forg= -2.5% <<<
>>> Test on task 11 : loss=0.892 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 75.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 12
************************************************************************************************************
| Epoch   1, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=4.626, TAw acc= 36.5% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=2.582, TAw acc= 83.3% | *
| Epoch   3, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=2.081, TAw acc= 96.9% | *
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.935, TAw acc= 97.9% | *
| Epoch   5, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.518, TAw acc=100.0% | *
| Epoch   6, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.540, TAw acc=100.0% |
| Epoch   7, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.221, TAw acc= 97.9% | *
| Epoch   8, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=1.255, TAw acc=100.0% |
| Epoch   9, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.228, TAw acc=100.0% |
| Epoch  10, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.088, TAw acc=100.0% | *
| Epoch  11, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.001, TAw acc=100.0% | *
| Epoch  12, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.041, TAw acc=100.0% |
| Epoch  13, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.999, TAw acc=100.0% | *
| Epoch  14, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.995, TAw acc=100.0% | *
| Epoch  15, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.061, TAw acc=100.0% |
| Epoch  16, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.807, TAw acc=100.0% | *
| Epoch  17, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.788, TAw acc=100.0% | *
| Epoch  18, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.796, TAw acc=100.0% |
| Epoch  19, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.750, TAw acc=100.0% | *
| Epoch  20, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.877, TAw acc=100.0% |
| Epoch   1, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.751, TAw acc=100.0% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.752, TAw acc=100.0% |
| Epoch   3, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.754, TAw acc=100.0% |
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.755, TAw acc=100.0% |
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.757, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4358 train exemplars, time=  0.1s
4358
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.769 | TAw acc= 86.8%, forg=  0.0%| TAg acc= 78.5%, forg=  2.8% <<<
>>> Test on task  1 : loss=0.453 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 90.8%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.225 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.490 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg=  4.2% <<<
>>> Test on task  4 : loss=0.792 | TAw acc= 93.3%, forg= -1.7%| TAg acc= 77.5%, forg=  3.3% <<<
>>> Test on task  5 : loss=0.754 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 80.0%, forg=  4.2% <<<
>>> Test on task  6 : loss=0.459 | TAw acc=100.0%, forg=  0.0%| TAg acc= 92.5%, forg=  0.8% <<<
>>> Test on task  7 : loss=0.462 | TAw acc=100.0%, forg=  0.0%| TAg acc= 88.3%, forg= 10.0% <<<
>>> Test on task  8 : loss=1.158 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 66.7%, forg=  8.3% <<<
>>> Test on task  9 : loss=0.406 | TAw acc=100.0%, forg=  0.0%| TAg acc= 90.8%, forg=  4.2% <<<
>>> Test on task 10 : loss=0.794 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 83.3%, forg= -9.2% <<<
>>> Test on task 11 : loss=0.835 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 80.0%, forg= -4.2% <<<
>>> Test on task 12 : loss=0.725 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 89.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 13
************************************************************************************************************
| Epoch   1, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=3.949, TAw acc= 46.9% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=3.076, TAw acc= 66.7% | *
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=2.467, TAw acc= 76.0% | *
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=2.004, TAw acc= 79.2% | *
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.804, TAw acc= 83.3% | *
| Epoch   6, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.897, TAw acc= 85.4% |
| Epoch   7, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.560, TAw acc= 93.8% | *
| Epoch   8, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.551, TAw acc= 87.5% | *
| Epoch   9, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.439, TAw acc= 93.8% | *
| Epoch  10, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.451, TAw acc= 96.9% |
| Epoch  11, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.494, TAw acc= 99.0% |
| Epoch  12, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.249, TAw acc= 85.4% | *
| Epoch  13, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.076, TAw acc= 99.0% | *
| Epoch  14, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.268, TAw acc=100.0% |
| Epoch  15, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.352, TAw acc= 95.8% |
| Epoch  16, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.140, TAw acc= 92.7% |
| Epoch  17, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.242, TAw acc= 96.9% |
| Epoch  18, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.355, TAw acc=100.0% | lr=3.3e-03
| Epoch  19, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.278, TAw acc= 97.9% |
| Epoch  20, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.215, TAw acc=100.0% |
| Epoch   1, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.090, TAw acc= 99.0% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.102, TAw acc= 99.0% |
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.116, TAw acc=100.0% |
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.128, TAw acc=100.0% |
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.140, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4668 train exemplars, time=  0.0s
4668
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.783 | TAw acc= 87.5%, forg= -0.7%| TAg acc= 79.2%, forg=  2.1% <<<
>>> Test on task  1 : loss=0.453 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 91.7%, forg= -0.8% <<<
>>> Test on task  2 : loss=0.211 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.584 | TAw acc=100.0%, forg=  0.0%| TAg acc= 85.8%, forg=  5.8% <<<
>>> Test on task  4 : loss=0.873 | TAw acc= 93.3%, forg=  0.0%| TAg acc= 78.3%, forg=  2.5% <<<
>>> Test on task  5 : loss=1.165 | TAw acc= 95.8%, forg=  0.8%| TAg acc= 65.8%, forg= 18.3% <<<
>>> Test on task  6 : loss=0.445 | TAw acc=100.0%, forg=  0.0%| TAg acc= 93.3%, forg=  0.0% <<<
>>> Test on task  7 : loss=0.377 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg=  3.3% <<<
>>> Test on task  8 : loss=1.152 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 71.7%, forg=  3.3% <<<
>>> Test on task  9 : loss=0.476 | TAw acc=100.0%, forg=  0.0%| TAg acc= 86.7%, forg=  8.3% <<<
>>> Test on task 10 : loss=1.016 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 70.0%, forg= 13.3% <<<
>>> Test on task 11 : loss=0.771 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 86.7%, forg= -6.7% <<<
>>> Test on task 12 : loss=0.677 | TAw acc=100.0%, forg= -0.8%| TAg acc= 89.2%, forg=  0.0% <<<
>>> Test on task 13 : loss=1.046 | TAw acc= 93.3%, forg=  0.0%| TAg acc= 73.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
    (13): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 14
************************************************************************************************************
| Epoch   1, time=  2.4s | Train: skip eval | Valid: time=  0.3s loss=4.263, TAw acc= 54.2% | *
| Epoch   2, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=3.046, TAw acc= 82.3% | *
| Epoch   3, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=2.378, TAw acc= 87.5% | *
| Epoch   4, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.937, TAw acc= 96.9% | *
| Epoch   5, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.958, TAw acc=100.0% |
| Epoch   6, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.713, TAw acc= 95.8% | *
| Epoch   7, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.634, TAw acc=100.0% | *
| Epoch   8, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=1.488, TAw acc=100.0% | *
| Epoch   9, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.403, TAw acc=100.0% | *
| Epoch  10, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.231, TAw acc= 96.9% | *
| Epoch  11, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=1.169, TAw acc= 99.0% | *
| Epoch  12, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=1.346, TAw acc= 96.9% |
| Epoch  13, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.260, TAw acc=100.0% |
| Epoch  14, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.200, TAw acc=100.0% |
| Epoch  15, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=1.306, TAw acc=100.0% |
| Epoch  16, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.057, TAw acc=100.0% | *
| Epoch  17, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.109, TAw acc=100.0% |
| Epoch  18, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.087, TAw acc=100.0% |
| Epoch  19, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.088, TAw acc= 97.9% |
| Epoch  20, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.058, TAw acc=100.0% |
| Epoch   1, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.055, TAw acc=100.0% | *
| Epoch   2, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.053, TAw acc=100.0% | *
| Epoch   3, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.052, TAw acc=100.0% | *
| Epoch   4, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.051, TAw acc=100.0% | *
| Epoch   5, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.050, TAw acc=100.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 40
Not enough samples to store. Select all samples instead.	Needed: 39
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4978 train exemplars, time=  0.0s
4978
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.773 | TAw acc= 87.5%, forg=  0.0%| TAg acc= 80.6%, forg=  0.7% <<<
>>> Test on task  1 : loss=0.461 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 91.7%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.206 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.567 | TAw acc=100.0%, forg=  0.0%| TAg acc= 85.8%, forg=  5.8% <<<
>>> Test on task  4 : loss=0.711 | TAw acc= 92.5%, forg=  0.8%| TAg acc= 84.2%, forg= -3.3% <<<
>>> Test on task  5 : loss=0.756 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 78.3%, forg=  5.8% <<<
>>> Test on task  6 : loss=0.446 | TAw acc=100.0%, forg=  0.0%| TAg acc= 91.7%, forg=  1.7% <<<
>>> Test on task  7 : loss=0.367 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 91.7%, forg=  6.7% <<<
>>> Test on task  8 : loss=1.079 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 77.5%, forg= -2.5% <<<
>>> Test on task  9 : loss=0.344 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg=  7.5% <<<
>>> Test on task 10 : loss=0.953 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 75.0%, forg=  8.3% <<<
>>> Test on task 11 : loss=0.676 | TAw acc= 98.3%, forg= -0.8%| TAg acc= 88.3%, forg= -1.7% <<<
>>> Test on task 12 : loss=0.727 | TAw acc=100.0%, forg=  0.0%| TAg acc= 85.8%, forg=  3.3% <<<
>>> Test on task 13 : loss=1.062 | TAw acc= 97.5%, forg= -4.2%| TAg acc= 73.3%, forg=  0.0% <<<
>>> Test on task 14 : loss=1.234 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 61.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_2/har_flex_eeil
************************************************************************************************************
TAw Acc
	 53.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 53.5% 
	 81.9%  85.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 83.5% 
	 86.8%  93.3%  94.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 91.4% 
	 86.1%  95.8%  97.5%  93.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 93.2% 
	 86.1%  95.8%  99.2%  99.2%  85.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 93.2% 
	 86.1%  94.2%  99.2%  97.5%  88.3%  80.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 90.9% 
	 86.1%  98.3% 100.0%  98.3%  85.8%  90.8%  90.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 92.9% 
	 86.1%  98.3% 100.0% 100.0%  89.2%  94.2%  93.3%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 94.9% 
	 86.8%  99.2% 100.0% 100.0%  90.0%  94.2%  97.5%  98.3%  95.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 95.8% 
	 86.8%  98.3% 100.0% 100.0%  89.2%  95.0% 100.0%  99.2%  96.7% 100.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.5% 
	 86.1%  98.3% 100.0% 100.0%  90.8%  95.8%  98.3% 100.0%  96.7%  99.2%  95.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.4% 
	 86.1%  98.3% 100.0% 100.0%  91.7%  96.7%  99.2% 100.0%  96.7% 100.0%  97.5%  97.5%   0.0%   0.0%   0.0% 	Avg.: 97.0% 
	 86.8%  97.5% 100.0% 100.0%  93.3%  96.7% 100.0% 100.0%  96.7% 100.0%  96.7%  97.5%  99.2%   0.0%   0.0% 	Avg.: 97.3% 
	 87.5%  97.5% 100.0% 100.0%  93.3%  95.8% 100.0% 100.0%  96.7% 100.0%  96.7%  97.5% 100.0%  93.3%   0.0% 	Avg.: 97.0% 
	 87.5%  98.3% 100.0% 100.0%  92.5%  96.7% 100.0%  99.2%  96.7% 100.0%  97.5%  98.3% 100.0%  97.5%  96.7% 	Avg.: 97.4% 
************************************************************************************************************
TAg Acc
	 53.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 53.5% 
	 67.4%  65.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 66.2% 
	 79.2%  87.5%  82.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 83.1% 
	 78.5%  85.0%  86.7%  74.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.1% 
	 79.2%  89.2%  93.3%  86.7%  62.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.2% 
	 77.8%  88.3%  90.8%  72.5%  65.0%  69.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 77.3% 
	 78.5%  85.8%  93.3%  89.2%  71.7%  70.0%  71.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 80.0% 
	 80.6%  85.0%  92.5%  91.7%  73.3%  70.8%  66.7%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.4% 
	 78.5%  87.5%  92.5%  90.0%  75.0%  84.2%  88.3%  95.8%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 85.2% 
	 81.2%  90.8%  97.5%  89.2%  75.0%  80.8%  87.5%  95.0%  66.7%  95.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 85.9% 
	 79.2%  90.0%  97.5%  88.3%  75.0%  75.0%  90.0%  94.2%  72.5%  83.3%  71.7%   0.0%   0.0%   0.0%   0.0% 	Avg.: 83.3% 
	 79.9%  90.0%  99.2%  87.5%  80.8%  79.2%  93.3%  95.8%  72.5%  87.5%  74.2%  75.8%   0.0%   0.0%   0.0% 	Avg.: 84.6% 
	 78.5%  90.8%  98.3%  87.5%  77.5%  80.0%  92.5%  88.3%  66.7%  90.8%  83.3%  80.0%  89.2%   0.0%   0.0% 	Avg.: 84.9% 
	 79.2%  91.7%  98.3%  85.8%  78.3%  65.8%  93.3%  95.0%  71.7%  86.7%  70.0%  86.7%  89.2%  73.3%   0.0% 	Avg.: 83.2% 
	 80.6%  91.7%  98.3%  85.8%  84.2%  78.3%  91.7%  91.7%  77.5%  87.5%  75.0%  88.3%  85.8%  73.3%  61.7% 	Avg.: 83.4% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-28.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-28.5% 
	 -4.9%  -8.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -6.6% 
	  0.7%  -2.5%  -3.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.7% 
	  0.7%   0.0%  -1.7%  -5.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.7% 
	  0.7%   1.7%   0.0%   1.7%  -2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.3% 
	  0.7%  -2.5%  -0.8%   0.8%   2.5% -10.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.7% 
	  0.7%   0.0%   0.0%  -0.8%  -0.8%  -3.3%  -2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.0% 
	  0.0%  -0.8%   0.0%   0.0%  -0.8%   0.0%  -4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.7% 
	  0.0%   0.8%   0.0%   0.0%   0.8%  -0.8%  -2.5%  -0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	  0.7%   0.8%   0.0%   0.0%  -0.8%  -0.8%   1.7%  -0.8%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.2% 
	  0.7%   0.8%   0.0%   0.0%  -0.8%  -0.8%   0.8%   0.0%   0.0%   0.0%  -2.5%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.2% 
	  0.0%   1.7%   0.0%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.1% 
	 -0.7%   1.7%   0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0%   0.8%   0.0%  -0.8%   0.0%   0.0% 	Avg.:  0.1% 
	  0.0%   0.8%   0.0%   0.0%   0.8%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%  -0.8%   0.0%  -4.2%   0.0% 	Avg.: -0.2% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-13.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-13.9% 
	-11.8% -22.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-17.2% 
	  0.7%   2.5%  -4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.3% 
	  0.0%  -1.7%  -6.7% -12.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -5.2% 
	  1.4%   0.8%   2.5%  14.2%  -2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.3% 
	  0.7%   3.3%   0.0%  -2.5%  -6.7%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.0% 
	 -1.4%   4.2%   0.8%  -2.5%  -1.7%  -0.8%   5.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.5% 
	  2.1%   1.7%   0.8%   1.7%  -1.7% -13.3% -16.7%   2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -2.9% 
	 -0.7%  -1.7%  -4.2%   2.5%   0.0%   3.3%   0.8%   3.3%   8.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.3% 
	  2.1%   0.8%   0.0%   3.3%   0.0%   9.2%  -1.7%   4.2%   2.5%  11.7%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.2% 
	  1.4%   0.8%  -1.7%   4.2%  -5.8%   5.0%  -3.3%   2.5%   2.5%   7.5%  -2.5%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.0% 
	  2.8%   0.0%   0.8%   4.2%   3.3%   4.2%   0.8%  10.0%   8.3%   4.2%  -9.2%  -4.2%   0.0%   0.0%   0.0% 	Avg.:  2.1% 
	  2.1%  -0.8%   0.8%   5.8%   2.5%  18.3%   0.0%   3.3%   3.3%   8.3%  13.3%  -6.7%   0.0%   0.0%   0.0% 	Avg.:  3.9% 
	  0.7%   0.0%   0.8%   5.8%  -3.3%   5.8%   1.7%   6.7%  -2.5%   7.5%   8.3%  -1.7%   3.3%   0.0%   0.0% 	Avg.:  2.4% 
************************************************************************************************************
[Elapsed time = 0.1 h]
Done!

f1_score_micro: 0.8338815789473685
f1_score_macro: 0.823714941117151
              precision    recall  f1-score   support

           0       1.00      0.83      0.91        12
           1       1.00      1.00      1.00        12
           2       0.32      0.50      0.39        12
           3       1.00      1.00      1.00        12
           4       0.38      0.50      0.43        12
           5       1.00      1.00      1.00        12
           6       0.86      1.00      0.92        12
           7       0.86      1.00      0.92        12
           8       0.29      0.17      0.21        12
           9       0.92      1.00      0.96        12
          10       1.00      0.83      0.91        12
          11       0.91      0.83      0.87        12
          12       1.00      1.00      1.00        12
          13       0.52      1.00      0.69        12
          14       0.73      0.92      0.81        12
          15       0.79      0.92      0.85        12
          16       0.85      0.92      0.88        12
          17       1.00      1.00      1.00        12
          18       1.00      1.00      1.00        12
          19       1.00      1.00      1.00        12
          20       0.71      0.42      0.53        12
          21       0.86      1.00      0.92        12
          22       0.86      1.00      0.92        12
          23       0.92      1.00      0.96        12
          24       0.92      1.00      0.96        12
          25       0.92      1.00      0.96        12
          26       1.00      1.00      1.00        12
          27       1.00      1.00      1.00        12
          28       1.00      1.00      1.00        12
          29       0.91      0.83      0.87        12
          30       0.92      1.00      0.96        12
          31       1.00      1.00      1.00        12
          32       1.00      1.00      1.00        12
          33       1.00      0.83      0.91        12
          34       0.50      0.33      0.40        12
          35       0.79      0.92      0.85        12
          36       1.00      1.00      1.00        12
          37       1.00      1.00      1.00        12
          38       0.77      0.83      0.80        12
          39       0.85      0.92      0.88        12
          40       1.00      0.92      0.96        12
          41       0.91      0.83      0.87        12
          42       0.31      0.33      0.32        12
          43       0.42      0.67      0.52        12
          44       1.00      1.00      1.00        12
          45       0.37      0.58      0.45        12
          46       1.00      1.00      1.00        12
          47       1.00      1.00      1.00        12
          48       0.92      1.00      0.96        12
          49       0.92      0.92      0.92        12
          50       0.79      0.92      0.85        12
          51       0.86      1.00      0.92        12
          52       1.00      1.00      1.00        12
          53       0.62      0.83      0.71        12
          54       1.00      1.00      1.00        12
          55       0.91      0.83      0.87        12
          56       0.44      0.58      0.50        12
          57       0.67      0.83      0.74        12
          58       0.75      0.75      0.75        12
          59       0.67      0.50      0.57        12
          60       1.00      1.00      1.00        12
          61       0.55      0.50      0.52        12
          62       1.00      1.00      1.00        12
          63       0.61      0.92      0.73        12
          64       0.91      0.83      0.87        12
          65       0.85      0.92      0.88        12
          66       0.92      1.00      0.96        12
          67       1.00      1.00      1.00        12
          68       0.69      0.75      0.72        12
          69       0.86      1.00      0.92        12
          70       1.00      1.00      1.00        12
          71       0.90      0.75      0.82        12
          72       0.90      0.75      0.82        12
          73       1.00      1.00      1.00        12
          74       0.83      0.83      0.83        12
          75       0.86      1.00      0.92        12
          76       0.85      0.92      0.88        12
          77       1.00      1.00      1.00        12
          78       1.00      1.00      1.00        12
          79       1.00      1.00      1.00        12
          80       0.62      0.67      0.64        12
          81       1.00      1.00      1.00        12
          82       0.50      1.00      0.67        12
          83       1.00      1.00      1.00        12
          84       0.92      1.00      0.96        12
          85       1.00      0.83      0.91        12
          86       0.50      0.17      0.25        12
          87       0.83      0.83      0.83        12
          88       1.00      1.00      1.00        12
          89       0.83      0.83      0.83        12
          90       0.85      0.92      0.88        12
          91       0.50      0.17      0.25        12
          92       0.00      0.00      0.00        12
          93       1.00      1.00      1.00        12
          94       1.00      1.00      1.00        12
          95       0.92      1.00      0.96        12
          96       0.64      0.75      0.69        12
          97       1.00      1.00      1.00        12
          98       1.00      1.00      1.00        12
          99       1.00      1.00      1.00        12
         100       1.00      1.00      1.00        12
         101       1.00      1.00      1.00        12
         102       0.85      0.92      0.88        12
         103       0.85      0.92      0.88        12
         104       0.82      0.75      0.78        12
         105       0.47      0.75      0.58        12
         106       0.50      0.83      0.62        12
         107       0.00      0.00      0.00        12
         108       0.91      0.83      0.87        12
         109       0.86      1.00      0.92        12
         110       0.86      0.50      0.63        12
         111       1.00      1.00      1.00        12
         112       1.00      0.75      0.86        12
         113       0.92      1.00      0.96        12
         114       0.90      0.75      0.82        12
         115       1.00      1.00      1.00        12
         116       0.92      0.92      0.92        12
         117       0.92      1.00      0.96        12
         118       1.00      1.00      1.00        12
         119       0.71      0.83      0.77        12
         120       0.71      0.83      0.77        12
         121       1.00      0.75      0.86        12
         122       1.00      0.83      0.91        12
         123       0.90      0.75      0.82        12
         124       0.83      0.83      0.83        12
         125       0.92      0.92      0.92        12
         126       0.50      0.25      0.33        12
         127       1.00      1.00      1.00        12
         128       0.92      1.00      0.96        12
         129       1.00      1.00      1.00        12
         130       1.00      1.00      1.00        12
         131       1.00      1.00      1.00        12
         132       0.00      0.00      0.00        12
         133       0.80      0.67      0.73        12
         134       1.00      1.00      1.00        12
         135       1.00      0.58      0.74        12
         136       1.00      1.00      1.00        12
         137       1.00      1.00      1.00        12
         138       0.69      0.75      0.72        12
         139       1.00      0.92      0.96        12
         140       0.67      0.50      0.57        12
         141       1.00      0.92      0.96        12
         142       0.60      0.25      0.35        12
         143       0.50      0.25      0.33        12
         144       0.86      1.00      0.92        12
         145       0.92      0.92      0.92        12
         146       0.50      0.58      0.54        12
         147       1.00      0.92      0.96        12
         148       0.79      0.92      0.85        12
         149       1.00      0.42      0.59        12
         150       0.64      0.58      0.61        12
         151       0.27      0.33      0.30        12

    accuracy                           0.83      1824
   macro avg       0.83      0.83      0.82      1824
weighted avg       0.83      0.83      0.82      1824

torch.Size([1824, 405]) torch.Size([1824])
Parameters: 36980
Task parameters: {0: 27600, 1: 28270, 2: 28940, 3: 29610, 4: 30280, 5: 30950, 6: 31620, 7: 32290, 8: 32960, 9: 33630, 10: 34300, 11: 34970, 12: 35640, 13: 36310, 14: 36980}
