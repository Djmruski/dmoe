	dataset_config: {'path': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'path_test': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'resize': None, 'pad': None, 'crop': None, 'normalize': None, 'class_order': None, 'extend_channel': None, 'flip': False}
CLASS_ORDER: [51, 68, 2, 23, 80, 63, 25, 42, 44, 29, 8, 143, 87, 91, 119, 64, 14, 24, 0, 92, 89, 125, 129, 65, 148, 74, 116, 9, 132, 101, 46, 73, 66, 113, 86, 19, 36, 45, 115, 104, 118, 61, 110, 4, 127, 88, 55, 107, 57, 35, 140, 90, 37, 84, 40, 18, 27, 120, 78, 93, 96, 54, 81, 108, 151, 39, 82, 7, 31, 76, 135, 144, 126, 56, 49, 17, 47, 6, 131, 103, 122, 121, 53, 11, 111, 32, 72, 20, 98, 97, 142, 43, 34, 69, 147, 133, 58, 109, 100, 117, 145, 99, 60, 149, 21, 106, 1, 48, 16, 52, 150, 28, 137, 141, 112, 33, 70, 12, 139, 79, 94, 134, 71, 15, 124, 62, 123, 95, 50, 22, 26, 10, 59, 3, 146, 41, 83, 13, 75, 136, 5, 85, 102, 130, 77, 67, 105, 30, 128, 38, 114, 138]
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList()
)
======

************************************************************************************************************
Task  0
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.448, TAw acc=  8.7% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.416, TAw acc= 18.3% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.385, TAw acc= 20.9% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.357, TAw acc= 16.5% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.319, TAw acc= 30.4% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.264, TAw acc= 34.8% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.219, TAw acc= 27.0% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.172, TAw acc= 31.3% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.135, TAw acc= 27.8% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.066, TAw acc= 33.0% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.015, TAw acc= 34.8% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.963, TAw acc= 34.8% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.917, TAw acc= 38.3% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.886, TAw acc= 26.1% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.829, TAw acc= 29.6% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.778, TAw acc= 40.9% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.724, TAw acc= 53.0% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.685, TAw acc= 52.2% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.645, TAw acc= 51.3% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.601, TAw acc= 53.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 425 train exemplars, time=  0.0s
425
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.547 | TAw acc= 56.9%, forg=  0.0%| TAg acc= 56.9%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
  )
)
======

************************************************************************************************************
Task  1
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=3.058, TAw acc= 17.7% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.843, TAw acc= 15.6% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.685, TAw acc= 18.8% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.550, TAw acc= 32.3% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.420, TAw acc= 35.4% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.333, TAw acc= 34.4% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.235, TAw acc= 44.8% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.174, TAw acc= 57.3% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.116, TAw acc= 59.4% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.016, TAw acc= 69.8% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.963, TAw acc= 61.5% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.885, TAw acc= 76.0% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.833, TAw acc= 65.6% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.770, TAw acc= 78.1% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.700, TAw acc= 69.8% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.655, TAw acc= 79.2% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.645, TAw acc= 76.0% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.582, TAw acc= 83.3% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.525, TAw acc= 94.8% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.491, TAw acc= 96.9% | *
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.490, TAw acc= 96.9% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.489, TAw acc= 96.9% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.489, TAw acc= 96.9% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.488, TAw acc= 96.9% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.487, TAw acc= 96.9% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 765 train exemplars, time=  0.0s
765
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.386 | TAw acc= 84.7%, forg=-27.8%| TAg acc= 79.9%, forg=-22.9% <<<
>>> Test on task  1 : loss=1.453 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 81.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  2
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.291, TAw acc= 19.8% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.009, TAw acc= 33.3% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.816, TAw acc= 53.1% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.630, TAw acc= 41.7% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.595, TAw acc= 61.5% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.529, TAw acc= 76.0% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.365, TAw acc= 78.1% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.260, TAw acc= 78.1% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.155, TAw acc= 79.2% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.165, TAw acc= 84.4% |
| Epoch  11, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.054, TAw acc= 81.2% | *
| Epoch  12, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.016, TAw acc= 83.3% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.939, TAw acc= 76.0% | *
| Epoch  14, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.890, TAw acc= 74.0% | *
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.751, TAw acc= 77.1% | *
| Epoch  16, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.705, TAw acc= 81.2% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.670, TAw acc= 84.4% | *
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.556, TAw acc= 84.4% | *
| Epoch  19, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.511, TAw acc= 91.7% | *
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.482, TAw acc= 87.5% | *
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.480, TAw acc= 87.5% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.477, TAw acc= 87.5% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.475, TAw acc= 87.5% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.473, TAw acc= 87.5% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.471, TAw acc= 87.5% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1105 train exemplars, time=  0.0s
1105
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.101 | TAw acc= 87.5%, forg= -2.8%| TAg acc= 81.9%, forg= -2.1% <<<
>>> Test on task  1 : loss=1.039 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 89.2%, forg= -7.5% <<<
>>> Test on task  2 : loss=1.518 | TAw acc= 85.0%, forg=  0.0%| TAg acc= 73.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  3
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.640, TAw acc= 33.3% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.002, TAw acc= 56.2% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.786, TAw acc= 49.0% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.527, TAw acc= 58.3% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.399, TAw acc= 88.5% | *
| Epoch   6, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.186, TAw acc= 87.5% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.088, TAw acc= 67.7% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.025, TAw acc= 81.2% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.887, TAw acc= 74.0% | *
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.815, TAw acc= 86.5% | *
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.817, TAw acc= 86.5% |
| Epoch  12, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.706, TAw acc= 86.5% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.625, TAw acc= 93.8% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.540, TAw acc= 93.8% | *
| Epoch  15, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.468, TAw acc= 84.4% | *
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.418, TAw acc= 84.4% | *
| Epoch  17, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.403, TAw acc= 84.4% | *
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.328, TAw acc= 91.7% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.280, TAw acc= 89.6% | *
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.239, TAw acc= 84.4% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.239, TAw acc= 84.4% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.239, TAw acc= 84.4% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.238, TAw acc= 84.4% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.238, TAw acc= 84.4% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.237, TAw acc= 85.4% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1445 train exemplars, time=  0.0s
1445
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.932 | TAw acc= 91.0%, forg= -3.5%| TAg acc= 88.9%, forg= -6.9% <<<
>>> Test on task  1 : loss=0.828 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 86.7%, forg=  2.5% <<<
>>> Test on task  2 : loss=0.986 | TAw acc= 99.2%, forg=-14.2%| TAg acc= 96.7%, forg=-23.3% <<<
>>> Test on task  3 : loss=1.256 | TAw acc= 87.5%, forg=  0.0%| TAg acc= 73.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  4
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=4.247, TAw acc= 21.9% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=3.215, TAw acc= 42.7% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.782, TAw acc= 58.3% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.378, TAw acc= 70.8% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.201, TAw acc= 82.3% | *
| Epoch   6, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.082, TAw acc= 88.5% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.949, TAw acc= 88.5% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.837, TAw acc= 89.6% | *
| Epoch   9, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.812, TAw acc= 91.7% | *
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.618, TAw acc= 91.7% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.538, TAw acc= 93.8% | *
| Epoch  12, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.533, TAw acc= 88.5% | *
| Epoch  13, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.407, TAw acc= 92.7% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.389, TAw acc= 95.8% | *
| Epoch  15, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.340, TAw acc= 95.8% | *
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.232, TAw acc= 96.9% | *
| Epoch  17, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.186, TAw acc= 99.0% | *
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.159, TAw acc= 99.0% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.031, TAw acc= 99.0% | *
| Epoch  20, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.056, TAw acc= 99.0% |
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.033, TAw acc= 99.0% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.035, TAw acc= 99.0% |
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.037, TAw acc= 99.0% |
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.040, TAw acc= 99.0% |
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.042, TAw acc= 99.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1785 train exemplars, time=  0.0s
1785
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.913 | TAw acc= 91.7%, forg= -0.7%| TAg acc= 83.3%, forg=  5.6% <<<
>>> Test on task  1 : loss=0.746 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 93.3%, forg= -4.2% <<<
>>> Test on task  2 : loss=0.631 | TAw acc=100.0%, forg= -0.8%| TAg acc= 98.3%, forg= -1.7% <<<
>>> Test on task  3 : loss=1.044 | TAw acc= 96.7%, forg= -9.2%| TAg acc= 87.5%, forg=-14.2% <<<
>>> Test on task  4 : loss=1.049 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 84.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  5
************************************************************************************************************
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=4.040, TAw acc= 50.0% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.850, TAw acc= 63.5% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.381, TAw acc= 66.7% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.139, TAw acc= 76.0% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.769, TAw acc= 71.9% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.809, TAw acc= 89.6% |
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.748, TAw acc= 85.4% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.620, TAw acc= 78.1% | *
| Epoch   9, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.649, TAw acc= 83.3% |
| Epoch  10, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.481, TAw acc= 86.5% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.468, TAw acc= 89.6% | *
| Epoch  12, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.411, TAw acc= 93.8% | *
| Epoch  13, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.351, TAw acc= 85.4% | *
| Epoch  14, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.387, TAw acc= 90.6% |
| Epoch  15, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.373, TAw acc= 89.6% |
| Epoch  16, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.243, TAw acc= 85.4% | *
| Epoch  17, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.095, TAw acc= 93.8% | *
| Epoch  18, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.262, TAw acc= 85.4% |
| Epoch  19, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.134, TAw acc= 87.5% |
| Epoch  20, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.146, TAw acc= 91.7% |
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.100, TAw acc= 93.8% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.105, TAw acc= 93.8% |
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.110, TAw acc= 93.8% |
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.114, TAw acc= 93.8% |
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.118, TAw acc= 93.8% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2125 train exemplars, time=  0.0s
2125
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.831 | TAw acc= 93.1%, forg= -1.4%| TAg acc= 88.9%, forg=  0.0% <<<
>>> Test on task  1 : loss=0.691 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.0%, forg=  3.3% <<<
>>> Test on task  2 : loss=0.525 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  1.7% <<<
>>> Test on task  3 : loss=1.001 | TAw acc= 97.5%, forg= -0.8%| TAg acc= 80.8%, forg=  6.7% <<<
>>> Test on task  4 : loss=0.882 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 87.5%, forg= -3.3% <<<
>>> Test on task  5 : loss=1.066 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 80.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  6
************************************************************************************************************
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=3.820, TAw acc= 30.2% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.781, TAw acc= 53.1% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.482, TAw acc= 60.4% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.305, TAw acc= 70.8% | *
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.911, TAw acc= 83.3% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.865, TAw acc= 81.2% | *
| Epoch   7, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.836, TAw acc= 72.9% | *
| Epoch   8, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.652, TAw acc= 76.0% | *
| Epoch   9, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.646, TAw acc= 80.2% | *
| Epoch  10, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.540, TAw acc= 86.5% | *
| Epoch  11, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.391, TAw acc= 75.0% | *
| Epoch  12, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.427, TAw acc= 72.9% |
| Epoch  13, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.362, TAw acc= 86.5% | *
| Epoch  14, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.281, TAw acc= 77.1% | *
| Epoch  15, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.222, TAw acc= 86.5% | *
| Epoch  16, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.219, TAw acc= 80.2% | *
| Epoch  17, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.169, TAw acc= 83.3% | *
| Epoch  18, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.085, TAw acc= 83.3% | *
| Epoch  19, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.006, TAw acc= 86.5% | *
| Epoch  20, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.015, TAw acc= 85.4% |
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.009, TAw acc= 86.5% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.012, TAw acc= 86.5% |
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.015, TAw acc= 86.5% |
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.018, TAw acc= 87.5% |
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.021, TAw acc= 87.5% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2465 train exemplars, time=  0.0s
2465
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.768 | TAw acc= 92.4%, forg=  0.7%| TAg acc= 85.4%, forg=  3.5% <<<
>>> Test on task  1 : loss=0.467 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 96.7%, forg= -3.3% <<<
>>> Test on task  2 : loss=0.527 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  1.7% <<<
>>> Test on task  3 : loss=0.819 | TAw acc= 98.3%, forg= -0.8%| TAg acc= 77.5%, forg= 10.0% <<<
>>> Test on task  4 : loss=0.749 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 90.0%, forg= -2.5% <<<
>>> Test on task  5 : loss=0.941 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 87.5%, forg= -7.5% <<<
>>> Test on task  6 : loss=0.898 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 83.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  7
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=3.867, TAw acc= 34.4% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=3.020, TAw acc= 58.3% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.521, TAw acc= 65.6% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.239, TAw acc= 63.5% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.208, TAw acc= 77.1% | *
| Epoch   6, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.279, TAw acc= 76.0% |
| Epoch   7, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.107, TAw acc= 82.3% | *
| Epoch   8, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.922, TAw acc= 77.1% | *
| Epoch   9, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.803, TAw acc= 85.4% | *
| Epoch  10, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.906, TAw acc= 92.7% |
| Epoch  11, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.710, TAw acc= 88.5% | *
| Epoch  12, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.750, TAw acc= 91.7% |
| Epoch  13, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.543, TAw acc= 87.5% | *
| Epoch  14, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.677, TAw acc= 95.8% |
| Epoch  15, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.580, TAw acc= 94.8% |
| Epoch  16, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.519, TAw acc= 85.4% | *
| Epoch  17, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.572, TAw acc= 97.9% |
| Epoch  18, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.580, TAw acc= 88.5% |
| Epoch  19, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.413, TAw acc= 96.9% | *
| Epoch  20, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.323, TAw acc= 96.9% | *
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.327, TAw acc= 95.8% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.331, TAw acc= 95.8% |
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.335, TAw acc= 95.8% |
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.338, TAw acc= 95.8% |
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.342, TAw acc= 95.8% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2805 train exemplars, time=  0.0s
2805
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.763 | TAw acc= 92.4%, forg=  0.7%| TAg acc= 86.1%, forg=  2.8% <<<
>>> Test on task  1 : loss=0.499 | TAw acc=100.0%, forg= -0.8%| TAg acc= 88.3%, forg=  8.3% <<<
>>> Test on task  2 : loss=0.499 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg= 10.8% <<<
>>> Test on task  3 : loss=0.713 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 80.8%, forg=  6.7% <<<
>>> Test on task  4 : loss=0.633 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 86.7%, forg=  3.3% <<<
>>> Test on task  5 : loss=0.859 | TAw acc= 98.3%, forg= -1.7%| TAg acc= 86.7%, forg=  0.8% <<<
>>> Test on task  6 : loss=0.716 | TAw acc= 97.5%, forg= -3.3%| TAg acc= 91.7%, forg= -8.3% <<<
>>> Test on task  7 : loss=1.277 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 60.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  8
************************************************************************************************************
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=4.460, TAw acc= 37.5% | *
| Epoch   2, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=2.817, TAw acc= 59.4% | *
| Epoch   3, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=2.317, TAw acc= 72.9% | *
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.134, TAw acc= 71.9% | *
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.960, TAw acc= 77.1% | *
| Epoch   6, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.893, TAw acc= 80.2% | *
| Epoch   7, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.846, TAw acc= 93.8% | *
| Epoch   8, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.697, TAw acc= 97.9% | *
| Epoch   9, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.643, TAw acc=100.0% | *
| Epoch  10, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.507, TAw acc=100.0% | *
| Epoch  11, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.400, TAw acc= 97.9% | *
| Epoch  12, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.325, TAw acc= 99.0% | *
| Epoch  13, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.392, TAw acc=100.0% |
| Epoch  14, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.274, TAw acc= 99.0% | *
| Epoch  15, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.290, TAw acc= 96.9% |
| Epoch  16, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.225, TAw acc= 99.0% | *
| Epoch  17, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.172, TAw acc= 99.0% | *
| Epoch  18, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.129, TAw acc= 97.9% | *
| Epoch  19, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.123, TAw acc= 96.9% | *
| Epoch  20, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.127, TAw acc= 99.0% |
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.119, TAw acc= 96.9% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.115, TAw acc= 96.9% | *
| Epoch   3, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.112, TAw acc= 97.9% | *
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.110, TAw acc= 99.0% | *
| Epoch   5, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.108, TAw acc= 99.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3142 train exemplars, time=  0.0s
3142
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.789 | TAw acc= 92.4%, forg=  0.7%| TAg acc= 84.7%, forg=  4.2% <<<
>>> Test on task  1 : loss=0.415 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.370 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  2.5% <<<
>>> Test on task  3 : loss=0.603 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 90.0%, forg= -2.5% <<<
>>> Test on task  4 : loss=0.635 | TAw acc= 98.3%, forg= -1.7%| TAg acc= 85.0%, forg=  5.0% <<<
>>> Test on task  5 : loss=0.738 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 89.2%, forg= -1.7% <<<
>>> Test on task  6 : loss=0.600 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 91.7%, forg=  0.0% <<<
>>> Test on task  7 : loss=1.271 | TAw acc= 95.8%, forg= -1.7%| TAg acc= 60.0%, forg=  0.0% <<<
>>> Test on task  8 : loss=1.137 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 67.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  9
************************************************************************************************************
| Epoch   1, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=3.477, TAw acc= 53.1% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.682, TAw acc= 64.6% | *
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.160, TAw acc= 65.6% | *
| Epoch   4, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.024, TAw acc= 84.4% | *
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.927, TAw acc= 89.6% | *
| Epoch   6, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.612, TAw acc= 85.4% | *
| Epoch   7, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.566, TAw acc= 90.6% | *
| Epoch   8, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.635, TAw acc= 93.8% |
| Epoch   9, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.442, TAw acc= 92.7% | *
| Epoch  10, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.358, TAw acc= 93.8% | *
| Epoch  11, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.348, TAw acc= 92.7% | *
| Epoch  12, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.397, TAw acc= 90.6% |
| Epoch  13, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.261, TAw acc= 89.6% | *
| Epoch  14, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.215, TAw acc= 93.8% | *
| Epoch  15, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.002, TAw acc= 91.7% | *
| Epoch  16, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.247, TAw acc= 89.6% |
| Epoch  17, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.241, TAw acc= 93.8% |
| Epoch  18, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.055, TAw acc= 91.7% |
| Epoch  19, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.131, TAw acc= 93.8% |
| Epoch  20, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.993, TAw acc= 93.8% | *
| Epoch   1, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.993, TAw acc= 93.8% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.993, TAw acc= 93.8% |
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.994, TAw acc= 93.8% |
| Epoch   4, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.995, TAw acc= 93.8% |
| Epoch   5, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=0.996, TAw acc= 93.8% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3452 train exemplars, time=  0.0s
3452
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.718 | TAw acc= 93.1%, forg=  0.0%| TAg acc= 84.0%, forg=  4.9% <<<
>>> Test on task  1 : loss=0.379 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.384 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.575 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.587 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.692 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 89.2%, forg=  0.0% <<<
>>> Test on task  6 : loss=0.614 | TAw acc= 95.0%, forg=  2.5%| TAg acc= 86.7%, forg=  5.0% <<<
>>> Test on task  7 : loss=1.135 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 69.2%, forg= -9.2% <<<
>>> Test on task  8 : loss=1.064 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 66.7%, forg=  0.8% <<<
>>> Test on task  9 : loss=1.024 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 69.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 10
************************************************************************************************************
| Epoch   1, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=4.193, TAw acc= 49.0% | *
| Epoch   2, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=3.177, TAw acc= 63.5% | *
| Epoch   3, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=2.669, TAw acc= 66.7% | *
| Epoch   4, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.473, TAw acc= 79.2% | *
| Epoch   5, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.008, TAw acc= 83.3% | *
| Epoch   6, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=2.073, TAw acc= 86.5% |
| Epoch   7, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.831, TAw acc= 87.5% | *
| Epoch   8, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.652, TAw acc= 88.5% | *
| Epoch   9, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.704, TAw acc= 84.4% |
| Epoch  10, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.767, TAw acc= 86.5% |
| Epoch  11, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.463, TAw acc= 86.5% | *
| Epoch  12, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.642, TAw acc= 81.2% |
| Epoch  13, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.456, TAw acc= 88.5% | *
| Epoch  14, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.525, TAw acc= 90.6% |
| Epoch  15, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.423, TAw acc= 86.5% | *
| Epoch  16, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.434, TAw acc= 86.5% |
| Epoch  17, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.353, TAw acc= 85.4% | *
| Epoch  18, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.391, TAw acc= 87.5% |
| Epoch  19, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.356, TAw acc= 91.7% |
| Epoch  20, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.255, TAw acc= 87.5% | *
| Epoch   1, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.252, TAw acc= 88.5% | *
| Epoch   2, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.251, TAw acc= 88.5% | *
| Epoch   3, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.250, TAw acc= 88.5% | *
| Epoch   4, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.249, TAw acc= 88.5% | *
| Epoch   5, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.248, TAw acc= 88.5% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3762 train exemplars, time=  0.0s
3762
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.693 | TAw acc= 93.8%, forg= -0.7%| TAg acc= 86.1%, forg=  2.8% <<<
>>> Test on task  1 : loss=0.325 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.318 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.567 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 88.3%, forg=  1.7% <<<
>>> Test on task  4 : loss=0.569 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.653 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 86.7%, forg=  2.5% <<<
>>> Test on task  6 : loss=0.662 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 84.2%, forg=  7.5% <<<
>>> Test on task  7 : loss=1.092 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 76.7%, forg= -7.5% <<<
>>> Test on task  8 : loss=0.923 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 78.3%, forg=-10.8% <<<
>>> Test on task  9 : loss=0.984 | TAw acc= 97.5%, forg= -0.8%| TAg acc= 70.0%, forg= -0.8% <<<
>>> Test on task 10 : loss=1.373 | TAw acc= 83.3%, forg=  0.0%| TAg acc= 55.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 11
************************************************************************************************************
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=4.263, TAw acc= 38.5% | *
| Epoch   2, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=2.228, TAw acc= 67.7% | *
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.531, TAw acc= 78.1% | *
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.345, TAw acc= 95.8% | *
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.333, TAw acc= 96.9% | *
| Epoch   6, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.138, TAw acc=100.0% | *
| Epoch   7, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.008, TAw acc=100.0% | *
| Epoch   8, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.099, TAw acc= 99.0% |
| Epoch   9, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.717, TAw acc=100.0% | *
| Epoch  10, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.895, TAw acc=100.0% |
| Epoch  11, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.723, TAw acc=100.0% |
| Epoch  12, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.758, TAw acc=100.0% |
| Epoch  13, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.719, TAw acc=100.0% |
| Epoch  14, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.724, TAw acc=100.0% | lr=3.3e-03
| Epoch  15, time=  1.7s | Train: skip eval | Valid: time=  0.3s loss=0.840, TAw acc=100.0% |
| Epoch  16, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.815, TAw acc=100.0% |
| Epoch  17, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.826, TAw acc=100.0% |
| Epoch  18, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.789, TAw acc=100.0% |
| Epoch  19, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.775, TAw acc=100.0% | lr=1.1e-03
| Epoch  20, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.796, TAw acc=100.0% |
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.727, TAw acc=100.0% | *
| Epoch   2, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.736, TAw acc=100.0% |
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.745, TAw acc=100.0% |
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.753, TAw acc=100.0% |
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.760, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4072 train exemplars, time=  0.0s
4072
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.826 | TAw acc= 95.1%, forg= -1.4%| TAg acc= 76.4%, forg= 12.5% <<<
>>> Test on task  1 : loss=0.412 | TAw acc=100.0%, forg=  0.0%| TAg acc= 91.7%, forg=  5.0% <<<
>>> Test on task  2 : loss=0.384 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.556 | TAw acc=100.0%, forg= -0.8%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.589 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 90.0%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.626 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.8%, forg= -1.7% <<<
>>> Test on task  6 : loss=0.764 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 80.0%, forg= 11.7% <<<
>>> Test on task  7 : loss=1.131 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 67.5%, forg=  9.2% <<<
>>> Test on task  8 : loss=0.884 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 75.8%, forg=  2.5% <<<
>>> Test on task  9 : loss=1.030 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 73.3%, forg= -3.3% <<<
>>> Test on task 10 : loss=1.375 | TAw acc= 82.5%, forg=  0.8%| TAg acc= 53.3%, forg=  1.7% <<<
>>> Test on task 11 : loss=0.823 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 79.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 12
************************************************************************************************************
| Epoch   1, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=4.397, TAw acc= 49.0% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=2.921, TAw acc= 71.9% | *
| Epoch   3, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=2.356, TAw acc= 80.2% | *
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=2.186, TAw acc= 88.5% | *
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.977, TAw acc= 85.4% | *
| Epoch   6, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.926, TAw acc= 90.6% | *
| Epoch   7, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.701, TAw acc= 88.5% | *
| Epoch   8, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.547, TAw acc= 87.5% | *
| Epoch   9, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.600, TAw acc= 90.6% |
| Epoch  10, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.433, TAw acc= 93.8% | *
| Epoch  11, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.537, TAw acc= 92.7% |
| Epoch  12, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.329, TAw acc= 91.7% | *
| Epoch  13, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.374, TAw acc= 92.7% |
| Epoch  14, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.403, TAw acc= 95.8% |
| Epoch  15, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.273, TAw acc= 89.6% | *
| Epoch  16, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.152, TAw acc= 94.8% | *
| Epoch  17, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.258, TAw acc= 93.8% |
| Epoch  18, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.204, TAw acc= 94.8% |
| Epoch  19, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.118, TAw acc= 94.8% | *
| Epoch  20, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.164, TAw acc= 94.8% |
| Epoch   1, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.115, TAw acc= 94.8% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.113, TAw acc= 94.8% | *
| Epoch   3, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.112, TAw acc= 96.9% | *
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.111, TAw acc= 96.9% | *
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.110, TAw acc= 95.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4382 train exemplars, time=  0.1s
4382
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.760 | TAw acc= 95.1%, forg=  0.0%| TAg acc= 84.0%, forg=  4.9% <<<
>>> Test on task  1 : loss=0.347 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.296 | TAw acc=100.0%, forg=  0.0%| TAg acc= 98.3%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.520 | TAw acc=100.0%, forg=  0.0%| TAg acc= 88.3%, forg=  1.7% <<<
>>> Test on task  4 : loss=0.525 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 88.3%, forg=  1.7% <<<
>>> Test on task  5 : loss=0.594 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 91.7%, forg= -0.8% <<<
>>> Test on task  6 : loss=0.656 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 80.8%, forg= 10.8% <<<
>>> Test on task  7 : loss=1.129 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 69.2%, forg=  7.5% <<<
>>> Test on task  8 : loss=0.768 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.8%, forg= -2.5% <<<
>>> Test on task  9 : loss=0.889 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 75.8%, forg= -2.5% <<<
>>> Test on task 10 : loss=1.292 | TAw acc= 87.5%, forg= -4.2%| TAg acc= 62.5%, forg= -7.5% <<<
>>> Test on task 11 : loss=0.675 | TAw acc= 99.2%, forg= -2.5%| TAg acc= 85.8%, forg= -6.7% <<<
>>> Test on task 12 : loss=1.049 | TAw acc= 93.3%, forg=  0.0%| TAg acc= 70.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 13
************************************************************************************************************
| Epoch   1, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=3.876, TAw acc= 44.8% | *
| Epoch   2, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=2.613, TAw acc= 61.5% | *
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=2.368, TAw acc= 93.8% | *
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.996, TAw acc= 94.8% | *
| Epoch   5, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.848, TAw acc= 99.0% | *
| Epoch   6, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.863, TAw acc= 90.6% |
| Epoch   7, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.624, TAw acc= 93.8% | *
| Epoch   8, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.582, TAw acc=100.0% | *
| Epoch   9, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.364, TAw acc= 94.8% | *
| Epoch  10, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.443, TAw acc=100.0% |
| Epoch  11, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.230, TAw acc= 96.9% | *
| Epoch  12, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.329, TAw acc= 99.0% |
| Epoch  13, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.198, TAw acc= 92.7% | *
| Epoch  14, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.161, TAw acc= 99.0% | *
| Epoch  15, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.170, TAw acc= 99.0% |
| Epoch  16, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.199, TAw acc= 96.9% |
| Epoch  17, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.097, TAw acc= 97.9% | *
| Epoch  18, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=0.992, TAw acc= 95.8% | *
| Epoch  19, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.057, TAw acc=100.0% |
| Epoch  20, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.016, TAw acc= 99.0% |
| Epoch   1, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=0.998, TAw acc= 96.9% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.004, TAw acc= 96.9% |
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.009, TAw acc= 99.0% |
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.014, TAw acc= 99.0% |
| Epoch   5, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.019, TAw acc= 99.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4692 train exemplars, time=  0.0s
4692
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.827 | TAw acc= 95.1%, forg=  0.0%| TAg acc= 79.2%, forg=  9.7% <<<
>>> Test on task  1 : loss=0.339 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg=  1.7% <<<
>>> Test on task  2 : loss=0.314 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg=  3.3% <<<
>>> Test on task  3 : loss=0.427 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.544 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 89.2%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.586 | TAw acc=100.0%, forg= -0.8%| TAg acc= 87.5%, forg=  4.2% <<<
>>> Test on task  6 : loss=0.668 | TAw acc= 98.3%, forg= -0.8%| TAg acc= 81.7%, forg= 10.0% <<<
>>> Test on task  7 : loss=1.049 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 68.3%, forg=  8.3% <<<
>>> Test on task  8 : loss=0.742 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 82.5%, forg= -1.7% <<<
>>> Test on task  9 : loss=0.886 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 70.0%, forg=  5.8% <<<
>>> Test on task 10 : loss=1.245 | TAw acc= 86.7%, forg=  0.8%| TAg acc= 62.5%, forg=  0.0% <<<
>>> Test on task 11 : loss=0.625 | TAw acc=100.0%, forg= -0.8%| TAg acc= 89.2%, forg= -3.3% <<<
>>> Test on task 12 : loss=0.952 | TAw acc= 94.2%, forg= -0.8%| TAg acc= 76.7%, forg= -6.7% <<<
>>> Test on task 13 : loss=1.203 | TAw acc= 92.5%, forg=  0.0%| TAg acc= 68.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
    (13): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 14
************************************************************************************************************
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=4.065, TAw acc= 35.4% | *
| Epoch   2, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=2.566, TAw acc= 72.9% | *
| Epoch   3, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=2.154, TAw acc= 84.4% | *
| Epoch   4, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.842, TAw acc= 94.8% | *
| Epoch   5, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.656, TAw acc= 87.5% | *
| Epoch   6, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.441, TAw acc= 86.5% | *
| Epoch   7, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.349, TAw acc= 94.8% | *
| Epoch   8, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.348, TAw acc= 92.7% | *
| Epoch   9, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.233, TAw acc= 96.9% | *
| Epoch  10, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.188, TAw acc= 97.9% | *
| Epoch  11, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.092, TAw acc= 96.9% | *
| Epoch  12, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.203, TAw acc= 99.0% |
| Epoch  13, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.917, TAw acc= 97.9% | *
| Epoch  14, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.002, TAw acc= 94.8% |
| Epoch  15, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.962, TAw acc= 95.8% |
| Epoch  16, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.779, TAw acc= 97.9% | *
| Epoch  17, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.888, TAw acc= 95.8% |
| Epoch  18, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.846, TAw acc= 99.0% |
| Epoch  19, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=0.855, TAw acc= 96.9% |
| Epoch  20, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.813, TAw acc= 96.9% |
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.790, TAw acc= 97.9% | *
| Epoch   2, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=0.800, TAw acc= 97.9% |
| Epoch   3, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.809, TAw acc= 99.0% |
| Epoch   4, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=0.818, TAw acc= 99.0% |
| Epoch   5, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.825, TAw acc= 99.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 38
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 5002 train exemplars, time=  0.0s
5002
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.774 | TAw acc= 95.8%, forg= -0.7%| TAg acc= 84.7%, forg=  4.2% <<<
>>> Test on task  1 : loss=0.323 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg=  1.7% <<<
>>> Test on task  2 : loss=0.309 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.465 | TAw acc=100.0%, forg=  0.0%| TAg acc= 90.0%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.524 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 90.0%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.563 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 85.8%, forg=  5.8% <<<
>>> Test on task  6 : loss=0.642 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 81.7%, forg= 10.0% <<<
>>> Test on task  7 : loss=1.112 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 70.8%, forg=  5.8% <<<
>>> Test on task  8 : loss=0.735 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 79.2%, forg=  3.3% <<<
>>> Test on task  9 : loss=0.866 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 74.2%, forg=  1.7% <<<
>>> Test on task 10 : loss=1.091 | TAw acc= 88.3%, forg= -0.8%| TAg acc= 67.5%, forg= -5.0% <<<
>>> Test on task 11 : loss=0.611 | TAw acc=100.0%, forg=  0.0%| TAg acc= 80.8%, forg=  8.3% <<<
>>> Test on task 12 : loss=0.806 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 80.8%, forg= -4.2% <<<
>>> Test on task 13 : loss=1.305 | TAw acc= 95.0%, forg= -2.5%| TAg acc= 68.3%, forg=  0.0% <<<
>>> Test on task 14 : loss=0.674 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 93.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_3/har_flex_eeil
************************************************************************************************************
TAw Acc
	 56.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 56.9% 
	 84.7%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 91.5% 
	 87.5%  98.3%  85.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 90.3% 
	 91.0%  99.2%  99.2%  87.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 94.2% 
	 91.7%  99.2% 100.0%  96.7%  95.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.7% 
	 93.1%  99.2% 100.0%  97.5%  96.7%  95.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.0% 
	 92.4%  99.2% 100.0%  98.3%  96.7%  96.7%  94.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.8% 
	 92.4% 100.0% 100.0%  98.3%  96.7%  98.3%  97.5%  94.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.2% 
	 92.4% 100.0% 100.0%  99.2%  98.3%  99.2%  96.7%  95.8%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.8% 
	 93.1% 100.0% 100.0%  99.2%  97.5%  99.2%  95.0%  95.8%  98.3%  96.7%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.5% 
	 93.8% 100.0% 100.0%  99.2%  98.3%  99.2%  97.5%  96.7%  99.2%  97.5%  83.3%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.8% 
	 95.1% 100.0% 100.0% 100.0%  97.5%  99.2%  97.5%  96.7%  99.2%  97.5%  82.5%  96.7%   0.0%   0.0%   0.0% 	Avg.: 96.8% 
	 95.1% 100.0% 100.0% 100.0%  97.5%  99.2%  96.7%  96.7%  99.2%  97.5%  87.5%  99.2%  93.3%   0.0%   0.0% 	Avg.: 97.1% 
	 95.1% 100.0% 100.0%  99.2%  97.5% 100.0%  98.3%  96.7%  99.2%  97.5%  86.7% 100.0%  94.2%  92.5%   0.0% 	Avg.: 96.9% 
	 95.8% 100.0% 100.0% 100.0%  97.5%  99.2%  97.5%  96.7%  99.2%  97.5%  88.3% 100.0%  94.2%  95.0%  99.2% 	Avg.: 97.3% 
************************************************************************************************************
TAg Acc
	 56.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 56.9% 
	 79.9%  81.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 80.8% 
	 81.9%  89.2%  73.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.5% 
	 88.9%  86.7%  96.7%  73.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 86.4% 
	 83.3%  93.3%  98.3%  87.5%  84.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 89.3% 
	 88.9%  90.0%  96.7%  80.8%  87.5%  80.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 87.3% 
	 85.4%  96.7%  96.7%  77.5%  90.0%  87.5%  83.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 88.2% 
	 86.1%  88.3%  87.5%  80.8%  86.7%  86.7%  91.7%  60.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 83.5% 
	 84.7%  95.8%  95.8%  90.0%  85.0%  89.2%  91.7%  60.0%  67.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 84.4% 
	 84.0%  96.7%  98.3%  89.2%  89.2%  89.2%  86.7%  69.2%  66.7%  69.2%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 83.8% 
	 86.1%  96.7%  98.3%  88.3%  89.2%  86.7%  84.2%  76.7%  78.3%  70.0%  55.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.7% 
	 76.4%  91.7%  97.5%  89.2%  90.0%  90.8%  80.0%  67.5%  75.8%  73.3%  53.3%  79.2%   0.0%   0.0%   0.0% 	Avg.: 80.4% 
	 84.0%  95.8%  98.3%  88.3%  88.3%  91.7%  80.8%  69.2%  80.8%  75.8%  62.5%  85.8%  70.0%   0.0%   0.0% 	Avg.: 82.4% 
	 79.2%  95.0%  95.0%  89.2%  89.2%  87.5%  81.7%  68.3%  82.5%  70.0%  62.5%  89.2%  76.7%  68.3%   0.0% 	Avg.: 81.0% 
	 84.7%  95.0%  97.5%  90.0%  90.0%  85.8%  81.7%  70.8%  79.2%  74.2%  67.5%  80.8%  80.8%  68.3%  93.3% 	Avg.: 82.6% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-27.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-27.8% 
	 -2.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.4% 
	 -3.5%  -0.8% -14.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -6.2% 
	 -0.7%   0.0%  -0.8%  -9.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -2.7% 
	 -1.4%   0.0%   0.0%  -0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.6% 
	  0.7%   0.0%   0.0%  -0.8%   0.0%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.2% 
	  0.7%  -0.8%   0.0%   0.0%   0.0%  -1.7%  -3.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.7% 
	  0.7%   0.0%   0.0%  -0.8%  -1.7%  -0.8%   0.8%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	  0.0%   0.0%   0.0%   0.0%   0.8%   0.0%   2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.4% 
	 -0.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%  -0.8%  -0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.3% 
	 -1.4%   0.0%   0.0%  -0.8%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.1% 
	  0.0%   0.0%   0.0%   0.0%   0.8%   0.0%   0.8%   0.0%   0.0%   0.0%  -4.2%  -2.5%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	  0.0%   0.0%   0.0%   0.8%   0.8%  -0.8%  -0.8%   0.0%   0.0%   0.0%   0.8%  -0.8%  -0.8%   0.0%   0.0% 	Avg.: -0.1% 
	 -0.7%   0.0%   0.0%   0.0%   0.8%   0.8%   0.8%   0.0%   0.0%   0.0%  -0.8%   0.0%   0.0%  -2.5%   0.0% 	Avg.: -0.1% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-22.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-22.9% 
	 -2.1%  -7.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -4.8% 
	 -6.9%   2.5% -23.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -9.3% 
	  5.6%  -4.2%  -1.7% -14.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -3.6% 
	  0.0%   3.3%   1.7%   6.7%  -3.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.7% 
	  3.5%  -3.3%   1.7%  10.0%  -2.5%  -7.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.3% 
	  2.8%   8.3%  10.8%   6.7%   3.3%   0.8%  -8.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.5% 
	  4.2%   0.8%   2.5%  -2.5%   5.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.0% 
	  4.9%   0.0%   0.0%   0.8%   0.8%   0.0%   5.0%  -9.2%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.4% 
	  2.8%   0.0%   0.0%   1.7%   0.8%   2.5%   7.5%  -7.5% -10.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	 12.5%   5.0%   0.8%   0.8%   0.0%  -1.7%  11.7%   9.2%   2.5%  -3.3%   1.7%   0.0%   0.0%   0.0%   0.0% 	Avg.:  3.6% 
	  4.9%   0.8%   0.0%   1.7%   1.7%  -0.8%  10.8%   7.5%  -2.5%  -2.5%  -7.5%  -6.7%   0.0%   0.0%   0.0% 	Avg.:  0.6% 
	  9.7%   1.7%   3.3%   0.8%   0.8%   4.2%  10.0%   8.3%  -1.7%   5.8%   0.0%  -3.3%  -6.7%   0.0%   0.0% 	Avg.:  2.5% 
	  4.2%   1.7%   0.8%   0.0%   0.0%   5.8%  10.0%   5.8%   3.3%   1.7%  -5.0%   8.3%  -4.2%   0.0%   0.0% 	Avg.:  2.3% 
************************************************************************************************************
[Elapsed time = 0.1 h]
Done!

f1_score_micro: 0.8267543859649122
f1_score_macro: 0.821303068237156
              precision    recall  f1-score   support

           0       0.50      0.50      0.50        12
           1       1.00      1.00      1.00        12
           2       0.79      0.92      0.85        12
           3       0.55      0.92      0.69        12
           4       1.00      0.83      0.91        12
           5       0.57      0.67      0.62        12
           6       1.00      0.75      0.86        12
           7       1.00      1.00      1.00        12
           8       0.92      1.00      0.96        12
           9       1.00      1.00      1.00        12
          10       0.62      0.67      0.64        12
          11       0.46      0.92      0.61        12
          12       1.00      1.00      1.00        12
          13       1.00      1.00      1.00        12
          14       1.00      1.00      1.00        12
          15       1.00      0.92      0.96        12
          16       0.79      0.92      0.85        12
          17       0.91      0.83      0.87        12
          18       0.91      0.83      0.87        12
          19       1.00      1.00      1.00        12
          20       1.00      1.00      1.00        12
          21       0.75      1.00      0.86        12
          22       1.00      1.00      1.00        12
          23       0.80      1.00      0.89        12
          24       0.92      1.00      0.96        12
          25       1.00      1.00      1.00        12
          26       1.00      1.00      1.00        12
          27       0.92      0.92      0.92        12
          28       0.86      1.00      0.92        12
          29       1.00      1.00      1.00        12
          30       0.83      0.83      0.83        12
          31       1.00      1.00      1.00        12
          32       0.86      1.00      0.92        12
          33       0.92      1.00      0.96        12
          34       0.79      0.92      0.85        12
          35       0.92      1.00      0.96        12
          36       1.00      1.00      1.00        12
          37       1.00      0.92      0.96        12
          38       0.92      1.00      0.96        12
          39       0.92      1.00      0.96        12
          40       1.00      1.00      1.00        12
          41       0.17      0.17      0.17        12
          42       1.00      1.00      1.00        12
          43       0.86      1.00      0.92        12
          44       1.00      1.00      1.00        12
          45       1.00      1.00      1.00        12
          46       0.60      0.50      0.55        12
          47       1.00      1.00      1.00        12
          48       0.54      0.58      0.56        12
          49       0.73      0.92      0.81        12
          50       1.00      1.00      1.00        12
          51       1.00      1.00      1.00        12
          52       0.83      0.83      0.83        12
          53       1.00      1.00      1.00        12
          54       0.92      1.00      0.96        12
          55       0.80      0.67      0.73        12
          56       1.00      0.92      0.96        12
          57       1.00      1.00      1.00        12
          58       0.90      0.75      0.82        12
          59       1.00      1.00      1.00        12
          60       0.91      0.83      0.87        12
          61       0.35      0.58      0.44        12
          62       1.00      1.00      1.00        12
          63       0.90      0.75      0.82        12
          64       0.53      0.75      0.62        12
          65       1.00      0.83      0.91        12
          66       1.00      1.00      1.00        12
          67       1.00      0.58      0.74        12
          68       0.79      0.92      0.85        12
          69       1.00      1.00      1.00        12
          70       0.41      0.75      0.53        12
          71       0.64      0.58      0.61        12
          72       1.00      0.92      0.96        12
          73       0.58      0.58      0.58        12
          74       0.75      0.25      0.38        12
          75       0.67      0.83      0.74        12
          76       0.83      0.83      0.83        12
          77       0.92      0.92      0.92        12
          78       0.25      0.08      0.12        12
          79       0.92      0.92      0.92        12
          80       0.90      0.75      0.82        12
          81       0.92      1.00      0.96        12
          82       0.50      0.33      0.40        12
          83       0.39      0.58      0.47        12
          84       1.00      0.67      0.80        12
          85       0.83      0.83      0.83        12
          86       0.86      1.00      0.92        12
          87       0.75      1.00      0.86        12
          88       0.92      0.92      0.92        12
          89       0.92      1.00      0.96        12
          90       1.00      1.00      1.00        12
          91       0.88      0.58      0.70        12
          92       1.00      0.67      0.80        12
          93       1.00      1.00      1.00        12
          94       0.88      0.58      0.70        12
          95       0.92      1.00      0.96        12
          96       0.57      0.33      0.42        12
          97       0.77      0.83      0.80        12
          98       1.00      1.00      1.00        12
          99       1.00      0.83      0.91        12
         100       0.54      0.58      0.56        12
         101       0.78      0.58      0.67        12
         102       0.45      0.42      0.43        12
         103       0.33      0.50      0.40        12
         104       0.80      0.67      0.73        12
         105       0.83      0.83      0.83        12
         106       0.86      1.00      0.92        12
         107       0.44      0.58      0.50        12
         108       0.82      0.75      0.78        12
         109       0.57      0.33      0.42        12
         110       1.00      0.67      0.80        12
         111       0.86      1.00      0.92        12
         112       1.00      1.00      1.00        12
         113       0.92      1.00      0.96        12
         114       0.89      0.67      0.76        12
         115       0.77      0.83      0.80        12
         116       1.00      0.67      0.80        12
         117       0.92      0.92      0.92        12
         118       0.00      0.00      0.00        12
         119       1.00      1.00      1.00        12
         120       1.00      1.00      1.00        12
         121       1.00      1.00      1.00        12
         122       1.00      1.00      1.00        12
         123       0.77      0.83      0.80        12
         124       0.92      1.00      0.96        12
         125       0.60      0.25      0.35        12
         126       1.00      1.00      1.00        12
         127       1.00      1.00      1.00        12
         128       0.22      0.50      0.31        12
         129       1.00      0.75      0.86        12
         130       0.83      0.83      0.83        12
         131       0.85      0.92      0.88        12
         132       0.00      0.00      0.00        12
         133       1.00      0.50      0.67        12
         134       0.67      0.50      0.57        12
         135       0.69      0.92      0.79        12
         136       1.00      0.75      0.86        12
         137       0.71      0.42      0.53        12
         138       1.00      1.00      1.00        12
         139       1.00      0.92      0.96        12
         140       0.91      0.83      0.87        12
         141       1.00      1.00      1.00        12
         142       0.67      1.00      0.80        12
         143       1.00      0.92      0.96        12
         144       0.92      1.00      0.96        12
         145       0.91      0.83      0.87        12
         146       0.69      0.92      0.79        12
         147       0.73      0.92      0.81        12
         148       0.91      0.83      0.87        12
         149       0.85      0.92      0.88        12
         150       1.00      1.00      1.00        12
         151       1.00      1.00      1.00        12

    accuracy                           0.83      1824
   macro avg       0.83      0.83      0.82      1824
weighted avg       0.83      0.83      0.82      1824

torch.Size([1824, 405]) torch.Size([1824])
Parameters: 36980
Task parameters: {0: 27600, 1: 28270, 2: 28940, 3: 29610, 4: 30280, 5: 30950, 6: 31620, 7: 32290, 8: 32960, 9: 33630, 10: 34300, 11: 34970, 12: 35640, 13: 36310, 14: 36980}
