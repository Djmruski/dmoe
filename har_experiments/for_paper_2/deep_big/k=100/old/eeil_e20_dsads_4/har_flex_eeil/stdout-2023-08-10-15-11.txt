	dataset_config: {'path': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'path_test': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'resize': None, 'pad': None, 'crop': None, 'normalize': None, 'class_order': None, 'extend_channel': None, 'flip': False}
CLASS_ORDER: [35, 5, 25, 137, 8, 108, 134, 128, 148, 22, 15, 147, 18, 120, 101, 105, 45, 99, 44, 73, 37, 117, 19, 58, 98, 30, 55, 86, 48, 62, 150, 102, 65, 60, 68, 72, 57, 121, 75, 33, 90, 142, 20, 143, 113, 41, 103, 43, 32, 111, 34, 46, 21, 27, 66, 92, 115, 138, 71, 16, 53, 135, 11, 24, 74, 67, 51, 141, 12, 116, 146, 77, 52, 38, 89, 3, 87, 79, 132, 93, 133, 100, 2, 109, 83, 149, 88, 112, 110, 104, 50, 9, 151, 39, 64, 82, 13, 28, 1, 63, 4, 126, 84, 17, 36, 95, 94, 49, 136, 10, 42, 96, 140, 124, 0, 145, 107, 144, 61, 26, 76, 81, 129, 119, 40, 114, 29, 7, 6, 47, 31, 131, 14, 97, 56, 127, 69, 91, 78, 70, 139, 122, 125, 130, 85, 59, 118, 54, 80, 106, 123, 23]
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList()
)
======

************************************************************************************************************
Task  0
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.440, TAw acc= 19.1% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.400, TAw acc= 18.3% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.356, TAw acc= 26.1% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.316, TAw acc= 29.6% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.270, TAw acc= 33.0% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.202, TAw acc= 25.2% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.155, TAw acc= 33.0% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.103, TAw acc= 40.0% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.050, TAw acc= 37.4% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.973, TAw acc= 28.7% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.923, TAw acc= 36.5% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.867, TAw acc= 42.6% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.818, TAw acc= 45.2% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.775, TAw acc= 51.3% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.713, TAw acc= 56.5% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.677, TAw acc= 54.8% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.617, TAw acc= 60.9% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.577, TAw acc= 57.4% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.531, TAw acc= 63.5% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.494, TAw acc= 64.3% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 423 train exemplars, time=  0.0s
423
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.458 | TAw acc= 59.7%, forg=  0.0%| TAg acc= 59.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
  )
)
======

************************************************************************************************************
Task  1
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.965, TAw acc= 32.3% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.790, TAw acc= 31.2% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.684, TAw acc= 32.3% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.580, TAw acc= 42.7% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.525, TAw acc= 46.9% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.413, TAw acc= 44.8% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.331, TAw acc= 56.2% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.279, TAw acc= 60.4% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.196, TAw acc= 50.0% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.166, TAw acc= 69.8% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.100, TAw acc= 71.9% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.050, TAw acc= 78.1% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.964, TAw acc= 89.6% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.906, TAw acc= 77.1% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.847, TAw acc= 74.0% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.828, TAw acc= 75.0% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.760, TAw acc= 66.7% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.728, TAw acc= 82.3% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.671, TAw acc= 95.8% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.629, TAw acc= 72.9% | *
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.628, TAw acc= 75.0% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.628, TAw acc= 75.0% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 76.0% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 76.0% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 75.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 763 train exemplars, time=  0.0s
763
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.157 | TAw acc= 84.7%, forg=-25.0%| TAg acc= 84.7%, forg=-25.0% <<<
>>> Test on task  1 : loss=1.606 | TAw acc= 80.0%, forg=  0.0%| TAg acc= 69.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  2
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=3.581, TAw acc= 34.4% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.999, TAw acc= 44.8% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.734, TAw acc= 38.5% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.596, TAw acc= 40.6% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.473, TAw acc= 40.6% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.390, TAw acc= 50.0% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.276, TAw acc= 61.5% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.196, TAw acc= 55.2% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.130, TAw acc= 64.6% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.172, TAw acc= 60.4% |
| Epoch  11, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.972, TAw acc= 69.8% | *
| Epoch  12, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.940, TAw acc= 56.2% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.863, TAw acc= 71.9% | *
| Epoch  14, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.890, TAw acc= 67.7% |
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.835, TAw acc= 65.6% | *
| Epoch  16, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.811, TAw acc= 78.1% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.733, TAw acc= 65.6% | *
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.693, TAw acc= 82.3% | *
| Epoch  19, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.636, TAw acc= 81.2% | *
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.528, TAw acc= 76.0% | *
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.530, TAw acc= 76.0% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.532, TAw acc= 77.1% |
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.533, TAw acc= 77.1% |
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.535, TAw acc= 77.1% |
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.536, TAw acc= 76.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 1103 train exemplars, time=  0.0s
1103
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.030 | TAw acc= 92.4%, forg= -7.6%| TAg acc= 75.7%, forg=  9.0% <<<
>>> Test on task  1 : loss=1.263 | TAw acc= 88.3%, forg= -8.3%| TAg acc= 69.2%, forg=  0.0% <<<
>>> Test on task  2 : loss=1.590 | TAw acc= 71.7%, forg=  0.0%| TAg acc= 63.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  3
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.538, TAw acc= 36.5% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.970, TAw acc= 43.8% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.625, TAw acc= 50.0% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.409, TAw acc= 63.5% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.265, TAw acc= 72.9% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.110, TAw acc= 82.3% | *
| Epoch   7, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.028, TAw acc= 60.4% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.988, TAw acc= 81.2% | *
| Epoch   9, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.862, TAw acc= 79.2% | *
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.820, TAw acc= 91.7% | *
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.726, TAw acc= 85.4% | *
| Epoch  12, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.691, TAw acc= 90.6% | *
| Epoch  13, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.619, TAw acc= 85.4% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.494, TAw acc= 89.6% | *
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.426, TAw acc= 90.6% | *
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.401, TAw acc= 89.6% | *
| Epoch  17, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.368, TAw acc= 89.6% | *
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.247, TAw acc= 90.6% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.296, TAw acc= 93.8% |
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.254, TAw acc= 94.8% |
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.249, TAw acc= 90.6% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.251, TAw acc= 91.7% |
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.253, TAw acc= 91.7% |
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.255, TAw acc= 92.7% |
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.257, TAw acc= 92.7% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 1443 train exemplars, time=  0.0s
1443
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.803 | TAw acc= 95.8%, forg= -3.5%| TAg acc= 94.4%, forg= -9.7% <<<
>>> Test on task  1 : loss=1.082 | TAw acc= 91.7%, forg= -3.3%| TAg acc= 80.0%, forg=-10.8% <<<
>>> Test on task  2 : loss=1.530 | TAw acc= 83.3%, forg=-11.7%| TAg acc= 65.8%, forg= -2.5% <<<
>>> Test on task  3 : loss=1.252 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 85.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  4
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.955, TAw acc= 46.9% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.964, TAw acc= 51.0% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=2.509, TAw acc= 64.6% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.380, TAw acc= 66.7% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.317, TAw acc= 72.9% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.101, TAw acc= 74.0% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.999, TAw acc= 72.9% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.852, TAw acc= 80.2% | *
| Epoch   9, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.871, TAw acc= 79.2% |
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.853, TAw acc= 72.9% |
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.772, TAw acc= 77.1% | *
| Epoch  12, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.715, TAw acc= 77.1% | *
| Epoch  13, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.621, TAw acc= 77.1% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.525, TAw acc= 84.4% | *
| Epoch  15, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.669, TAw acc= 79.2% |
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.485, TAw acc= 85.4% | *
| Epoch  17, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.554, TAw acc= 85.4% |
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.395, TAw acc= 82.3% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.351, TAw acc= 85.4% | *
| Epoch  20, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.361, TAw acc= 84.4% |
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.352, TAw acc= 85.4% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.352, TAw acc= 85.4% |
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.353, TAw acc= 85.4% |
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.354, TAw acc= 85.4% |
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.355, TAw acc= 85.4% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 1783 train exemplars, time=  0.0s
1783
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.646 | TAw acc= 97.2%, forg= -1.4%| TAg acc= 93.8%, forg=  0.7% <<<
>>> Test on task  1 : loss=0.958 | TAw acc= 98.3%, forg= -6.7%| TAg acc= 84.2%, forg= -4.2% <<<
>>> Test on task  2 : loss=1.294 | TAw acc= 83.3%, forg=  0.0%| TAg acc= 72.5%, forg= -6.7% <<<
>>> Test on task  3 : loss=0.960 | TAw acc= 98.3%, forg= -1.7%| TAg acc= 81.7%, forg=  4.2% <<<
>>> Test on task  4 : loss=1.337 | TAw acc= 90.0%, forg=  0.0%| TAg acc= 74.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  5
************************************************************************************************************
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=3.979, TAw acc= 42.7% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.621, TAw acc= 56.2% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.379, TAw acc= 54.2% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.054, TAw acc= 76.0% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.971, TAw acc= 72.9% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.846, TAw acc= 66.7% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.609, TAw acc= 81.2% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.686, TAw acc= 91.7% |
| Epoch   9, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.581, TAw acc= 79.2% | *
| Epoch  10, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.513, TAw acc= 84.4% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.390, TAw acc= 93.8% | *
| Epoch  12, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.354, TAw acc= 93.8% | *
| Epoch  13, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.268, TAw acc= 92.7% | *
| Epoch  14, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.160, TAw acc= 90.6% | *
| Epoch  15, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.237, TAw acc= 93.8% |
| Epoch  16, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.201, TAw acc= 87.5% |
| Epoch  17, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.137, TAw acc= 93.8% | *
| Epoch  18, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.107, TAw acc= 94.8% | *
| Epoch  19, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.003, TAw acc= 91.7% | *
| Epoch  20, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.096, TAw acc= 94.8% |
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.004, TAw acc= 91.7% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.005, TAw acc= 91.7% |
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.006, TAw acc= 91.7% |
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.006, TAw acc= 91.7% |
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.007, TAw acc= 91.7% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 2123 train exemplars, time=  0.0s
2123
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.634 | TAw acc= 97.9%, forg= -0.7%| TAg acc= 93.1%, forg=  1.4% <<<
>>> Test on task  1 : loss=0.787 | TAw acc= 97.5%, forg=  0.8%| TAg acc= 87.5%, forg= -3.3% <<<
>>> Test on task  2 : loss=1.160 | TAw acc= 85.8%, forg= -2.5%| TAg acc= 72.5%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.712 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 86.7%, forg= -0.8% <<<
>>> Test on task  4 : loss=1.114 | TAw acc= 91.7%, forg= -1.7%| TAg acc= 75.8%, forg= -1.7% <<<
>>> Test on task  5 : loss=1.060 | TAw acc= 90.0%, forg=  0.0%| TAg acc= 72.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  6
************************************************************************************************************
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=4.090, TAw acc= 37.5% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.775, TAw acc= 79.2% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.280, TAw acc= 74.0% | *
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=2.142, TAw acc= 96.9% | *
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.922, TAw acc= 96.9% | *
| Epoch   6, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.814, TAw acc= 87.5% | *
| Epoch   7, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.622, TAw acc= 99.0% | *
| Epoch   8, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.524, TAw acc=100.0% | *
| Epoch   9, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.443, TAw acc= 92.7% | *
| Epoch  10, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.476, TAw acc= 99.0% |
| Epoch  11, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.336, TAw acc= 99.0% | *
| Epoch  12, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.220, TAw acc= 97.9% | *
| Epoch  13, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.223, TAw acc= 94.8% |
| Epoch  14, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.139, TAw acc= 99.0% | *
| Epoch  15, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.059, TAw acc= 99.0% | *
| Epoch  16, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.040, TAw acc= 94.8% | *
| Epoch  17, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.097, TAw acc= 97.9% |
| Epoch  18, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.945, TAw acc=100.0% | *
| Epoch  19, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.949, TAw acc= 99.0% |
| Epoch  20, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.029, TAw acc=100.0% |
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.946, TAw acc=100.0% | *
| Epoch   2, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.946, TAw acc=100.0% |
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.947, TAw acc=100.0% |
| Epoch   4, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.948, TAw acc=100.0% |
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=0.948, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 2463 train exemplars, time=  0.0s
2463
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.623 | TAw acc= 96.5%, forg=  1.4%| TAg acc= 88.2%, forg=  6.2% <<<
>>> Test on task  1 : loss=0.698 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 87.5%, forg=  0.0% <<<
>>> Test on task  2 : loss=1.077 | TAw acc= 85.8%, forg=  0.0%| TAg acc= 74.2%, forg= -1.7% <<<
>>> Test on task  3 : loss=0.574 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 90.0%, forg= -3.3% <<<
>>> Test on task  4 : loss=0.931 | TAw acc= 91.7%, forg=  0.0%| TAg acc= 80.8%, forg= -5.0% <<<
>>> Test on task  5 : loss=1.059 | TAw acc= 91.7%, forg= -1.7%| TAg acc= 67.5%, forg=  5.0% <<<
>>> Test on task  6 : loss=1.036 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 85.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  7
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=3.813, TAw acc= 30.2% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.592, TAw acc= 40.6% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=2.088, TAw acc= 55.2% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.841, TAw acc= 65.6% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.656, TAw acc= 78.1% | *
| Epoch   6, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.533, TAw acc= 93.8% | *
| Epoch   7, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.446, TAw acc= 92.7% | *
| Epoch   8, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.356, TAw acc= 89.6% | *
| Epoch   9, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.331, TAw acc= 84.4% | *
| Epoch  10, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.280, TAw acc= 95.8% | *
| Epoch  11, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.247, TAw acc= 87.5% | *
| Epoch  12, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.176, TAw acc= 95.8% | *
| Epoch  13, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.106, TAw acc=100.0% | *
| Epoch  14, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.010, TAw acc= 91.7% | *
| Epoch  15, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.971, TAw acc=100.0% | *
| Epoch  16, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.967, TAw acc=100.0% | *
| Epoch  17, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.916, TAw acc=100.0% | *
| Epoch  18, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.865, TAw acc=100.0% | *
| Epoch  19, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.885, TAw acc= 91.7% |
| Epoch  20, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.823, TAw acc=100.0% | *
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.824, TAw acc=100.0% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.824, TAw acc=100.0% |
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.825, TAw acc=100.0% |
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.826, TAw acc=100.0% |
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=0.827, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
| Selected 2803 train exemplars, time=  0.0s
2803
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.574 | TAw acc= 97.9%, forg=  0.0%| TAg acc= 89.6%, forg=  4.9% <<<
>>> Test on task  1 : loss=0.560 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.0%, forg= -2.5% <<<
>>> Test on task  2 : loss=0.975 | TAw acc= 86.7%, forg= -0.8%| TAg acc= 76.7%, forg= -2.5% <<<
>>> Test on task  3 : loss=0.486 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 90.0%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.793 | TAw acc= 95.8%, forg= -4.2%| TAg acc= 88.3%, forg= -7.5% <<<
>>> Test on task  5 : loss=0.890 | TAw acc= 95.0%, forg= -3.3%| TAg acc= 80.0%, forg= -7.5% <<<
>>> Test on task  6 : loss=0.920 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 81.7%, forg=  4.2% <<<
>>> Test on task  7 : loss=0.899 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 81.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  8
************************************************************************************************************
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=4.392, TAw acc= 39.6% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.891, TAw acc= 58.3% | *
| Epoch   3, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.361, TAw acc= 85.4% | *
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=2.092, TAw acc= 71.9% | *
| Epoch   5, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.746, TAw acc= 88.5% | *
| Epoch   6, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.668, TAw acc= 92.7% | *
| Epoch   7, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.579, TAw acc= 95.8% | *
| Epoch   8, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.473, TAw acc= 96.9% | *
| Epoch   9, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.467, TAw acc= 97.9% | *
| Epoch  10, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.304, TAw acc= 96.9% | *
| Epoch  11, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.315, TAw acc= 99.0% |
| Epoch  12, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.237, TAw acc=100.0% | *
| Epoch  13, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.293, TAw acc=100.0% |
| Epoch  14, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.266, TAw acc= 99.0% |
| Epoch  15, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.189, TAw acc=100.0% | *
| Epoch  16, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.162, TAw acc=100.0% | *
| Epoch  17, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.090, TAw acc= 97.9% | *
| Epoch  18, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.147, TAw acc=100.0% |
| Epoch  19, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.026, TAw acc= 99.0% | *
| Epoch  20, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=0.931, TAw acc=100.0% | *
| Epoch   1, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.932, TAw acc=100.0% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=0.932, TAw acc=100.0% |
| Epoch   3, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.933, TAw acc=100.0% |
| Epoch   4, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.935, TAw acc=100.0% |
| Epoch   5, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=0.935, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3119 train exemplars, time=  0.0s
3119
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.474 | TAw acc= 97.9%, forg=  0.0%| TAg acc= 95.1%, forg= -0.7% <<<
>>> Test on task  1 : loss=0.511 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 92.5%, forg= -2.5% <<<
>>> Test on task  2 : loss=1.049 | TAw acc= 90.0%, forg= -3.3%| TAg acc= 71.7%, forg=  5.0% <<<
>>> Test on task  3 : loss=0.428 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 90.8%, forg= -0.8% <<<
>>> Test on task  4 : loss=0.681 | TAw acc= 93.3%, forg=  2.5%| TAg acc= 87.5%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.791 | TAw acc= 95.8%, forg= -0.8%| TAg acc= 78.3%, forg=  1.7% <<<
>>> Test on task  6 : loss=0.867 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 82.5%, forg=  3.3% <<<
>>> Test on task  7 : loss=0.753 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 82.5%, forg= -0.8% <<<
>>> Test on task  8 : loss=0.881 | TAw acc=100.0%, forg=  0.0%| TAg acc= 87.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  9
************************************************************************************************************
| Epoch   1, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=4.231, TAw acc= 47.9% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=3.138, TAw acc= 50.0% | *
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.694, TAw acc= 64.6% | *
| Epoch   4, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.697, TAw acc= 68.8% |
| Epoch   5, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=2.067, TAw acc= 76.0% | *
| Epoch   6, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=2.160, TAw acc= 79.2% |
| Epoch   7, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=2.045, TAw acc= 86.5% | *
| Epoch   8, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.611, TAw acc= 90.6% | *
| Epoch   9, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.725, TAw acc= 93.8% |
| Epoch  10, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.499, TAw acc= 95.8% | *
| Epoch  11, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.606, TAw acc= 97.9% |
| Epoch  12, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.370, TAw acc= 89.6% | *
| Epoch  13, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.713, TAw acc= 95.8% |
| Epoch  14, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.392, TAw acc= 89.6% |
| Epoch  15, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.486, TAw acc= 95.8% |
| Epoch  16, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.285, TAw acc= 89.6% | *
| Epoch  17, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.449, TAw acc= 96.9% |
| Epoch  18, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.201, TAw acc= 95.8% | *
| Epoch  19, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.284, TAw acc= 90.6% |
| Epoch  20, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.130, TAw acc= 95.8% | *
| Epoch   1, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.128, TAw acc= 96.9% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.127, TAw acc= 96.9% | *
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.127, TAw acc= 97.9% | *
| Epoch   4, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.127, TAw acc= 97.9% | *
| Epoch   5, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.126, TAw acc= 97.9% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3429 train exemplars, time=  0.0s
3429
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.478 | TAw acc= 98.6%, forg= -0.7%| TAg acc= 95.1%, forg=  0.0% <<<
>>> Test on task  1 : loss=0.477 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.8%, forg=  1.7% <<<
>>> Test on task  2 : loss=0.966 | TAw acc= 89.2%, forg=  0.8%| TAg acc= 73.3%, forg=  3.3% <<<
>>> Test on task  3 : loss=0.486 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 91.7%, forg= -0.8% <<<
>>> Test on task  4 : loss=0.574 | TAw acc= 98.3%, forg= -2.5%| TAg acc= 95.8%, forg= -7.5% <<<
>>> Test on task  5 : loss=0.663 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 85.8%, forg= -5.8% <<<
>>> Test on task  6 : loss=0.848 | TAw acc= 94.2%, forg=  0.8%| TAg acc= 81.7%, forg=  4.2% <<<
>>> Test on task  7 : loss=0.614 | TAw acc=100.0%, forg= -0.8%| TAg acc= 85.8%, forg= -3.3% <<<
>>> Test on task  8 : loss=0.833 | TAw acc=100.0%, forg=  0.0%| TAg acc= 82.5%, forg=  5.0% <<<
>>> Test on task  9 : loss=1.127 | TAw acc= 92.5%, forg=  0.0%| TAg acc= 75.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 10
************************************************************************************************************
| Epoch   1, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=4.805, TAw acc= 59.4% | *
| Epoch   2, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.737, TAw acc= 85.4% | *
| Epoch   3, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.141, TAw acc= 95.8% | *
| Epoch   4, time=  1.3s | Train: skip eval | Valid: time=  0.3s loss=1.890, TAw acc= 96.9% | *
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.542, TAw acc= 95.8% | *
| Epoch   6, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.355, TAw acc= 99.0% | *
| Epoch   7, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.316, TAw acc= 99.0% | *
| Epoch   8, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.319, TAw acc= 97.9% |
| Epoch   9, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.190, TAw acc= 99.0% | *
| Epoch  10, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.122, TAw acc= 99.0% | *
| Epoch  11, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.139, TAw acc= 99.0% |
| Epoch  12, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.018, TAw acc= 99.0% | *
| Epoch  13, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.010, TAw acc= 99.0% | *
| Epoch  14, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.009, TAw acc= 99.0% | *
| Epoch  15, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.887, TAw acc= 99.0% | *
| Epoch  16, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.903, TAw acc= 99.0% |
| Epoch  17, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.878, TAw acc= 99.0% | *
| Epoch  18, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.824, TAw acc= 99.0% | *
| Epoch  19, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.845, TAw acc= 99.0% |
| Epoch  20, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.739, TAw acc= 99.0% | *
| Epoch   1, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.743, TAw acc= 99.0% | *
| Epoch   2, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=0.746, TAw acc= 99.0% |
| Epoch   3, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.749, TAw acc= 99.0% |
| Epoch   4, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.752, TAw acc= 99.0% |
| Epoch   5, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.755, TAw acc= 99.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3739 train exemplars, time=  0.0s
3739
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.444 | TAw acc= 98.6%, forg=  0.0%| TAg acc= 93.8%, forg=  1.4% <<<
>>> Test on task  1 : loss=0.473 | TAw acc=100.0%, forg= -0.8%| TAg acc= 86.7%, forg=  5.8% <<<
>>> Test on task  2 : loss=1.024 | TAw acc= 90.0%, forg=  0.0%| TAg acc= 72.5%, forg=  4.2% <<<
>>> Test on task  3 : loss=0.417 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 91.7%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.537 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 95.8%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.645 | TAw acc= 99.2%, forg= -2.5%| TAg acc= 84.2%, forg=  1.7% <<<
>>> Test on task  6 : loss=0.740 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 82.5%, forg=  3.3% <<<
>>> Test on task  7 : loss=0.556 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 86.7%, forg= -0.8% <<<
>>> Test on task  8 : loss=0.765 | TAw acc=100.0%, forg=  0.0%| TAg acc= 83.3%, forg=  4.2% <<<
>>> Test on task  9 : loss=1.032 | TAw acc= 94.2%, forg= -1.7%| TAg acc= 77.5%, forg= -1.7% <<<
>>> Test on task 10 : loss=0.806 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 80.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 11
************************************************************************************************************
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=4.865, TAw acc= 38.5% | *
| Epoch   2, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=2.853, TAw acc= 65.6% | *
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=2.273, TAw acc= 85.4% | *
| Epoch   4, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=1.870, TAw acc= 90.6% | *
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.577, TAw acc= 93.8% | *
| Epoch   6, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.471, TAw acc= 91.7% | *
| Epoch   7, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.404, TAw acc= 93.8% | *
| Epoch   8, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.434, TAw acc= 89.6% |
| Epoch   9, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.224, TAw acc= 94.8% | *
| Epoch  10, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.176, TAw acc= 93.8% | *
| Epoch  11, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.192, TAw acc= 93.8% |
| Epoch  12, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.121, TAw acc= 99.0% | *
| Epoch  13, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.010, TAw acc= 89.6% | *
| Epoch  14, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.029, TAw acc= 92.7% |
| Epoch  15, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.013, TAw acc= 93.8% |
| Epoch  16, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.804, TAw acc= 97.9% | *
| Epoch  17, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.845, TAw acc= 91.7% |
| Epoch  18, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.816, TAw acc= 89.6% |
| Epoch  19, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.939, TAw acc= 95.8% |
| Epoch  20, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.905, TAw acc= 95.8% |
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.818, TAw acc= 97.9% | *
| Epoch   2, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.832, TAw acc= 97.9% |
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.844, TAw acc= 97.9% |
| Epoch   4, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.854, TAw acc= 97.9% |
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=0.864, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4049 train exemplars, time=  0.0s
4049
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.524 | TAw acc= 98.6%, forg=  0.0%| TAg acc= 90.3%, forg=  4.9% <<<
>>> Test on task  1 : loss=0.469 | TAw acc=100.0%, forg=  0.0%| TAg acc= 90.8%, forg=  1.7% <<<
>>> Test on task  2 : loss=1.040 | TAw acc= 90.0%, forg=  0.0%| TAg acc= 72.5%, forg=  4.2% <<<
>>> Test on task  3 : loss=0.495 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.8%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.511 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 95.8%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.603 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 86.7%, forg= -0.8% <<<
>>> Test on task  6 : loss=0.857 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 77.5%, forg=  8.3% <<<
>>> Test on task  7 : loss=0.511 | TAw acc= 99.2%, forg=  0.8%| TAg acc= 90.8%, forg= -4.2% <<<
>>> Test on task  8 : loss=0.790 | TAw acc=100.0%, forg=  0.0%| TAg acc= 80.8%, forg=  6.7% <<<
>>> Test on task  9 : loss=0.993 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 73.3%, forg=  4.2% <<<
>>> Test on task 10 : loss=0.768 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task 11 : loss=0.953 | TAw acc= 93.3%, forg=  0.0%| TAg acc= 76.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 12
************************************************************************************************************
| Epoch   1, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=3.844, TAw acc= 42.7% | *
| Epoch   2, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=2.249, TAw acc= 76.0% | *
| Epoch   3, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.948, TAw acc= 85.4% | *
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.793, TAw acc= 77.1% | *
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.562, TAw acc= 91.7% | *
| Epoch   6, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.678, TAw acc= 86.5% |
| Epoch   7, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.259, TAw acc= 80.2% | *
| Epoch   8, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=1.457, TAw acc= 95.8% |
| Epoch   9, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.199, TAw acc= 91.7% | *
| Epoch  10, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.116, TAw acc= 89.6% | *
| Epoch  11, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.072, TAw acc= 91.7% | *
| Epoch  12, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.184, TAw acc= 96.9% |
| Epoch  13, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.169, TAw acc= 97.9% |
| Epoch  14, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.220, TAw acc= 97.9% |
| Epoch  15, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.111, TAw acc= 97.9% |
| Epoch  16, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.906, TAw acc= 99.0% | *
| Epoch  17, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.030, TAw acc= 97.9% |
| Epoch  18, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.944, TAw acc= 99.0% |
| Epoch  19, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.950, TAw acc= 97.9% |
| Epoch  20, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.858, TAw acc= 97.9% | *
| Epoch   1, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=0.853, TAw acc= 97.9% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.849, TAw acc= 99.0% | *
| Epoch   3, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=0.846, TAw acc= 99.0% | *
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.843, TAw acc= 99.0% | *
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=0.841, TAw acc= 99.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4359 train exemplars, time=  0.0s
4359
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.427 | TAw acc= 98.6%, forg=  0.0%| TAg acc= 95.1%, forg=  0.0% <<<
>>> Test on task  1 : loss=0.400 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.0%, forg= -2.5% <<<
>>> Test on task  2 : loss=1.000 | TAw acc= 89.2%, forg=  0.8%| TAg acc= 74.2%, forg=  2.5% <<<
>>> Test on task  3 : loss=0.423 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.0%, forg=  1.7% <<<
>>> Test on task  4 : loss=0.433 | TAw acc=100.0%, forg= -1.7%| TAg acc= 99.2%, forg= -3.3% <<<
>>> Test on task  5 : loss=0.603 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 86.7%, forg=  0.0% <<<
>>> Test on task  6 : loss=0.732 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 85.8%, forg=  0.0% <<<
>>> Test on task  7 : loss=0.468 | TAw acc=100.0%, forg=  0.0%| TAg acc= 88.3%, forg=  2.5% <<<
>>> Test on task  8 : loss=0.681 | TAw acc=100.0%, forg=  0.0%| TAg acc= 86.7%, forg=  0.8% <<<
>>> Test on task  9 : loss=0.791 | TAw acc= 97.5%, forg= -3.3%| TAg acc= 87.5%, forg=-10.0% <<<
>>> Test on task 10 : loss=0.729 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 78.3%, forg=  2.5% <<<
>>> Test on task 11 : loss=0.934 | TAw acc= 97.5%, forg= -4.2%| TAg acc= 75.0%, forg=  1.7% <<<
>>> Test on task 12 : loss=0.855 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 77.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 13
************************************************************************************************************
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=3.959, TAw acc= 41.7% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=2.728, TAw acc= 65.6% | *
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=2.241, TAw acc= 87.5% | *
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.759, TAw acc= 93.8% | *
| Epoch   5, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.544, TAw acc= 95.8% | *
| Epoch   6, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.496, TAw acc= 94.8% | *
| Epoch   7, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.364, TAw acc= 97.9% | *
| Epoch   8, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=0.989, TAw acc= 91.7% | *
| Epoch   9, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.134, TAw acc= 96.9% |
| Epoch  10, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.076, TAw acc= 94.8% |
| Epoch  11, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.075, TAw acc= 97.9% |
| Epoch  12, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.005, TAw acc= 96.9% |
| Epoch  13, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.059, TAw acc= 97.9% | lr=3.3e-03
| Epoch  14, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.142, TAw acc= 95.8% |
| Epoch  15, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.133, TAw acc= 94.8% |
| Epoch  16, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.123, TAw acc= 97.9% |
| Epoch  17, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.130, TAw acc= 96.9% |
| Epoch  18, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.123, TAw acc= 96.9% | lr=1.1e-03
| Epoch  19, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.119, TAw acc= 95.8% |
| Epoch  20, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.165, TAw acc= 96.9% |
| Epoch   1, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.009, TAw acc= 92.7% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=1.028, TAw acc= 93.8% |
| Epoch   3, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.045, TAw acc= 93.8% |
| Epoch   4, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.060, TAw acc= 93.8% |
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.073, TAw acc= 94.8% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4669 train exemplars, time=  0.0s
4669
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.454 | TAw acc= 98.6%, forg=  0.0%| TAg acc= 92.4%, forg=  2.8% <<<
>>> Test on task  1 : loss=0.347 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg= -1.7% <<<
>>> Test on task  2 : loss=1.290 | TAw acc= 86.7%, forg=  3.3%| TAg acc= 65.0%, forg= 11.7% <<<
>>> Test on task  3 : loss=0.526 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 88.3%, forg=  3.3% <<<
>>> Test on task  4 : loss=0.686 | TAw acc=100.0%, forg=  0.0%| TAg acc= 82.5%, forg= 16.7% <<<
>>> Test on task  5 : loss=0.565 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.0%, forg= -3.3% <<<
>>> Test on task  6 : loss=0.776 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 85.8%, forg=  0.0% <<<
>>> Test on task  7 : loss=0.467 | TAw acc=100.0%, forg=  0.0%| TAg acc= 90.8%, forg=  0.0% <<<
>>> Test on task  8 : loss=0.775 | TAw acc=100.0%, forg=  0.0%| TAg acc= 83.3%, forg=  4.2% <<<
>>> Test on task  9 : loss=0.819 | TAw acc= 95.8%, forg=  1.7%| TAg acc= 82.5%, forg=  5.0% <<<
>>> Test on task 10 : loss=0.700 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 84.2%, forg= -3.3% <<<
>>> Test on task 11 : loss=1.048 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 70.8%, forg=  5.8% <<<
>>> Test on task 12 : loss=0.963 | TAw acc= 95.8%, forg=  1.7%| TAg acc= 70.0%, forg=  7.5% <<<
>>> Test on task 13 : loss=1.059 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 70.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
    (13): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 14
************************************************************************************************************
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=4.630, TAw acc= 52.1% | *
| Epoch   2, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=3.296, TAw acc= 71.9% | *
| Epoch   3, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=2.636, TAw acc= 79.2% | *
| Epoch   4, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=2.286, TAw acc= 83.3% | *
| Epoch   5, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=2.126, TAw acc= 84.4% | *
| Epoch   6, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.855, TAw acc= 94.8% | *
| Epoch   7, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.860, TAw acc= 89.6% |
| Epoch   8, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.757, TAw acc= 96.9% | *
| Epoch   9, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.825, TAw acc= 94.8% |
| Epoch  10, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.631, TAw acc= 96.9% | *
| Epoch  11, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.619, TAw acc= 87.5% | *
| Epoch  12, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.486, TAw acc= 88.5% | *
| Epoch  13, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.388, TAw acc= 96.9% | *
| Epoch  14, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.473, TAw acc= 90.6% |
| Epoch  15, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.284, TAw acc= 88.5% | *
| Epoch  16, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.454, TAw acc= 91.7% |
| Epoch  17, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.321, TAw acc= 90.6% |
| Epoch  18, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.271, TAw acc= 96.9% | *
| Epoch  19, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.212, TAw acc= 96.9% | *
| Epoch  20, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.191, TAw acc= 95.8% | *
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=1.191, TAw acc= 95.8% | *
| Epoch   2, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.191, TAw acc= 95.8% |
| Epoch   3, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.191, TAw acc= 96.9% |
| Epoch   4, time=  2.1s | Train: skip eval | Valid: time=  0.2s loss=1.191, TAw acc= 96.9% |
| Epoch   5, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.192, TAw acc= 96.9% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 37
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4979 train exemplars, time=  0.0s
4979
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.406 | TAw acc= 98.6%, forg=  0.0%| TAg acc= 93.1%, forg=  2.1% <<<
>>> Test on task  1 : loss=0.376 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  0.8% <<<
>>> Test on task  2 : loss=1.134 | TAw acc= 87.5%, forg=  2.5%| TAg acc= 70.8%, forg=  5.8% <<<
>>> Test on task  3 : loss=0.480 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.8%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.488 | TAw acc=100.0%, forg=  0.0%| TAg acc= 94.2%, forg=  5.0% <<<
>>> Test on task  5 : loss=0.588 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 86.7%, forg=  3.3% <<<
>>> Test on task  6 : loss=0.645 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 87.5%, forg= -1.7% <<<
>>> Test on task  7 : loss=0.470 | TAw acc=100.0%, forg=  0.0%| TAg acc= 89.2%, forg=  1.7% <<<
>>> Test on task  8 : loss=0.626 | TAw acc=100.0%, forg=  0.0%| TAg acc= 89.2%, forg= -1.7% <<<
>>> Test on task  9 : loss=0.709 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 86.7%, forg=  0.8% <<<
>>> Test on task 10 : loss=0.592 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 87.5%, forg= -3.3% <<<
>>> Test on task 11 : loss=0.848 | TAw acc= 99.2%, forg= -1.7%| TAg acc= 77.5%, forg= -0.8% <<<
>>> Test on task 12 : loss=0.767 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 80.0%, forg= -2.5% <<<
>>> Test on task 13 : loss=1.055 | TAw acc= 98.3%, forg= -2.5%| TAg acc= 66.7%, forg=  4.2% <<<
>>> Test on task 14 : loss=1.208 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 75.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_4/har_flex_eeil
************************************************************************************************************
TAw Acc
	 59.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 59.7% 
	 84.7%  80.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.4% 
	 92.4%  88.3%  71.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 84.1% 
	 95.8%  91.7%  83.3%  96.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 91.9% 
	 97.2%  98.3%  83.3%  98.3%  90.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 93.4% 
	 97.9%  97.5%  85.8%  98.3%  91.7%  90.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 93.5% 
	 96.5%  99.2%  85.8%  98.3%  91.7%  91.7%  95.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 94.0% 
	 97.9%  99.2%  86.7%  99.2%  95.8%  95.0%  95.0%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 95.9% 
	 97.9%  99.2%  90.0%  97.5%  93.3%  95.8%  95.0%  99.2% 100.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.4% 
	 98.6%  99.2%  89.2%  97.5%  98.3%  96.7%  94.2% 100.0% 100.0%  92.5%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.6% 
	 98.6% 100.0%  90.0%  98.3%  98.3%  99.2%  95.0%  99.2% 100.0%  94.2%  98.3%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.4% 
	 98.6% 100.0%  90.0%  98.3%  98.3%  99.2%  95.0%  99.2% 100.0%  94.2%  98.3%  93.3%   0.0%   0.0%   0.0% 	Avg.: 97.0% 
	 98.6% 100.0%  89.2%  99.2% 100.0%  99.2%  95.0% 100.0% 100.0%  97.5%  99.2%  97.5%  97.5%   0.0%   0.0% 	Avg.: 97.9% 
	 98.6% 100.0%  86.7%  99.2% 100.0%  99.2%  95.0% 100.0% 100.0%  95.8%  99.2%  96.7%  95.8%  95.8%   0.0% 	Avg.: 97.3% 
	 98.6% 100.0%  87.5%  99.2% 100.0%  99.2%  95.0% 100.0% 100.0%  96.7%  99.2%  99.2%  97.5%  98.3%  95.0% 	Avg.: 97.7% 
************************************************************************************************************
TAg Acc
	 59.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 59.7% 
	 84.7%  69.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 76.9% 
	 75.7%  69.2%  63.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 69.4% 
	 94.4%  80.0%  65.8%  85.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.5% 
	 93.8%  84.2%  72.5%  81.7%  74.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.2% 
	 93.1%  87.5%  72.5%  86.7%  75.8%  72.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.3% 
	 88.2%  87.5%  74.2%  90.0%  80.8%  67.5%  85.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.0% 
	 89.6%  90.0%  76.7%  90.0%  88.3%  80.0%  81.7%  81.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 84.7% 
	 95.1%  92.5%  71.7%  90.8%  87.5%  78.3%  82.5%  82.5%  87.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 85.4% 
	 95.1%  90.8%  73.3%  91.7%  95.8%  85.8%  81.7%  85.8%  82.5%  75.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 85.8% 
	 93.8%  86.7%  72.5%  91.7%  95.8%  84.2%  82.5%  86.7%  83.3%  77.5%  80.8%   0.0%   0.0%   0.0%   0.0% 	Avg.: 85.0% 
	 90.3%  90.8%  72.5%  90.8%  95.8%  86.7%  77.5%  90.8%  80.8%  73.3%  80.8%  76.7%   0.0%   0.0%   0.0% 	Avg.: 83.9% 
	 95.1%  95.0%  74.2%  90.0%  99.2%  86.7%  85.8%  88.3%  86.7%  87.5%  78.3%  75.0%  77.5%   0.0%   0.0% 	Avg.: 86.1% 
	 92.4%  96.7%  65.0%  88.3%  82.5%  90.0%  85.8%  90.8%  83.3%  82.5%  84.2%  70.8%  70.0%  70.8%   0.0% 	Avg.: 82.4% 
	 93.1%  95.8%  70.8%  90.8%  94.2%  86.7%  87.5%  89.2%  89.2%  86.7%  87.5%  77.5%  80.0%  66.7%  75.0% 	Avg.: 84.7% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-25.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-25.0% 
	 -7.6%  -8.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -8.0% 
	 -3.5%  -3.3% -11.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -6.2% 
	 -1.4%  -6.7%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -2.4% 
	 -0.7%   0.8%  -2.5%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.8% 
	  1.4%  -0.8%   0.0%   0.0%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.2% 
	  0.0%   0.0%  -0.8%  -0.8%  -4.2%  -3.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.3% 
	  0.0%   0.0%  -3.3%   1.7%   2.5%  -0.8%   0.0%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.1% 
	 -0.7%   0.0%   0.8%   1.7%  -2.5%  -0.8%   0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.2% 
	  0.0%  -0.8%   0.0%   0.8%   0.0%  -2.5%   0.0%   0.8%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.3% 
	  0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.2% 
	  0.0%   0.0%   0.8%   0.0%  -1.7%   0.0%   0.0%   0.0%   0.0%  -3.3%  -0.8%  -4.2%   0.0%   0.0%   0.0% 	Avg.: -0.8% 
	  0.0%   0.0%   3.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   1.7%   0.0%   0.8%   1.7%   0.0%   0.0% 	Avg.:  0.6% 
	  0.0%   0.0%   2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.8%   0.0%  -1.7%   0.0%  -2.5%   0.0% 	Avg.: -0.1% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-25.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-25.0% 
	  9.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  4.5% 
	 -9.7% -10.8%  -2.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -7.7% 
	  0.7%  -4.2%  -6.7%   4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.5% 
	  1.4%  -3.3%   0.0%  -0.8%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.9% 
	  6.2%   0.0%  -1.7%  -3.3%  -5.0%   5.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.2% 
	  4.9%  -2.5%  -2.5%   0.0%  -7.5%  -7.5%   4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.6% 
	 -0.7%  -2.5%   5.0%  -0.8%   0.8%   1.7%   3.3%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.7% 
	  0.0%   1.7%   3.3%  -0.8%  -7.5%  -5.8%   4.2%  -3.3%   5.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	  1.4%   5.8%   4.2%   0.0%   0.0%   1.7%   3.3%  -0.8%   4.2%  -1.7%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.8% 
	  4.9%   1.7%   4.2%   0.8%   0.0%  -0.8%   8.3%  -4.2%   6.7%   4.2%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  2.3% 
	  0.0%  -2.5%   2.5%   1.7%  -3.3%   0.0%   0.0%   2.5%   0.8% -10.0%   2.5%   1.7%   0.0%   0.0%   0.0% 	Avg.: -0.3% 
	  2.8%  -1.7%  11.7%   3.3%  16.7%  -3.3%   0.0%   0.0%   4.2%   5.0%  -3.3%   5.8%   7.5%   0.0%   0.0% 	Avg.:  3.7% 
	  2.1%   0.8%   5.8%   0.8%   5.0%   3.3%  -1.7%   1.7%  -1.7%   0.8%  -3.3%  -0.8%  -2.5%   4.2%   0.0% 	Avg.:  1.0% 
************************************************************************************************************
[Elapsed time = 0.1 h]
Done!

f1_score_micro: 0.8481359649122807
f1_score_macro: 0.8406515359702758
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        12
           1       0.86      1.00      0.92        12
           2       1.00      0.75      0.86        12
           3       1.00      1.00      1.00        12
           4       0.77      0.83      0.80        12
           5       0.92      1.00      0.96        12
           6       1.00      1.00      1.00        12
           7       1.00      0.75      0.86        12
           8       0.86      1.00      0.92        12
           9       0.80      1.00      0.89        12
          10       0.69      0.92      0.79        12
          11       0.85      0.92      0.88        12
          12       0.92      0.92      0.92        12
          13       0.86      1.00      0.92        12
          14       1.00      1.00      1.00        12
          15       1.00      0.92      0.96        12
          16       1.00      1.00      1.00        12
          17       1.00      0.92      0.96        12
          18       1.00      1.00      1.00        12
          19       1.00      1.00      1.00        12
          20       0.85      0.92      0.88        12
          21       1.00      0.92      0.96        12
          22       0.86      1.00      0.92        12
          23       0.45      0.42      0.43        12
          24       0.92      1.00      0.96        12
          25       0.79      0.92      0.85        12
          26       0.50      0.42      0.45        12
          27       0.62      0.83      0.71        12
          28       0.50      0.25      0.33        12
          29       0.29      0.42      0.34        12
          30       0.73      0.92      0.81        12
          31       1.00      0.92      0.96        12
          32       0.71      1.00      0.83        12
          33       0.57      0.67      0.62        12
          34       1.00      1.00      1.00        12
          35       0.86      1.00      0.92        12
          36       0.46      0.50      0.48        12
          37       0.92      1.00      0.96        12
          38       1.00      1.00      1.00        12
          39       0.85      0.92      0.88        12
          40       1.00      1.00      1.00        12
          41       1.00      1.00      1.00        12
          42       0.92      0.92      0.92        12
          43       0.45      0.83      0.59        12
          44       0.92      1.00      0.96        12
          45       1.00      1.00      1.00        12
          46       1.00      0.83      0.91        12
          47       0.80      1.00      0.89        12
          48       0.91      0.83      0.87        12
          49       1.00      1.00      1.00        12
          50       0.92      1.00      0.96        12
          51       0.86      1.00      0.92        12
          52       0.92      1.00      0.96        12
          53       0.86      1.00      0.92        12
          54       1.00      1.00      1.00        12
          55       1.00      1.00      1.00        12
          56       1.00      0.92      0.96        12
          57       1.00      1.00      1.00        12
          58       1.00      1.00      1.00        12
          59       0.91      0.83      0.87        12
          60       0.31      0.42      0.36        12
          61       0.43      0.50      0.46        12
          62       0.90      0.75      0.82        12
          63       0.92      0.92      0.92        12
          64       1.00      1.00      1.00        12
          65       1.00      0.92      0.96        12
          66       0.67      0.33      0.44        12
          67       1.00      1.00      1.00        12
          68       0.67      1.00      0.80        12
          69       1.00      1.00      1.00        12
          70       0.91      0.83      0.87        12
          71       0.92      1.00      0.96        12
          72       0.70      0.58      0.64        12
          73       0.90      0.75      0.82        12
          74       1.00      1.00      1.00        12
          75       0.44      0.58      0.50        12
          76       1.00      1.00      1.00        12
          77       1.00      1.00      1.00        12
          78       0.92      1.00      0.96        12
          79       1.00      1.00      1.00        12
          80       0.86      1.00      0.92        12
          81       0.92      1.00      0.96        12
          82       0.91      0.83      0.87        12
          83       1.00      1.00      1.00        12
          84       1.00      0.92      0.96        12
          85       0.67      0.83      0.74        12
          86       1.00      1.00      1.00        12
          87       0.80      1.00      0.89        12
          88       1.00      1.00      1.00        12
          89       0.92      1.00      0.96        12
          90       0.29      0.33      0.31        12
          91       0.92      1.00      0.96        12
          92       0.61      0.92      0.73        12
          93       0.83      0.83      0.83        12
          94       0.86      1.00      0.92        12
          95       1.00      1.00      1.00        12
          96       0.90      0.75      0.82        12
          97       1.00      0.92      0.96        12
          98       0.83      0.83      0.83        12
          99       0.80      0.67      0.73        12
         100       0.83      0.83      0.83        12
         101       1.00      0.92      0.96        12
         102       1.00      1.00      1.00        12
         103       0.89      0.67      0.76        12
         104       0.92      1.00      0.96        12
         105       1.00      1.00      1.00        12
         106       1.00      1.00      1.00        12
         107       0.30      0.25      0.27        12
         108       1.00      1.00      1.00        12
         109       0.80      1.00      0.89        12
         110       0.91      0.83      0.87        12
         111       0.86      1.00      0.92        12
         112       1.00      1.00      1.00        12
         113       0.86      1.00      0.92        12
         114       0.80      0.67      0.73        12
         115       1.00      0.67      0.80        12
         116       1.00      1.00      1.00        12
         117       0.67      0.17      0.27        12
         118       0.27      0.25      0.26        12
         119       0.92      1.00      0.96        12
         120       1.00      1.00      1.00        12
         121       1.00      1.00      1.00        12
         122       1.00      1.00      1.00        12
         123       0.92      0.92      0.92        12
         124       1.00      1.00      1.00        12
         125       0.92      1.00      0.96        12
         126       1.00      0.92      0.96        12
         127       0.60      0.50      0.55        12
         128       0.80      0.67      0.73        12
         129       1.00      0.75      0.86        12
         130       0.85      0.92      0.88        12
         131       0.40      0.33      0.36        12
         132       0.85      0.92      0.88        12
         133       0.85      0.92      0.88        12
         134       1.00      0.08      0.15        12
         135       1.00      0.83      0.91        12
         136       1.00      0.75      0.86        12
         137       1.00      1.00      1.00        12
         138       0.86      0.50      0.63        12
         139       1.00      0.75      0.86        12
         140       0.00      0.00      0.00        12
         141       0.85      0.92      0.88        12
         142       1.00      0.75      0.86        12
         143       0.80      1.00      0.89        12
         144       0.92      0.92      0.92        12
         145       0.33      0.08      0.13        12
         146       1.00      0.83      0.91        12
         147       0.33      0.42      0.37        12
         148       1.00      0.83      0.91        12
         149       0.92      0.92      0.92        12
         150       1.00      0.92      0.96        12
         151       0.62      0.83      0.71        12

    accuracy                           0.85      1824
   macro avg       0.85      0.85      0.84      1824
weighted avg       0.85      0.85      0.84      1824

torch.Size([1824, 405]) torch.Size([1824])
Parameters: 36980
Task parameters: {0: 27600, 1: 28270, 2: 28940, 3: 29610, 4: 30280, 5: 30950, 6: 31620, 7: 32290, 8: 32960, 9: 33630, 10: 34300, 11: 34970, 12: 35640, 13: 36310, 14: 36980}
