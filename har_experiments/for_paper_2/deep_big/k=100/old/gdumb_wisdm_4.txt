Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='c4cfdedc-1d67-4c8b-a93f-ef71ab3f4b31', conf_timestamp='2023-08-10 06:05:32.756294', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 67.37 % 	 [Task-IL]: 45.79 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 45.64 % 	 [Task-IL]: 37.5 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 33.79 % 	 [Task-IL]: 34.37 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 34.14 % 	 [Task-IL]: 32.31 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 29.26 % 	 [Task-IL]: 33.26 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 28.57 % 	 [Task-IL]: 32.73 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 22.11 % 	 [Task-IL]: 32.04 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 19.6 % 	 [Task-IL]: 30.15 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 20.8 % 	 [Task-IL]: 28.35 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 22.46 % 	 [Task-IL]: 28.56 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 18.02 % 	 [Task-IL]: 28.0 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 16.86 % 	 [Task-IL]: 27.73 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 18.73 % 	 [Task-IL]: 27.34 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 16.87 % 	 [Task-IL]: 27.16 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 14.26 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 14.0 % 	 [Task-IL]: 27.18 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.27 % 	 [Task-IL]: 27.28 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 11.83 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 8.73 % 	 [Task-IL]: 27.1 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 7.87 % 	 [Task-IL]: 26.6 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.14 % 	 [Task-IL]: 26.53 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.58 % 	 [Task-IL]: 26.37 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.99 % 	 [Task-IL]: 26.55 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 10.19 % 	 [Task-IL]: 26.62 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 9.13 % 	 [Task-IL]: 26.7 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.29 % 	 [Task-IL]: 26.47 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.53 % 	 [Task-IL]: 26.62 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.57 % 	 [Task-IL]: 26.35 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.21 % 	 [Task-IL]: 26.46 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.37 % 	 [Task-IL]: 25.95 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 7.36 % 	 [Task-IL]: 25.89 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.32 % 	 [Task-IL]: 25.59 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.79 % 	 [Task-IL]: 26.02 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.35 % 	 [Task-IL]: 25.66 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.19 % 	 [Task-IL]: 25.66 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.7 % 	 [Task-IL]: 25.67 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.2 % 	 [Task-IL]: 25.58 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 4.56 % 	 [Task-IL]: 25.4 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.28 % 	 [Task-IL]: 25.39 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.59 % 	 [Task-IL]: 25.31 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.77 % 	 [Task-IL]: 25.33 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.03 % 	 [Task-IL]: 25.28 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 5.25 % 	 [Task-IL]: 25.45 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74900, 405: 35, 791: 34, 37: 33, 70: 33, 108: 33, 181: 33, 447: 33, 468: 33, 890: 33, 299: 32, 372: 32, 393: 32, 465: 32, 493: 32, 511: 32, 497: 32, 523: 32, 551: 32, 589: 32, 762: 32, 763: 32, 831: 32, 817: 32, 869: 32, 12: 31, 21: 31, 19: 31, 14: 31, 73: 31, 82: 31, 99: 31, 149: 31, 186: 31, 229: 31, 260: 31, 313: 31, 418: 31, 439: 31, 582: 31, 611: 31, 647: 31, 634: 31, 667: 31, 708: 31, 707: 31, 722: 31, 727: 31, 761: 31, 794: 31, 830: 31, 841: 31, 54: 30, 79: 30, 114: 30, 150: 30, 141: 30, 148: 30, 207: 30, 230: 30, 227: 30, 226: 30, 221: 30, 286: 30, 344: 30, 367: 30, 368: 30, 383: 30, 408: 30, 415: 30, 428: 30, 441: 30, 445: 30, 448: 30, 474: 30, 533: 30, 526: 30, 545: 30, 540: 30, 543: 30, 569: 30, 623: 30, 635: 30, 764: 30, 771: 30, 800: 30, 835: 30, 848: 30, 868: 30, 860: 30, 32: 29, 48: 29, 95: 29, 140: 29, 157: 29, 208: 29, 201: 29, 195: 29, 245: 29, 235: 29, 280: 29, 351: 29, 347: 29, 362: 29, 390: 29, 392: 29, 413: 29, 420: 29, 440: 29, 473: 29, 487: 29, 527: 29, 568: 29, 583: 29, 610: 29, 655: 29, 664: 29, 713: 29, 725: 29, 744: 29, 735: 29, 767: 29, 775: 29, 793: 29, 851: 29, 888: 29, 875: 29, 42: 28, 71: 28, 59: 28, 58: 28, 117: 28, 125: 28, 152: 28, 134: 28, 169: 28, 211: 28, 210: 28, 199: 28, 328: 28, 380: 28, 377: 28, 387: 28, 382: 28, 402: 28, 409: 28, 411: 28, 446: 28, 462: 28, 508: 28, 516: 28, 539: 28, 565: 28, 574: 28, 576: 28, 601: 28, 608: 28, 609: 28, 653: 28, 658: 28, 687: 28, 695: 28, 795: 28, 871: 28, 879: 28, 892: 28, 13: 27, 20: 27, 50: 27, 66: 27, 135: 27, 137: 27, 170: 27, 191: 27, 339: 27, 338: 27, 357: 27, 386: 27, 394: 27, 419: 27, 453: 27, 437: 27, 488: 27, 580: 27, 603: 27, 628: 27, 684: 27, 712: 27, 733: 27, 740: 27, 770: 27, 827: 27, 856: 27, 891: 27, 83: 26, 110: 26, 376: 26, 396: 26, 431: 26, 505: 26, 512: 26, 531: 26, 524: 26, 550: 26, 562: 26, 555: 26, 590: 26, 612: 26, 691: 26, 701: 26, 766: 26, 812: 26, 843: 26, 10: 25, 272: 25, 326: 25, 335: 25, 455: 25, 519: 25, 521: 25, 541: 25, 547: 25, 627: 25, 788: 25, 811: 25, 24: 24, 127: 24, 370: 24, 694: 24, 750: 24, 129: 23, 233: 23, 591: 23, 616: 23, 773: 23, 553: 22, 93: 21, 444: 21, 187: 19, 144: 17, 166: 17, 244: 17, 309: 17, 319: 17, 581: 17, 643: 17, 693: 17, 741: 17, 876: 17, 131: 16, 192: 16, 212: 16, 333: 16, 343: 16, 375: 16, 443: 16, 522: 16, 560: 16, 606: 16, 718: 16, 805: 16, 825: 16, 824: 16, 839: 16, 38: 15, 63: 15, 72: 15, 67: 15, 92: 15, 97: 15, 123: 15, 163: 15, 183: 15, 178: 15, 197: 15, 206: 15, 223: 15, 268: 15, 310: 15, 330: 15, 346: 15, 350: 15, 349: 15, 365: 15, 410: 15, 403: 15, 423: 15, 456: 15, 530: 15, 546: 15, 549: 15, 588: 15, 613: 15, 624: 15, 637: 15, 657: 15, 656: 15, 698: 15, 709: 15, 699: 15, 734: 15, 768: 15, 828: 15, 823: 15, 15: 14, 6: 14, 16: 14, 43: 14, 56: 14, 68: 14, 119: 14, 115: 14, 124: 14, 146: 14, 162: 14, 168: 14, 238: 14, 255: 14, 257: 14, 266: 14, 261: 14, 305: 14, 301: 14, 329: 14, 316: 14, 366: 14, 379: 14, 398: 14, 422: 14, 450: 14, 466: 14, 481: 14, 490: 14, 500: 14, 503: 14, 525: 14, 538: 14, 548: 14, 552: 14, 571: 14, 578: 14, 598: 14, 710: 14, 757: 14, 804: 14, 813: 14, 803: 14, 797: 14, 878: 14, 7: 13, 30: 13, 18: 13, 5: 13, 39: 13, 41: 13, 40: 13, 34: 13, 61: 13, 86: 13, 90: 13, 88: 13, 80: 13, 87: 13, 100: 13, 101: 13, 128: 13, 132: 13, 136: 13, 160: 13, 193: 13, 205: 13, 232: 13, 217: 13, 288: 13, 278: 13, 284: 13, 307: 13, 303: 13, 302: 13, 296: 13, 327: 13, 322: 13, 345: 13, 342: 13, 369: 13, 360: 13, 373: 13, 363: 13, 391: 13, 397: 13, 399: 13, 407: 13, 426: 13, 417: 13, 430: 13, 435: 13, 459: 13, 454: 13, 469: 13, 492: 13, 484: 13, 507: 13, 496: 13, 494: 13, 509: 13, 517: 13, 520: 13, 532: 13, 542: 13, 564: 13, 572: 13, 561: 13, 577: 13, 592: 13, 605: 13, 620: 13, 626: 13, 631: 13, 636: 13, 670: 13, 660: 13, 672: 13, 676: 13, 688: 13, 678: 13, 689: 13, 706: 13, 704: 13, 723: 13, 716: 13, 719: 13, 717: 13, 736: 13, 745: 13, 749: 13, 769: 13, 754: 13, 777: 13, 787: 13, 798: 13, 806: 13, 801: 13, 796: 13, 833: 13, 847: 13, 834: 13, 855: 13, 865: 13, 889: 13, 885: 13, 887: 13, 25: 12, 31: 12, 9: 12, 2: 12, 26: 12, 3: 12, 49: 12, 46: 12, 53: 12, 35: 12, 78: 12, 74: 12, 76: 12, 75: 12, 109: 12, 118: 12, 130: 12, 147: 12, 167: 12, 159: 12, 156: 12, 190: 12, 176: 12, 188: 12, 194: 12, 196: 12, 204: 12, 231: 12, 222: 12, 219: 12, 237: 12, 246: 12, 236: 12, 240: 12, 234: 12, 248: 12, 242: 12, 271: 12, 263: 12, 254: 12, 256: 12, 265: 12, 276: 12, 274: 12, 287: 12, 277: 12, 279: 12, 290: 12, 312: 12, 332: 12, 323: 12, 318: 12, 321: 12, 320: 12, 334: 12, 348: 12, 337: 12, 371: 12, 356: 12, 389: 12, 378: 12, 412: 12, 400: 12, 421: 12, 425: 12, 429: 12, 451: 12, 436: 12, 452: 12, 470: 12, 471: 12, 460: 12, 458: 12, 464: 12, 475: 12, 480: 12, 483: 12, 478: 12, 499: 12, 495: 12, 506: 12, 498: 12, 513: 12, 518: 12, 537: 12, 559: 12, 567: 12, 557: 12, 587: 12, 593: 12, 575: 12, 597: 12, 602: 12, 595: 12, 599: 12, 607: 12, 633: 12, 621: 12, 614: 12, 617: 12, 649: 12, 648: 12, 640: 12, 639: 12, 661: 12, 662: 12, 669: 12, 659: 12, 692: 12, 681: 12, 700: 12, 705: 12, 720: 12, 721: 12, 732: 12, 726: 12, 731: 12, 753: 12, 743: 12, 751: 12, 760: 12, 772: 12, 785: 12, 792: 12, 790: 12, 786: 12, 783: 12, 779: 12, 802: 12, 799: 12, 809: 12, 821: 12, 844: 12, 850: 12, 836: 12, 837: 12, 846: 12, 845: 12, 838: 12, 857: 12, 862: 12, 859: 12, 880: 12, 4: 11, 27: 11, 11: 11, 28: 11, 33: 11, 23: 11, 1: 11, 47: 11, 45: 11, 69: 11, 77: 11, 91: 11, 89: 11, 84: 11, 85: 11, 81: 11, 104: 11, 96: 11, 111: 11, 102: 11, 107: 11, 105: 11, 94: 11, 133: 11, 120: 11, 145: 11, 139: 11, 138: 11, 164: 11, 172: 11, 161: 11, 189: 11, 185: 11, 182: 11, 202: 11, 213: 11, 209: 11, 218: 11, 215: 11, 228: 11, 220: 11, 250: 11, 241: 11, 249: 11, 269: 11, 264: 11, 262: 11, 275: 11, 289: 11, 282: 11, 292: 11, 304: 11, 297: 11, 300: 11, 315: 11, 314: 11, 340: 11, 354: 11, 388: 11, 384: 11, 406: 11, 404: 11, 414: 11, 416: 11, 449: 11, 434: 11, 467: 11, 457: 11, 477: 11, 486: 11, 501: 11, 502: 11, 504: 11, 529: 11, 535: 11, 534: 11, 536: 11, 573: 11, 563: 11, 556: 11, 579: 11, 585: 11, 584: 11, 596: 11, 632: 11, 625: 11, 615: 11, 622: 11, 646: 11, 645: 11, 652: 11, 644: 11, 638: 11, 666: 11, 668: 11, 683: 11, 677: 11, 686: 11, 685: 11, 679: 11, 675: 11, 674: 11, 680: 11, 697: 11, 728: 11, 715: 11, 724: 11, 729: 11, 742: 11, 738: 11, 739: 11, 752: 11, 765: 11, 755: 11, 774: 11, 780: 11, 808: 11, 819: 11, 816: 11, 814: 11, 829: 11, 870: 11, 866: 11, 861: 11, 872: 11, 858: 11, 873: 11, 881: 11, 884: 11, 882: 11, 886: 11, 17: 10, 36: 10, 52: 10, 44: 10, 57: 10, 64: 10, 62: 10, 60: 10, 65: 10, 55: 10, 116: 10, 121: 10, 143: 10, 155: 10, 165: 10, 154: 10, 171: 10, 174: 10, 177: 10, 184: 10, 180: 10, 203: 10, 200: 10, 216: 10, 225: 10, 224: 10, 239: 10, 267: 10, 270: 10, 283: 10, 285: 10, 291: 10, 281: 10, 298: 10, 308: 10, 311: 10, 324: 10, 336: 10, 353: 10, 361: 10, 355: 10, 381: 10, 374: 10, 395: 10, 432: 10, 427: 10, 438: 10, 472: 10, 463: 10, 479: 10, 476: 10, 489: 10, 485: 10, 491: 10, 544: 10, 566: 10, 570: 10, 586: 10, 604: 10, 629: 10, 618: 10, 642: 10, 641: 10, 651: 10, 650: 10, 671: 10, 663: 10, 673: 10, 690: 10, 682: 10, 711: 10, 702: 10, 703: 10, 730: 10, 714: 10, 747: 10, 746: 10, 759: 10, 776: 10, 789: 10, 782: 10, 832: 10, 818: 10, 852: 10, 849: 10, 840: 10, 867: 10, 863: 10, 864: 10, 883: 10, 877: 10, 8: 9, 98: 9, 113: 9, 112: 9, 106: 9, 122: 9, 151: 9, 153: 9, 142: 9, 173: 9, 158: 9, 198: 9, 214: 9, 247: 9, 252: 9, 253: 9, 251: 9, 243: 9, 258: 9, 259: 9, 325: 9, 317: 9, 331: 9, 352: 9, 401: 9, 424: 9, 433: 9, 442: 9, 461: 9, 510: 9, 515: 9, 528: 9, 558: 9, 554: 9, 600: 9, 594: 9, 619: 9, 630: 9, 654: 9, 665: 9, 696: 9, 737: 9, 748: 9, 758: 9, 756: 9, 781: 9, 784: 9, 807: 9, 810: 9, 815: 9, 822: 9, 820: 9, 842: 9, 853: 9, 854: 9, 874: 9, 893: 9, 29: 8, 22: 8, 51: 8, 103: 8, 126: 8, 175: 8, 273: 8, 293: 8, 294: 8, 295: 8, 306: 8, 358: 8, 359: 8, 385: 8, 482: 8, 514: 8, 778: 8, 826: 8, 179: 7, 341: 7, 364: 6})
fit_time: 7.629229814000002

Accuracy for 44 task(s): 	 [Class-IL]: 67.05 % 	 [Task-IL]: 28.78 %

CLASS_IL_ACC: 
	[60.0, 75.96153846153845, 57.85123966942148, 68.93203883495146, 63.366336633663366, 66.35514018691589, 58.59375, 79.7979797979798, 49.01960784313725, 69.74789915966386, 76.78571428571429, 66.30434782608695, 51.61290322580645, 57.608695652173914, 64.8936170212766, 67.70833333333334, 71.9298245614035, 67.85714285714286, 59.84848484848485, 77.77777777777779, 69.91150442477876, 60.150375939849624, 69.36936936936937, 81.55339805825243, 68.46846846846847, 75.59055118110236, 75.78125, 57.943925233644855, 74.19354838709677, 66.94915254237289, 65.65656565656566, 73.33333333333333, 81.73076923076923, 39.175257731958766, 68.33333333333333, 80.18867924528303, 60.78431372549019, 67.1875, 67.32673267326733, 58.55855855855856, 70.47619047619048, 64.81481481481481, 69.81132075471697, 70.79646017699115]
TASK_IL_ACC: 
	[58.42105263157895, 25.961538461538463, 33.057851239669425, 25.24271844660194, 33.663366336633665, 29.906542056074763, 21.875, 28.28282828282828, 21.568627450980394, 30.252100840336134, 21.428571428571427, 31.521739130434785, 18.27956989247312, 22.82608695652174, 29.78723404255319, 27.083333333333332, 33.33333333333333, 24.107142857142858, 25.757575757575758, 26.984126984126984, 35.39823008849557, 23.308270676691727, 26.126126126126124, 27.184466019417474, 27.027027027027028, 25.196850393700785, 19.53125, 24.299065420560748, 26.61290322580645, 21.1864406779661, 26.262626262626267, 32.38095238095238, 32.69230769230769, 22.68041237113402, 28.333333333333332, 23.58490566037736, 26.47058823529412, 20.3125, 27.722772277227726, 27.027027027027028, 27.61904761904762, 28.703703703703702, 23.58490566037736, 93.80530973451327]
f1_micro: 67.07341875127109
f1_macro: 61.39517941951136
              precision    recall  f1-score   support

           0       1.00      0.11      0.20         9
           1       0.00      0.00      0.00         4
           2       0.44      1.00      0.62         4
           3       1.00      1.00      1.00         4
           4       0.00      0.00      0.00         4
           5       1.00      0.50      0.67         4
           6       0.42      1.00      0.59         5
           7       1.00      0.50      0.67         4
           8       1.00      1.00      1.00         4
           9       0.80      1.00      0.89         4
          10       0.90      1.00      0.95         9
          11       1.00      0.40      0.57         5
          12       0.00      0.00      0.00         9
          13       0.25      0.11      0.15         9
          14       0.90      1.00      0.95         9
          15       0.50      0.25      0.33         4
          16       0.80      0.80      0.80         5
          17       1.00      1.00      1.00         4
          18       0.27      0.75      0.40         4
          19       0.00      0.00      0.00         9
          20       0.89      0.89      0.89         9
          21       0.00      0.00      0.00         9
          22       0.00      0.00      0.00         4
          23       0.67      1.00      0.80         4
          24       0.80      0.89      0.84         9
          25       1.00      1.00      1.00         5
          26       0.67      1.00      0.80         4
          27       1.00      1.00      1.00         4
          28       0.67      1.00      0.80         4
          29       1.00      0.25      0.40         4
          30       0.50      0.75      0.60         4
          31       1.00      0.25      0.40         4
          32       1.00      1.00      1.00         9
          33       0.50      1.00      0.67         4
          34       0.08      0.50      0.14         4
          35       0.40      1.00      0.57         4
          36       0.67      0.50      0.57         4
          37       1.00      1.00      1.00         9
          38       0.57      0.80      0.67         5
          39       0.33      0.25      0.29         4
          40       1.00      0.80      0.89         5
          41       1.00      1.00      1.00         5
          42       0.73      0.89      0.80         9
          43       0.75      0.60      0.67         5
          44       0.00      0.00      0.00         4
          45       0.00      0.00      0.00         4
          46       0.67      0.50      0.57         4
          47       0.80      1.00      0.89         4
          48       0.75      1.00      0.86         9
          49       1.00      1.00      1.00         4
          50       1.00      1.00      1.00         9
          51       1.00      1.00      1.00         4
          52       0.36      1.00      0.53         4
          53       1.00      0.25      0.40         4
          54       1.00      0.89      0.94         9
          55       0.67      1.00      0.80         4
          56       0.40      0.40      0.40         5
          57       1.00      0.25      0.40         4
          58       0.60      1.00      0.75         9
          59       1.00      0.44      0.62         9
          60       0.00      0.00      0.00         4
          61       1.00      0.80      0.89         5
          62       0.67      0.50      0.57         4
          63       1.00      0.40      0.57         5
          64       0.00      0.00      0.00         4
          65       0.00      0.00      0.00         4
          66       1.00      0.78      0.88         9
          67       1.00      1.00      1.00         5
          68       0.50      0.40      0.44         5
          69       1.00      0.25      0.40         4
          70       0.03      0.11      0.05         9
          71       0.78      0.78      0.78         9
          72       1.00      0.80      0.89         5
          73       0.78      0.78      0.78         9
          74       0.80      1.00      0.89         4
          75       1.00      0.75      0.86         4
          76       0.07      0.25      0.11         4
          77       0.00      0.00      0.00         4
          78       0.00      0.00      0.00         4
          79       1.00      0.78      0.88         9
          80       1.00      0.75      0.86         4
          81       0.80      1.00      0.89         4
          82       0.90      1.00      0.95         9
          83       0.90      1.00      0.95         9
          84       1.00      1.00      1.00         4
          85       0.80      1.00      0.89         4
          86       1.00      0.75      0.86         4
          87       0.00      0.00      0.00         4
          88       0.50      0.20      0.29         5
          89       0.60      0.75      0.67         4
          90       0.00      0.00      0.00         5
          91       1.00      1.00      1.00         4
          92       1.00      0.80      0.89         5
          93       1.00      0.89      0.94         9
          94       1.00      1.00      1.00         4
          95       0.00      0.00      0.00         9
          96       1.00      1.00      1.00         4
          97       1.00      0.80      0.89         5
          98       0.00      0.00      0.00         4
          99       0.88      0.78      0.82         9
         100       0.57      1.00      0.73         4
         101       1.00      1.00      1.00         4
         102       0.80      1.00      0.89         4
         103       1.00      0.25      0.40         4
         104       0.80      1.00      0.89         4
         105       0.57      1.00      0.73         4
         106       0.80      1.00      0.89         4
         107       0.00      0.00      0.00         4
         108       1.00      0.89      0.94         9
         109       1.00      0.25      0.40         4
         110       1.00      0.78      0.88         9
         111       0.75      0.75      0.75         4
         112       0.50      0.25      0.33         4
         113       0.00      0.00      0.00         4
         114       1.00      0.78      0.88         9
         115       0.00      0.00      0.00         4
         116       0.40      0.50      0.44         4
         117       0.70      0.78      0.74         9
         118       0.80      1.00      0.89         4
         119       0.57      0.80      0.67         5
         120       1.00      0.50      0.67         4
         121       0.19      0.75      0.30         4
         122       0.67      1.00      0.80         4
         123       0.12      0.75      0.21         4
         124       1.00      0.17      0.29         6
         125       0.70      0.78      0.74         9
         126       0.67      1.00      0.80         4
         127       1.00      0.89      0.94         9
         128       0.57      1.00      0.73         4
         129       0.67      0.86      0.75         7
         130       0.00      0.00      0.00         4
         131       0.83      1.00      0.91         5
         132       0.00      0.00      0.00         4
         133       0.00      0.00      0.00         4
         134       0.83      0.56      0.67         9
         135       0.00      0.00      0.00         9
         136       1.00      1.00      1.00         4
         137       0.70      0.78      0.74         9
         138       0.00      0.00      0.00         4
         139       0.00      0.00      0.00         4
         140       0.00      0.00      0.00         9
         141       1.00      1.00      1.00         9
         142       1.00      1.00      1.00         4
         143       1.00      0.80      0.89         5
         144       0.00      0.00      0.00         5
         145       0.67      1.00      0.80         4
         146       0.75      0.60      0.67         5
         147       0.17      0.50      0.25         4
         148       0.67      0.89      0.76         9
         149       0.82      1.00      0.90         9
         150       0.70      0.78      0.74         9
         151       1.00      1.00      1.00         4
         152       1.00      0.56      0.71         9
         153       0.00      0.00      0.00         4
         154       1.00      0.50      0.67         4
         155       0.75      0.75      0.75         4
         156       0.50      0.50      0.50         4
         157       1.00      1.00      1.00         9
         158       1.00      1.00      1.00         4
         159       0.80      1.00      0.89         4
         160       0.67      0.50      0.57         4
         161       0.33      0.75      0.46         4
         162       0.71      1.00      0.83         5
         163       1.00      1.00      1.00         5
         164       1.00      0.75      0.86         4
         165       0.00      0.00      0.00         4
         166       0.75      0.60      0.67         5
         167       1.00      1.00      1.00         4
         168       1.00      1.00      1.00         5
         169       0.69      1.00      0.82         9
         170       1.00      0.89      0.94         9
         171       0.67      1.00      0.80         4
         172       0.44      1.00      0.62         4
         173       0.00      0.00      0.00         4
         174       0.67      0.50      0.57         4
         175       0.80      1.00      0.89         4
         176       1.00      0.75      0.86         4
         177       0.00      0.00      0.00         4
         178       0.75      0.60      0.67         5
         179       1.00      0.75      0.86         4
         180       0.00      0.00      0.00         4
         181       0.00      0.00      0.00         9
         182       0.00      0.00      0.00         4
         183       0.60      0.60      0.60         5
         184       0.67      1.00      0.80         4
         185       0.67      0.50      0.57         4
         186       0.60      0.33      0.43         9
         187       0.88      0.88      0.88         8
         188       0.00      0.00      0.00         4
         189       1.00      0.75      0.86         4
         190       1.00      0.25      0.40         4
         191       0.70      0.78      0.74         9
         192       1.00      0.60      0.75         5
         193       1.00      0.50      0.67         4
         194       1.00      0.80      0.89         5
         195       1.00      1.00      1.00         9
         196       1.00      0.75      0.86         4
         197       1.00      1.00      1.00         5
         198       0.80      1.00      0.89         4
         199       0.90      1.00      0.95         9
         200       0.00      0.00      0.00         4
         201       0.67      0.22      0.33         9
         202       1.00      1.00      1.00         4
         203       1.00      1.00      1.00         4
         204       0.67      0.80      0.73         5
         205       0.75      0.75      0.75         4
         206       0.00      0.00      0.00         4
         207       1.00      1.00      1.00         9
         208       0.89      0.89      0.89         9
         209       0.00      0.00      0.00         4
         210       0.00      0.00      0.00         9
         211       0.60      1.00      0.75         9
         212       1.00      1.00      1.00         5
         213       0.50      0.25      0.33         4
         214       0.00      0.00      0.00         4
         215       1.00      1.00      1.00         4
         216       0.80      1.00      0.89         4
         217       1.00      1.00      1.00         4
         218       1.00      1.00      1.00         4
         219       0.75      0.75      0.75         4
         220       0.80      1.00      0.89         4
         221       0.60      0.33      0.43         9
         222       0.80      1.00      0.89         4
         223       1.00      1.00      1.00         5
         224       0.50      1.00      0.67         4
         225       1.00      0.75      0.86         4
         226       0.00      0.00      0.00         9
         227       0.90      1.00      0.95         9
         228       0.80      1.00      0.89         4
         229       0.57      0.89      0.70         9
         230       1.00      1.00      1.00         9
         231       1.00      1.00      1.00         4
         232       1.00      0.20      0.33         5
         233       0.82      1.00      0.90         9
         234       0.75      0.75      0.75         4
         235       0.90      1.00      0.95         9
         236       1.00      0.75      0.86         4
         237       1.00      1.00      1.00         4
         238       0.60      0.60      0.60         5
         239       0.00      0.00      0.00         4
         240       1.00      1.00      1.00         4
         241       1.00      0.50      0.67         4
         242       1.00      1.00      1.00         4
         243       0.00      0.00      0.00         4
         244       0.50      0.20      0.29         5
         245       0.90      1.00      0.95         9
         246       1.00      1.00      1.00         4
         247       0.00      0.00      0.00         4
         248       1.00      0.75      0.86         4
         249       1.00      0.75      0.86         4
         250       0.43      0.75      0.55         4
         251       0.00      0.00      0.00         4
         252       0.80      1.00      0.89         4
         253       1.00      0.50      0.67         4
         254       0.00      0.00      0.00         4
         255       1.00      0.25      0.40         4
         256       0.00      0.00      0.00         4
         257       0.00      0.00      0.00         4
         258       0.80      1.00      0.89         4
         259       0.06      0.25      0.10         4
         260       1.00      1.00      1.00         9
         261       0.80      1.00      0.89         4
         262       0.00      0.00      0.00         4
         263       0.14      0.20      0.17         5
         264       0.80      0.80      0.80         5
         265       0.80      1.00      0.89         4
         266       0.00      0.00      0.00         4
         267       0.00      0.00      0.00         4
         268       1.00      1.00      1.00         5
         269       1.00      0.50      0.67         4
         270       1.00      0.25      0.40         4
         271       0.67      1.00      0.80         4
         272       0.57      0.89      0.70         9
         273       0.00      0.00      0.00         4
         274       0.00      0.00      0.00         4
         275       0.00      0.00      0.00         4
         276       1.00      0.75      0.86         4
         277       0.50      0.75      0.60         4
         278       0.67      0.80      0.73         5
         279       0.83      1.00      0.91         5
         280       0.89      0.89      0.89         9
         281       0.60      0.75      0.67         4
         282       0.00      0.00      0.00         4
         283       0.00      0.00      0.00         4
         284       1.00      1.00      1.00         4
         285       0.50      0.25      0.33         4
         286       0.78      0.78      0.78         9
         287       0.00      0.00      0.00         4
         288       0.36      1.00      0.53         4
         289       0.75      0.75      0.75         4
         290       0.80      1.00      0.89         4
         291       0.00      0.00      0.00         4
         292       0.80      1.00      0.89         4
         293       0.00      0.00      0.00         4
         294       0.10      0.50      0.17         4
         295       0.50      0.25      0.33         4
         296       0.43      0.75      0.55         4
         297       0.18      0.75      0.29         4
         298       0.12      0.50      0.20         4
         299       0.71      0.56      0.63         9
         300       0.75      0.75      0.75         4
         301       0.67      1.00      0.80         4
         302       0.44      1.00      0.62         4
         303       0.20      0.25      0.22         4
         304       0.00      0.00      0.00         4
         305       0.80      0.80      0.80         5
         306       1.00      1.00      1.00         4
         307       0.50      0.60      0.55         5
         308       0.00      0.00      0.00         4
         309       0.83      1.00      0.91         5
         310       1.00      0.80      0.89         5
         311       0.00      0.00      0.00         4
         312       0.80      1.00      0.89         4
         313       0.75      1.00      0.86         9
         314       0.00      0.00      0.00         4
         315       0.00      0.00      0.00         4
         316       0.50      0.80      0.62         5
         317       0.50      0.75      0.60         4
         318       0.67      0.50      0.57         4
         319       0.60      0.60      0.60         5
         320       1.00      0.50      0.67         4
         321       0.43      0.75      0.55         4
         322       1.00      1.00      1.00         5
         323       0.00      0.00      0.00         4
         324       0.75      0.75      0.75         4
         325       1.00      1.00      1.00         4
         326       0.90      1.00      0.95         9
         327       0.00      0.00      0.00         4
         328       1.00      0.89      0.94         9
         329       0.71      1.00      0.83         5
         330       1.00      1.00      1.00         5
         331       0.00      0.00      0.00         4
         332       0.14      1.00      0.25         4
         333       0.71      1.00      0.83         5
         334       0.57      1.00      0.73         4
         335       1.00      1.00      1.00         9
         336       0.00      0.00      0.00         4
         337       1.00      1.00      1.00         4
         338       0.75      0.67      0.71         9
         339       1.00      1.00      1.00         9
         340       0.75      0.75      0.75         4
         341       0.60      0.75      0.67         4
         342       0.00      0.00      0.00         4
         343       0.71      1.00      0.83         5
         344       0.50      0.78      0.61         9
         345       1.00      1.00      1.00         4
         346       0.67      0.80      0.73         5
         347       0.82      1.00      0.90         9
         348       0.00      0.00      0.00         4
         349       0.71      1.00      0.83         5
         350       0.71      1.00      0.83         5
         351       0.00      0.00      0.00         9
         352       1.00      0.50      0.67         4
         353       0.50      0.75      0.60         4
         354       1.00      1.00      1.00         4
         355       0.00      0.00      0.00         4
         356       1.00      1.00      1.00         4
         357       0.89      0.89      0.89         9
         358       0.00      0.00      0.00         4
         359       0.50      0.25      0.33         4
         360       0.75      0.75      0.75         4
         361       1.00      1.00      1.00         4
         362       1.00      0.67      0.80         9
         363       0.50      0.50      0.50         4
         364       0.00      0.00      0.00         4
         365       1.00      0.40      0.57         5
         366       0.67      0.50      0.57         4
         367       1.00      0.89      0.94         9
         368       0.70      0.78      0.74         9
         369       0.44      0.80      0.57         5
         370       0.89      0.89      0.89         9
         371       1.00      1.00      1.00         4
         372       1.00      0.56      0.71         9
         373       0.57      1.00      0.73         4
         374       1.00      0.75      0.86         4
         375       1.00      0.60      0.75         5
         376       0.43      0.33      0.38         9
         377       0.73      0.89      0.80         9
         378       1.00      1.00      1.00         4
         379       0.80      1.00      0.89         4
         380       1.00      0.89      0.94         9
         381       1.00      1.00      1.00         4
         382       0.86      0.67      0.75         9
         383       0.00      0.00      0.00         9
         384       1.00      0.75      0.86         4
         385       1.00      0.75      0.86         4
         386       1.00      0.67      0.80         9
         387       0.80      0.89      0.84         9
         388       0.33      0.50      0.40         4
         389       0.75      0.60      0.67         5
         390       0.00      0.00      0.00         9
         391       0.67      0.50      0.57         4
         392       0.00      0.00      0.00         9
         393       0.90      1.00      0.95         9
         394       0.11      1.00      0.20         9
         395       0.00      0.00      0.00         4
         396       1.00      0.78      0.88         9
         397       0.60      0.75      0.67         4
         398       0.80      0.80      0.80         5
         399       1.00      0.80      0.89         5
         400       0.67      1.00      0.80         4
         401       0.00      0.00      0.00         4
         402       1.00      0.67      0.80         9
         403       1.00      1.00      1.00         5
         404       0.80      0.80      0.80         5
         405       0.75      0.67      0.71         9
         406       0.75      0.75      0.75         4
         407       0.67      0.40      0.50         5
         408       1.00      1.00      1.00         9
         409       0.90      1.00      0.95         9
         410       0.75      0.60      0.67         5
         411       1.00      1.00      1.00         9
         412       1.00      1.00      1.00         4
         413       0.88      0.78      0.82         9
         414       0.80      1.00      0.89         4
         415       0.89      0.89      0.89         9
         416       0.80      1.00      0.89         4
         417       1.00      0.40      0.57         5
         418       1.00      1.00      1.00         9
         419       0.82      1.00      0.90         9
         420       1.00      1.00      1.00         9
         421       1.00      1.00      1.00         5
         422       0.33      0.25      0.29         4
         423       0.83      1.00      0.91         5
         424       0.00      0.00      0.00         4
         425       0.75      0.75      0.75         4
         426       1.00      0.50      0.67         4
         427       0.80      1.00      0.89         4
         428       0.89      0.89      0.89         9
         429       0.67      0.50      0.57         4
         430       0.75      0.75      0.75         4
         431       0.00      0.00      0.00         9
         432       0.00      0.00      0.00         4
         433       1.00      0.25      0.40         4
         434       1.00      0.25      0.40         4
         435       0.57      1.00      0.73         4
         436       0.00      0.00      0.00         4
         437       0.89      0.89      0.89         9
         438       0.57      1.00      0.73         4
         439       0.88      0.78      0.82         9
         440       0.40      0.44      0.42         9
         441       0.83      0.56      0.67         9
         442       0.00      0.00      0.00         4
         443       0.80      0.80      0.80         5
         444       0.57      0.44      0.50         9
         445       0.86      0.67      0.75         9
         446       0.89      0.89      0.89         9
         447       1.00      0.22      0.36         9
         448       0.67      0.67      0.67         9
         449       1.00      0.80      0.89         5
         450       0.50      0.20      0.29         5
         451       0.80      1.00      0.89         4
         452       1.00      0.25      0.40         4
         453       0.88      0.78      0.82         9
         454       1.00      1.00      1.00         5
         455       0.80      0.89      0.84         9
         456       0.00      0.00      0.00         5
         457       0.50      0.50      0.50         4
         458       0.80      1.00      0.89         4
         459       1.00      1.00      1.00         5
         460       0.00      0.00      0.00         4
         461       1.00      1.00      1.00         4
         462       0.47      1.00      0.64         9
         463       0.00      0.00      0.00         4
         464       0.50      0.20      0.29         5
         465       0.78      0.78      0.78         9
         466       0.67      0.40      0.50         5
         467       0.00      0.00      0.00         4
         468       0.80      0.89      0.84         9
         469       1.00      0.75      0.86         4
         470       1.00      0.50      0.67         4
         471       0.80      1.00      0.89         4
         472       0.62      1.00      0.77         5
         473       1.00      0.89      0.94         9
         474       0.44      0.78      0.56         9
         475       0.00      0.00      0.00         4
         476       0.80      1.00      0.89         4
         477       1.00      1.00      1.00         4
         478       0.67      1.00      0.80         4
         479       0.80      1.00      0.89         4
         480       0.11      0.25      0.15         4
         481       0.60      0.75      0.67         4
         482       0.50      0.25      0.33         4
         483       1.00      1.00      1.00         5
         484       0.00      0.00      0.00         4
         485       0.80      1.00      0.89         4
         486       0.80      1.00      0.89         4
         487       1.00      1.00      1.00         9
         488       0.60      1.00      0.75         9
         489       1.00      0.75      0.86         4
         490       1.00      1.00      1.00         5
         491       1.00      0.75      0.86         4
         492       0.83      1.00      0.91         5
         493       1.00      1.00      1.00         9
         494       0.00      0.00      0.00         4
         495       0.00      0.00      0.00         4
         496       0.83      1.00      0.91         5
         497       0.90      1.00      0.95         9
         498       1.00      0.20      0.33         5
         499       0.75      0.75      0.75         4
         500       1.00      1.00      1.00         5
         501       0.80      1.00      0.89         4
         502       0.44      0.80      0.57         5
         503       0.60      0.60      0.60         5
         504       0.00      0.00      0.00         4
         505       0.75      0.67      0.71         9
         506       0.83      1.00      0.91         5
         507       0.00      0.00      0.00         4
         508       0.88      0.78      0.82         9
         509       1.00      1.00      1.00         4
         510       0.00      0.00      0.00         4
         511       0.75      1.00      0.86         9
         512       0.88      0.78      0.82         9
         513       0.80      1.00      0.89         4
         514       0.00      0.00      0.00         4
         515       1.00      0.50      0.67         4
         516       0.57      0.89      0.70         9
         517       1.00      0.50      0.67         4
         518       1.00      0.25      0.40         4
         519       1.00      0.89      0.94         9
         520       1.00      1.00      1.00         4
         521       0.73      0.89      0.80         9
         522       1.00      1.00      1.00         5
         523       0.44      0.78      0.56         9
         524       0.78      0.78      0.78         9
         525       1.00      0.75      0.86         4
         526       0.71      0.56      0.63         9
         527       1.00      0.78      0.88         9
         528       0.67      1.00      0.80         4
         529       0.67      0.50      0.57         4
         530       0.57      0.80      0.67         5
         531       0.57      0.89      0.70         9
         532       1.00      1.00      1.00         4
         533       0.64      0.78      0.70         9
         534       0.00      0.00      0.00         4
         535       0.00      0.00      0.00         4
         536       0.75      0.75      0.75         4
         537       0.50      0.50      0.50         4
         538       0.44      0.80      0.57         5
         539       0.89      0.89      0.89         9
         540       0.64      1.00      0.78         9
         541       0.78      0.78      0.78         9
         542       0.75      0.75      0.75         4
         543       0.50      0.11      0.18         9
         544       0.75      0.75      0.75         4
         545       0.28      1.00      0.44         9
         546       1.00      1.00      1.00         5
         547       0.82      1.00      0.90         9
         548       0.00      0.00      0.00         4
         549       0.57      1.00      0.73         4
         550       0.90      1.00      0.95         9
         551       0.67      0.89      0.76         9
         552       0.71      1.00      0.83         5
         553       0.73      0.89      0.80         9
         554       0.80      1.00      0.89         4
         555       1.00      0.78      0.88         9
         556       1.00      0.75      0.86         4
         557       0.00      0.00      0.00         4
         558       0.67      0.50      0.57         4
         559       1.00      0.75      0.86         4
         560       1.00      0.80      0.89         5
         561       0.14      0.25      0.18         4
         562       1.00      0.44      0.62         9
         563       0.50      0.75      0.60         4
         564       0.00      0.00      0.00         4
         565       0.00      0.00      0.00         9
         566       1.00      0.75      0.86         4
         567       1.00      1.00      1.00         4
         568       1.00      1.00      1.00         9
         569       1.00      0.56      0.71         9
         570       0.80      1.00      0.89         4
         571       0.60      0.60      0.60         5
         572       0.00      0.00      0.00         4
         573       1.00      0.75      0.86         4
         574       1.00      0.56      0.71         9
         575       0.67      0.50      0.57         4
         576       1.00      0.67      0.80         9
         577       0.00      0.00      0.00         4
         578       1.00      0.80      0.89         5
         579       1.00      1.00      1.00         4
         580       1.00      0.89      0.94         9
         581       0.50      0.40      0.44         5
         582       0.44      0.44      0.44         9
         583       1.00      1.00      1.00         9
         584       0.00      0.00      0.00         4
         585       0.83      1.00      0.91         5
         586       0.27      1.00      0.42         4
         587       1.00      1.00      1.00         4
         588       1.00      1.00      1.00         5
         589       0.90      1.00      0.95         9
         590       0.38      0.56      0.45         9
         591       0.90      1.00      0.95         9
         592       0.80      1.00      0.89         4
         593       0.60      0.75      0.67         4
         594       0.00      0.00      0.00         4
         595       1.00      0.75      0.86         4
         596       0.83      1.00      0.91         5
         597       0.09      0.50      0.15         4
         598       0.00      0.00      0.00         4
         599       0.00      0.00      0.00         4
         600       0.67      0.50      0.57         4
         601       0.89      0.89      0.89         9
         602       0.60      0.75      0.67         4
         603       0.39      0.78      0.52         9
         604       1.00      0.75      0.86         4
         605       0.30      0.75      0.43         4
         606       1.00      0.80      0.89         5
         607       1.00      0.75      0.86         4
         608       0.10      0.56      0.17         9
         609       0.78      0.78      0.78         9
         610       0.60      0.67      0.63         9
         611       0.89      0.89      0.89         9
         612       0.80      0.89      0.84         9
         613       1.00      0.40      0.57         5
         614       1.00      1.00      1.00         4
         615       0.80      1.00      0.89         4
         616       0.28      0.71      0.40         7
         617       0.00      0.00      0.00         4
         618       0.00      0.00      0.00         4
         619       1.00      1.00      1.00         4
         620       0.00      0.00      0.00         4
         621       0.00      0.00      0.00         4
         622       0.00      0.00      0.00         4
         623       0.80      0.89      0.84         9
         624       1.00      0.80      0.89         5
         625       0.50      0.75      0.60         4
         626       0.57      1.00      0.73         4
         627       0.89      0.89      0.89         9
         628       1.00      1.00      1.00         9
         629       0.00      0.00      0.00         4
         630       0.75      0.75      0.75         4
         631       0.17      0.50      0.25         4
         632       1.00      0.75      0.86         4
         633       0.67      1.00      0.80         4
         634       0.43      0.33      0.38         9
         635       1.00      1.00      1.00         9
         636       0.13      1.00      0.24         4
         637       0.50      0.40      0.44         5
         638       1.00      0.75      0.86         4
         639       0.57      1.00      0.73         4
         640       1.00      0.25      0.40         4
         641       0.60      0.75      0.67         4
         642       1.00      0.75      0.86         4
         643       0.88      1.00      0.93         7
         644       1.00      0.50      0.67         4
         645       1.00      1.00      1.00         5
         646       0.80      1.00      0.89         4
         647       0.67      0.89      0.76         9
         648       0.60      0.75      0.67         4
         649       1.00      0.50      0.67         4
         650       0.40      0.50      0.44         4
         651       1.00      0.75      0.86         4
         652       0.00      0.00      0.00         4
         653       1.00      1.00      1.00         9
         654       1.00      1.00      1.00         4
         655       1.00      0.78      0.88         9
         656       0.56      1.00      0.71         5
         657       1.00      0.80      0.89         5
         658       0.82      1.00      0.90         9
         659       1.00      0.75      0.86         4
         660       0.67      0.80      0.73         5
         661       1.00      0.25      0.40         4
         662       1.00      0.75      0.86         4
         663       1.00      1.00      1.00         4
         664       1.00      0.89      0.94         9
         665       1.00      1.00      1.00         4
         666       0.36      1.00      0.53         4
         667       1.00      0.67      0.80         9
         668       0.67      1.00      0.80         4
         669       1.00      0.50      0.67         4
         670       1.00      0.80      0.89         5
         671       0.57      1.00      0.73         4
         672       1.00      0.50      0.67         4
         673       0.75      0.75      0.75         4
         674       0.00      0.00      0.00         4
         675       0.60      0.75      0.67         4
         676       0.33      0.25      0.29         4
         677       0.67      1.00      0.80         4
         678       0.00      0.00      0.00         4
         679       0.00      0.00      0.00         4
         680       0.67      0.50      0.57         4
         681       0.50      0.25      0.33         4
         682       0.80      1.00      0.89         4
         683       1.00      0.75      0.86         4
         684       0.75      0.67      0.71         9
         685       0.13      1.00      0.23         4
         686       0.00      0.00      0.00         5
         687       1.00      0.22      0.36         9
         688       0.00      0.00      0.00         4
         689       0.43      0.75      0.55         4
         690       0.00      0.00      0.00         4
         691       0.60      0.33      0.43         9
         692       0.00      0.00      0.00         4
         693       0.33      0.40      0.36         5
         694       1.00      1.00      1.00         9
         695       1.00      0.78      0.88         9
         696       0.60      0.75      0.67         4
         697       0.11      0.25      0.15         4
         698       0.60      0.60      0.60         5
         699       1.00      1.00      1.00         5
         700       0.00      0.00      0.00         4
         701       1.00      0.89      0.94         9
         702       0.50      0.25      0.33         4
         703       0.50      0.25      0.33         4
         704       1.00      1.00      1.00         5
         705       0.00      0.00      0.00         4
         706       1.00      0.75      0.86         4
         707       1.00      1.00      1.00         9
         708       0.90      1.00      0.95         9
         709       1.00      0.20      0.33         5
         710       1.00      0.40      0.57         5
         711       0.00      0.00      0.00         4
         712       0.78      0.78      0.78         9
         713       0.89      0.89      0.89         9
         714       0.00      0.00      0.00         4
         715       1.00      1.00      1.00         4
         716       0.43      0.75      0.55         4
         717       0.71      1.00      0.83         5
         718       0.62      1.00      0.77         5
         719       1.00      1.00      1.00         5
         720       0.43      0.75      0.55         4
         721       0.80      1.00      0.89         4
         722       0.67      0.89      0.76         9
         723       0.80      0.80      0.80         5
         724       1.00      0.50      0.67         4
         725       0.82      1.00      0.90         9
         726       0.57      1.00      0.73         4
         727       0.67      0.67      0.67         9
         728       0.80      1.00      0.89         4
         729       1.00      0.25      0.40         4
         730       1.00      0.75      0.86         4
         731       1.00      0.20      0.33         5
         732       0.83      1.00      0.91         5
         733       0.90      1.00      0.95         9
         734       0.80      0.80      0.80         5
         735       0.00      0.00      0.00         9
         736       1.00      0.50      0.67         4
         737       1.00      0.25      0.40         4
         738       0.00      0.00      0.00         4
         739       0.00      0.00      0.00         4
         740       0.70      0.78      0.74         9
         741       0.83      1.00      0.91         5
         742       0.67      1.00      0.80         4
         743       1.00      1.00      1.00         4
         744       0.89      0.89      0.89         9
         745       1.00      0.50      0.67         4
         746       1.00      0.75      0.86         4
         747       1.00      1.00      1.00         4
         748       0.00      0.00      0.00         4
         749       0.67      1.00      0.80         4
         750       1.00      0.67      0.80         9
         751       0.00      0.00      0.00         4
         752       0.14      1.00      0.25         4
         753       0.40      1.00      0.57         4
         754       0.45      1.00      0.62         5
         755       0.00      0.00      0.00         4
         756       0.17      0.25      0.20         4
         757       0.00      0.00      0.00         5
         758       1.00      0.25      0.40         4
         759       1.00      0.50      0.67         4
         760       1.00      1.00      1.00         4
         761       1.00      0.78      0.88         9
         762       1.00      0.67      0.80         9
         763       0.64      1.00      0.78         9
         764       0.69      1.00      0.82         9
         765       1.00      0.50      0.67         4
         766       0.75      0.67      0.71         9
         767       0.00      0.00      0.00         9
         768       0.80      0.80      0.80         5
         769       0.83      1.00      0.91         5
         770       0.73      0.89      0.80         9
         771       0.86      0.67      0.75         9
         772       1.00      1.00      1.00         4
         773       1.00      0.88      0.93         8
         774       0.00      0.00      0.00         4
         775       0.88      0.78      0.82         9
         776       0.00      0.00      0.00         4
         777       0.83      1.00      0.91         5
         778       1.00      0.50      0.67         4
         779       0.80      1.00      0.89         4
         780       0.29      0.50      0.36         4
         781       1.00      0.25      0.40         4
         782       1.00      1.00      1.00         4
         783       0.15      0.75      0.25         4
         784       1.00      0.50      0.67         4
         785       0.00      0.00      0.00         4
         786       0.75      0.75      0.75         4
         787       0.00      0.00      0.00         4
         788       0.75      1.00      0.86         9
         789       0.50      0.75      0.60         4
         790       1.00      0.75      0.86         4
         791       0.67      0.89      0.76         9
         792       1.00      0.75      0.86         4
         793       1.00      1.00      1.00         9
         794       0.70      0.78      0.74         9
         795       0.00      0.00      0.00         9
         796       1.00      0.80      0.89         5
         797       1.00      1.00      1.00         5
         798       0.75      0.75      0.75         4
         799       0.00      0.00      0.00         4
         800       0.75      0.67      0.71         9
         801       0.00      0.00      0.00         4
         802       0.67      1.00      0.80         4
         803       1.00      0.40      0.57         5
         804       1.00      0.80      0.89         5
         805       0.18      1.00      0.30         5
         806       0.71      1.00      0.83         5
         807       0.00      0.00      0.00         4
         808       0.33      0.50      0.40         4
         809       0.60      0.75      0.67         4
         810       0.00      0.00      0.00         4
         811       1.00      0.89      0.94         9
         812       0.58      0.78      0.67         9
         813       0.00      0.00      0.00         4
         814       0.57      1.00      0.73         4
         815       0.00      0.00      0.00         4
         816       0.50      0.50      0.50         4
         817       0.82      1.00      0.90         9
         818       1.00      0.50      0.67         4
         819       0.57      1.00      0.73         4
         820       1.00      1.00      1.00         4
         821       0.67      1.00      0.80         4
         822       0.20      0.75      0.32         4
         823       1.00      1.00      1.00         5
         824       1.00      0.80      0.89         5
         825       0.75      0.60      0.67         5
         826       0.50      0.50      0.50         4
         827       0.00      0.00      0.00         9
         828       1.00      0.60      0.75         5
         829       0.80      1.00      0.89         4
         830       0.67      0.89      0.76         9
         831       0.89      0.89      0.89         9
         832       0.00      0.00      0.00         4
         833       0.83      1.00      0.91         5
         834       0.83      1.00      0.91         5
         835       0.90      1.00      0.95         9
         836       1.00      1.00      1.00         4
         837       1.00      0.80      0.89         5
         838       0.00      0.00      0.00         4
         839       0.62      1.00      0.77         5
         840       0.43      0.75      0.55         4
         841       0.70      0.78      0.74         9
         842       0.00      0.00      0.00         4
         843       0.29      1.00      0.44         8
         844       1.00      0.40      0.57         5
         845       0.00      0.00      0.00         4
         846       0.12      0.25      0.17         4
         847       1.00      1.00      1.00         4
         848       0.00      0.00      0.00         9
         849       1.00      1.00      1.00         4
         850       0.11      0.50      0.18         4
         851       0.86      0.67      0.75         9
         852       1.00      0.50      0.67         4
         853       1.00      1.00      1.00         4
         854       0.00      0.00      0.00         4
         855       0.00      0.00      0.00         4
         856       1.00      1.00      1.00         9
         857       0.67      0.50      0.57         4
         858       0.67      1.00      0.80         4
         859       0.00      0.00      0.00         4
         860       0.83      0.56      0.67         9
         861       0.80      1.00      0.89         4
         862       1.00      0.75      0.86         4
         863       1.00      0.75      0.86         4
         864       1.00      1.00      1.00         4
         865       0.33      0.75      0.46         4
         866       0.67      1.00      0.80         4
         867       0.33      0.25      0.29         4
         868       0.73      0.89      0.80         9
         869       0.30      0.89      0.44         9
         870       0.00      0.00      0.00         4
         871       1.00      0.89      0.94         9
         872       0.50      1.00      0.67         4
         873       0.57      0.80      0.67         5
         874       0.62      1.00      0.77         5
         875       0.80      0.89      0.84         9
         876       1.00      1.00      1.00         5
         877       0.80      1.00      0.89         4
         878       1.00      1.00      1.00         4
         879       0.80      0.89      0.84         9
         880       0.67      0.50      0.57         4
         881       0.00      0.00      0.00         4
         882       1.00      1.00      1.00         4
         883       0.60      0.75      0.67         4
         884       0.50      0.75      0.60         4
         885       0.67      1.00      0.80         4
         886       0.00      0.00      0.00         4
         887       0.36      1.00      0.53         4
         888       0.00      0.00      0.00         9
         889       1.00      0.80      0.89         5
         890       0.83      0.56      0.67         9
         891       0.86      0.67      0.75         9
         892       0.89      0.89      0.89         9
         893       0.75      0.75      0.75         4

    accuracy                           0.67      4917
   macro avg       0.64      0.64      0.61      4917
weighted avg       0.67      0.67      0.64      4917

task_train_time: {0: 0.118456848000001, 1: 0.029949931000000873, 2: 0.03675956500000055, 3: 0.02887087399999899, 4: 0.027331793000000104, 5: 0.030892154000000005, 6: 0.03791978299999954, 7: 0.028694157999998637, 8: 0.02935690500000021, 9: 0.0344593040000003, 10: 0.03229761000000053, 11: 0.0274266549999993, 12: 0.026380298999999496, 13: 0.026780661000000094, 14: 0.02572985399999972, 15: 0.02631341200000037, 16: 0.03433456800000023, 17: 0.03140617699999915, 18: 0.03977260699999974, 19: 0.035252472999999895, 20: 0.033649275000000145, 21: 0.039131123000000656, 22: 0.031515012999999925, 23: 0.029759780999999208, 24: 0.03233902800000088, 25: 0.03726351200000089, 26: 0.038090963000000144, 27: 0.03056919399999991, 28: 0.03555394799999867, 29: 0.03398173100000079, 30: 0.028426667999999822, 31: 0.030102437000000037, 32: 0.030150431999999228, 33: 0.029522566000000694, 34: 0.03585458499999916, 35: 0.030853617, 36: 0.028939532000000767, 37: 0.03918102300000115, 38: 0.028966512999996752, 39: 0.03300444399999947, 40: 0.031982319000000814, 41: 0.03075220999999928, 42: 0.03215385000000026, 43: 0.0340669389999988}
prediction_time: 0.00025145200000054047
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
