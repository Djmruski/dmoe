Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='122f9a22-c266-4d55-a99d-38b87788310b', conf_timestamp='2023-08-10 06:04:02.479686', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 55.19 % 	 [Task-IL]: 52.46 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 41.25 % 	 [Task-IL]: 38.24 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 38.88 % 	 [Task-IL]: 34.53 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 34.41 % 	 [Task-IL]: 33.6 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 34.87 % 	 [Task-IL]: 32.57 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 26.04 % 	 [Task-IL]: 32.39 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.27 % 	 [Task-IL]: 31.41 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 20.86 % 	 [Task-IL]: 31.83 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 20.79 % 	 [Task-IL]: 32.03 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 18.9 % 	 [Task-IL]: 31.49 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 14.58 % 	 [Task-IL]: 30.3 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 12.81 % 	 [Task-IL]: 30.75 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 13.59 % 	 [Task-IL]: 29.41 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 13.3 % 	 [Task-IL]: 29.19 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.21 % 	 [Task-IL]: 29.35 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 11.99 % 	 [Task-IL]: 28.9 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 9.32 % 	 [Task-IL]: 27.81 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 7.68 % 	 [Task-IL]: 27.6 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 10.18 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 10.76 % 	 [Task-IL]: 27.9 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.92 % 	 [Task-IL]: 27.76 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 7.75 % 	 [Task-IL]: 27.79 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 7.79 % 	 [Task-IL]: 27.27 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 9.31 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.42 % 	 [Task-IL]: 26.88 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.89 % 	 [Task-IL]: 27.57 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.58 % 	 [Task-IL]: 27.21 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.04 % 	 [Task-IL]: 26.83 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.67 % 	 [Task-IL]: 26.25 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.6 % 	 [Task-IL]: 26.07 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.68 % 	 [Task-IL]: 26.4 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.52 % 	 [Task-IL]: 26.29 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 7.52 % 	 [Task-IL]: 26.53 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 7.74 % 	 [Task-IL]: 26.13 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.93 % 	 [Task-IL]: 25.71 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 7.61 % 	 [Task-IL]: 26.25 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.66 % 	 [Task-IL]: 25.75 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 6.34 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 3.74 % 	 [Task-IL]: 25.55 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 3.91 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.53 % 	 [Task-IL]: 25.6 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.89 % 	 [Task-IL]: 25.54 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 5.71 % 	 [Task-IL]: 25.72 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74905, 97: 33, 180: 33, 351: 33, 436: 33, 486: 33, 633: 33, 717: 33, 795: 33, 827: 33, 250: 32, 267: 32, 371: 32, 548: 32, 605: 32, 626: 32, 669: 32, 787: 32, 781: 32, 20: 31, 50: 31, 64: 31, 156: 31, 256: 31, 312: 31, 324: 31, 363: 31, 386: 31, 405: 31, 398: 31, 439: 31, 463: 31, 464: 31, 530: 31, 534: 31, 642: 31, 661: 31, 701: 31, 744: 31, 889: 31, 26: 30, 16: 30, 35: 30, 43: 30, 90: 30, 119: 30, 178: 30, 210: 30, 216: 30, 230: 30, 279: 30, 306: 30, 389: 30, 378: 30, 395: 30, 417: 30, 418: 30, 442: 30, 472: 30, 469: 30, 497: 30, 514: 30, 518: 30, 540: 30, 569: 30, 563: 30, 608: 30, 610: 30, 612: 30, 623: 30, 643: 30, 646: 30, 668: 30, 686: 30, 729: 30, 726: 30, 752: 30, 754: 30, 765: 30, 803: 30, 880: 30, 881: 30, 32: 29, 76: 29, 82: 29, 83: 29, 123: 29, 114: 29, 125: 29, 138: 29, 140: 29, 168: 29, 211: 29, 197: 29, 248: 29, 262: 29, 293: 29, 286: 29, 289: 29, 328: 29, 325: 29, 373: 29, 354: 29, 433: 29, 440: 29, 443: 29, 445: 29, 435: 29, 444: 29, 471: 29, 478: 29, 477: 29, 483: 29, 500: 29, 541: 29, 551: 29, 553: 29, 550: 29, 588: 29, 664: 29, 688: 29, 674: 29, 711: 29, 706: 29, 714: 29, 748: 29, 791: 29, 777: 29, 820: 29, 886: 29, 18: 28, 34: 28, 79: 28, 77: 28, 152: 28, 159: 28, 228: 28, 251: 28, 237: 28, 254: 28, 285: 28, 281: 28, 292: 28, 299: 28, 329: 28, 353: 28, 409: 28, 429: 28, 454: 28, 547: 28, 594: 28, 595: 28, 600: 28, 699: 28, 779: 28, 774: 28, 786: 28, 805: 28, 807: 28, 832: 28, 840: 28, 837: 28, 46: 27, 42: 27, 100: 27, 109: 27, 142: 27, 179: 27, 200: 27, 226: 27, 225: 27, 265: 27, 290: 27, 341: 27, 348: 27, 346: 27, 372: 27, 394: 27, 431: 27, 461: 27, 510: 27, 577: 27, 582: 27, 604: 27, 632: 27, 619: 27, 652: 27, 734: 27, 788: 27, 864: 27, 876: 27, 24: 26, 31: 26, 131: 26, 134: 26, 224: 26, 263: 26, 466: 26, 545: 26, 572: 26, 587: 26, 596: 26, 684: 26, 735: 26, 772: 26, 845: 26, 842: 26, 861: 26, 858: 26, 71: 25, 116: 25, 143: 25, 157: 25, 283: 25, 294: 25, 304: 25, 501: 25, 535: 25, 629: 25, 637: 25, 656: 25, 719: 25, 733: 25, 720: 25, 882: 25, 94: 24, 133: 24, 174: 24, 344: 24, 679: 24, 768: 24, 793: 24, 19: 23, 421: 23, 432: 23, 659: 23, 810: 23, 460: 22, 581: 21, 865: 21, 834: 19, 51: 18, 635: 18, 809: 18, 802: 18, 72: 17, 87: 17, 102: 17, 121: 17, 171: 17, 164: 17, 338: 17, 359: 17, 381: 17, 509: 17, 528: 17, 660: 17, 691: 17, 800: 17, 873: 17, 86: 16, 141: 16, 191: 16, 233: 16, 241: 16, 242: 16, 271: 16, 273: 16, 345: 16, 385: 16, 488: 16, 539: 16, 586: 16, 598: 16, 621: 16, 715: 16, 830: 16, 859: 16, 40: 15, 49: 15, 75: 15, 84: 15, 110: 15, 213: 15, 221: 15, 231: 15, 272: 15, 308: 15, 302: 15, 295: 15, 336: 15, 349: 15, 355: 15, 473: 15, 479: 15, 498: 15, 529: 15, 552: 15, 611: 15, 653: 15, 731: 15, 721: 15, 737: 15, 751: 15, 769: 15, 784: 15, 841: 15, 872: 15, 885: 15, 12: 14, 27: 14, 33: 14, 37: 14, 74: 14, 107: 14, 118: 14, 129: 14, 148: 14, 160: 14, 183: 14, 222: 14, 215: 14, 243: 14, 236: 14, 261: 14, 278: 14, 287: 14, 322: 14, 316: 14, 368: 14, 383: 14, 450: 14, 459: 14, 562: 14, 570: 14, 573: 14, 574: 14, 613: 14, 601: 14, 641: 14, 671: 14, 665: 14, 685: 14, 683: 14, 722: 14, 829: 14, 836: 14, 838: 14, 868: 14, 860: 14, 869: 14, 874: 14, 9: 13, 22: 13, 28: 13, 2: 13, 1: 13, 8: 13, 29: 13, 6: 13, 36: 13, 60: 13, 68: 13, 59: 13, 57: 13, 91: 13, 98: 13, 112: 13, 111: 13, 106: 13, 117: 13, 147: 13, 145: 13, 137: 13, 149: 13, 170: 13, 162: 13, 169: 13, 158: 13, 176: 13, 193: 13, 204: 13, 201: 13, 194: 13, 207: 13, 195: 13, 232: 13, 223: 13, 259: 13, 288: 13, 275: 13, 305: 13, 319: 13, 332: 13, 331: 13, 334: 13, 343: 13, 358: 13, 374: 13, 388: 13, 408: 13, 425: 13, 424: 13, 447: 13, 457: 13, 465: 13, 458: 13, 468: 13, 493: 13, 492: 13, 475: 13, 502: 13, 513: 13, 519: 13, 516: 13, 520: 13, 517: 13, 543: 13, 560: 13, 566: 13, 558: 13, 589: 13, 585: 13, 576: 13, 597: 13, 615: 13, 644: 13, 648: 13, 636: 13, 647: 13, 657: 13, 712: 13, 694: 13, 705: 13, 698: 13, 709: 13, 728: 13, 727: 13, 739: 13, 761: 13, 770: 13, 764: 13, 762: 13, 785: 13, 797: 13, 819: 13, 823: 13, 847: 13, 849: 13, 854: 13, 871: 13, 870: 13, 879: 13, 21: 12, 14: 12, 39: 12, 38: 12, 70: 12, 66: 12, 55: 12, 61: 12, 78: 12, 104: 12, 108: 12, 130: 12, 128: 12, 122: 12, 124: 12, 153: 12, 150: 12, 173: 12, 163: 12, 155: 12, 182: 12, 187: 12, 190: 12, 186: 12, 184: 12, 185: 12, 202: 12, 208: 12, 196: 12, 209: 12, 212: 12, 214: 12, 229: 12, 247: 12, 235: 12, 253: 12, 238: 12, 257: 12, 269: 12, 258: 12, 277: 12, 280: 12, 276: 12, 309: 12, 301: 12, 296: 12, 310: 12, 307: 12, 326: 12, 315: 12, 318: 12, 330: 12, 323: 12, 314: 12, 340: 12, 339: 12, 366: 12, 360: 12, 364: 12, 393: 12, 392: 12, 382: 12, 397: 12, 404: 12, 399: 12, 401: 12, 407: 12, 428: 12, 415: 12, 414: 12, 451: 12, 448: 12, 437: 12, 467: 12, 487: 12, 482: 12, 506: 12, 499: 12, 507: 12, 511: 12, 504: 12, 512: 12, 526: 12, 531: 12, 522: 12, 538: 12, 571: 12, 554: 12, 557: 12, 584: 12, 575: 12, 599: 12, 616: 12, 627: 12, 622: 12, 639: 12, 640: 12, 663: 12, 654: 12, 658: 12, 673: 12, 682: 12, 689: 12, 708: 12, 704: 12, 700: 12, 696: 12, 697: 12, 749: 12, 746: 12, 736: 12, 740: 12, 756: 12, 757: 12, 763: 12, 775: 12, 812: 12, 799: 12, 794: 12, 824: 12, 826: 12, 839: 12, 852: 12, 848: 12, 844: 12, 835: 12, 866: 12, 883: 12, 875: 12, 888: 12, 884: 12, 5: 11, 4: 11, 3: 11, 52: 11, 48: 11, 45: 11, 54: 11, 56: 11, 69: 11, 85: 11, 81: 11, 93: 11, 99: 11, 103: 11, 105: 11, 132: 11, 127: 11, 144: 11, 146: 11, 135: 11, 139: 11, 165: 11, 172: 11, 166: 11, 181: 11, 192: 11, 205: 11, 206: 11, 220: 11, 244: 11, 239: 11, 240: 11, 245: 11, 270: 11, 260: 11, 274: 11, 291: 11, 297: 11, 311: 11, 300: 11, 333: 11, 327: 11, 352: 11, 347: 11, 362: 11, 357: 11, 369: 11, 376: 11, 380: 11, 384: 11, 390: 11, 402: 11, 403: 11, 400: 11, 410: 11, 423: 11, 427: 11, 422: 11, 430: 11, 420: 11, 446: 11, 434: 11, 455: 11, 474: 11, 491: 11, 490: 11, 484: 11, 480: 11, 503: 11, 494: 11, 505: 11, 524: 11, 515: 11, 521: 11, 525: 11, 532: 11, 536: 11, 542: 11, 537: 11, 555: 11, 561: 11, 559: 11, 580: 11, 583: 11, 579: 11, 590: 11, 591: 11, 602: 11, 606: 11, 618: 11, 624: 11, 631: 11, 620: 11, 617: 11, 651: 11, 649: 11, 655: 11, 670: 11, 667: 11, 675: 11, 676: 11, 678: 11, 681: 11, 693: 11, 677: 11, 692: 11, 718: 11, 723: 11, 725: 11, 750: 11, 741: 11, 745: 11, 743: 11, 747: 11, 753: 11, 738: 11, 771: 11, 758: 11, 767: 11, 760: 11, 792: 11, 783: 11, 790: 11, 776: 11, 782: 11, 796: 11, 798: 11, 821: 11, 828: 11, 815: 11, 831: 11, 833: 11, 825: 11, 817: 11, 853: 11, 851: 11, 863: 11, 856: 11, 862: 11, 857: 11, 890: 11, 887: 11, 10: 10, 7: 10, 17: 10, 11: 10, 15: 10, 47: 10, 41: 10, 44: 10, 65: 10, 73: 10, 67: 10, 88: 10, 80: 10, 89: 10, 95: 10, 101: 10, 96: 10, 115: 10, 151: 10, 136: 10, 175: 10, 188: 10, 177: 10, 199: 10, 198: 10, 218: 10, 217: 10, 252: 10, 255: 10, 282: 10, 284: 10, 298: 10, 313: 10, 320: 10, 337: 10, 356: 10, 365: 10, 370: 10, 361: 10, 396: 10, 419: 10, 416: 10, 441: 10, 453: 10, 462: 10, 470: 10, 489: 10, 481: 10, 495: 10, 508: 10, 496: 10, 523: 10, 546: 10, 549: 10, 565: 10, 568: 10, 578: 10, 593: 10, 609: 10, 603: 10, 630: 10, 625: 10, 614: 10, 628: 10, 645: 10, 662: 10, 666: 10, 672: 10, 710: 10, 703: 10, 724: 10, 716: 10, 732: 10, 742: 10, 766: 10, 789: 10, 778: 10, 780: 10, 811: 10, 804: 10, 850: 10, 867: 10, 892: 10, 893: 10, 891: 10, 23: 9, 30: 9, 62: 9, 63: 9, 113: 9, 126: 9, 120: 9, 154: 9, 189: 9, 203: 9, 219: 9, 227: 9, 246: 9, 268: 9, 264: 9, 266: 9, 321: 9, 317: 9, 350: 9, 335: 9, 367: 9, 379: 9, 375: 9, 387: 9, 391: 9, 412: 9, 411: 9, 413: 9, 452: 9, 449: 9, 438: 9, 476: 9, 527: 9, 533: 9, 544: 9, 556: 9, 592: 9, 607: 9, 680: 9, 687: 9, 702: 9, 707: 9, 713: 9, 730: 9, 773: 9, 759: 9, 755: 9, 808: 9, 806: 9, 801: 9, 813: 9, 816: 9, 818: 9, 843: 9, 846: 9, 877: 9, 25: 8, 53: 8, 58: 8, 92: 8, 161: 8, 167: 8, 249: 8, 303: 8, 342: 8, 377: 8, 406: 8, 426: 8, 456: 8, 564: 8, 567: 8, 650: 8, 638: 8, 634: 8, 690: 8, 695: 8, 814: 8, 822: 8, 855: 8, 13: 7, 234: 7, 878: 7, 485: 6})
fit_time: 7.425052533000002

Accuracy for 44 task(s): 	 [Class-IL]: 66.63 % 	 [Task-IL]: 30.5 %

CLASS_IL_ACC: 
	[60.10928961748634, 71.30434782608695, 57.14285714285714, 58.620689655172406, 57.28155339805825, 73.50427350427351, 61.60714285714286, 77.35849056603774, 73.07692307692307, 68.26923076923077, 72.17391304347827, 75.96153846153845, 62.60869565217392, 53.96825396825397, 73.39449541284404, 61.904761904761905, 71.05263157894737, 67.27272727272727, 71.71717171717171, 70.47619047619048, 68.14159292035397, 70.73170731707317, 75.59055118110236, 65.38461538461539, 70.87378640776699, 61.76470588235294, 60.902255639097746, 71.1340206185567, 69.52380952380952, 67.44186046511628, 69.64285714285714, 63.63636363636363, 61.40350877192983, 78.30188679245283, 76.47058823529412, 78.33333333333333, 66.97247706422019, 63.366336633663366, 56.34920634920635, 67.88990825688074, 48.45360824742268, 52.38095238095239, 68.57142857142857, 59.82142857142857]
TASK_IL_ACC: 
	[53.551912568306015, 28.695652173913043, 23.076923076923077, 34.48275862068966, 30.097087378640776, 31.62393162393162, 28.57142857142857, 35.84905660377358, 34.61538461538461, 25.961538461538463, 25.217391304347824, 26.923076923076923, 27.82608695652174, 23.015873015873016, 29.357798165137616, 20.952380952380953, 21.929824561403507, 27.27272727272727, 27.27272727272727, 33.33333333333333, 28.31858407079646, 29.268292682926827, 21.25984251968504, 35.57692307692308, 29.126213592233007, 32.35294117647059, 25.563909774436087, 23.711340206185564, 27.61904761904762, 27.906976744186046, 26.785714285714285, 26.36363636363636, 28.947368421052634, 32.075471698113205, 30.392156862745097, 32.5, 32.11009174311927, 27.722772277227726, 29.365079365079367, 27.522935779816514, 22.68041237113402, 30.476190476190478, 26.666666666666668, 98.21428571428571]
f1_micro: 66.54464104128533
f1_macro: 60.51135188855109
              precision    recall  f1-score   support

           0       0.69      1.00      0.82         9
           1       1.00      0.50      0.67         4
           2       0.67      1.00      0.80         4
           3       0.00      0.00      0.00         4
           4       1.00      1.00      1.00         4
           5       1.00      1.00      1.00         4
           6       0.75      0.60      0.67         5
           7       0.00      0.00      0.00         4
           8       0.50      0.25      0.33         4
           9       0.13      0.50      0.21         4
          10       0.50      0.75      0.60         4
          11       0.50      0.75      0.60         4
          12       1.00      0.75      0.86         4
          13       1.00      1.00      1.00         4
          14       0.00      0.00      0.00         4
          15       1.00      1.00      1.00         4
          16       0.89      0.89      0.89         9
          17       0.50      0.50      0.50         4
          18       0.06      0.33      0.11         9
          19       1.00      0.89      0.94         9
          20       0.69      1.00      0.82         9
          21       0.60      0.75      0.67         4
          22       0.50      0.75      0.60         4
          23       1.00      0.50      0.67         4
          24       1.00      1.00      1.00         9
          25       0.00      0.00      0.00         4
          26       0.80      0.44      0.57         9
          27       0.83      1.00      0.91         5
          28       0.00      0.00      0.00         4
          29       0.12      0.75      0.21         4
          30       0.75      0.75      0.75         4
          31       0.00      0.00      0.00         9
          32       0.00      0.00      0.00         9
          33       1.00      0.50      0.67         4
          34       1.00      0.67      0.80         9
          35       1.00      0.89      0.94         9
          36       0.60      0.75      0.67         4
          37       0.75      0.60      0.67         5
          38       0.50      0.25      0.33         4
          39       0.00      0.00      0.00         4
          40       0.62      1.00      0.77         5
          41       0.67      1.00      0.80         4
          42       0.57      0.89      0.70         9
          43       0.12      0.67      0.21         9
          44       0.80      1.00      0.89         4
          45       0.75      0.60      0.67         5
          46       0.78      0.78      0.78         9
          47       1.00      0.50      0.67         4
          48       0.57      1.00      0.73         4
          49       1.00      0.20      0.33         5
          50       1.00      0.78      0.88         9
          51       0.71      1.00      0.83         5
          52       0.75      0.75      0.75         4
          53       1.00      0.50      0.67         4
          54       0.50      0.25      0.33         4
          55       1.00      1.00      1.00         4
          56       0.00      0.00      0.00         4
          57       1.00      0.75      0.86         4
          58       1.00      1.00      1.00         4
          59       0.60      0.75      0.67         4
          60       1.00      0.75      0.86         4
          61       1.00      1.00      1.00         4
          62       0.00      0.00      0.00         4
          63       0.50      0.75      0.60         4
          64       0.88      0.78      0.82         9
          65       0.07      0.25      0.11         4
          66       1.00      0.75      0.86         4
          67       0.00      0.00      0.00         4
          68       1.00      1.00      1.00         4
          69       0.00      0.00      0.00         4
          70       0.00      0.00      0.00         4
          71       0.90      1.00      0.95         9
          72       1.00      0.40      0.57         5
          73       0.33      0.25      0.29         4
          74       0.00      0.00      0.00         5
          75       1.00      0.80      0.89         5
          76       0.00      0.00      0.00         9
          77       0.60      1.00      0.75         9
          78       0.80      1.00      0.89         4
          79       0.75      1.00      0.86         9
          80       0.00      0.00      0.00         4
          81       0.00      0.00      0.00         4
          82       1.00      0.78      0.88         9
          83       1.00      0.22      0.36         9
          84       1.00      1.00      1.00         5
          85       0.80      1.00      0.89         4
          86       0.43      0.60      0.50         5
          87       0.67      0.80      0.73         5
          88       0.80      1.00      0.89         4
          89       0.75      0.75      0.75         4
          90       0.88      0.78      0.82         9
          91       0.00      0.00      0.00         5
          92       1.00      0.50      0.67         4
          93       1.00      0.25      0.40         4
          94       0.73      0.89      0.80         9
          95       0.00      0.00      0.00         4
          96       0.80      1.00      0.89         4
          97       0.00      0.00      0.00         9
          98       0.00      0.00      0.00         4
          99       1.00      0.25      0.40         4
         100       1.00      0.78      0.88         9
         101       1.00      0.75      0.86         4
         102       1.00      1.00      1.00         5
         103       0.40      0.50      0.44         4
         104       1.00      1.00      1.00         4
         105       1.00      0.75      0.86         4
         106       0.57      1.00      0.73         4
         107       0.14      1.00      0.24         4
         108       0.67      0.80      0.73         5
         109       0.64      0.78      0.70         9
         110       0.50      0.40      0.44         5
         111       0.00      0.00      0.00         4
         112       0.00      0.00      0.00         4
         113       0.50      0.25      0.33         4
         114       0.64      0.78      0.70         9
         115       0.80      1.00      0.89         4
         116       0.86      0.67      0.75         9
         117       0.60      0.75      0.67         4
         118       1.00      1.00      1.00         4
         119       0.67      0.89      0.76         9
         120       0.33      0.75      0.46         4
         121       1.00      0.80      0.89         5
         122       1.00      1.00      1.00         5
         123       0.82      1.00      0.90         9
         124       0.80      1.00      0.89         4
         125       1.00      0.78      0.88         9
         126       0.75      0.75      0.75         4
         127       0.00      0.00      0.00         4
         128       0.00      0.00      0.00         4
         129       0.83      1.00      0.91         5
         130       0.29      0.50      0.36         4
         131       0.89      0.89      0.89         9
         132       0.00      0.00      0.00         4
         133       0.80      0.50      0.62         8
         134       0.00      0.00      0.00         9
         135       0.00      0.00      0.00         4
         136       0.75      0.75      0.75         4
         137       0.50      0.75      0.60         4
         138       0.90      1.00      0.95         9
         139       1.00      0.75      0.86         4
         140       0.86      0.67      0.75         9
         141       1.00      0.60      0.75         5
         142       0.70      0.78      0.74         9
         143       0.82      1.00      0.90         9
         144       0.33      0.25      0.29         4
         145       0.00      0.00      0.00         4
         146       0.75      0.75      0.75         4
         147       0.00      0.00      0.00         4
         148       0.75      0.75      0.75         4
         149       0.67      0.50      0.57         4
         150       1.00      1.00      1.00         5
         151       0.60      0.75      0.67         4
         152       0.69      1.00      0.82         9
         153       0.00      0.00      0.00         4
         154       1.00      1.00      1.00         4
         155       0.83      1.00      0.91         5
         156       0.90      1.00      0.95         9
         157       1.00      0.78      0.88         9
         158       0.15      1.00      0.27         4
         159       1.00      1.00      1.00         9
         160       0.67      0.80      0.73         5
         161       0.75      0.75      0.75         4
         162       0.67      1.00      0.80         4
         163       0.67      0.80      0.73         5
         164       1.00      1.00      1.00         5
         165       0.00      0.00      0.00         4
         166       1.00      0.75      0.86         4
         167       0.00      0.00      0.00         4
         168       1.00      0.78      0.88         9
         169       1.00      1.00      1.00         5
         170       1.00      0.75      0.86         4
         171       1.00      0.40      0.57         5
         172       0.00      0.00      0.00         4
         173       0.44      1.00      0.62         4
         174       1.00      1.00      1.00         9
         175       0.67      0.50      0.57         4
         176       1.00      0.20      0.33         5
         177       0.00      0.00      0.00         4
         178       0.69      1.00      0.82         9
         179       0.73      0.89      0.80         9
         180       0.82      1.00      0.90         9
         181       1.00      0.25      0.40         4
         182       1.00      0.50      0.67         4
         183       0.67      0.80      0.73         5
         184       1.00      1.00      1.00         4
         185       0.80      1.00      0.89         4
         186       0.23      0.75      0.35         4
         187       1.00      1.00      1.00         4
         188       1.00      0.60      0.75         5
         189       1.00      0.50      0.67         4
         190       0.67      0.50      0.57         4
         191       1.00      1.00      1.00         5
         192       0.00      0.00      0.00         4
         193       0.80      1.00      0.89         4
         194       0.00      0.00      0.00         4
         195       0.00      0.00      0.00         5
         196       0.67      0.50      0.57         4
         197       0.90      1.00      0.95         9
         198       1.00      1.00      1.00         4
         199       0.00      0.00      0.00         4
         200       0.80      0.89      0.84         9
         201       0.00      0.00      0.00         4
         202       0.80      1.00      0.89         4
         203       0.67      1.00      0.80         4
         204       0.36      1.00      0.53         4
         205       0.60      0.75      0.67         4
         206       0.67      0.80      0.73         5
         207       0.38      0.60      0.46         5
         208       1.00      0.75      0.86         4
         209       0.10      0.75      0.18         4
         210       0.75      0.67      0.71         9
         211       0.90      1.00      0.95         9
         212       0.00      0.00      0.00         4
         213       0.83      1.00      0.91         5
         214       1.00      1.00      1.00         4
         215       1.00      0.40      0.57         5
         216       0.90      1.00      0.95         9
         217       0.00      0.00      0.00         4
         218       0.00      0.00      0.00         4
         219       0.00      0.00      0.00         4
         220       0.33      0.25      0.29         4
         221       1.00      1.00      1.00         5
         222       1.00      0.40      0.57         5
         223       1.00      1.00      1.00         4
         224       1.00      1.00      1.00         9
         225       0.70      0.78      0.74         9
         226       0.82      1.00      0.90         9
         227       1.00      1.00      1.00         4
         228       0.60      1.00      0.75         9
         229       0.29      0.50      0.36         4
         230       0.88      0.78      0.82         9
         231       1.00      1.00      1.00         5
         232       0.00      0.00      0.00         4
         233       1.00      0.80      0.89         5
         234       0.00      0.00      0.00         4
         235       0.80      1.00      0.89         4
         236       1.00      1.00      1.00         5
         237       0.50      0.78      0.61         9
         238       0.00      0.00      0.00         4
         239       0.67      1.00      0.80         4
         240       1.00      1.00      1.00         4
         241       1.00      0.80      0.89         5
         242       1.00      1.00      1.00         5
         243       0.57      0.80      0.67         5
         244       0.80      1.00      0.89         4
         245       0.75      0.75      0.75         4
         246       0.00      0.00      0.00         4
         247       1.00      0.75      0.86         4
         248       0.82      1.00      0.90         9
         249       0.00      0.00      0.00         4
         250       0.75      1.00      0.86         9
         251       1.00      1.00      1.00         9
         252       0.80      1.00      0.89         4
         253       0.50      0.25      0.33         4
         254       1.00      0.11      0.20         9
         255       1.00      0.50      0.67         4
         256       0.89      0.89      0.89         9
         257       1.00      0.75      0.86         4
         258       0.00      0.00      0.00         4
         259       0.80      0.80      0.80         5
         260       0.00      0.00      0.00         4
         261       0.71      1.00      0.83         5
         262       0.00      0.00      0.00         9
         263       0.88      0.78      0.82         9
         264       0.00      0.00      0.00         4
         265       0.70      0.78      0.74         9
         266       1.00      1.00      1.00         4
         267       0.73      0.89      0.80         9
         268       0.50      0.25      0.33         4
         269       1.00      1.00      1.00         4
         270       0.80      1.00      0.89         4
         271       1.00      1.00      1.00         5
         272       1.00      0.80      0.89         5
         273       0.71      1.00      0.83         5
         274       0.00      0.00      0.00         4
         275       0.38      0.75      0.50         4
         276       0.67      1.00      0.80         4
         277       0.80      1.00      0.89         4
         278       0.67      0.40      0.50         5
         279       0.67      0.44      0.53         9
         280       0.00      0.00      0.00         4
         281       0.67      0.44      0.53         9
         282       0.50      0.50      0.50         4
         283       0.62      0.56      0.59         9
         284       1.00      1.00      1.00         4
         285       0.36      0.44      0.40         9
         286       1.00      0.78      0.88         9
         287       0.00      0.00      0.00         4
         288       0.00      0.00      0.00         4
         289       0.86      0.67      0.75         9
         290       0.67      0.22      0.33         9
         291       0.14      1.00      0.25         4
         292       0.57      0.44      0.50         9
         293       0.69      1.00      0.82         9
         294       0.46      0.67      0.55         9
         295       1.00      1.00      1.00         5
         296       1.00      0.75      0.86         4
         297       0.25      0.75      0.38         4
         298       1.00      1.00      1.00         4
         299       0.64      0.78      0.70         9
         300       1.00      1.00      1.00         4
         301       1.00      0.25      0.40         4
         302       0.83      1.00      0.91         5
         303       0.00      0.00      0.00         4
         304       1.00      1.00      1.00         9
         305       0.56      1.00      0.71         5
         306       0.88      0.78      0.82         9
         307       0.75      0.75      0.75         4
         308       1.00      0.80      0.89         5
         309       0.75      0.75      0.75         4
         310       0.80      1.00      0.89         4
         311       0.00      0.00      0.00         4
         312       0.64      0.78      0.70         9
         313       0.00      0.00      0.00         4
         314       0.25      0.50      0.33         4
         315       1.00      0.75      0.86         4
         316       0.71      1.00      0.83         5
         317       0.80      1.00      0.89         4
         318       1.00      0.50      0.67         4
         319       1.00      1.00      1.00         4
         320       1.00      1.00      1.00         5
         321       0.00      0.00      0.00         4
         322       0.60      0.60      0.60         5
         323       0.50      0.75      0.60         4
         324       0.75      0.67      0.71         9
         325       0.00      0.00      0.00         9
         326       0.00      0.00      0.00         4
         327       0.80      1.00      0.89         4
         328       1.00      1.00      1.00         9
         329       0.90      1.00      0.95         9
         330       0.00      0.00      0.00         5
         331       0.29      0.50      0.36         4
         332       0.80      0.80      0.80         5
         333       0.00      0.00      0.00         4
         334       0.60      0.75      0.67         4
         335       1.00      1.00      1.00         4
         336       0.62      1.00      0.77         5
         337       0.00      0.00      0.00         4
         338       0.75      0.60      0.67         5
         339       0.00      0.00      0.00         4
         340       0.33      0.50      0.40         4
         341       0.73      0.89      0.80         9
         342       0.00      0.00      0.00         4
         343       0.67      1.00      0.80         4
         344       0.69      1.00      0.82         9
         345       1.00      1.00      1.00         5
         346       1.00      0.78      0.88         9
         347       0.80      1.00      0.89         4
         348       0.86      0.67      0.75         9
         349       0.60      0.60      0.60         5
         350       0.00      0.00      0.00         4
         351       0.88      0.78      0.82         9
         352       0.75      0.75      0.75         4
         353       0.89      0.89      0.89         9
         354       1.00      0.67      0.80         9
         355       0.80      0.80      0.80         5
         356       1.00      1.00      1.00         4
         357       0.17      0.25      0.20         4
         358       1.00      0.80      0.89         5
         359       0.62      1.00      0.77         5
         360       1.00      0.25      0.40         4
         361       0.33      0.25      0.29         4
         362       1.00      0.50      0.67         4
         363       1.00      1.00      1.00         9
         364       1.00      0.75      0.86         4
         365       0.75      0.75      0.75         4
         366       0.44      0.80      0.57         5
         367       0.33      0.25      0.29         4
         368       0.71      1.00      0.83         5
         369       0.57      1.00      0.73         4
         370       0.00      0.00      0.00         4
         371       0.56      0.56      0.56         9
         372       0.80      0.89      0.84         9
         373       0.80      0.44      0.57         9
         374       0.00      0.00      0.00         4
         375       0.67      0.50      0.57         4
         376       1.00      1.00      1.00         4
         377       1.00      0.25      0.40         4
         378       1.00      1.00      1.00         9
         379       0.00      0.00      0.00         4
         380       1.00      0.80      0.89         5
         381       1.00      1.00      1.00         5
         382       0.80      1.00      0.89         4
         383       0.50      1.00      0.67         4
         384       0.00      0.00      0.00         4
         385       0.17      0.60      0.26         5
         386       1.00      1.00      1.00         9
         387       1.00      0.25      0.40         4
         388       0.60      0.60      0.60         5
         389       0.90      1.00      0.95         9
         390       1.00      1.00      1.00         4
         391       1.00      0.75      0.86         4
         392       0.29      0.50      0.36         4
         393       0.80      1.00      0.89         4
         394       1.00      0.78      0.88         9
         395       1.00      1.00      1.00         9
         396       0.00      0.00      0.00         4
         397       0.67      0.50      0.57         4
         398       1.00      0.67      0.80         9
         399       0.50      0.75      0.60         4
         400       0.80      1.00      0.89         4
         401       1.00      1.00      1.00         4
         402       1.00      0.75      0.86         4
         403       0.00      0.00      0.00         4
         404       1.00      1.00      1.00         4
         405       0.86      0.67      0.75         9
         406       0.00      0.00      0.00         4
         407       0.80      1.00      0.89         4
         408       1.00      0.75      0.86         4
         409       0.60      0.67      0.63         9
         410       0.40      0.50      0.44         4
         411       1.00      1.00      1.00         4
         412       1.00      1.00      1.00         4
         413       0.50      0.75      0.60         4
         414       0.57      1.00      0.73         4
         415       1.00      1.00      1.00         4
         416       0.00      0.00      0.00         4
         417       0.82      1.00      0.90         9
         418       0.58      0.78      0.67         9
         419       1.00      0.75      0.86         4
         420       0.50      0.25      0.33         4
         421       1.00      0.43      0.60         7
         422       1.00      0.50      0.67         4
         423       0.75      0.75      0.75         4
         424       0.40      1.00      0.57         4
         425       0.67      0.50      0.57         4
         426       0.00      0.00      0.00         4
         427       1.00      1.00      1.00         4
         428       0.00      0.00      0.00         4
         429       0.69      1.00      0.82         9
         430       1.00      1.00      1.00         4
         431       0.67      0.67      0.67         9
         432       0.31      0.56      0.40         9
         433       1.00      0.78      0.88         9
         434       1.00      0.25      0.40         4
         435       0.64      0.78      0.70         9
         436       0.75      1.00      0.86         9
         437       0.75      0.75      0.75         4
         438       1.00      1.00      1.00         4
         439       0.80      0.89      0.84         9
         440       0.44      0.78      0.56         9
         441       0.80      0.80      0.80         5
         442       1.00      0.78      0.88         9
         443       0.82      1.00      0.90         9
         444       1.00      0.22      0.36         9
         445       1.00      0.56      0.71         9
         446       0.00      0.00      0.00         4
         447       1.00      1.00      1.00         5
         448       0.00      0.00      0.00         4
         449       0.75      0.75      0.75         4
         450       1.00      1.00      1.00         5
         451       1.00      0.75      0.86         4
         452       1.00      0.75      0.86         4
         453       1.00      0.50      0.67         4
         454       0.90      1.00      0.95         9
         455       0.50      0.75      0.60         4
         456       1.00      0.75      0.86         4
         457       0.00      0.00      0.00         4
         458       1.00      0.75      0.86         4
         459       1.00      0.75      0.86         4
         460       1.00      1.00      1.00         9
         461       0.73      0.89      0.80         9
         462       0.00      0.00      0.00         4
         463       0.67      0.67      0.67         9
         464       0.80      0.89      0.84         9
         465       0.00      0.00      0.00         4
         466       0.82      1.00      0.90         9
         467       1.00      0.75      0.86         4
         468       0.67      0.80      0.73         5
         469       0.64      1.00      0.78         9
         470       0.00      0.00      0.00         4
         471       0.70      0.78      0.74         9
         472       1.00      1.00      1.00         9
         473       0.50      0.60      0.55         5
         474       0.25      0.20      0.22         5
         475       0.30      0.60      0.40         5
         476       0.50      0.25      0.33         4
         477       1.00      0.67      0.80         9
         478       0.80      0.89      0.84         9
         479       0.40      0.80      0.53         5
         480       0.50      0.25      0.33         4
         481       1.00      0.75      0.86         4
         482       0.00      0.00      0.00         4
         483       1.00      1.00      1.00         9
         484       1.00      1.00      1.00         4
         485       0.80      1.00      0.89         4
         486       0.75      1.00      0.86         9
         487       0.80      1.00      0.89         4
         488       1.00      1.00      1.00         5
         489       0.67      0.50      0.57         4
         490       0.00      0.00      0.00         4
         491       0.80      1.00      0.89         4
         492       0.00      0.00      0.00         4
         493       0.00      0.00      0.00         4
         494       0.67      0.50      0.57         4
         495       0.80      1.00      0.89         4
         496       1.00      0.75      0.86         4
         497       0.60      1.00      0.75         9
         498       1.00      0.40      0.57         5
         499       0.57      1.00      0.73         4
         500       0.00      0.00      0.00         9
         501       0.75      1.00      0.86         9
         502       0.67      0.50      0.57         4
         503       0.67      1.00      0.80         4
         504       0.60      0.75      0.67         4
         505       0.00      0.00      0.00         4
         506       0.12      0.75      0.21         4
         507       1.00      0.50      0.67         4
         508       0.60      0.60      0.60         5
         509       0.56      1.00      0.71         5
         510       0.73      0.89      0.80         9
         511       0.80      1.00      0.89         4
         512       0.40      0.50      0.44         4
         513       1.00      1.00      1.00         4
         514       0.60      1.00      0.75         9
         515       0.30      0.75      0.43         4
         516       0.40      0.50      0.44         4
         517       0.71      1.00      0.83         5
         518       0.08      0.11      0.09         9
         519       0.83      1.00      0.91         5
         520       1.00      0.60      0.75         5
         521       0.40      0.50      0.44         4
         522       0.00      0.00      0.00         4
         523       1.00      1.00      1.00         4
         524       0.00      0.00      0.00         4
         525       1.00      0.75      0.86         4
         526       1.00      1.00      1.00         5
         527       0.36      1.00      0.53         4
         528       0.80      0.80      0.80         5
         529       1.00      0.60      0.75         5
         530       0.90      1.00      0.95         9
         531       0.00      0.00      0.00         4
         532       1.00      0.20      0.33         5
         533       0.00      0.00      0.00         4
         534       1.00      0.67      0.80         9
         535       1.00      0.89      0.94         9
         536       0.00      0.00      0.00         4
         537       0.00      0.00      0.00         4
         538       1.00      0.25      0.40         4
         539       1.00      1.00      1.00         5
         540       0.46      0.67      0.55         9
         541       0.00      0.00      0.00         9
         542       1.00      1.00      1.00         4
         543       1.00      0.60      0.75         5
         544       0.00      0.00      0.00         4
         545       0.80      0.89      0.84         9
         546       0.50      0.50      0.50         4
         547       0.00      0.00      0.00         9
         548       0.90      1.00      0.95         9
         549       0.12      0.25      0.17         4
         550       1.00      1.00      1.00         9
         551       0.80      0.89      0.84         9
         552       0.83      1.00      0.91         5
         553       1.00      0.67      0.80         9
         554       1.00      1.00      1.00         4
         555       0.80      1.00      0.89         4
         556       1.00      0.25      0.40         4
         557       0.12      1.00      0.21         4
         558       0.67      1.00      0.80         4
         559       1.00      0.75      0.86         4
         560       0.60      0.75      0.67         4
         561       0.13      1.00      0.24         4
         562       0.00      0.00      0.00         4
         563       1.00      1.00      1.00         9
         564       1.00      1.00      1.00         4
         565       0.71      1.00      0.83         5
         566       0.00      0.00      0.00         4
         567       0.00      0.00      0.00         4
         568       1.00      0.50      0.67         4
         569       0.40      0.44      0.42         9
         570       0.12      0.75      0.21         4
         571       1.00      1.00      1.00         4
         572       0.80      0.89      0.84         9
         573       0.75      0.60      0.67         5
         574       0.00      0.00      0.00         4
         575       0.75      0.75      0.75         4
         576       0.00      0.00      0.00         5
         577       0.80      0.89      0.84         9
         578       0.67      1.00      0.80         4
         579       0.15      1.00      0.26         4
         580       0.00      0.00      0.00         4
         581       1.00      0.71      0.83         7
         582       1.00      1.00      1.00         8
         583       0.67      0.50      0.57         4
         584       0.57      1.00      0.73         4
         585       0.43      0.75      0.55         4
         586       0.26      1.00      0.42         5
         587       0.44      0.44      0.44         9
         588       0.90      1.00      0.95         9
         589       0.50      0.60      0.55         5
         590       0.00      0.00      0.00         4
         591       1.00      0.75      0.86         4
         592       0.80      1.00      0.89         4
         593       0.67      1.00      0.80         4
         594       1.00      0.89      0.94         9
         595       1.00      0.22      0.36         9
         596       0.62      0.89      0.73         9
         597       0.67      0.80      0.73         5
         598       0.33      0.20      0.25         5
         599       0.00      0.00      0.00         4
         600       1.00      0.78      0.88         9
         601       0.67      0.80      0.73         5
         602       0.80      1.00      0.89         4
         603       0.00      0.00      0.00         4
         604       0.00      0.00      0.00         9
         605       0.90      1.00      0.95         9
         606       0.67      0.50      0.57         4
         607       0.80      1.00      0.89         4
         608       0.82      1.00      0.90         9
         609       0.50      0.75      0.60         4
         610       0.42      0.89      0.57         9
         611       1.00      1.00      1.00         5
         612       0.90      1.00      0.95         9
         613       0.00      0.00      0.00         4
         614       0.00      0.00      0.00         4
         615       1.00      0.75      0.86         4
         616       0.00      0.00      0.00         4
         617       0.80      1.00      0.89         4
         618       0.71      1.00      0.83         5
         619       0.89      0.89      0.89         9
         620       1.00      0.50      0.67         4
         621       0.75      0.60      0.67         5
         622       0.80      1.00      0.89         4
         623       0.80      0.89      0.84         9
         624       0.57      1.00      0.73         4
         625       0.00      0.00      0.00         4
         626       1.00      0.89      0.94         9
         627       1.00      0.50      0.67         4
         628       0.67      1.00      0.80         4
         629       1.00      0.78      0.88         9
         630       0.00      0.00      0.00         4
         631       1.00      1.00      1.00         4
         632       1.00      0.78      0.88         9
         633       0.71      0.56      0.63         9
         634       1.00      0.75      0.86         4
         635       0.33      0.20      0.25         5
         636       1.00      1.00      1.00         5
         637       1.00      0.89      0.94         9
         638       1.00      1.00      1.00         4
         639       0.00      0.00      0.00         4
         640       0.09      0.75      0.16         4
         641       0.25      0.20      0.22         5
         642       1.00      0.78      0.88         9
         643       0.00      0.00      0.00         9
         644       0.60      0.75      0.67         4
         645       0.20      0.25      0.22         4
         646       1.00      1.00      1.00         9
         647       0.80      0.80      0.80         5
         648       0.80      1.00      0.89         4
         649       0.50      1.00      0.67         4
         650       1.00      0.75      0.86         4
         651       1.00      0.75      0.86         4
         652       1.00      0.22      0.36         9
         653       0.56      1.00      0.71         5
         654       0.00      0.00      0.00         4
         655       0.00      0.00      0.00         4
         656       0.88      0.78      0.82         9
         657       1.00      1.00      1.00         4
         658       0.67      0.80      0.73         5
         659       1.00      0.11      0.20         9
         660       0.83      1.00      0.91         5
         661       0.90      1.00      0.95         9
         662       0.00      0.00      0.00         4
         663       1.00      0.75      0.86         4
         664       0.00      0.00      0.00         9
         665       1.00      1.00      1.00         5
         666       0.00      0.00      0.00         4
         667       0.57      1.00      0.73         4
         668       0.78      0.78      0.78         9
         669       0.90      1.00      0.95         9
         670       1.00      1.00      1.00         4
         671       1.00      0.80      0.89         5
         672       1.00      1.00      1.00         4
         673       0.00      0.00      0.00         4
         674       0.82      1.00      0.90         9
         675       0.60      0.75      0.67         4
         676       0.50      1.00      0.67         4
         677       0.75      0.75      0.75         4
         678       0.13      0.75      0.22         4
         679       0.90      1.00      0.95         9
         680       1.00      1.00      1.00         4
         681       0.00      0.00      0.00         4
         682       0.08      0.25      0.12         4
         683       0.57      1.00      0.73         4
         684       1.00      1.00      1.00         8
         685       0.71      1.00      0.83         5
         686       0.67      0.89      0.76         9
         687       1.00      1.00      1.00         4
         688       1.00      1.00      1.00         9
         689       0.33      0.75      0.46         4
         690       1.00      0.50      0.67         4
         691       1.00      0.80      0.89         5
         692       0.00      0.00      0.00         4
         693       0.00      0.00      0.00         4
         694       1.00      1.00      1.00         5
         695       0.00      0.00      0.00         4
         696       0.75      0.75      0.75         4
         697       0.83      1.00      0.91         5
         698       0.80      1.00      0.89         4
         699       0.78      0.78      0.78         9
         700       0.80      1.00      0.89         4
         701       0.78      0.78      0.78         9
         702       1.00      0.50      0.67         4
         703       0.60      0.75      0.67         4
         704       1.00      1.00      1.00         4
         705       0.57      1.00      0.73         4
         706       0.09      0.56      0.16         9
         707       0.00      0.00      0.00         4
         708       1.00      1.00      1.00         4
         709       1.00      0.25      0.40         4
         710       1.00      1.00      1.00         4
         711       0.89      0.89      0.89         9
         712       1.00      1.00      1.00         4
         713       0.80      1.00      0.89         4
         714       1.00      0.67      0.80         9
         715       0.50      0.60      0.55         5
         716       1.00      0.50      0.67         4
         717       0.90      1.00      0.95         9
         718       1.00      0.50      0.67         4
         719       1.00      1.00      1.00         9
         720       0.88      0.78      0.82         9
         721       1.00      1.00      1.00         5
         722       0.80      1.00      0.89         4
         723       0.00      0.00      0.00         4
         724       0.00      0.00      0.00         4
         725       0.75      0.75      0.75         4
         726       0.70      0.78      0.74         9
         727       1.00      1.00      1.00         5
         728       0.50      1.00      0.67         5
         729       0.90      1.00      0.95         9
         730       1.00      0.75      0.86         4
         731       0.80      0.80      0.80         5
         732       0.14      0.75      0.23         4
         733       0.73      0.89      0.80         9
         734       1.00      0.89      0.94         9
         735       0.78      0.78      0.78         9
         736       0.50      0.50      0.50         4
         737       0.62      1.00      0.77         5
         738       1.00      1.00      1.00         4
         739       1.00      0.40      0.57         5
         740       1.00      0.60      0.75         5
         741       1.00      0.25      0.40         4
         742       1.00      0.75      0.86         4
         743       0.00      0.00      0.00         4
         744       0.62      0.89      0.73         9
         745       1.00      1.00      1.00         4
         746       0.00      0.00      0.00         4
         747       0.67      0.50      0.57         4
         748       0.83      0.56      0.67         9
         749       1.00      1.00      1.00         4
         750       0.57      1.00      0.73         4
         751       1.00      0.60      0.75         5
         752       0.89      0.89      0.89         9
         753       0.00      0.00      0.00         4
         754       0.47      0.78      0.58         9
         755       1.00      1.00      1.00         4
         756       0.67      1.00      0.80         4
         757       0.57      1.00      0.73         4
         758       0.43      0.75      0.55         4
         759       0.75      0.75      0.75         4
         760       0.00      0.00      0.00         4
         761       0.60      0.75      0.67         4
         762       0.80      1.00      0.89         4
         763       0.50      1.00      0.67         4
         764       1.00      0.50      0.67         4
         765       0.17      0.11      0.13         9
         766       0.40      1.00      0.57         4
         767       0.00      0.00      0.00         4
         768       0.53      0.89      0.67         9
         769       1.00      0.80      0.89         5
         770       0.00      0.00      0.00         4
         771       0.36      1.00      0.53         4
         772       1.00      0.56      0.71         9
         773       0.00      0.00      0.00         4
         774       0.75      1.00      0.86         9
         775       0.00      0.00      0.00         4
         776       0.00      0.00      0.00         4
         777       0.89      0.89      0.89         9
         778       0.50      0.75      0.60         4
         779       1.00      0.44      0.62         9
         780       0.00      0.00      0.00         4
         781       0.62      0.56      0.59         9
         782       0.00      0.00      0.00         4
         783       0.00      0.00      0.00         4
         784       0.80      0.80      0.80         5
         785       0.50      0.75      0.60         4
         786       0.75      1.00      0.86         9
         787       1.00      0.89      0.94         9
         788       0.00      0.00      0.00         9
         789       0.50      0.25      0.33         4
         790       1.00      0.75      0.86         4
         791       0.80      0.89      0.84         9
         792       1.00      0.25      0.40         4
         793       1.00      0.56      0.71         9
         794       0.80      1.00      0.89         4
         795       0.80      0.89      0.84         9
         796       0.00      0.00      0.00         4
         797       1.00      1.00      1.00         5
         798       0.80      1.00      0.89         4
         799       0.00      0.00      0.00         4
         800       0.83      1.00      0.91         5
         801       0.40      0.50      0.44         4
         802       0.40      0.80      0.53         5
         803       0.62      0.56      0.59         9
         804       0.80      1.00      0.89         4
         805       1.00      0.78      0.88         9
         806       1.00      1.00      1.00         4
         807       0.00      0.00      0.00         9
         808       0.00      0.00      0.00         4
         809       1.00      1.00      1.00         5
         810       0.86      0.67      0.75         9
         811       0.13      0.75      0.22         4
         812       1.00      1.00      1.00         4
         813       1.00      1.00      1.00         4
         814       0.00      0.00      0.00         4
         815       0.60      0.75      0.67         4
         816       0.80      1.00      0.89         4
         817       1.00      0.75      0.86         4
         818       0.50      0.25      0.33         4
         819       0.50      1.00      0.67         4
         820       0.00      0.00      0.00         9
         821       0.25      0.25      0.25         4
         822       0.00      0.00      0.00         4
         823       0.00      0.00      0.00         4
         824       1.00      0.75      0.86         4
         825       1.00      1.00      1.00         4
         826       0.33      0.40      0.36         5
         827       1.00      1.00      1.00         9
         828       1.00      0.50      0.67         4
         829       0.00      0.00      0.00         4
         830       1.00      0.80      0.89         5
         831       0.00      0.00      0.00         4
         832       0.88      0.78      0.82         9
         833       0.00      0.00      0.00         4
         834       1.00      0.33      0.50         6
         835       0.67      1.00      0.80         4
         836       0.43      0.60      0.50         5
         837       0.64      0.78      0.70         9
         838       1.00      1.00      1.00         4
         839       0.00      0.00      0.00         4
         840       0.44      0.44      0.44         9
         841       0.80      0.80      0.80         5
         842       0.00      0.00      0.00         9
         843       0.60      0.75      0.67         4
         844       1.00      0.20      0.33         5
         845       1.00      0.33      0.50         9
         846       0.80      1.00      0.89         4
         847       1.00      1.00      1.00         4
         848       0.80      1.00      0.89         4
         849       0.00      0.00      0.00         4
         850       0.67      1.00      0.80         4
         851       0.00      0.00      0.00         4
         852       0.00      0.00      0.00         4
         853       1.00      1.00      1.00         4
         854       1.00      0.40      0.57         5
         855       0.50      1.00      0.67         4
         856       0.00      0.00      0.00         4
         857       0.75      0.75      0.75         4
         858       1.00      0.67      0.80         9
         859       1.00      0.60      0.75         5
         860       0.50      0.20      0.29         5
         861       1.00      1.00      1.00         9
         862       0.80      1.00      0.89         4
         863       1.00      0.50      0.67         4
         864       0.80      0.89      0.84         9
         865       1.00      0.71      0.83         7
         866       0.80      1.00      0.89         4
         867       0.00      0.00      0.00         4
         868       0.00      0.00      0.00         4
         869       1.00      1.00      1.00         5
         870       0.75      0.75      0.75         4
         871       0.56      1.00      0.71         5
         872       0.75      0.60      0.67         5
         873       0.83      1.00      0.91         5
         874       0.75      0.75      0.75         4
         875       0.00      0.00      0.00         4
         876       0.10      0.11      0.11         9
         877       1.00      1.00      1.00         4
         878       0.00      0.00      0.00         4
         879       0.80      1.00      0.89         4
         880       0.53      0.89      0.67         9
         881       0.89      0.89      0.89         9
         882       1.00      0.56      0.71         9
         883       0.75      0.75      0.75         4
         884       1.00      0.80      0.89         5
         885       0.75      0.60      0.67         5
         886       0.88      0.78      0.82         9
         887       0.00      0.00      0.00         4
         888       0.00      0.00      0.00         4
         889       0.75      1.00      0.86         9
         890       0.57      1.00      0.73         4
         891       0.50      0.25      0.33         4
         892       0.00      0.00      0.00         4
         893       0.50      0.75      0.60         4

    accuracy                           0.67      4917
   macro avg       0.63      0.64      0.61      4917
weighted avg       0.66      0.67      0.64      4917

task_train_time: {0: 0.1178910559999995, 1: 0.03234800000000071, 2: 0.024525331999999622, 3: 0.033814503999998635, 4: 0.02882618099999945, 5: 0.03227920500000003, 6: 0.03044140899999981, 7: 0.030330300999999338, 8: 0.02991091300000015, 9: 0.029330235999999843, 10: 0.03279939300000123, 11: 0.030373840999999402, 12: 0.03395996800000134, 13: 0.036436674000000835, 14: 0.03037572699999913, 15: 0.030999786999998946, 16: 0.031228904999998974, 17: 0.032455322000000564, 18: 0.028984031000000243, 19: 0.03021432300000093, 20: 0.03304276799999961, 21: 0.03630792700000107, 22: 0.037492250999999754, 23: 0.02993508999999861, 24: 0.030824975999999893, 25: 0.027943899000000272, 26: 0.039139870999999715, 27: 0.027727696000001245, 28: 0.030418054000000083, 29: 0.037765170000000126, 30: 0.032012503999999, 31: 0.032033814999998356, 32: 0.032948167999999, 33: 0.031500726999999173, 34: 0.02914903599999974, 35: 0.03432762000000089, 36: 0.03422650499999946, 37: 0.02865235499999841, 38: 0.039419707000000415, 39: 0.032081111000000107, 40: 0.029630677000000105, 41: 0.030774011999998407, 42: 0.030344908000000004, 43: 0.0338358449999987}
prediction_time: 0.0002614600000008238
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
