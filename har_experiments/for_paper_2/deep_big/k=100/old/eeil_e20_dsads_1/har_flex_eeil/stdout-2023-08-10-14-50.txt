	dataset_config: {'path': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'path_test': '/home/fr27/Documents/pyscript/har/DSADS/dsads.mat', 'resize': None, 'pad': None, 'crop': None, 'normalize': None, 'class_order': None, 'extend_channel': None, 'flip': False}
CLASS_ORDER: [50, 131, 62, 60, 86, 69, 23, 121, 3, 96, 95, 136, 124, 125, 52, 57, 132, 14, 0, 38, 53, 83, 119, 8, 19, 115, 7, 64, 142, 77, 1, 149, 151, 133, 89, 67, 2, 51, 111, 107, 34, 11, 114, 22, 108, 85, 72, 100, 80, 112, 20, 87, 143, 71, 104, 12, 24, 33, 4, 75, 130, 43, 32, 117, 88, 10, 101, 98, 105, 120, 54, 63, 74, 126, 134, 61, 37, 122, 147, 21, 42, 41, 27, 146, 138, 145, 46, 128, 113, 18, 59, 31, 140, 36, 94, 79, 58, 40, 68, 5, 66, 78, 47, 116, 150, 139, 55, 127, 6, 26, 29, 28, 56, 35, 109, 123, 48, 30, 15, 148, 103, 81, 106, 141, 70, 135, 102, 82, 73, 45, 90, 16, 91, 93, 13, 84, 49, 137, 97, 25, 39, 144, 9, 110, 65, 129, 118, 76, 99, 92, 44, 17]
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList()
)
======

************************************************************************************************************
Task  0
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=2.452, TAw acc= 34.8% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.422, TAw acc= 34.8% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.381, TAw acc= 38.3% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.345, TAw acc= 47.8% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.307, TAw acc= 46.1% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.250, TAw acc= 45.2% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=2.205, TAw acc= 36.5% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.157, TAw acc= 35.7% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.119, TAw acc= 34.8% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.043, TAw acc= 40.0% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.989, TAw acc= 36.5% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.930, TAw acc= 35.7% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.878, TAw acc= 36.5% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.834, TAw acc= 40.0% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.773, TAw acc= 43.5% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.717, TAw acc= 42.6% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.653, TAw acc= 55.7% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.615, TAw acc= 62.6% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.557, TAw acc= 60.9% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.508, TAw acc= 49.6% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 412 train exemplars, time=  0.0s
412
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.453 | TAw acc= 56.2%, forg=  0.0%| TAg acc= 56.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
  )
)
======

************************************************************************************************************
Task  1
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.998, TAw acc= 28.1% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.848, TAw acc= 29.2% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.761, TAw acc= 35.4% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.660, TAw acc= 39.6% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.562, TAw acc= 55.2% | *
| Epoch   6, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.472, TAw acc= 52.1% | *
| Epoch   7, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.396, TAw acc= 47.9% | *
| Epoch   8, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.327, TAw acc= 49.0% | *
| Epoch   9, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.267, TAw acc= 50.0% | *
| Epoch  10, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.209, TAw acc= 57.3% | *
| Epoch  11, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.151, TAw acc= 54.2% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.099, TAw acc= 55.2% | *
| Epoch  13, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.055, TAw acc= 69.8% | *
| Epoch  14, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.993, TAw acc= 69.8% | *
| Epoch  15, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.951, TAw acc= 59.4% | *
| Epoch  16, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.894, TAw acc= 70.8% | *
| Epoch  17, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.852, TAw acc= 71.9% | *
| Epoch  18, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.828, TAw acc= 72.9% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.779, TAw acc= 71.9% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.750, TAw acc= 74.0% | *
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.749, TAw acc= 74.0% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.748, TAw acc= 74.0% | *
| Epoch   3, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.746, TAw acc= 74.0% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.745, TAw acc= 74.0% | *
| Epoch   5, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.744, TAw acc= 74.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 752 train exemplars, time=  0.0s
752
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.322 | TAw acc= 88.9%, forg=-32.6%| TAg acc= 77.8%, forg=-21.5% <<<
>>> Test on task  1 : loss=1.727 | TAw acc= 76.7%, forg=  0.0%| TAg acc= 51.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  2
************************************************************************************************************
| Epoch   1, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=3.749, TAw acc= 16.7% | *
| Epoch   2, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=3.123, TAw acc= 17.7% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.765, TAw acc= 37.5% | *
| Epoch   4, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=2.564, TAw acc= 44.8% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.394, TAw acc= 53.1% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.307, TAw acc= 65.6% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.185, TAw acc= 67.7% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.047, TAw acc= 76.0% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.999, TAw acc= 75.0% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.926, TAw acc= 77.1% | *
| Epoch  11, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.849, TAw acc= 82.3% | *
| Epoch  12, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.785, TAw acc= 79.2% | *
| Epoch  13, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.746, TAw acc= 83.3% | *
| Epoch  14, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.689, TAw acc= 79.2% | *
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.560, TAw acc= 82.3% | *
| Epoch  16, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.551, TAw acc= 84.4% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.456, TAw acc= 84.4% | *
| Epoch  18, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.416, TAw acc= 83.3% | *
| Epoch  19, time=  0.2s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% | *
| Epoch  20, time=  0.2s | Train: skip eval | Valid: time=  0.2s loss=1.392, TAw acc= 83.3% |
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% |
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% |
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 87.5% |
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.361, TAw acc= 87.5% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1092 train exemplars, time=  0.0s
1092
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.191 | TAw acc= 91.7%, forg= -2.8%| TAg acc= 81.9%, forg= -4.2% <<<
>>> Test on task  1 : loss=1.470 | TAw acc= 85.8%, forg= -9.2%| TAg acc= 63.3%, forg=-11.7% <<<
>>> Test on task  2 : loss=1.419 | TAw acc= 88.3%, forg=  0.0%| TAg acc= 77.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  3
************************************************************************************************************
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=3.871, TAw acc= 29.2% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=3.055, TAw acc= 26.0% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.707, TAw acc= 49.0% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.554, TAw acc= 56.2% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.334, TAw acc= 65.6% | *
| Epoch   6, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.246, TAw acc= 65.6% | *
| Epoch   7, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=2.127, TAw acc= 65.6% | *
| Epoch   8, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=2.006, TAw acc= 67.7% | *
| Epoch   9, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.926, TAw acc= 76.0% | *
| Epoch  10, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.853, TAw acc= 80.2% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.3s loss=1.748, TAw acc= 81.2% | *
| Epoch  12, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.715, TAw acc= 80.2% | *
| Epoch  13, time=  0.5s | Train: skip eval | Valid: time=  0.3s loss=1.572, TAw acc= 88.5% | *
| Epoch  14, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.603, TAw acc= 71.9% |
| Epoch  15, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.546, TAw acc= 82.3% | *
| Epoch  16, time=  0.3s | Train: skip eval | Valid: time=  0.2s loss=1.478, TAw acc= 77.1% | *
| Epoch  17, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.429, TAw acc= 91.7% | *
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.387, TAw acc= 89.6% | *
| Epoch  19, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.363, TAw acc= 80.2% | *
| Epoch  20, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.333, TAw acc= 81.2% | *
| Epoch   1, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.333, TAw acc= 81.2% | *
| Epoch   2, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.332, TAw acc= 81.2% | *
| Epoch   3, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.331, TAw acc= 81.2% | *
| Epoch   4, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.331, TAw acc= 81.2% | *
| Epoch   5, time=  0.3s | Train: skip eval | Valid: time=  0.1s loss=1.330, TAw acc= 81.2% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1432 train exemplars, time=  0.0s
1432
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=1.030 | TAw acc= 92.4%, forg= -0.7%| TAg acc= 79.2%, forg=  2.8% <<<
>>> Test on task  1 : loss=1.266 | TAw acc= 93.3%, forg= -7.5%| TAg acc= 79.2%, forg=-15.8% <<<
>>> Test on task  2 : loss=1.158 | TAw acc= 95.0%, forg= -6.7%| TAg acc= 77.5%, forg=  0.0% <<<
>>> Test on task  3 : loss=1.350 | TAw acc= 88.3%, forg=  0.0%| TAg acc= 50.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  4
************************************************************************************************************
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=3.440, TAw acc= 34.4% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.809, TAw acc= 65.6% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=2.541, TAw acc= 49.0% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.394, TAw acc= 56.2% | *
| Epoch   5, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=2.173, TAw acc= 72.9% | *
| Epoch   6, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=2.181, TAw acc= 87.5% |
| Epoch   7, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=2.032, TAw acc= 90.6% | *
| Epoch   8, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.951, TAw acc= 77.1% | *
| Epoch   9, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.874, TAw acc= 80.2% | *
| Epoch  10, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.819, TAw acc= 83.3% | *
| Epoch  11, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.719, TAw acc= 83.3% | *
| Epoch  12, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.596, TAw acc= 80.2% | *
| Epoch  13, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.537, TAw acc= 91.7% | *
| Epoch  14, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.519, TAw acc= 83.3% | *
| Epoch  15, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.473, TAw acc= 84.4% | *
| Epoch  16, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.405, TAw acc= 81.2% | *
| Epoch  17, time=  0.4s | Train: skip eval | Valid: time=  0.2s loss=1.403, TAw acc= 88.5% | *
| Epoch  18, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.324, TAw acc= 90.6% | *
| Epoch  19, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.289, TAw acc= 97.9% | *
| Epoch  20, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.224, TAw acc= 96.9% | *
| Epoch   1, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.224, TAw acc= 96.9% | *
| Epoch   2, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.223, TAw acc= 96.9% | *
| Epoch   3, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.223, TAw acc= 96.9% | *
| Epoch   4, time=  0.4s | Train: skip eval | Valid: time=  0.1s loss=1.223, TAw acc= 95.8% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.223, TAw acc= 95.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 1772 train exemplars, time=  0.0s
1772
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.864 | TAw acc= 91.7%, forg=  0.7%| TAg acc= 82.6%, forg= -0.7% <<<
>>> Test on task  1 : loss=1.160 | TAw acc= 94.2%, forg= -0.8%| TAg acc= 74.2%, forg=  5.0% <<<
>>> Test on task  2 : loss=0.990 | TAw acc= 94.2%, forg=  0.8%| TAg acc= 79.2%, forg= -1.7% <<<
>>> Test on task  3 : loss=1.046 | TAw acc= 97.5%, forg= -9.2%| TAg acc= 74.2%, forg=-23.3% <<<
>>> Test on task  4 : loss=1.209 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 85.0%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  5
************************************************************************************************************
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=3.743, TAw acc= 34.4% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=2.760, TAw acc= 43.8% | *
| Epoch   3, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=2.478, TAw acc= 60.4% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=2.202, TAw acc= 84.4% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=2.007, TAw acc= 84.4% | *
| Epoch   6, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.976, TAw acc= 79.2% | *
| Epoch   7, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.836, TAw acc= 88.5% | *
| Epoch   8, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.724, TAw acc= 91.7% | *
| Epoch   9, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.627, TAw acc= 90.6% | *
| Epoch  10, time=  0.5s | Train: skip eval | Valid: time=  0.2s loss=1.574, TAw acc= 91.7% | *
| Epoch  11, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.452, TAw acc= 93.8% | *
| Epoch  12, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.476, TAw acc= 94.8% |
| Epoch  13, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.308, TAw acc= 92.7% | *
| Epoch  14, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.318, TAw acc= 93.8% |
| Epoch  15, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.263, TAw acc= 93.8% | *
| Epoch  16, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.293, TAw acc= 93.8% |
| Epoch  17, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.160, TAw acc= 93.8% | *
| Epoch  18, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.185, TAw acc= 93.8% |
| Epoch  19, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.146, TAw acc= 94.8% | *
| Epoch  20, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.160, TAw acc= 95.8% |
| Epoch   1, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.144, TAw acc= 94.8% | *
| Epoch   2, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.142, TAw acc= 94.8% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.140, TAw acc= 94.8% | *
| Epoch   4, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.139, TAw acc= 94.8% | *
| Epoch   5, time=  0.5s | Train: skip eval | Valid: time=  0.1s loss=1.138, TAw acc= 94.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2112 train exemplars, time=  0.0s
2112
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.808 | TAw acc= 94.4%, forg= -2.1%| TAg acc= 81.9%, forg=  0.7% <<<
>>> Test on task  1 : loss=1.114 | TAw acc= 95.8%, forg= -1.7%| TAg acc= 75.8%, forg=  3.3% <<<
>>> Test on task  2 : loss=0.906 | TAw acc= 95.0%, forg=  0.0%| TAg acc= 81.7%, forg= -2.5% <<<
>>> Test on task  3 : loss=0.921 | TAw acc= 97.5%, forg=  0.0%| TAg acc= 80.8%, forg= -6.7% <<<
>>> Test on task  4 : loss=0.878 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 93.3%, forg= -8.3% <<<
>>> Test on task  5 : loss=1.145 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 77.5%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  6
************************************************************************************************************
| Epoch   1, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=4.279, TAw acc= 47.9% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=3.102, TAw acc= 67.7% | *
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=2.562, TAw acc= 74.0% | *
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.284, TAw acc= 75.0% | *
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=2.255, TAw acc= 82.3% | *
| Epoch   6, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=2.003, TAw acc= 83.3% | *
| Epoch   7, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.971, TAw acc= 79.2% | *
| Epoch   8, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.878, TAw acc= 88.5% | *
| Epoch   9, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.767, TAw acc= 83.3% | *
| Epoch  10, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.705, TAw acc= 82.3% | *
| Epoch  11, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.645, TAw acc= 90.6% | *
| Epoch  12, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.586, TAw acc= 88.5% | *
| Epoch  13, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.473, TAw acc= 89.6% | *
| Epoch  14, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.462, TAw acc= 90.6% | *
| Epoch  15, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.390, TAw acc= 89.6% | *
| Epoch  16, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.362, TAw acc= 88.5% | *
| Epoch  17, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.348, TAw acc= 90.6% | *
| Epoch  18, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.334, TAw acc= 91.7% | *
| Epoch  19, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.381, TAw acc= 89.6% |
| Epoch  20, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.192, TAw acc= 88.5% | *
| Epoch   1, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.194, TAw acc= 88.5% | *
| Epoch   2, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.196, TAw acc= 88.5% |
| Epoch   3, time=  0.6s | Train: skip eval | Valid: time=  0.2s loss=1.198, TAw acc= 88.5% |
| Epoch   4, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.200, TAw acc= 88.5% |
| Epoch   5, time=  0.6s | Train: skip eval | Valid: time=  0.1s loss=1.202, TAw acc= 88.5% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2452 train exemplars, time=  0.0s
2452
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.756 | TAw acc= 95.1%, forg= -0.7%| TAg acc= 83.3%, forg= -0.7% <<<
>>> Test on task  1 : loss=1.091 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 75.8%, forg=  3.3% <<<
>>> Test on task  2 : loss=0.857 | TAw acc= 96.7%, forg= -1.7%| TAg acc= 82.5%, forg= -0.8% <<<
>>> Test on task  3 : loss=0.834 | TAw acc= 96.7%, forg=  0.8%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.687 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 95.8%, forg= -2.5% <<<
>>> Test on task  5 : loss=0.896 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 81.7%, forg= -4.2% <<<
>>> Test on task  6 : loss=1.078 | TAw acc= 92.5%, forg=  0.0%| TAg acc= 76.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  7
************************************************************************************************************
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=4.145, TAw acc= 47.9% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=3.104, TAw acc= 74.0% | *
| Epoch   3, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=2.636, TAw acc= 87.5% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=2.285, TAw acc= 91.7% | *
| Epoch   5, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=2.133, TAw acc= 91.7% | *
| Epoch   6, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.853, TAw acc= 89.6% | *
| Epoch   7, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.777, TAw acc= 96.9% | *
| Epoch   8, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.635, TAw acc= 95.8% | *
| Epoch   9, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.547, TAw acc= 92.7% | *
| Epoch  10, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.330, TAw acc= 95.8% | *
| Epoch  11, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.366, TAw acc= 94.8% |
| Epoch  12, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.425, TAw acc= 95.8% |
| Epoch  13, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.258, TAw acc= 97.9% | *
| Epoch  14, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.296, TAw acc= 95.8% |
| Epoch  15, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.307, TAw acc= 94.8% |
| Epoch  16, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.187, TAw acc= 95.8% | *
| Epoch  17, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.202, TAw acc= 95.8% |
| Epoch  18, time=  0.7s | Train: skip eval | Valid: time=  0.1s loss=1.221, TAw acc= 97.9% |
| Epoch  19, time=  0.7s | Train: skip eval | Valid: time=  0.2s loss=1.129, TAw acc= 91.7% | *
| Epoch  20, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.230, TAw acc= 95.8% |
| Epoch   1, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.129, TAw acc= 91.7% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.128, TAw acc= 92.7% | *
| Epoch   3, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.128, TAw acc= 93.8% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.128, TAw acc= 94.8% | *
| Epoch   5, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=1.128, TAw acc= 94.8% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
| Selected 2792 train exemplars, time=  0.0s
2792
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.765 | TAw acc= 95.1%, forg=  0.0%| TAg acc= 82.6%, forg=  0.7% <<<
>>> Test on task  1 : loss=0.952 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 79.2%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.757 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 82.5%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.844 | TAw acc= 99.2%, forg= -1.7%| TAg acc= 80.0%, forg=  0.8% <<<
>>> Test on task  4 : loss=0.489 | TAw acc=100.0%, forg= -0.8%| TAg acc= 95.8%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.785 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.0%, forg=  1.7% <<<
>>> Test on task  6 : loss=1.029 | TAw acc= 93.3%, forg= -0.8%| TAg acc= 75.0%, forg=  1.7% <<<
>>> Test on task  7 : loss=1.058 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 73.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  8
************************************************************************************************************
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=4.669, TAw acc= 49.0% | *
| Epoch   2, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=2.757, TAw acc= 60.4% | *
| Epoch   3, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=2.364, TAw acc= 71.9% | *
| Epoch   4, time=  0.8s | Train: skip eval | Valid: time=  0.1s loss=2.069, TAw acc= 79.2% | *
| Epoch   5, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.923, TAw acc= 80.2% | *
| Epoch   6, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.908, TAw acc= 81.2% | *
| Epoch   7, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.872, TAw acc= 86.5% | *
| Epoch   8, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.742, TAw acc= 90.6% | *
| Epoch   9, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.799, TAw acc= 89.6% |
| Epoch  10, time=  0.8s | Train: skip eval | Valid: time=  0.2s loss=1.557, TAw acc= 89.6% | *
| Epoch  11, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.532, TAw acc= 87.5% | *
| Epoch  12, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.437, TAw acc= 88.5% | *
| Epoch  13, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.524, TAw acc= 91.7% |
| Epoch  14, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.473, TAw acc= 87.5% |
| Epoch  15, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.446, TAw acc= 91.7% |
| Epoch  16, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.263, TAw acc= 89.6% | *
| Epoch  17, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.301, TAw acc= 93.8% |
| Epoch  18, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.222, TAw acc= 94.8% | *
| Epoch  19, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.345, TAw acc= 90.6% |
| Epoch  20, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.200, TAw acc= 91.7% | *
| Epoch   1, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.200, TAw acc= 91.7% | *
| Epoch   2, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.200, TAw acc= 91.7% |
| Epoch   3, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.201, TAw acc= 91.7% |
| Epoch   4, time=  0.9s | Train: skip eval | Valid: time=  0.2s loss=1.202, TAw acc= 91.7% |
| Epoch   5, time=  0.9s | Train: skip eval | Valid: time=  0.1s loss=1.203, TAw acc= 91.7% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3114 train exemplars, time=  0.0s
3114
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.703 | TAw acc= 93.1%, forg=  2.1%| TAg acc= 86.8%, forg= -3.5% <<<
>>> Test on task  1 : loss=0.968 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 74.2%, forg=  5.0% <<<
>>> Test on task  2 : loss=0.856 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 80.0%, forg=  2.5% <<<
>>> Test on task  3 : loss=0.818 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.394 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.683 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 89.2%, forg= -7.5% <<<
>>> Test on task  6 : loss=0.836 | TAw acc= 94.2%, forg= -0.8%| TAg acc= 81.7%, forg= -5.0% <<<
>>> Test on task  7 : loss=0.967 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 80.0%, forg= -6.7% <<<
>>> Test on task  8 : loss=1.087 | TAw acc= 92.5%, forg=  0.0%| TAg acc= 75.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task  9
************************************************************************************************************
| Epoch   1, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=3.943, TAw acc= 60.4% | *
| Epoch   2, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=2.508, TAw acc= 57.3% | *
| Epoch   3, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=2.008, TAw acc= 81.2% | *
| Epoch   4, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.697, TAw acc= 83.3% | *
| Epoch   5, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.584, TAw acc= 91.7% | *
| Epoch   6, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.492, TAw acc=100.0% | *
| Epoch   7, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.427, TAw acc= 90.6% | *
| Epoch   8, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=1.238, TAw acc=100.0% | *
| Epoch   9, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.160, TAw acc=100.0% | *
| Epoch  10, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=1.141, TAw acc= 95.8% | *
| Epoch  11, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.978, TAw acc= 99.0% | *
| Epoch  12, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.032, TAw acc= 99.0% |
| Epoch  13, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.028, TAw acc=100.0% |
| Epoch  14, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=1.008, TAw acc= 93.8% |
| Epoch  15, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.900, TAw acc=100.0% | *
| Epoch  16, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.869, TAw acc=100.0% | *
| Epoch  17, time=  1.0s | Train: skip eval | Valid: time=  0.2s loss=0.903, TAw acc= 97.9% |
| Epoch  18, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.849, TAw acc= 99.0% | *
| Epoch  19, time=  1.0s | Train: skip eval | Valid: time=  0.1s loss=0.856, TAw acc= 93.8% |
| Epoch  20, time=  1.3s | Train: skip eval | Valid: time=  0.2s loss=0.706, TAw acc=100.0% | *
| Epoch   1, time=  1.5s | Train: skip eval | Valid: time=  0.3s loss=0.711, TAw acc=100.0% | *
| Epoch   2, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.714, TAw acc=100.0% |
| Epoch   3, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.718, TAw acc=100.0% |
| Epoch   4, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.721, TAw acc=100.0% |
| Epoch   5, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=0.724, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3424 train exemplars, time=  0.0s
3424
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.833 | TAw acc= 95.1%, forg=  0.0%| TAg acc= 77.1%, forg=  9.7% <<<
>>> Test on task  1 : loss=0.955 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 75.0%, forg=  4.2% <<<
>>> Test on task  2 : loss=0.721 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 81.7%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.739 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 79.2%, forg=  1.7% <<<
>>> Test on task  4 : loss=0.331 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg= -1.7% <<<
>>> Test on task  5 : loss=0.668 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 86.7%, forg=  2.5% <<<
>>> Test on task  6 : loss=0.818 | TAw acc= 95.0%, forg= -0.8%| TAg acc= 73.3%, forg=  8.3% <<<
>>> Test on task  7 : loss=0.808 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 85.8%, forg= -5.8% <<<
>>> Test on task  8 : loss=0.944 | TAw acc= 96.7%, forg= -4.2%| TAg acc= 75.8%, forg=  0.0% <<<
>>> Test on task  9 : loss=0.699 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 85.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 10
************************************************************************************************************
| Epoch   1, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=4.617, TAw acc= 53.1% | *
| Epoch   2, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=2.844, TAw acc= 81.2% | *
| Epoch   3, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=2.608, TAw acc= 81.2% | *
| Epoch   4, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=2.381, TAw acc= 77.1% | *
| Epoch   5, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=2.071, TAw acc= 85.4% | *
| Epoch   6, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=2.146, TAw acc= 92.7% |
| Epoch   7, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.965, TAw acc= 91.7% | *
| Epoch   8, time=  1.1s | Train: skip eval | Valid: time=  0.1s loss=1.896, TAw acc= 89.6% | *
| Epoch   9, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=2.001, TAw acc= 91.7% |
| Epoch  10, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.651, TAw acc= 95.8% | *
| Epoch  11, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.741, TAw acc= 92.7% |
| Epoch  12, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.574, TAw acc= 91.7% | *
| Epoch  13, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.717, TAw acc= 94.8% |
| Epoch  14, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.764, TAw acc= 92.7% |
| Epoch  15, time=  1.1s | Train: skip eval | Valid: time=  0.2s loss=1.683, TAw acc= 90.6% |
| Epoch  16, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.569, TAw acc= 90.6% | *
| Epoch  17, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.631, TAw acc= 92.7% |
| Epoch  18, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.621, TAw acc= 92.7% |
| Epoch  19, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.576, TAw acc= 93.8% |
| Epoch  20, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.457, TAw acc= 91.7% | *
| Epoch   1, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.455, TAw acc= 91.7% | *
| Epoch   2, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.455, TAw acc= 91.7% | *
| Epoch   3, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.454, TAw acc= 91.7% | *
| Epoch   4, time=  1.2s | Train: skip eval | Valid: time=  0.2s loss=1.455, TAw acc= 91.7% |
| Epoch   5, time=  1.2s | Train: skip eval | Valid: time=  0.1s loss=1.455, TAw acc= 91.7% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 3734 train exemplars, time=  0.0s
3734
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.813 | TAw acc= 94.4%, forg=  0.7%| TAg acc= 79.2%, forg=  7.6% <<<
>>> Test on task  1 : loss=0.835 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 80.8%, forg= -1.7% <<<
>>> Test on task  2 : loss=0.802 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 81.7%, forg=  0.8% <<<
>>> Test on task  3 : loss=0.734 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 76.7%, forg=  4.2% <<<
>>> Test on task  4 : loss=0.322 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.584 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 90.8%, forg= -1.7% <<<
>>> Test on task  6 : loss=0.790 | TAw acc= 95.8%, forg= -0.8%| TAg acc= 80.0%, forg=  1.7% <<<
>>> Test on task  7 : loss=0.744 | TAw acc=100.0%, forg= -3.3%| TAg acc= 85.8%, forg=  0.0% <<<
>>> Test on task  8 : loss=0.952 | TAw acc= 95.8%, forg=  0.8%| TAg acc= 70.8%, forg=  5.0% <<<
>>> Test on task  9 : loss=0.600 | TAw acc= 99.2%, forg= -0.8%| TAg acc= 85.8%, forg=  0.0% <<<
>>> Test on task 10 : loss=1.161 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 70.8%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 11
************************************************************************************************************
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=4.853, TAw acc= 57.3% | *
| Epoch   2, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=3.101, TAw acc= 74.0% | *
| Epoch   3, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=2.590, TAw acc= 79.2% | *
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=2.410, TAw acc= 81.2% | *
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=2.256, TAw acc= 85.4% | *
| Epoch   6, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=2.026, TAw acc= 85.4% | *
| Epoch   7, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.871, TAw acc= 91.7% | *
| Epoch   8, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.915, TAw acc= 90.6% |
| Epoch   9, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.679, TAw acc= 92.7% | *
| Epoch  10, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.664, TAw acc= 91.7% | *
| Epoch  11, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.671, TAw acc= 91.7% |
| Epoch  12, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.683, TAw acc= 90.6% |
| Epoch  13, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.537, TAw acc= 93.8% | *
| Epoch  14, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.462, TAw acc= 92.7% | *
| Epoch  15, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.220, TAw acc= 92.7% | *
| Epoch  16, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.256, TAw acc= 94.8% |
| Epoch  17, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.360, TAw acc= 91.7% |
| Epoch  18, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.307, TAw acc= 95.8% |
| Epoch  19, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.336, TAw acc= 95.8% |
| Epoch  20, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.339, TAw acc= 91.7% | lr=3.3e-03
| Epoch   1, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.229, TAw acc= 92.7% | *
| Epoch   2, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.239, TAw acc= 92.7% |
| Epoch   3, time=  1.3s | Train: skip eval | Valid: time=  0.1s loss=1.247, TAw acc= 92.7% |
| Epoch   4, time=  1.4s | Train: skip eval | Valid: time=  0.2s loss=1.255, TAw acc= 92.7% |
| Epoch   5, time=  1.4s | Train: skip eval | Valid: time=  0.1s loss=1.262, TAw acc= 92.7% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4044 train exemplars, time=  0.0s
4044
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.739 | TAw acc= 95.8%, forg= -0.7%| TAg acc= 84.0%, forg=  2.8% <<<
>>> Test on task  1 : loss=0.919 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 80.0%, forg=  0.8% <<<
>>> Test on task  2 : loss=0.817 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 79.2%, forg=  3.3% <<<
>>> Test on task  3 : loss=0.864 | TAw acc= 97.5%, forg=  1.7%| TAg acc= 75.0%, forg=  5.8% <<<
>>> Test on task  4 : loss=0.338 | TAw acc=100.0%, forg=  0.0%| TAg acc= 97.5%, forg=  0.0% <<<
>>> Test on task  5 : loss=0.652 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 83.3%, forg=  7.5% <<<
>>> Test on task  6 : loss=0.705 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 87.5%, forg= -5.8% <<<
>>> Test on task  7 : loss=0.781 | TAw acc= 98.3%, forg=  1.7%| TAg acc= 79.2%, forg=  6.7% <<<
>>> Test on task  8 : loss=0.853 | TAw acc= 95.8%, forg=  0.8%| TAg acc= 79.2%, forg= -3.3% <<<
>>> Test on task  9 : loss=0.635 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 84.2%, forg=  1.7% <<<
>>> Test on task 10 : loss=1.242 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 65.8%, forg=  5.0% <<<
>>> Test on task 11 : loss=1.148 | TAw acc= 94.2%, forg=  0.0%| TAg acc= 71.7%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 12
************************************************************************************************************
| Epoch   1, time=  1.5s | Train: skip eval | Valid: time=  0.2s loss=4.128, TAw acc= 60.4% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=2.464, TAw acc= 74.0% | *
| Epoch   3, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=2.114, TAw acc= 97.9% | *
| Epoch   4, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=1.762, TAw acc= 99.0% | *
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.476, TAw acc= 93.8% | *
| Epoch   6, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.357, TAw acc= 99.0% | *
| Epoch   7, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.254, TAw acc=100.0% | *
| Epoch   8, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=1.134, TAw acc=100.0% | *
| Epoch   9, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=1.024, TAw acc=100.0% | *
| Epoch  10, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=1.072, TAw acc=100.0% |
| Epoch  11, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.995, TAw acc=100.0% | *
| Epoch  12, time=  1.6s | Train: skip eval | Valid: time=  0.2s loss=0.930, TAw acc=100.0% | *
| Epoch  13, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=0.850, TAw acc=100.0% | *
| Epoch  14, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.929, TAw acc=100.0% |
| Epoch  15, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.818, TAw acc=100.0% | *
| Epoch  16, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=0.805, TAw acc=100.0% | *
| Epoch  17, time=  1.5s | Train: skip eval | Valid: time=  0.1s loss=0.766, TAw acc=100.0% | *
| Epoch  18, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.696, TAw acc=100.0% | *
| Epoch  19, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.717, TAw acc=100.0% |
| Epoch  20, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.726, TAw acc=100.0% |
| Epoch   1, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.698, TAw acc=100.0% | *
| Epoch   2, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.701, TAw acc=100.0% |
| Epoch   3, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.703, TAw acc=100.0% |
| Epoch   4, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.706, TAw acc=100.0% |
| Epoch   5, time=  1.6s | Train: skip eval | Valid: time=  0.1s loss=0.708, TAw acc=100.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4354 train exemplars, time=  0.1s
4354
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.800 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 82.6%, forg=  4.2% <<<
>>> Test on task  1 : loss=0.892 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 78.3%, forg=  2.5% <<<
>>> Test on task  2 : loss=0.784 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 78.3%, forg=  4.2% <<<
>>> Test on task  3 : loss=0.673 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.297 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.526 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.0%, forg=  0.8% <<<
>>> Test on task  6 : loss=0.724 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 80.8%, forg=  6.7% <<<
>>> Test on task  7 : loss=0.752 | TAw acc=100.0%, forg=  0.0%| TAg acc= 80.8%, forg=  5.0% <<<
>>> Test on task  8 : loss=0.810 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 82.5%, forg= -3.3% <<<
>>> Test on task  9 : loss=0.625 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.8%, forg=  5.0% <<<
>>> Test on task 10 : loss=1.038 | TAw acc= 95.8%, forg=  0.0%| TAg acc= 69.2%, forg=  1.7% <<<
>>> Test on task 11 : loss=1.227 | TAw acc= 95.8%, forg= -1.7%| TAg acc= 63.3%, forg=  8.3% <<<
>>> Test on task 12 : loss=0.687 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 84.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 13
************************************************************************************************************
| Epoch   1, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=4.155, TAw acc= 56.2% | *
| Epoch   2, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=2.404, TAw acc= 97.9% | *
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=2.057, TAw acc= 84.4% | *
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.893, TAw acc=100.0% | *
| Epoch   5, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.681, TAw acc=100.0% | *
| Epoch   6, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.500, TAw acc=100.0% | *
| Epoch   7, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.523, TAw acc= 99.0% |
| Epoch   8, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.302, TAw acc=100.0% | *
| Epoch   9, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.273, TAw acc=100.0% | *
| Epoch  10, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.153, TAw acc=100.0% | *
| Epoch  11, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.268, TAw acc=100.0% |
| Epoch  12, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.106, TAw acc=100.0% | *
| Epoch  13, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=1.165, TAw acc=100.0% |
| Epoch  14, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=0.990, TAw acc=100.0% | *
| Epoch  15, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.020, TAw acc=100.0% |
| Epoch  16, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=1.021, TAw acc=100.0% |
| Epoch  17, time=  1.7s | Train: skip eval | Valid: time=  0.2s loss=0.967, TAw acc=100.0% | *
| Epoch  18, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=1.037, TAw acc=100.0% |
| Epoch  19, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=0.914, TAw acc=100.0% | *
| Epoch  20, time=  1.7s | Train: skip eval | Valid: time=  0.1s loss=0.997, TAw acc=100.0% |
| Epoch   1, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=0.912, TAw acc=100.0% | *
| Epoch   2, time=  1.8s | Train: skip eval | Valid: time=  0.2s loss=0.910, TAw acc=100.0% | *
| Epoch   3, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=0.909, TAw acc=100.0% | *
| Epoch   4, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=0.908, TAw acc=100.0% | *
| Epoch   5, time=  1.8s | Train: skip eval | Valid: time=  0.1s loss=0.906, TAw acc=100.0% | *
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4664 train exemplars, time=  0.0s
4664
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.812 | TAw acc= 96.5%, forg= -0.7%| TAg acc= 81.2%, forg=  5.6% <<<
>>> Test on task  1 : loss=0.898 | TAw acc= 95.0%, forg=  0.8%| TAg acc= 78.3%, forg=  2.5% <<<
>>> Test on task  2 : loss=0.812 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 80.8%, forg=  1.7% <<<
>>> Test on task  3 : loss=0.668 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.272 | TAw acc=100.0%, forg=  0.0%| TAg acc= 96.7%, forg=  0.8% <<<
>>> Test on task  5 : loss=0.494 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.0%, forg=  0.8% <<<
>>> Test on task  6 : loss=0.701 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 85.0%, forg=  2.5% <<<
>>> Test on task  7 : loss=0.595 | TAw acc=100.0%, forg=  0.0%| TAg acc= 89.2%, forg= -3.3% <<<
>>> Test on task  8 : loss=0.730 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 87.5%, forg= -5.0% <<<
>>> Test on task  9 : loss=0.520 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 87.5%, forg= -1.7% <<<
>>> Test on task 10 : loss=0.967 | TAw acc= 98.3%, forg= -2.5%| TAg acc= 76.7%, forg= -5.8% <<<
>>> Test on task 11 : loss=1.009 | TAw acc= 96.7%, forg= -0.8%| TAg acc= 73.3%, forg= -1.7% <<<
>>> Test on task 12 : loss=0.586 | TAw acc=100.0%, forg= -0.8%| TAg acc= 85.0%, forg= -0.8% <<<
>>> Test on task 13 : loss=0.859 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 74.2%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
======
LLL_Net(
  (model): SimpleMLP(
    (fc1): Linear(in_features=405, out_features=66, bias=True)
    (fc2): Sequential()
  )
  (heads): ModuleList(
    (0): Linear(in_features=66, out_features=12, bias=True)
    (1): Linear(in_features=66, out_features=10, bias=True)
    (2): Linear(in_features=66, out_features=10, bias=True)
    (3): Linear(in_features=66, out_features=10, bias=True)
    (4): Linear(in_features=66, out_features=10, bias=True)
    (5): Linear(in_features=66, out_features=10, bias=True)
    (6): Linear(in_features=66, out_features=10, bias=True)
    (7): Linear(in_features=66, out_features=10, bias=True)
    (8): Linear(in_features=66, out_features=10, bias=True)
    (9): Linear(in_features=66, out_features=10, bias=True)
    (10): Linear(in_features=66, out_features=10, bias=True)
    (11): Linear(in_features=66, out_features=10, bias=True)
    (12): Linear(in_features=66, out_features=10, bias=True)
    (13): Linear(in_features=66, out_features=10, bias=True)
  )
)
======

************************************************************************************************************
Task 14
************************************************************************************************************
| Epoch   1, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=4.070, TAw acc= 65.6% | *
| Epoch   2, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=2.408, TAw acc= 97.9% | *
| Epoch   3, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=1.893, TAw acc= 99.0% | *
| Epoch   4, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=1.839, TAw acc= 97.9% | *
| Epoch   5, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=1.577, TAw acc= 99.0% | *
| Epoch   6, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=1.282, TAw acc= 99.0% | *
| Epoch   7, time=  2.0s | Train: skip eval | Valid: time=  0.3s loss=1.142, TAw acc= 99.0% | *
| Epoch   8, time=  2.6s | Train: skip eval | Valid: time=  0.1s loss=1.237, TAw acc= 99.0% |
| Epoch   9, time=  1.9s | Train: skip eval | Valid: time=  0.2s loss=1.103, TAw acc= 99.0% | *
| Epoch  10, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.905, TAw acc= 99.0% | *
| Epoch  11, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=0.929, TAw acc= 99.0% |
| Epoch  12, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.884, TAw acc= 99.0% | *
| Epoch  13, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.862, TAw acc= 99.0% | *
| Epoch  14, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.803, TAw acc= 99.0% | *
| Epoch  15, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=0.919, TAw acc= 99.0% |
| Epoch  16, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.761, TAw acc= 99.0% | *
| Epoch  17, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.765, TAw acc= 99.0% |
| Epoch  18, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.749, TAw acc= 99.0% | *
| Epoch  19, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.643, TAw acc= 99.0% | *
| Epoch  20, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.676, TAw acc= 99.0% |
| Epoch   1, time=  1.9s | Train: skip eval | Valid: time=  0.1s loss=0.647, TAw acc= 99.0% | *
| Epoch   2, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.651, TAw acc= 99.0% |
| Epoch   3, time=  2.0s | Train: skip eval | Valid: time=  0.1s loss=0.654, TAw acc= 99.0% |
| Epoch   4, time=  2.0s | Train: skip eval | Valid: time=  0.2s loss=0.657, TAw acc= 99.0% |
| Epoch   5, time=  2.1s | Train: skip eval | Valid: time=  0.1s loss=0.660, TAw acc= 99.0% |
EXEMPLARS_PER_CLASS: 100
Not enough samples to store. Select all samples instead.	Needed: 100
Not enough samples to store. Select all samples instead.	Needed: 35
Not enough samples to store. Select all samples instead.	Needed: 34
| Selected 4974 train exemplars, time=  0.0s
4974
------------------------------------------------------------------------------------------------------------
>>> Test on task  0 : loss=0.730 | TAw acc= 95.8%, forg=  0.7%| TAg acc= 82.6%, forg=  4.2% <<<
>>> Test on task  1 : loss=0.896 | TAw acc= 94.2%, forg=  1.7%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  2 : loss=0.802 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 82.5%, forg=  0.0% <<<
>>> Test on task  3 : loss=0.650 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 80.8%, forg=  0.0% <<<
>>> Test on task  4 : loss=0.266 | TAw acc=100.0%, forg=  0.0%| TAg acc= 95.8%, forg=  1.7% <<<
>>> Test on task  5 : loss=0.465 | TAw acc= 98.3%, forg=  0.8%| TAg acc= 90.0%, forg=  0.8% <<<
>>> Test on task  6 : loss=0.660 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 85.0%, forg=  2.5% <<<
>>> Test on task  7 : loss=0.552 | TAw acc=100.0%, forg=  0.0%| TAg acc= 88.3%, forg=  0.8% <<<
>>> Test on task  8 : loss=0.783 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 81.7%, forg=  5.8% <<<
>>> Test on task  9 : loss=0.527 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 87.5%, forg=  0.0% <<<
>>> Test on task 10 : loss=0.982 | TAw acc= 98.3%, forg=  0.0%| TAg acc= 73.3%, forg=  3.3% <<<
>>> Test on task 11 : loss=0.840 | TAw acc= 96.7%, forg=  0.0%| TAg acc= 76.7%, forg= -3.3% <<<
>>> Test on task 12 : loss=0.555 | TAw acc=100.0%, forg=  0.0%| TAg acc= 83.3%, forg=  1.7% <<<
>>> Test on task 13 : loss=0.829 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 76.7%, forg= -2.5% <<<
>>> Test on task 14 : loss=0.727 | TAw acc= 99.2%, forg=  0.0%| TAg acc= 83.3%, forg=  0.0% <<<
Save at k=100/eeil_e5_dsads_1/har_flex_eeil
************************************************************************************************************
TAw Acc
	 56.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 56.2% 
	 88.9%  76.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.8% 
	 91.7%  85.8%  88.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 88.6% 
	 92.4%  93.3%  95.0%  88.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 92.3% 
	 91.7%  94.2%  94.2%  97.5%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 95.2% 
	 94.4%  95.8%  95.0%  97.5%  99.2%  99.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.9% 
	 95.1%  95.0%  96.7%  96.7%  99.2%  99.2%  92.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.3% 
	 95.1%  95.0%  96.7%  99.2% 100.0%  99.2%  93.3%  95.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.8% 
	 93.1%  95.0%  96.7%  99.2% 100.0%  99.2%  94.2%  96.7%  92.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 96.3% 
	 95.1%  95.8%  96.7%  98.3% 100.0%  99.2%  95.0%  96.7%  96.7%  98.3%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.2% 
	 94.4%  95.0%  96.7%  98.3% 100.0%  99.2%  95.8% 100.0%  95.8%  99.2%  95.8%   0.0%   0.0%   0.0%   0.0% 	Avg.: 97.3% 
	 95.8%  95.8%  96.7%  97.5% 100.0%  98.3%  95.8%  98.3%  95.8%  99.2%  95.8%  94.2%   0.0%   0.0%   0.0% 	Avg.: 96.9% 
	 95.8%  95.0%  96.7%  98.3% 100.0%  98.3%  95.8% 100.0%  96.7%  99.2%  95.8%  95.8%  99.2%   0.0%   0.0% 	Avg.: 97.4% 
	 96.5%  95.0%  96.7%  99.2% 100.0%  98.3%  96.7% 100.0%  96.7%  99.2%  98.3%  96.7% 100.0%  99.2%   0.0% 	Avg.: 98.0% 
	 95.8%  94.2%  96.7%  99.2% 100.0%  98.3%  96.7% 100.0%  96.7%  99.2%  98.3%  96.7% 100.0%  99.2%  99.2% 	Avg.: 98.0% 
************************************************************************************************************
TAg Acc
	 56.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 56.2% 
	 77.8%  51.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 64.7% 
	 81.9%  63.3%  77.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 74.3% 
	 79.2%  79.2%  77.5%  50.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 71.7% 
	 82.6%  74.2%  79.2%  74.2%  85.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 79.0% 
	 81.9%  75.8%  81.7%  80.8%  93.3%  77.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.9% 
	 83.3%  75.8%  82.5%  80.8%  95.8%  81.7%  76.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.4% 
	 82.6%  79.2%  82.5%  80.0%  95.8%  80.0%  75.0%  73.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.1% 
	 86.8%  74.2%  80.0%  80.8%  95.8%  89.2%  81.7%  80.0%  75.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 82.7% 
	 77.1%  75.0%  81.7%  79.2%  97.5%  86.7%  73.3%  85.8%  75.8%  85.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.8% 
	 79.2%  80.8%  81.7%  76.7%  96.7%  90.8%  80.0%  85.8%  70.8%  85.8%  70.8%   0.0%   0.0%   0.0%   0.0% 	Avg.: 81.7% 
	 84.0%  80.0%  79.2%  75.0%  97.5%  83.3%  87.5%  79.2%  79.2%  84.2%  65.8%  71.7%   0.0%   0.0%   0.0% 	Avg.: 80.5% 
	 82.6%  78.3%  78.3%  80.8%  96.7%  90.0%  80.8%  80.8%  82.5%  80.8%  69.2%  63.3%  84.2%   0.0%   0.0% 	Avg.: 80.7% 
	 81.2%  78.3%  80.8%  80.8%  96.7%  90.0%  85.0%  89.2%  87.5%  87.5%  76.7%  73.3%  85.0%  74.2%   0.0% 	Avg.: 83.3% 
	 82.6%  80.8%  82.5%  80.8%  95.8%  90.0%  85.0%  88.3%  81.7%  87.5%  73.3%  76.7%  83.3%  76.7%  83.3% 	Avg.: 83.2% 
************************************************************************************************************
TAw Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-32.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-32.6% 
	 -2.8%  -9.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -6.0% 
	 -0.7%  -7.5%  -6.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -5.0% 
	  0.7%  -0.8%   0.8%  -9.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -2.1% 
	 -2.1%  -1.7%   0.0%   0.0%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.9% 
	 -0.7%   0.8%  -1.7%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.1% 
	  0.0%   0.8%   0.0%  -1.7%  -0.8%   0.0%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.4% 
	  2.1%   0.8%   0.0%   0.0%   0.0%   0.0%  -0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.2% 
	  0.0%   0.0%   0.0%   0.8%   0.0%   0.0%  -0.8%   0.0%  -4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.5% 
	  0.7%   0.8%   0.0%   0.8%   0.0%   0.0%  -0.8%  -3.3%   0.8%  -0.8%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.2% 
	 -0.7%   0.0%   0.0%   1.7%   0.0%   0.8%   0.0%   1.7%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.4% 
	  0.0%   0.8%   0.0%   0.8%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%  -1.7%   0.0%   0.0%   0.0% 	Avg.:  0.1% 
	 -0.7%   0.8%   0.0%   0.0%   0.0%   0.8%  -0.8%   0.0%   0.0%   0.0%  -2.5%  -0.8%  -0.8%   0.0%   0.0% 	Avg.: -0.3% 
	  0.7%   1.7%   0.0%   0.0%   0.0%   0.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.2% 
************************************************************************************************************
TAg Forg
	  0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 
	-21.5%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:-21.5% 
	 -4.2% -11.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -7.9% 
	  2.8% -15.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -4.4% 
	 -0.7%   5.0%  -1.7% -23.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -5.2% 
	  0.7%   3.3%  -2.5%  -6.7%  -8.3%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -2.7% 
	 -0.7%   3.3%  -0.8%   0.0%  -2.5%  -4.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -0.8% 
	  0.7%   0.0%   0.0%   0.8%   0.0%   1.7%   1.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  0.7% 
	 -3.5%   5.0%   2.5%   0.0%   0.0%  -7.5%  -5.0%  -6.7%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.: -1.9% 
	  9.7%   4.2%   0.8%   1.7%  -1.7%   2.5%   8.3%  -5.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  2.2% 
	  7.6%  -1.7%   0.8%   4.2%   0.8%  -1.7%   1.7%   0.0%   5.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  1.7% 
	  2.8%   0.8%   3.3%   5.8%   0.0%   7.5%  -5.8%   6.7%  -3.3%   1.7%   5.0%   0.0%   0.0%   0.0%   0.0% 	Avg.:  2.2% 
	  4.2%   2.5%   4.2%   0.0%   0.8%   0.8%   6.7%   5.0%  -3.3%   5.0%   1.7%   8.3%   0.0%   0.0%   0.0% 	Avg.:  3.0% 
	  5.6%   2.5%   1.7%   0.0%   0.8%   0.8%   2.5%  -3.3%  -5.0%  -1.7%  -5.8%  -1.7%  -0.8%   0.0%   0.0% 	Avg.: -0.3% 
	  4.2%   0.0%   0.0%   0.0%   1.7%   0.8%   2.5%   0.8%   5.8%   0.0%   3.3%  -3.3%   1.7%  -2.5%   0.0% 	Avg.:  1.1% 
************************************************************************************************************
[Elapsed time = 0.1 h]
Done!

f1_score_micro: 0.8322368421052633
f1_score_macro: 0.8265103154905008
              precision    recall  f1-score   support

           0       0.43      0.75      0.55        12
           1       0.50      0.92      0.65        12
           2       0.56      0.42      0.48        12
           3       0.50      0.42      0.45        12
           4       0.92      0.92      0.92        12
           5       0.85      0.92      0.88        12
           6       0.69      0.92      0.79        12
           7       1.00      1.00      1.00        12
           8       0.80      0.67      0.73        12
           9       0.71      1.00      0.83        12
          10       1.00      1.00      1.00        12
          11       1.00      1.00      1.00        12
          12       1.00      1.00      1.00        12
          13       1.00      1.00      1.00        12
          14       0.56      0.83      0.67        12
          15       1.00      0.17      0.29        12
          16       1.00      1.00      1.00        12
          17       0.77      0.83      0.80        12
          18       0.65      0.92      0.76        12
          19       0.91      0.83      0.87        12
          20       0.50      0.50      0.50        12
          21       1.00      1.00      1.00        12
          22       0.92      0.92      0.92        12
          23       0.79      0.92      0.85        12
          24       0.92      1.00      0.96        12
          25       1.00      0.67      0.80        12
          26       1.00      0.58      0.74        12
          27       1.00      0.92      0.96        12
          28       1.00      1.00      1.00        12
          29       1.00      1.00      1.00        12
          30       0.69      0.75      0.72        12
          31       0.55      0.50      0.52        12
          32       0.90      0.75      0.82        12
          33       0.86      1.00      0.92        12
          34       1.00      1.00      1.00        12
          35       0.90      0.75      0.82        12
          36       1.00      0.58      0.74        12
          37       0.50      0.50      0.50        12
          38       1.00      0.92      0.96        12
          39       1.00      1.00      1.00        12
          40       1.00      1.00      1.00        12
          41       0.70      0.58      0.64        12
          42       1.00      1.00      1.00        12
          43       1.00      0.92      0.96        12
          44       0.92      1.00      0.96        12
          45       1.00      1.00      1.00        12
          46       1.00      1.00      1.00        12
          47       1.00      1.00      1.00        12
          48       0.92      1.00      0.96        12
          49       0.91      0.83      0.87        12
          50       1.00      0.83      0.91        12
          51       1.00      1.00      1.00        12
          52       0.50      1.00      0.67        12
          53       1.00      1.00      1.00        12
          54       0.92      1.00      0.96        12
          55       0.82      0.75      0.78        12
          56       0.85      0.92      0.88        12
          57       1.00      1.00      1.00        12
          58       0.85      0.92      0.88        12
          59       1.00      1.00      1.00        12
          60       1.00      0.92      0.96        12
          61       0.86      0.50      0.63        12
          62       1.00      0.58      0.74        12
          63       1.00      1.00      1.00        12
          64       1.00      1.00      1.00        12
          65       0.92      1.00      0.96        12
          66       0.92      1.00      0.96        12
          67       1.00      1.00      1.00        12
          68       0.85      0.92      0.88        12
          69       1.00      0.92      0.96        12
          70       0.33      0.42      0.37        12
          71       0.67      0.67      0.67        12
          72       1.00      1.00      1.00        12
          73       0.92      1.00      0.96        12
          74       0.91      0.83      0.87        12
          75       0.33      0.58      0.42        12
          76       0.86      1.00      0.92        12
          77       1.00      0.92      0.96        12
          78       0.82      0.75      0.78        12
          79       0.79      0.92      0.85        12
          80       1.00      0.92      0.96        12
          81       0.65      0.92      0.76        12
          82       0.86      1.00      0.92        12
          83       0.73      0.67      0.70        12
          84       1.00      1.00      1.00        12
          85       0.65      0.92      0.76        12
          86       0.85      0.92      0.88        12
          87       0.75      1.00      0.86        12
          88       0.79      0.92      0.85        12
          89       0.50      0.42      0.45        12
          90       0.50      0.42      0.45        12
          91       0.92      0.92      0.92        12
          92       1.00      1.00      1.00        12
          93       0.92      1.00      0.96        12
          94       1.00      1.00      1.00        12
          95       1.00      1.00      1.00        12
          96       0.67      0.33      0.44        12
          97       1.00      0.92      0.96        12
          98       0.92      1.00      0.96        12
          99       0.75      0.75      0.75        12
         100       0.83      0.83      0.83        12
         101       0.92      0.92      0.92        12
         102       1.00      1.00      1.00        12
         103       1.00      1.00      1.00        12
         104       0.90      0.75      0.82        12
         105       0.00      0.00      0.00        12
         106       0.62      0.42      0.50        12
         107       0.73      0.92      0.81        12
         108       0.77      0.83      0.80        12
         109       0.88      0.58      0.70        12
         110       0.91      0.83      0.87        12
         111       0.92      1.00      0.96        12
         112       0.28      0.42      0.33        12
         113       0.80      1.00      0.89        12
         114       0.92      0.92      0.92        12
         115       1.00      1.00      1.00        12
         116       0.50      0.25      0.33        12
         117       0.77      0.83      0.80        12
         118       0.53      0.67      0.59        12
         119       0.61      0.92      0.73        12
         120       0.90      0.75      0.82        12
         121       1.00      0.92      0.96        12
         122       1.00      0.92      0.96        12
         123       1.00      1.00      1.00        12
         124       1.00      0.92      0.96        12
         125       0.67      0.17      0.27        12
         126       0.91      0.83      0.87        12
         127       1.00      1.00      1.00        12
         128       1.00      1.00      1.00        12
         129       0.75      1.00      0.86        12
         130       1.00      1.00      1.00        12
         131       0.75      0.50      0.60        12
         132       1.00      1.00      1.00        12
         133       1.00      1.00      1.00        12
         134       0.89      0.67      0.76        12
         135       1.00      1.00      1.00        12
         136       0.75      0.25      0.38        12
         137       1.00      1.00      1.00        12
         138       1.00      1.00      1.00        12
         139       0.60      0.50      0.55        12
         140       0.85      0.92      0.88        12
         141       0.67      0.33      0.44        12
         142       0.83      0.83      0.83        12
         143       1.00      0.92      0.96        12
         144       0.82      0.75      0.78        12
         145       1.00      1.00      1.00        12
         146       0.75      0.75      0.75        12
         147       1.00      1.00      1.00        12
         148       0.78      0.58      0.67        12
         149       1.00      1.00      1.00        12
         150       0.86      1.00      0.92        12
         151       0.27      0.50      0.35        12

    accuracy                           0.83      1824
   macro avg       0.84      0.83      0.83      1824
weighted avg       0.84      0.83      0.83      1824

torch.Size([1824, 405]) torch.Size([1824])
Parameters: 36980
Task parameters: {0: 27600, 1: 28270, 2: 28940, 3: 29610, 4: 30280, 5: 30950, 6: 31620, 7: 32290, 8: 32960, 9: 33630, 10: 34300, 11: 34970, 12: 35640, 13: 36310, 14: 36980}
