Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='b93daa26-fe9c-4877-bf15-2812dda6124f', conf_timestamp='2023-08-10 06:04:32.691989', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 76.29 % 	 [Task-IL]: 52.06 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 52.11 % 	 [Task-IL]: 43.62 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 42.22 % 	 [Task-IL]: 37.17 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 32.23 % 	 [Task-IL]: 34.53 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 31.11 % 	 [Task-IL]: 33.68 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 30.88 % 	 [Task-IL]: 33.24 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 25.42 % 	 [Task-IL]: 31.05 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 25.92 % 	 [Task-IL]: 30.45 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.2 % 	 [Task-IL]: 29.33 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 20.38 % 	 [Task-IL]: 29.29 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 20.39 % 	 [Task-IL]: 28.27 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 16.23 % 	 [Task-IL]: 28.63 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 15.11 % 	 [Task-IL]: 28.45 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.98 % 	 [Task-IL]: 27.73 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.82 % 	 [Task-IL]: 28.1 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.34 % 	 [Task-IL]: 27.55 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.05 % 	 [Task-IL]: 28.13 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 12.84 % 	 [Task-IL]: 28.34 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 12.24 % 	 [Task-IL]: 28.13 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.43 % 	 [Task-IL]: 27.54 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.21 % 	 [Task-IL]: 27.6 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 10.13 % 	 [Task-IL]: 27.45 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.04 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 9.52 % 	 [Task-IL]: 26.43 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 9.1 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 6.2 % 	 [Task-IL]: 26.68 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.13 % 	 [Task-IL]: 26.56 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.92 % 	 [Task-IL]: 26.64 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.17 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.6 % 	 [Task-IL]: 27.46 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.25 % 	 [Task-IL]: 27.46 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.3 % 	 [Task-IL]: 27.32 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.47 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.97 % 	 [Task-IL]: 26.77 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.86 % 	 [Task-IL]: 26.15 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 7.68 % 	 [Task-IL]: 26.02 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 7.36 % 	 [Task-IL]: 26.4 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 7.04 % 	 [Task-IL]: 26.28 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.69 % 	 [Task-IL]: 26.14 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.72 % 	 [Task-IL]: 26.08 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.18 % 	 [Task-IL]: 26.07 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.24 % 	 [Task-IL]: 26.02 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.57 % 	 [Task-IL]: 26.0 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74891, 530: 35, 430: 34, 62: 33, 210: 33, 340: 33, 519: 33, 816: 33, 16: 32, 36: 32, 112: 32, 129: 32, 161: 32, 284: 32, 304: 32, 469: 32, 531: 32, 614: 32, 638: 32, 707: 32, 710: 32, 883: 32, 12: 31, 74: 31, 88: 31, 96: 31, 148: 31, 136: 31, 167: 31, 194: 31, 281: 31, 313: 31, 357: 31, 370: 31, 379: 31, 406: 31, 403: 31, 423: 31, 483: 31, 510: 31, 515: 31, 568: 31, 577: 31, 599: 31, 598: 31, 658: 31, 668: 31, 681: 31, 732: 31, 851: 31, 889: 31, 10: 30, 68: 30, 93: 30, 94: 30, 145: 30, 139: 30, 189: 30, 175: 30, 237: 30, 326: 30, 373: 30, 450: 30, 484: 30, 576: 30, 591: 30, 609: 30, 620: 30, 617: 30, 636: 30, 709: 30, 772: 30, 800: 30, 811: 30, 842: 30, 852: 30, 866: 30, 48: 29, 34: 29, 44: 29, 61: 29, 80: 29, 101: 29, 97: 29, 100: 29, 128: 29, 146: 29, 186: 29, 181: 29, 245: 29, 250: 29, 244: 29, 256: 29, 283: 29, 329: 29, 337: 29, 362: 29, 358: 29, 382: 29, 432: 29, 440: 29, 464: 29, 487: 29, 504: 29, 547: 29, 554: 29, 610: 29, 619: 29, 644: 29, 660: 29, 673: 29, 682: 29, 703: 29, 721: 29, 739: 29, 757: 29, 760: 29, 790: 29, 791: 29, 861: 29, 868: 29, 856: 29, 890: 29, 887: 29, 25: 28, 33: 28, 18: 28, 63: 28, 78: 28, 133: 28, 191: 28, 226: 28, 409: 28, 413: 28, 404: 28, 401: 28, 441: 28, 443: 28, 453: 28, 465: 28, 520: 28, 573: 28, 572: 28, 574: 28, 632: 28, 616: 28, 650: 28, 713: 28, 751: 28, 773: 28, 798: 28, 839: 28, 892: 28, 876: 28, 874: 28, 22: 27, 71: 27, 91: 27, 168: 27, 178: 27, 232: 27, 259: 27, 291: 27, 345: 27, 364: 27, 375: 27, 425: 27, 422: 27, 437: 27, 470: 27, 513: 27, 507: 27, 544: 27, 557: 27, 571: 27, 582: 27, 628: 27, 664: 27, 748: 27, 797: 27, 848: 27, 5: 26, 28: 26, 35: 26, 49: 26, 84: 26, 152: 26, 251: 26, 271: 26, 287: 26, 318: 26, 330: 26, 339: 26, 355: 26, 365: 26, 393: 26, 446: 26, 473: 26, 476: 26, 495: 26, 514: 26, 588: 26, 581: 26, 662: 26, 690: 26, 705: 26, 763: 26, 805: 26, 815: 26, 13: 25, 50: 25, 37: 25, 119: 25, 144: 25, 230: 25, 235: 25, 282: 25, 426: 25, 635: 25, 686: 25, 722: 25, 734: 25, 827: 25, 826: 25, 843: 25, 837: 25, 893: 25, 54: 24, 65: 24, 172: 24, 613: 24, 680: 24, 737: 24, 295: 23, 352: 23, 351: 23, 858: 23, 884: 23, 196: 21, 509: 20, 594: 20, 517: 19, 248: 18, 104: 17, 347: 17, 342: 17, 428: 17, 521: 17, 801: 17, 53: 16, 41: 16, 132: 16, 187: 16, 213: 16, 207: 16, 270: 16, 306: 16, 338: 16, 367: 16, 419: 16, 482: 16, 490: 16, 642: 16, 670: 16, 687: 16, 693: 16, 712: 16, 724: 16, 749: 16, 740: 16, 741: 16, 765: 16, 768: 16, 796: 16, 828: 16, 844: 16, 6: 15, 17: 15, 59: 15, 141: 15, 193: 15, 211: 15, 233: 15, 234: 15, 297: 15, 343: 15, 366: 15, 449: 15, 435: 15, 477: 15, 511: 15, 527: 15, 538: 15, 602: 15, 603: 15, 651: 15, 669: 15, 688: 15, 684: 15, 706: 15, 720: 15, 742: 15, 771: 15, 818: 15, 873: 15, 891: 15, 24: 14, 21: 14, 19: 14, 11: 14, 2: 14, 9: 14, 43: 14, 51: 14, 40: 14, 67: 14, 87: 14, 153: 14, 179: 14, 200: 14, 219: 14, 220: 14, 247: 14, 242: 14, 260: 14, 255: 14, 267: 14, 310: 14, 294: 14, 303: 14, 305: 14, 319: 14, 333: 14, 363: 14, 398: 14, 412: 14, 414: 14, 420: 14, 429: 14, 452: 14, 451: 14, 468: 14, 471: 14, 474: 14, 518: 14, 524: 14, 537: 14, 542: 14, 556: 14, 562: 14, 563: 14, 606: 14, 611: 14, 597: 14, 626: 14, 615: 14, 649: 14, 641: 14, 653: 14, 666: 14, 659: 14, 678: 14, 691: 14, 692: 14, 679: 14, 738: 14, 784: 14, 783: 14, 789: 14, 775: 14, 786: 14, 794: 14, 864: 14, 885: 14, 877: 14, 31: 13, 26: 13, 32: 13, 38: 13, 72: 13, 56: 13, 81: 13, 85: 13, 107: 13, 114: 13, 120: 13, 117: 13, 151: 13, 164: 13, 173: 13, 156: 13, 162: 13, 177: 13, 185: 13, 208: 13, 204: 13, 205: 13, 202: 13, 215: 13, 236: 13, 266: 13, 263: 13, 264: 13, 274: 13, 276: 13, 293: 13, 289: 13, 328: 13, 336: 13, 371: 13, 372: 13, 369: 13, 385: 13, 392: 13, 383: 13, 387: 13, 384: 13, 386: 13, 396: 13, 405: 13, 436: 13, 444: 13, 438: 13, 460: 13, 457: 13, 454: 13, 463: 13, 499: 13, 503: 13, 501: 13, 494: 13, 545: 13, 546: 13, 552: 13, 550: 13, 561: 13, 565: 13, 555: 13, 583: 13, 590: 13, 575: 13, 593: 13, 633: 13, 621: 13, 631: 13, 625: 13, 639: 13, 663: 13, 667: 13, 672: 13, 674: 13, 697: 13, 700: 13, 717: 13, 728: 13, 744: 13, 750: 13, 747: 13, 745: 13, 769: 13, 756: 13, 761: 13, 788: 13, 785: 13, 813: 13, 812: 13, 799: 13, 814: 13, 819: 13, 841: 13, 846: 13, 860: 13, 855: 13, 875: 13, 27: 12, 39: 12, 57: 12, 86: 12, 75: 12, 99: 12, 105: 12, 106: 12, 126: 12, 121: 12, 118: 12, 122: 12, 137: 12, 149: 12, 143: 12, 138: 12, 155: 12, 154: 12, 170: 12, 160: 12, 176: 12, 184: 12, 182: 12, 195: 12, 197: 12, 201: 12, 206: 12, 225: 12, 223: 12, 218: 12, 253: 12, 252: 12, 238: 12, 246: 12, 269: 12, 288: 12, 290: 12, 278: 12, 280: 12, 300: 12, 298: 12, 299: 12, 325: 12, 331: 12, 323: 12, 322: 12, 349: 12, 389: 12, 377: 12, 394: 12, 395: 12, 418: 12, 424: 12, 433: 12, 427: 12, 439: 12, 442: 12, 445: 12, 467: 12, 466: 12, 462: 12, 489: 12, 479: 12, 480: 12, 491: 12, 497: 12, 529: 12, 536: 12, 548: 12, 543: 12, 567: 12, 569: 12, 559: 12, 584: 12, 578: 12, 589: 12, 604: 12, 605: 12, 623: 12, 624: 12, 640: 12, 634: 12, 665: 12, 695: 12, 698: 12, 696: 12, 723: 12, 729: 12, 714: 12, 727: 12, 753: 12, 754: 12, 755: 12, 759: 12, 780: 12, 782: 12, 787: 12, 774: 12, 803: 12, 808: 12, 804: 12, 817: 12, 823: 12, 831: 12, 820: 12, 822: 12, 835: 12, 845: 12, 838: 12, 853: 12, 850: 12, 840: 12, 854: 12, 863: 12, 871: 12, 878: 12, 888: 12, 15: 11, 8: 11, 23: 11, 3: 11, 20: 11, 46: 11, 42: 11, 47: 11, 60: 11, 55: 11, 69: 11, 64: 11, 83: 11, 89: 11, 92: 11, 102: 11, 103: 11, 111: 11, 98: 11, 116: 11, 124: 11, 125: 11, 115: 11, 147: 11, 165: 11, 163: 11, 158: 11, 157: 11, 166: 11, 190: 11, 174: 11, 192: 11, 212: 11, 199: 11, 228: 11, 229: 11, 227: 11, 224: 11, 272: 11, 257: 11, 268: 11, 254: 11, 265: 11, 277: 11, 275: 11, 285: 11, 301: 11, 302: 11, 315: 11, 327: 11, 332: 11, 334: 11, 348: 11, 344: 11, 368: 11, 360: 11, 378: 11, 381: 11, 376: 11, 374: 11, 407: 11, 408: 11, 397: 11, 431: 11, 421: 11, 417: 11, 415: 11, 458: 11, 459: 11, 472: 11, 486: 11, 488: 11, 492: 11, 505: 11, 506: 11, 512: 11, 502: 11, 508: 11, 523: 11, 526: 11, 528: 11, 551: 11, 534: 11, 560: 11, 558: 11, 566: 11, 592: 11, 585: 11, 579: 11, 580: 11, 612: 11, 600: 11, 596: 11, 648: 11, 683: 11, 685: 11, 699: 11, 701: 11, 719: 11, 718: 11, 726: 11, 725: 11, 752: 11, 758: 11, 764: 11, 767: 11, 766: 11, 776: 11, 792: 11, 781: 11, 795: 11, 809: 11, 825: 11, 824: 11, 830: 11, 821: 11, 832: 11, 849: 11, 869: 11, 862: 11, 870: 11, 857: 11, 859: 11, 865: 11, 867: 11, 882: 11, 879: 11, 880: 11, 29: 10, 30: 10, 7: 10, 45: 10, 73: 10, 70: 10, 58: 10, 113: 10, 127: 10, 142: 10, 140: 10, 150: 10, 180: 10, 188: 10, 203: 10, 222: 10, 214: 10, 216: 10, 231: 10, 239: 10, 240: 10, 249: 10, 273: 10, 258: 10, 261: 10, 292: 10, 286: 10, 279: 10, 312: 10, 296: 10, 324: 10, 314: 10, 320: 10, 321: 10, 341: 10, 350: 10, 354: 10, 361: 10, 359: 10, 390: 10, 391: 10, 388: 10, 410: 10, 399: 10, 400: 10, 416: 10, 448: 10, 447: 10, 485: 10, 500: 10, 496: 10, 498: 10, 525: 10, 532: 10, 535: 10, 540: 10, 549: 10, 564: 10, 586: 10, 587: 10, 608: 10, 618: 10, 637: 10, 647: 10, 656: 10, 671: 10, 675: 10, 676: 10, 677: 10, 694: 10, 711: 10, 730: 10, 736: 10, 735: 10, 793: 10, 778: 10, 779: 10, 777: 10, 807: 10, 802: 10, 833: 10, 836: 10, 872: 10, 4: 9, 14: 9, 1: 9, 52: 9, 66: 9, 82: 9, 76: 9, 90: 9, 79: 9, 110: 9, 95: 9, 109: 9, 130: 9, 131: 9, 134: 9, 171: 9, 183: 9, 198: 9, 221: 9, 243: 9, 241: 9, 262: 9, 311: 9, 307: 9, 308: 9, 309: 9, 317: 9, 316: 9, 353: 9, 335: 9, 356: 9, 380: 9, 402: 9, 434: 9, 455: 9, 456: 9, 493: 9, 478: 9, 533: 9, 539: 9, 553: 9, 601: 9, 630: 9, 629: 9, 622: 9, 627: 9, 645: 9, 646: 9, 643: 9, 652: 9, 657: 9, 661: 9, 689: 9, 702: 9, 704: 9, 716: 9, 731: 9, 715: 9, 746: 9, 770: 9, 762: 9, 806: 9, 829: 9, 847: 9, 881: 9, 886: 9, 77: 8, 108: 8, 123: 8, 135: 8, 159: 8, 169: 8, 209: 8, 217: 8, 346: 8, 411: 8, 461: 8, 481: 8, 475: 8, 522: 8, 541: 8, 570: 8, 595: 8, 607: 8, 654: 8, 655: 8, 708: 8, 733: 8, 743: 8, 810: 8, 834: 8, 516: 7})
fit_time: 7.534715148

Accuracy for 44 task(s): 	 [Class-IL]: 66.41 % 	 [Task-IL]: 29.63 %

CLASS_IL_ACC: 
	[63.4020618556701, 83.73983739837398, 68.96551724137932, 55.65217391304348, 66.3716814159292, 63.725490196078425, 72.64957264957265, 66.33663366336634, 73.91304347826086, 59.4059405940594, 75.78947368421053, 61.40350877192983, 42.857142857142854, 72.32142857142857, 53.535353535353536, 57.99999999999999, 64.28571428571429, 75.2, 71.28712871287128, 64.28571428571429, 66.66666666666666, 61.66666666666667, 67.5925925925926, 60.19417475728155, 64.54545454545455, 72.03389830508475, 67.74193548387096, 72.56637168141593, 78.63247863247864, 66.96428571428571, 71.1864406779661, 72.47706422018348, 67.2566371681416, 65.17857142857143, 69.02654867256636, 68.04123711340206, 66.05504587155964, 53.21100917431193, 72.16494845360825, 71.81818181818181, 63.725490196078425, 62.71186440677966, 64.81481481481481, 62.698412698412696]
TASK_IL_ACC: 
	[57.73195876288659, 34.959349593495936, 25.0, 29.565217391304348, 35.39823008849557, 27.450980392156865, 28.205128205128204, 20.792079207920793, 27.82608695652174, 30.693069306930692, 24.210526315789473, 28.947368421052634, 21.428571428571427, 20.535714285714285, 29.292929292929294, 25.0, 31.25, 28.799999999999997, 32.67326732673268, 16.964285714285715, 23.076923076923077, 24.166666666666668, 23.14814814814815, 27.184466019417474, 26.36363636363636, 32.20338983050847, 27.956989247311824, 29.20353982300885, 33.33333333333333, 33.035714285714285, 34.74576271186441, 33.02752293577982, 22.123893805309734, 18.75, 22.123893805309734, 19.587628865979383, 34.862385321100916, 25.688073394495415, 23.711340206185564, 30.909090909090907, 33.33333333333333, 27.966101694915253, 32.407407407407405, 88.09523809523809]
f1_micro: 66.52430343705511
f1_macro: 60.88514305460795
              precision    recall  f1-score   support

           0       0.50      0.80      0.62         5
           1       0.67      1.00      0.80         4
           2       0.00      0.00      0.00         5
           3       0.67      0.50      0.57         4
           4       0.00      0.00      0.00         4
           5       0.60      0.67      0.63         9
           6       1.00      0.80      0.89         5
           7       1.00      1.00      1.00         4
           8       0.67      1.00      0.80         4
           9       0.83      1.00      0.91         5
          10       0.13      0.78      0.23         9
          11       1.00      0.80      0.89         5
          12       1.00      0.67      0.80         9
          13       0.75      1.00      0.86         9
          14       0.00      0.00      0.00         4
          15       0.67      0.50      0.57         4
          16       0.60      0.33      0.43         9
          17       0.50      0.40      0.44         5
          18       1.00      0.56      0.71         9
          19       0.80      0.80      0.80         5
          20       0.00      0.00      0.00         4
          21       0.00      0.00      0.00         4
          22       0.89      0.89      0.89         9
          23       0.00      0.00      0.00         4
          24       1.00      1.00      1.00         4
          25       0.55      0.67      0.60         9
          26       0.71      1.00      0.83         5
          27       0.00      0.00      0.00         4
          28       0.78      0.78      0.78         9
          29       0.33      1.00      0.50         4
          30       1.00      1.00      1.00         4
          31       0.00      0.00      0.00         4
          32       0.40      0.50      0.44         4
          33       0.89      0.89      0.89         9
          34       1.00      1.00      1.00         9
          35       0.90      1.00      0.95         9
          36       0.89      0.89      0.89         9
          37       0.69      1.00      0.82         9
          38       1.00      0.75      0.86         4
          39       0.00      0.00      0.00         4
          40       0.50      1.00      0.67         4
          41       0.83      1.00      0.91         5
          42       0.80      1.00      0.89         4
          43       1.00      1.00      1.00         5
          44       0.50      0.89      0.64         9
          45       1.00      0.75      0.86         4
          46       1.00      1.00      1.00         4
          47       0.75      0.75      0.75         4
          48       0.89      0.89      0.89         9
          49       1.00      0.78      0.88         9
          50       1.00      1.00      1.00         9
          51       0.25      0.25      0.25         4
          52       0.00      0.00      0.00         4
          53       1.00      0.80      0.89         5
          54       0.62      1.00      0.76         8
          55       0.00      0.00      0.00         4
          56       1.00      1.00      1.00         4
          57       1.00      0.75      0.86         4
          58       0.80      1.00      0.89         4
          59       0.60      0.60      0.60         5
          60       1.00      1.00      1.00         4
          61       0.55      0.67      0.60         9
          62       0.58      0.78      0.67         9
          63       0.80      0.89      0.84         9
          64       1.00      0.25      0.40         4
          65       0.86      0.67      0.75         9
          66       0.00      0.00      0.00         4
          67       0.62      1.00      0.77         5
          68       0.27      0.44      0.33         9
          69       1.00      0.75      0.86         4
          70       1.00      0.75      0.86         4
          71       0.58      0.78      0.67         9
          72       0.80      1.00      0.89         4
          73       0.00      0.00      0.00         4
          74       0.00      0.00      0.00         9
          75       0.60      0.75      0.67         4
          76       0.00      0.00      0.00         4
          77       0.00      0.00      0.00         4
          78       0.00      0.00      0.00         9
          79       1.00      0.75      0.86         4
          80       0.86      0.67      0.75         9
          81       0.00      0.00      0.00         4
          82       1.00      1.00      1.00         4
          83       0.67      1.00      0.80         4
          84       0.90      1.00      0.95         9
          85       0.00      0.00      0.00         4
          86       0.44      1.00      0.62         4
          87       0.12      0.25      0.17         4
          88       1.00      0.78      0.88         9
          89       1.00      0.50      0.67         4
          90       0.00      0.00      0.00         4
          91       0.73      0.89      0.80         9
          92       0.57      1.00      0.73         4
          93       1.00      1.00      1.00         9
          94       0.75      1.00      0.86         9
          95       0.23      0.75      0.35         4
          96       0.90      1.00      0.95         9
          97       0.00      0.00      0.00         9
          98       1.00      0.50      0.67         4
          99       1.00      0.20      0.33         5
         100       0.53      0.89      0.67         9
         101       0.89      0.89      0.89         9
         102       1.00      1.00      1.00         4
         103       0.00      0.00      0.00         4
         104       0.50      0.60      0.55         5
         105       0.75      0.75      0.75         4
         106       1.00      0.25      0.40         4
         107       1.00      0.80      0.89         5
         108       1.00      1.00      1.00         4
         109       0.80      1.00      0.89         4
         110       0.00      0.00      0.00         4
         111       1.00      1.00      1.00         4
         112       0.89      0.89      0.89         9
         113       0.00      0.00      0.00         4
         114       1.00      1.00      1.00         4
         115       0.11      0.50      0.18         4
         116       0.00      0.00      0.00         4
         117       0.00      0.00      0.00         4
         118       0.00      0.00      0.00         4
         119       0.43      1.00      0.60         9
         120       0.80      1.00      0.89         4
         121       0.75      0.75      0.75         4
         122       0.67      0.50      0.57         4
         123       0.00      0.00      0.00         4
         124       1.00      0.50      0.67         4
         125       0.67      1.00      0.80         4
         126       1.00      1.00      1.00         4
         127       1.00      0.80      0.89         5
         128       0.58      0.78      0.67         9
         129       0.82      1.00      0.90         9
         130       1.00      0.25      0.40         4
         131       0.00      0.00      0.00         4
         132       0.62      1.00      0.77         5
         133       0.56      0.56      0.56         9
         134       1.00      0.75      0.86         4
         135       1.00      0.75      0.86         4
         136       0.82      1.00      0.90         9
         137       0.67      0.50      0.57         4
         138       0.83      1.00      0.91         5
         139       0.89      0.89      0.89         9
         140       0.22      0.50      0.31         4
         141       1.00      1.00      1.00         5
         142       0.00      0.00      0.00         4
         143       0.80      1.00      0.89         4
         144       0.00      0.00      0.00         9
         145       1.00      0.67      0.80         9
         146       1.00      0.67      0.80         9
         147       1.00      0.50      0.67         4
         148       0.89      0.89      0.89         9
         149       1.00      1.00      1.00         4
         150       1.00      1.00      1.00         4
         151       0.50      1.00      0.67         4
         152       0.53      0.89      0.67         9
         153       1.00      0.50      0.67         4
         154       0.60      0.75      0.67         4
         155       0.00      0.00      0.00         4
         156       1.00      0.75      0.86         4
         157       0.67      0.50      0.57         4
         158       0.57      1.00      0.73         4
         159       0.00      0.00      0.00         4
         160       1.00      1.00      1.00         4
         161       1.00      0.89      0.94         9
         162       0.00      0.00      0.00         4
         163       0.21      0.75      0.33         4
         164       0.83      1.00      0.91         5
         165       0.00      0.00      0.00         4
         166       0.15      1.00      0.26         4
         167       0.82      1.00      0.90         9
         168       0.00      0.00      0.00         9
         169       1.00      0.75      0.86         4
         170       0.50      0.50      0.50         4
         171       0.50      1.00      0.67         4
         172       1.00      1.00      1.00         9
         173       1.00      1.00      1.00         4
         174       1.00      0.50      0.67         4
         175       0.60      1.00      0.75         9
         176       0.21      0.60      0.32         5
         177       0.00      0.00      0.00         4
         178       0.69      1.00      0.82         9
         179       1.00      1.00      1.00         4
         180       0.00      0.00      0.00         4
         181       0.73      0.89      0.80         9
         182       1.00      0.75      0.86         4
         183       1.00      0.75      0.86         4
         184       1.00      1.00      1.00         5
         185       1.00      1.00      1.00         5
         186       1.00      0.78      0.88         9
         187       1.00      1.00      1.00         5
         188       1.00      0.75      0.86         4
         189       0.03      0.11      0.05         9
         190       0.80      1.00      0.89         4
         191       0.75      0.67      0.71         9
         192       1.00      0.75      0.86         4
         193       0.83      1.00      0.91         5
         194       0.71      0.56      0.63         9
         195       0.67      1.00      0.80         4
         196       0.88      0.78      0.82         9
         197       0.67      0.40      0.50         5
         198       0.00      0.00      0.00         4
         199       1.00      0.25      0.40         4
         200       0.50      1.00      0.67         4
         201       0.67      1.00      0.80         4
         202       1.00      0.80      0.89         5
         203       1.00      1.00      1.00         4
         204       0.00      0.00      0.00         4
         205       0.00      0.00      0.00         5
         206       0.50      0.25      0.33         4
         207       0.71      1.00      0.83         5
         208       0.06      0.25      0.09         4
         209       0.00      0.00      0.00         4
         210       1.00      1.00      1.00         9
         211       0.42      1.00      0.59         5
         212       0.00      0.00      0.00         4
         213       0.67      0.80      0.73         5
         214       1.00      1.00      1.00         4
         215       0.80      1.00      0.89         4
         216       0.67      1.00      0.80         4
         217       0.00      0.00      0.00         4
         218       0.75      0.75      0.75         4
         219       1.00      1.00      1.00         4
         220       0.25      0.25      0.25         4
         221       1.00      0.25      0.40         4
         222       0.17      0.50      0.25         4
         223       1.00      1.00      1.00         4
         224       0.80      1.00      0.89         4
         225       0.20      0.25      0.22         4
         226       0.88      0.78      0.82         9
         227       0.00      0.00      0.00         4
         228       0.67      1.00      0.80         4
         229       0.80      1.00      0.89         4
         230       0.75      1.00      0.86         9
         231       1.00      1.00      1.00         4
         232       1.00      1.00      1.00         8
         233       1.00      0.80      0.89         5
         234       1.00      0.60      0.75         5
         235       1.00      0.89      0.94         9
         236       0.40      0.50      0.44         4
         237       1.00      0.44      0.62         9
         238       1.00      0.25      0.40         4
         239       0.00      0.00      0.00         4
         240       1.00      0.50      0.67         4
         241       0.00      0.00      0.00         4
         242       1.00      0.50      0.67         4
         243       1.00      1.00      1.00         4
         244       0.43      1.00      0.60         9
         245       0.82      1.00      0.90         9
         246       0.00      0.00      0.00         4
         247       0.00      0.00      0.00         4
         248       0.80      0.80      0.80         5
         249       1.00      0.20      0.33         5
         250       0.10      0.67      0.17         9
         251       0.75      0.67      0.71         9
         252       1.00      1.00      1.00         4
         253       0.42      1.00      0.59         5
         254       0.00      0.00      0.00         4
         255       0.50      0.75      0.60         4
         256       0.00      0.00      0.00         9
         257       1.00      1.00      1.00         4
         258       0.80      1.00      0.89         4
         259       0.50      0.33      0.40         9
         260       1.00      1.00      1.00         4
         261       0.00      0.00      0.00         4
         262       0.57      1.00      0.73         4
         263       0.75      0.75      0.75         4
         264       0.11      0.50      0.18         4
         265       0.00      0.00      0.00         4
         266       0.00      0.00      0.00         4
         267       1.00      0.40      0.57         5
         268       0.00      0.00      0.00         4
         269       0.00      0.00      0.00         4
         270       1.00      0.20      0.33         5
         271       0.70      0.78      0.74         9
         272       0.07      0.25      0.11         4
         273       1.00      0.80      0.89         5
         274       0.83      1.00      0.91         5
         275       1.00      1.00      1.00         4
         276       1.00      0.25      0.40         4
         277       0.50      0.75      0.60         4
         278       0.80      1.00      0.89         4
         279       0.75      0.75      0.75         4
         280       1.00      0.75      0.86         4
         281       0.86      0.67      0.75         9
         282       1.00      0.56      0.71         9
         283       1.00      1.00      1.00         9
         284       0.90      1.00      0.95         9
         285       0.00      0.00      0.00         4
         286       1.00      1.00      1.00         4
         287       1.00      0.89      0.94         9
         288       0.00      0.00      0.00         4
         289       0.43      0.60      0.50         5
         290       0.11      0.50      0.18         4
         291       0.90      1.00      0.95         9
         292       0.67      0.50      0.57         4
         293       1.00      0.25      0.40         4
         294       1.00      1.00      1.00         5
         295       1.00      0.89      0.94         9
         296       0.17      0.50      0.25         4
         297       0.20      0.20      0.20         5
         298       0.50      0.75      0.60         4
         299       1.00      0.25      0.40         4
         300       0.18      0.50      0.27         4
         301       1.00      1.00      1.00         4
         302       0.00      0.00      0.00         4
         303       1.00      0.20      0.33         5
         304       1.00      0.89      0.94         9
         305       1.00      0.50      0.67         4
         306       0.50      0.40      0.44         5
         307       0.00      0.00      0.00         4
         308       0.00      0.00      0.00         4
         309       0.00      0.00      0.00         4
         310       0.14      0.25      0.18         4
         311       1.00      1.00      1.00         4
         312       1.00      0.50      0.67         4
         313       0.70      0.78      0.74         9
         314       1.00      1.00      1.00         4
         315       0.00      0.00      0.00         4
         316       1.00      0.50      0.67         4
         317       0.00      0.00      0.00         4
         318       0.62      0.89      0.73         9
         319       0.57      1.00      0.73         4
         320       1.00      1.00      1.00         4
         321       0.00      0.00      0.00         4
         322       0.00      0.00      0.00         4
         323       1.00      0.50      0.67         4
         324       0.67      1.00      0.80         4
         325       0.00      0.00      0.00         4
         326       0.88      0.78      0.82         9
         327       0.50      1.00      0.67         4
         328       0.00      0.00      0.00         4
         329       0.69      1.00      0.82         9
         330       0.00      0.00      0.00         9
         331       0.60      0.75      0.67         4
         332       0.67      1.00      0.80         4
         333       0.50      0.75      0.60         4
         334       0.80      1.00      0.89         4
         335       0.00      0.00      0.00         4
         336       1.00      1.00      1.00         5
         337       1.00      0.78      0.88         9
         338       1.00      0.60      0.75         5
         339       0.00      0.00      0.00         9
         340       0.73      0.89      0.80         9
         341       0.80      1.00      0.89         4
         342       0.67      0.80      0.73         5
         343       0.57      0.80      0.67         5
         344       0.75      0.75      0.75         4
         345       1.00      1.00      1.00         9
         346       1.00      1.00      1.00         4
         347       0.00      0.00      0.00         5
         348       1.00      0.25      0.40         4
         349       1.00      0.25      0.40         4
         350       0.75      0.75      0.75         4
         351       0.88      0.88      0.88         8
         352       0.50      0.14      0.22         7
         353       1.00      1.00      1.00         4
         354       0.00      0.00      0.00         4
         355       0.43      0.33      0.38         9
         356       0.67      1.00      0.80         4
         357       1.00      0.89      0.94         9
         358       1.00      1.00      1.00         9
         359       1.00      0.75      0.86         4
         360       1.00      0.75      0.86         4
         361       1.00      1.00      1.00         4
         362       0.80      0.89      0.84         9
         363       0.50      0.60      0.55         5
         364       0.82      1.00      0.90         9
         365       0.82      1.00      0.90         9
         366       1.00      0.80      0.89         5
         367       0.71      1.00      0.83         5
         368       0.60      0.60      0.60         5
         369       0.60      0.75      0.67         4
         370       0.00      0.00      0.00         9
         371       0.83      1.00      0.91         5
         372       0.50      0.50      0.50         4
         373       0.90      1.00      0.95         9
         374       0.33      0.25      0.29         4
         375       0.62      0.89      0.73         9
         376       0.00      0.00      0.00         4
         377       1.00      1.00      1.00         4
         378       1.00      0.75      0.86         4
         379       0.89      0.89      0.89         9
         380       1.00      1.00      1.00         4
         381       0.00      0.00      0.00         4
         382       1.00      0.89      0.94         9
         383       0.80      1.00      0.89         4
         384       0.83      1.00      0.91         5
         385       0.00      0.00      0.00         4
         386       0.00      0.00      0.00         4
         387       0.67      1.00      0.80         4
         388       0.60      0.75      0.67         4
         389       0.80      1.00      0.89         4
         390       1.00      1.00      1.00         4
         391       0.00      0.00      0.00         4
         392       1.00      0.75      0.86         4
         393       0.90      1.00      0.95         9
         394       0.00      0.00      0.00         4
         395       0.60      0.75      0.67         4
         396       0.75      0.75      0.75         4
         397       0.38      0.75      0.50         4
         398       1.00      0.50      0.67         4
         399       0.00      0.00      0.00         4
         400       0.00      0.00      0.00         4
         401       0.67      0.89      0.76         9
         402       0.10      0.50      0.17         4
         403       0.00      0.00      0.00         9
         404       1.00      0.89      0.94         9
         405       1.00      1.00      1.00         4
         406       0.50      1.00      0.67         9
         407       1.00      1.00      1.00         5
         408       0.00      0.00      0.00         4
         409       0.62      0.89      0.73         9
         410       1.00      1.00      1.00         4
         411       1.00      0.75      0.86         4
         412       0.75      0.60      0.67         5
         413       0.88      0.78      0.82         9
         414       0.00      0.00      0.00         5
         415       0.67      1.00      0.80         4
         416       0.00      0.00      0.00         4
         417       1.00      1.00      1.00         4
         418       1.00      1.00      1.00         5
         419       1.00      0.80      0.89         5
         420       0.71      1.00      0.83         5
         421       1.00      1.00      1.00         4
         422       0.50      0.11      0.18         9
         423       1.00      0.56      0.71         9
         424       1.00      1.00      1.00         4
         425       0.32      1.00      0.49         9
         426       1.00      1.00      1.00         9
         427       0.83      1.00      0.91         5
         428       0.75      0.60      0.67         5
         429       0.75      0.60      0.67         5
         430       1.00      0.67      0.80         9
         431       0.00      0.00      0.00         4
         432       0.54      0.78      0.64         9
         433       0.00      0.00      0.00         4
         434       1.00      1.00      1.00         4
         435       1.00      0.80      0.89         5
         436       0.00      0.00      0.00         4
         437       0.90      1.00      0.95         9
         438       1.00      0.25      0.40         4
         439       0.00      0.00      0.00         4
         440       0.00      0.00      0.00         9
         441       0.83      0.56      0.67         9
         442       0.80      1.00      0.89         4
         443       1.00      0.78      0.88         9
         444       0.21      1.00      0.35         4
         445       1.00      0.40      0.57         5
         446       0.00      0.00      0.00         9
         447       0.00      0.00      0.00         4
         448       0.80      1.00      0.89         4
         449       1.00      1.00      1.00         5
         450       0.67      0.89      0.76         9
         451       0.80      0.80      0.80         5
         452       0.83      1.00      0.91         5
         453       0.80      0.89      0.84         9
         454       0.45      1.00      0.62         5
         455       0.67      1.00      0.80         4
         456       1.00      0.50      0.67         4
         457       0.60      0.75      0.67         4
         458       0.00      0.00      0.00         4
         459       1.00      0.75      0.86         4
         460       0.50      0.40      0.44         5
         461       1.00      0.50      0.67         4
         462       0.50      0.20      0.29         5
         463       0.38      0.75      0.50         4
         464       0.41      1.00      0.58         9
         465       0.80      0.89      0.84         9
         466       1.00      0.75      0.86         4
         467       1.00      1.00      1.00         4
         468       0.57      1.00      0.73         4
         469       0.89      0.89      0.89         9
         470       0.00      0.00      0.00         9
         471       0.50      0.25      0.33         4
         472       0.43      0.75      0.55         4
         473       0.73      0.89      0.80         9
         474       0.00      0.00      0.00         4
         475       1.00      0.50      0.67         4
         476       1.00      0.89      0.94         9
         477       0.40      0.80      0.53         5
         478       0.80      1.00      0.89         4
         479       0.80      1.00      0.89         4
         480       0.80      1.00      0.89         4
         481       1.00      1.00      1.00         4
         482       0.67      0.40      0.50         5
         483       0.64      1.00      0.78         9
         484       1.00      0.89      0.94         9
         485       0.80      1.00      0.89         4
         486       0.33      0.50      0.40         4
         487       0.00      0.00      0.00         9
         488       0.50      0.25      0.33         4
         489       0.00      0.00      0.00         4
         490       0.50      0.40      0.44         5
         491       0.00      0.00      0.00         4
         492       0.00      0.00      0.00         4
         493       0.80      1.00      0.89         4
         494       0.80      1.00      0.89         4
         495       1.00      0.56      0.71         9
         496       1.00      0.50      0.67         4
         497       1.00      0.50      0.67         4
         498       0.67      0.50      0.57         4
         499       0.67      0.40      0.50         5
         500       1.00      0.75      0.86         4
         501       0.50      0.60      0.55         5
         502       0.75      0.75      0.75         4
         503       0.67      1.00      0.80         4
         504       0.00      0.00      0.00         9
         505       1.00      0.75      0.86         4
         506       0.67      1.00      0.80         4
         507       1.00      0.89      0.94         9
         508       0.33      0.25      0.29         4
         509       0.67      0.33      0.44         6
         510       1.00      1.00      1.00         9
         511       1.00      1.00      1.00         5
         512       0.00      0.00      0.00         4
         513       0.75      1.00      0.86         9
         514       0.70      0.78      0.74         9
         515       0.78      0.78      0.78         9
         516       1.00      1.00      1.00         4
         517       1.00      0.71      0.83         7
         518       0.00      0.00      0.00         4
         519       0.44      0.78      0.56         9
         520       1.00      0.89      0.94         9
         521       0.56      1.00      0.71         5
         522       0.00      0.00      0.00         4
         523       1.00      0.80      0.89         5
         524       1.00      0.50      0.67         4
         525       0.80      1.00      0.89         4
         526       0.50      0.20      0.29         5
         527       1.00      1.00      1.00         5
         528       0.80      1.00      0.89         4
         529       0.27      0.75      0.40         4
         530       1.00      0.78      0.88         9
         531       0.90      1.00      0.95         9
         532       1.00      0.60      0.75         5
         533       0.00      0.00      0.00         4
         534       0.00      0.00      0.00         4
         535       1.00      1.00      1.00         4
         536       1.00      1.00      1.00         4
         537       0.33      0.40      0.36         5
         538       0.80      0.80      0.80         5
         539       1.00      1.00      1.00         4
         540       0.40      0.50      0.44         4
         541       1.00      1.00      1.00         4
         542       0.83      1.00      0.91         5
         543       0.12      0.75      0.20         4
         544       1.00      1.00      1.00         9
         545       1.00      1.00      1.00         4
         546       0.00      0.00      0.00         4
         547       0.67      0.89      0.76         9
         548       0.67      1.00      0.80         4
         549       0.00      0.00      0.00         4
         550       0.33      0.25      0.29         4
         551       0.00      0.00      0.00         4
         552       0.12      0.25      0.17         4
         553       1.00      1.00      1.00         4
         554       0.62      0.56      0.59         9
         555       0.80      1.00      0.89         4
         556       0.83      1.00      0.91         5
         557       0.73      0.89      0.80         9
         558       1.00      1.00      1.00         4
         559       0.80      1.00      0.89         4
         560       0.00      0.00      0.00         4
         561       1.00      0.75      0.86         4
         562       0.50      0.80      0.62         5
         563       1.00      0.80      0.89         5
         564       0.50      0.75      0.60         4
         565       0.25      0.25      0.25         4
         566       1.00      0.25      0.40         4
         567       0.12      0.75      0.21         4
         568       1.00      0.89      0.94         9
         569       1.00      1.00      1.00         4
         570       1.00      1.00      1.00         4
         571       1.00      0.89      0.94         9
         572       1.00      1.00      1.00         9
         573       0.00      0.00      0.00         9
         574       0.70      0.78      0.74         9
         575       0.40      0.80      0.53         5
         576       0.73      0.89      0.80         9
         577       1.00      0.89      0.94         9
         578       1.00      0.80      0.89         5
         579       0.80      1.00      0.89         4
         580       0.75      0.75      0.75         4
         581       0.90      1.00      0.95         9
         582       0.55      0.67      0.60         9
         583       0.80      1.00      0.89         4
         584       0.00      0.00      0.00         4
         585       1.00      0.25      0.40         4
         586       0.50      0.25      0.33         4
         587       0.00      0.00      0.00         4
         588       1.00      0.89      0.94         9
         589       0.80      1.00      0.89         4
         590       1.00      1.00      1.00         4
         591       0.82      1.00      0.90         9
         592       0.50      1.00      0.67         4
         593       1.00      1.00      1.00         4
         594       0.50      0.71      0.59         7
         595       0.40      1.00      0.57         4
         596       1.00      0.75      0.86         4
         597       0.00      0.00      0.00         5
         598       0.83      0.56      0.67         9
         599       0.86      0.67      0.75         9
         600       1.00      0.50      0.67         4
         601       0.00      0.00      0.00         4
         602       1.00      0.80      0.89         5
         603       1.00      0.80      0.89         5
         604       1.00      1.00      1.00         4
         605       1.00      0.50      0.67         4
         606       1.00      1.00      1.00         5
         607       1.00      0.75      0.86         4
         608       0.00      0.00      0.00         4
         609       0.73      0.89      0.80         9
         610       1.00      0.78      0.88         9
         611       0.80      1.00      0.89         4
         612       0.00      0.00      0.00         4
         613       1.00      1.00      1.00         9
         614       0.80      0.89      0.84         9
         615       1.00      0.75      0.86         4
         616       0.44      0.89      0.59         9
         617       0.80      0.89      0.84         9
         618       1.00      1.00      1.00         4
         619       0.33      0.89      0.48         9
         620       0.00      0.00      0.00         9
         621       1.00      1.00      1.00         5
         622       1.00      0.75      0.86         4
         623       1.00      0.25      0.40         4
         624       0.00      0.00      0.00         4
         625       1.00      0.80      0.89         5
         626       0.71      1.00      0.83         5
         627       0.50      0.50      0.50         4
         628       0.56      0.56      0.56         9
         629       1.00      0.75      0.86         4
         630       1.00      1.00      1.00         4
         631       0.00      0.00      0.00         4
         632       0.75      1.00      0.86         9
         633       0.57      1.00      0.73         4
         634       0.00      0.00      0.00         4
         635       0.70      0.78      0.74         9
         636       1.00      0.89      0.94         9
         637       0.80      1.00      0.89         4
         638       1.00      1.00      1.00         9
         639       1.00      0.50      0.67         4
         640       0.67      1.00      0.80         4
         641       0.71      1.00      0.83         5
         642       1.00      0.60      0.75         5
         643       1.00      1.00      1.00         4
         644       0.70      0.78      0.74         9
         645       1.00      0.50      0.67         4
         646       0.40      0.50      0.44         4
         647       1.00      1.00      1.00         4
         648       0.00      0.00      0.00         4
         649       1.00      0.20      0.33         5
         650       0.90      1.00      0.95         9
         651       0.57      0.80      0.67         5
         652       0.00      0.00      0.00         4
         653       0.14      1.00      0.24         4
         654       1.00      0.25      0.40         4
         655       0.40      0.50      0.44         4
         656       1.00      1.00      1.00         4
         657       0.44      1.00      0.62         4
         658       0.00      0.00      0.00         9
         659       1.00      0.75      0.86         4
         660       1.00      0.44      0.62         9
         661       0.00      0.00      0.00         4
         662       1.00      0.89      0.94         9
         663       0.44      1.00      0.62         4
         664       1.00      1.00      1.00         9
         665       1.00      0.25      0.40         4
         666       0.30      0.75      0.43         4
         667       0.67      0.80      0.73         5
         668       1.00      0.89      0.94         9
         669       0.00      0.00      0.00         5
         670       1.00      0.80      0.89         5
         671       0.80      1.00      0.89         4
         672       1.00      1.00      1.00         4
         673       1.00      1.00      1.00         9
         674       0.00      0.00      0.00         4
         675       0.06      0.25      0.09         4
         676       0.60      0.75      0.67         4
         677       0.50      0.20      0.29         5
         678       0.00      0.00      0.00         4
         679       0.00      0.00      0.00         5
         680       0.75      1.00      0.86         9
         681       0.90      1.00      0.95         9
         682       0.75      0.33      0.46         9
         683       0.60      0.75      0.67         4
         684       0.75      0.60      0.67         5
         685       1.00      1.00      1.00         4
         686       0.82      1.00      0.90         9
         687       1.00      1.00      1.00         5
         688       0.71      1.00      0.83         5
         689       1.00      1.00      1.00         4
         690       0.00      0.00      0.00         9
         691       0.80      1.00      0.89         4
         692       0.83      1.00      0.91         5
         693       1.00      1.00      1.00         5
         694       1.00      1.00      1.00         4
         695       1.00      0.75      0.86         4
         696       0.00      0.00      0.00         5
         697       0.50      0.75      0.60         4
         698       1.00      0.25      0.40         4
         699       0.13      1.00      0.24         4
         700       0.00      0.00      0.00         4
         701       0.00      0.00      0.00         4
         702       0.67      0.50      0.57         4
         703       1.00      0.89      0.94         9
         704       0.00      0.00      0.00         4
         705       0.75      1.00      0.86         9
         706       0.83      1.00      0.91         5
         707       1.00      1.00      1.00         9
         708       1.00      1.00      1.00         4
         709       1.00      0.89      0.94         9
         710       0.90      1.00      0.95         9
         711       0.50      0.25      0.33         4
         712       1.00      1.00      1.00         5
         713       0.75      0.33      0.46         9
         714       0.67      1.00      0.80         4
         715       0.80      1.00      0.89         4
         716       0.00      0.00      0.00         4
         717       0.67      0.50      0.57         4
         718       0.00      0.00      0.00         4
         719       0.50      0.50      0.50         4
         720       1.00      1.00      1.00         5
         721       0.78      0.78      0.78         9
         722       0.89      0.89      0.89         9
         723       0.80      1.00      0.89         4
         724       0.67      0.80      0.73         5
         725       1.00      0.75      0.86         4
         726       0.80      1.00      0.89         4
         727       1.00      0.50      0.67         4
         728       0.80      1.00      0.89         4
         729       0.60      0.75      0.67         4
         730       0.00      0.00      0.00         4
         731       0.00      0.00      0.00         4
         732       0.90      1.00      0.95         9
         733       0.20      0.25      0.22         4
         734       0.54      0.78      0.64         9
         735       1.00      1.00      1.00         4
         736       0.00      0.00      0.00         4
         737       1.00      0.89      0.94         9
         738       0.80      1.00      0.89         4
         739       0.56      0.56      0.56         9
         740       1.00      1.00      1.00         5
         741       1.00      0.60      0.75         5
         742       1.00      1.00      1.00         5
         743       0.50      0.25      0.33         4
         744       0.00      0.00      0.00         4
         745       0.67      1.00      0.80         4
         746       1.00      0.50      0.67         4
         747       1.00      0.75      0.86         4
         748       0.83      0.56      0.67         9
         749       0.60      0.60      0.60         5
         750       0.50      0.50      0.50         4
         751       0.80      0.89      0.84         9
         752       0.00      0.00      0.00         4
         753       1.00      0.75      0.86         4
         754       0.75      0.75      0.75         4
         755       1.00      0.75      0.86         4
         756       1.00      0.60      0.75         5
         757       0.80      0.89      0.84         9
         758       1.00      1.00      1.00         4
         759       0.00      0.00      0.00         4
         760       0.55      0.67      0.60         9
         761       0.20      0.25      0.22         4
         762       1.00      0.50      0.67         4
         763       0.60      0.33      0.43         9
         764       1.00      1.00      1.00         4
         765       0.00      0.00      0.00         5
         766       0.50      0.75      0.60         4
         767       1.00      1.00      1.00         4
         768       0.00      0.00      0.00         5
         769       0.60      0.60      0.60         5
         770       0.80      1.00      0.89         4
         771       0.00      0.00      0.00         4
         772       0.70      0.78      0.74         9
         773       0.00      0.00      0.00         9
         774       0.75      0.75      0.75         4
         775       1.00      1.00      1.00         4
         776       0.71      1.00      0.83         5
         777       0.80      1.00      0.89         4
         778       1.00      1.00      1.00         4
         779       0.00      0.00      0.00         4
         780       0.00      0.00      0.00         4
         781       1.00      0.50      0.67         4
         782       1.00      0.60      0.75         5
         783       1.00      1.00      1.00         4
         784       1.00      1.00      1.00         5
         785       1.00      0.50      0.67         4
         786       1.00      0.40      0.57         5
         787       0.57      1.00      0.73         4
         788       0.71      1.00      0.83         5
         789       1.00      0.60      0.75         5
         790       0.89      0.89      0.89         9
         791       1.00      0.89      0.94         9
         792       0.67      1.00      0.80         4
         793       0.00      0.00      0.00         5
         794       0.75      0.60      0.67         5
         795       0.80      1.00      0.89         4
         796       1.00      1.00      1.00         5
         797       0.78      0.78      0.78         9
         798       0.78      0.78      0.78         9
         799       0.80      0.80      0.80         5
         800       1.00      0.56      0.71         9
         801       0.62      1.00      0.77         5
         802       1.00      1.00      1.00         4
         803       1.00      0.75      0.86         4
         804       0.08      0.25      0.12         4
         805       1.00      0.11      0.20         9
         806       1.00      1.00      1.00         4
         807       0.60      0.75      0.67         4
         808       1.00      0.80      0.89         5
         809       0.50      0.25      0.33         4
         810       1.00      0.50      0.67         4
         811       0.89      0.89      0.89         9
         812       0.57      1.00      0.73         4
         813       0.80      1.00      0.89         4
         814       0.25      0.25      0.25         4
         815       0.89      0.89      0.89         9
         816       0.67      0.67      0.67         9
         817       0.75      0.75      0.75         4
         818       0.50      0.20      0.29         5
         819       0.50      1.00      0.67         4
         820       0.00      0.00      0.00         4
         821       1.00      0.75      0.86         4
         822       0.67      1.00      0.80         4
         823       0.60      0.75      0.67         4
         824       0.75      0.75      0.75         4
         825       0.60      0.75      0.67         4
         826       0.83      0.56      0.67         9
         827       0.90      1.00      0.95         9
         828       0.50      0.60      0.55         5
         829       0.67      1.00      0.80         4
         830       0.50      1.00      0.67         4
         831       0.09      0.25      0.13         4
         832       0.00      0.00      0.00         4
         833       0.00      0.00      0.00         4
         834       0.17      0.25      0.20         4
         835       0.12      0.50      0.19         4
         836       0.00      0.00      0.00         4
         837       0.75      0.67      0.71         9
         838       1.00      0.40      0.57         5
         839       0.89      0.89      0.89         9
         840       0.13      0.50      0.21         4
         841       0.00      0.00      0.00         4
         842       1.00      1.00      1.00         9
         843       1.00      0.78      0.88         9
         844       1.00      0.20      0.33         5
         845       0.00      0.00      0.00         4
         846       0.60      0.75      0.67         4
         847       1.00      0.75      0.86         4
         848       0.90      1.00      0.95         9
         849       0.00      0.00      0.00         4
         850       0.00      0.00      0.00         4
         851       0.89      0.89      0.89         9
         852       0.89      0.89      0.89         9
         853       1.00      1.00      1.00         5
         854       1.00      1.00      1.00         4
         855       0.50      0.60      0.55         5
         856       0.00      0.00      0.00         9
         857       1.00      1.00      1.00         4
         858       1.00      0.44      0.62         9
         859       0.67      1.00      0.80         4
         860       1.00      0.50      0.67         4
         861       1.00      0.89      0.94         9
         862       1.00      1.00      1.00         4
         863       1.00      0.80      0.89         5
         864       1.00      0.75      0.86         4
         865       1.00      1.00      1.00         4
         866       0.80      0.89      0.84         9
         867       0.00      0.00      0.00         4
         868       0.88      0.78      0.82         9
         869       0.00      0.00      0.00         4
         870       1.00      0.25      0.40         4
         871       0.75      0.75      0.75         4
         872       0.15      0.75      0.25         4
         873       1.00      0.80      0.89         5
         874       0.78      0.78      0.78         9
         875       0.00      0.00      0.00         4
         876       1.00      1.00      1.00         9
         877       0.00      0.00      0.00         4
         878       0.00      0.00      0.00         4
         879       0.00      0.00      0.00         4
         880       1.00      0.75      0.86         4
         881       0.00      0.00      0.00         4
         882       0.50      0.25      0.33         4
         883       0.78      0.78      0.78         9
         884       1.00      0.78      0.88         9
         885       0.33      0.50      0.40         4
         886       0.00      0.00      0.00         4
         887       1.00      0.89      0.94         9
         888       0.00      0.00      0.00         4
         889       0.90      1.00      0.95         9
         890       0.67      0.89      0.76         9
         891       1.00      1.00      1.00         5
         892       0.90      1.00      0.95         9
         893       1.00      0.44      0.62         9

    accuracy                           0.67      4917
   macro avg       0.64      0.64      0.61      4917
weighted avg       0.66      0.67      0.64      4917

task_train_time: {0: 0.1201090899999997, 1: 0.03498338400000023, 2: 0.03454259999999998, 3: 0.033767985999999084, 4: 0.03141221499999958, 5: 0.02952743599999863, 6: 0.03483787200000066, 7: 0.02821750100000031, 8: 0.033885753999999935, 9: 0.02838299099999908, 10: 0.025893871000000956, 11: 0.03153623600000088, 12: 0.02785660399999834, 13: 0.031948567000000594, 14: 0.028315945999999315, 15: 0.0298845459999999, 16: 0.03327326700000022, 17: 0.035822987000001305, 18: 0.028856979000000393, 19: 0.033192960999999244, 20: 0.034117993000000624, 21: 0.036062058999998925, 22: 0.03028282799999893, 23: 0.03113946700000092, 24: 0.03258961600000099, 25: 0.034091198999998795, 26: 0.027556125000000264, 27: 0.03336805700000056, 28: 0.03446070300000059, 29: 0.02916611900000099, 30: 0.03590258999999918, 31: 0.03288738400000035, 32: 0.03411929700000016, 33: 0.033611804999999606, 34: 0.0341848899999988, 35: 0.028145890000001117, 36: 0.03233838399999911, 37: 0.03322246199999768, 38: 0.028064426000000253, 39: 0.03382784000000072, 40: 0.02943489300000124, 41: 0.0360385739999991, 42: 0.03170832700000048, 43: 0.0396613890000026}
prediction_time: 0.0002590649999980599
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
