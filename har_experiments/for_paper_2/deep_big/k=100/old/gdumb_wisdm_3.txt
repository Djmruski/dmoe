Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='17c4461b-cac2-4cf2-9e50-121c3a6cbc3d', conf_timestamp='2023-08-10 06:05:02.672138', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 77.32 % 	 [Task-IL]: 39.69 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 58.9 % 	 [Task-IL]: 34.38 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 38.8 % 	 [Task-IL]: 31.54 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 31.45 % 	 [Task-IL]: 31.11 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 22.01 % 	 [Task-IL]: 28.29 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 27.35 % 	 [Task-IL]: 28.57 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.05 % 	 [Task-IL]: 28.6 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 23.36 % 	 [Task-IL]: 27.43 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 19.21 % 	 [Task-IL]: 26.78 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 21.9 % 	 [Task-IL]: 27.22 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.99 % 	 [Task-IL]: 27.56 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 17.74 % 	 [Task-IL]: 26.55 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 15.01 % 	 [Task-IL]: 26.95 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 13.67 % 	 [Task-IL]: 27.52 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 13.09 % 	 [Task-IL]: 26.86 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 16.92 % 	 [Task-IL]: 26.45 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 8.03 % 	 [Task-IL]: 26.03 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.11 % 	 [Task-IL]: 26.68 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.85 % 	 [Task-IL]: 27.54 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 5.41 % 	 [Task-IL]: 26.81 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 7.02 % 	 [Task-IL]: 26.9 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 6.06 % 	 [Task-IL]: 26.31 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.05 % 	 [Task-IL]: 26.41 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 9.43 % 	 [Task-IL]: 26.55 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 8.07 % 	 [Task-IL]: 26.1 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.96 % 	 [Task-IL]: 26.06 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 8.41 % 	 [Task-IL]: 25.9 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 8.8 % 	 [Task-IL]: 25.5 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 8.16 % 	 [Task-IL]: 25.24 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 9.02 % 	 [Task-IL]: 24.78 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 8.38 % 	 [Task-IL]: 25.48 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.15 % 	 [Task-IL]: 25.2 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.15 % 	 [Task-IL]: 25.09 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 5.56 % 	 [Task-IL]: 25.31 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.88 % 	 [Task-IL]: 25.03 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.18 % 	 [Task-IL]: 25.42 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.71 % 	 [Task-IL]: 24.99 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.96 % 	 [Task-IL]: 24.84 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.83 % 	 [Task-IL]: 24.88 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 6.24 % 	 [Task-IL]: 25.05 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 6.73 % 	 [Task-IL]: 25.06 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.15 % 	 [Task-IL]: 25.01 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.82 % 	 [Task-IL]: 25.26 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74879, 254: 34, 119: 33, 305: 33, 300: 33, 406: 33, 506: 33, 637: 33, 643: 33, 12: 32, 65: 32, 72: 32, 150: 32, 184: 32, 190: 32, 221: 32, 287: 32, 408: 32, 448: 32, 465: 32, 576: 32, 612: 32, 625: 32, 659: 32, 657: 32, 726: 32, 751: 32, 840: 32, 886: 32, 29: 31, 20: 31, 24: 31, 69: 31, 201: 31, 425: 31, 441: 31, 492: 31, 580: 31, 614: 31, 644: 31, 671: 31, 700: 31, 702: 31, 775: 31, 809: 31, 845: 31, 869: 31, 858: 31, 22: 30, 51: 30, 68: 30, 92: 30, 94: 30, 136: 30, 162: 30, 168: 30, 191: 30, 194: 30, 273: 30, 268: 30, 331: 30, 347: 30, 392: 30, 375: 30, 439: 30, 451: 30, 552: 30, 594: 30, 652: 30, 662: 30, 749: 30, 734: 30, 761: 30, 780: 30, 797: 30, 838: 30, 852: 30, 859: 30, 880: 30, 36: 29, 44: 29, 39: 29, 53: 29, 78: 29, 93: 29, 100: 29, 103: 29, 120: 29, 151: 29, 139: 29, 179: 29, 199: 29, 247: 29, 251: 29, 282: 29, 294: 29, 301: 29, 308: 29, 344: 29, 338: 29, 366: 29, 356: 29, 376: 29, 409: 29, 423: 29, 432: 29, 450: 29, 504: 29, 535: 29, 549: 29, 543: 29, 587: 29, 629: 29, 640: 29, 642: 29, 686: 29, 787: 29, 784: 29, 817: 29, 854: 29, 871: 29, 890: 29, 893: 29, 4: 28, 17: 28, 64: 28, 97: 28, 110: 28, 149: 28, 204: 28, 225: 28, 274: 28, 303: 28, 306: 28, 341: 28, 340: 28, 361: 28, 362: 28, 359: 28, 374: 28, 383: 28, 381: 28, 403: 28, 399: 28, 443: 28, 462: 28, 508: 28, 501: 28, 528: 28, 527: 28, 626: 28, 677: 28, 722: 28, 763: 28, 878: 28, 21: 27, 52: 27, 67: 27, 66: 27, 83: 27, 135: 27, 170: 27, 185: 27, 219: 27, 279: 27, 278: 27, 348: 27, 398: 27, 426: 27, 414: 27, 452: 27, 481: 27, 502: 27, 521: 27, 574: 27, 600: 27, 667: 27, 691: 27, 789: 27, 801: 27, 830: 27, 836: 27, 860: 27, 888: 27, 18: 26, 77: 26, 121: 26, 226: 26, 345: 26, 349: 26, 430: 26, 476: 26, 537: 26, 664: 26, 663: 26, 683: 26, 679: 26, 674: 26, 729: 26, 745: 26, 747: 26, 753: 26, 762: 26, 777: 26, 776: 26, 829: 26, 847: 26, 837: 26, 872: 26, 49: 25, 70: 25, 140: 25, 183: 25, 243: 25, 320: 25, 363: 25, 386: 25, 436: 25, 446: 25, 623: 25, 653: 25, 815: 25, 855: 25, 865: 25, 7: 24, 56: 24, 351: 24, 435: 24, 473: 24, 513: 24, 601: 24, 666: 24, 842: 24, 883: 24, 309: 23, 620: 23, 322: 22, 290: 21, 84: 20, 466: 20, 713: 19, 118: 18, 26: 17, 241: 17, 336: 17, 431: 17, 563: 17, 786: 17, 47: 16, 148: 16, 163: 16, 311: 16, 412: 16, 485: 16, 480: 16, 512: 16, 511: 16, 564: 16, 572: 16, 692: 16, 708: 16, 714: 16, 750: 16, 746: 16, 769: 16, 806: 16, 823: 16, 825: 16, 835: 16, 856: 16, 28: 15, 6: 15, 23: 15, 45: 15, 61: 15, 96: 15, 142: 15, 167: 15, 182: 15, 220: 15, 223: 15, 289: 15, 335: 15, 370: 15, 355: 15, 393: 15, 418: 15, 445: 15, 447: 15, 458: 15, 533: 15, 544: 15, 590: 15, 597: 15, 617: 15, 636: 15, 647: 15, 673: 15, 690: 15, 697: 15, 704: 15, 739: 15, 759: 15, 758: 15, 785: 15, 792: 15, 800: 15, 828: 15, 841: 15, 868: 15, 5: 14, 32: 14, 13: 14, 30: 14, 89: 14, 102: 14, 122: 14, 126: 14, 158: 14, 212: 14, 209: 14, 211: 14, 207: 14, 218: 14, 216: 14, 240: 14, 236: 14, 245: 14, 259: 14, 291: 14, 286: 14, 307: 14, 332: 14, 319: 14, 325: 14, 350: 14, 378: 14, 411: 14, 400: 14, 416: 14, 456: 14, 454: 14, 515: 14, 588: 14, 583: 14, 609: 14, 613: 14, 649: 14, 701: 14, 698: 14, 732: 14, 736: 14, 760: 14, 783: 14, 812: 14, 802: 14, 827: 14, 820: 14, 846: 14, 861: 14, 27: 13, 16: 13, 46: 13, 54: 13, 57: 13, 60: 13, 86: 13, 88: 13, 81: 13, 91: 13, 105: 13, 111: 13, 95: 13, 114: 13, 146: 13, 134: 13, 164: 13, 186: 13, 177: 13, 210: 13, 217: 13, 231: 13, 234: 13, 272: 13, 264: 13, 262: 13, 270: 13, 293: 13, 283: 13, 321: 13, 342: 13, 337: 13, 368: 13, 360: 13, 389: 13, 384: 13, 388: 13, 402: 13, 401: 13, 427: 13, 419: 13, 438: 13, 455: 13, 468: 13, 470: 13, 489: 13, 479: 13, 490: 13, 482: 13, 495: 13, 497: 13, 509: 13, 510: 13, 498: 13, 531: 13, 530: 13, 517: 13, 547: 13, 538: 13, 569: 13, 557: 13, 570: 13, 610: 13, 607: 13, 631: 13, 618: 13, 621: 13, 627: 13, 633: 13, 658: 13, 654: 13, 681: 13, 688: 13, 687: 13, 678: 13, 705: 13, 717: 13, 728: 13, 719: 13, 770: 13, 754: 13, 755: 13, 773: 13, 804: 13, 796: 13, 799: 13, 824: 13, 818: 13, 833: 13, 821: 13, 814: 13, 839: 13, 864: 13, 870: 13, 873: 13, 879: 13, 885: 13, 889: 13, 8: 12, 25: 12, 3: 12, 31: 12, 38: 12, 34: 12, 73: 12, 59: 12, 58: 12, 63: 12, 85: 12, 82: 12, 108: 12, 104: 12, 106: 12, 112: 12, 128: 12, 132: 12, 133: 12, 147: 12, 156: 12, 154: 12, 157: 12, 166: 12, 174: 12, 206: 12, 224: 12, 214: 12, 233: 12, 222: 12, 238: 12, 239: 12, 246: 12, 250: 12, 249: 12, 252: 12, 260: 12, 271: 12, 269: 12, 288: 12, 275: 12, 280: 12, 284: 12, 285: 12, 277: 12, 312: 12, 296: 12, 318: 12, 315: 12, 323: 12, 326: 12, 317: 12, 328: 12, 324: 12, 314: 12, 346: 12, 334: 12, 339: 12, 343: 12, 373: 12, 371: 12, 367: 12, 358: 12, 394: 12, 433: 12, 417: 12, 428: 12, 444: 12, 442: 12, 437: 12, 471: 12, 464: 12, 486: 12, 505: 12, 503: 12, 526: 12, 525: 12, 520: 12, 529: 12, 524: 12, 522: 12, 546: 12, 571: 12, 555: 12, 558: 12, 567: 12, 582: 12, 591: 12, 586: 12, 602: 12, 595: 12, 616: 12, 619: 12, 622: 12, 615: 12, 646: 12, 648: 12, 638: 12, 660: 12, 672: 12, 689: 12, 685: 12, 676: 12, 684: 12, 699: 12, 712: 12, 695: 12, 733: 12, 720: 12, 716: 12, 721: 12, 742: 12, 737: 12, 748: 12, 766: 12, 756: 12, 772: 12, 782: 12, 778: 12, 813: 12, 794: 12, 832: 12, 831: 12, 850: 12, 843: 12, 848: 12, 857: 12, 866: 12, 891: 12, 892: 12, 881: 12, 882: 12, 33: 11, 10: 11, 9: 11, 2: 11, 50: 11, 43: 11, 35: 11, 41: 11, 37: 11, 42: 11, 76: 11, 80: 11, 74: 11, 99: 11, 107: 11, 116: 11, 125: 11, 123: 11, 131: 11, 130: 11, 124: 11, 141: 11, 152: 11, 145: 11, 137: 11, 160: 11, 171: 11, 161: 11, 165: 11, 193: 11, 181: 11, 188: 11, 195: 11, 205: 11, 197: 11, 208: 11, 200: 11, 215: 11, 229: 11, 253: 11, 248: 11, 242: 11, 261: 11, 267: 11, 281: 11, 292: 11, 310: 11, 297: 11, 330: 11, 333: 11, 364: 11, 372: 11, 354: 11, 365: 11, 357: 11, 382: 11, 379: 11, 380: 11, 387: 11, 377: 11, 396: 11, 397: 11, 404: 11, 420: 11, 422: 11, 415: 11, 424: 11, 449: 11, 434: 11, 469: 11, 459: 11, 457: 11, 467: 11, 461: 11, 491: 11, 478: 11, 474: 11, 487: 11, 496: 11, 500: 11, 523: 11, 514: 11, 518: 11, 532: 11, 542: 11, 539: 11, 548: 11, 553: 11, 551: 11, 534: 11, 568: 11, 573: 11, 566: 11, 562: 11, 585: 11, 581: 11, 577: 11, 593: 11, 575: 11, 589: 11, 578: 11, 579: 11, 599: 11, 604: 11, 608: 11, 606: 11, 605: 11, 603: 11, 624: 11, 628: 11, 665: 11, 661: 11, 669: 11, 682: 11, 693: 11, 675: 11, 694: 11, 710: 11, 706: 11, 723: 11, 730: 11, 727: 11, 718: 11, 724: 11, 743: 11, 744: 11, 767: 11, 765: 11, 774: 11, 791: 11, 790: 11, 779: 11, 808: 11, 810: 11, 805: 11, 798: 11, 803: 11, 816: 11, 853: 11, 851: 11, 863: 11, 876: 11, 884: 11, 877: 11, 874: 11, 875: 11, 15: 10, 11: 10, 14: 10, 48: 10, 71: 10, 55: 10, 90: 10, 87: 10, 75: 10, 79: 10, 98: 10, 101: 10, 113: 10, 115: 10, 127: 10, 153: 10, 144: 10, 143: 10, 155: 10, 169: 10, 178: 10, 192: 10, 180: 10, 175: 10, 187: 10, 213: 10, 203: 10, 202: 10, 232: 10, 235: 10, 258: 10, 255: 10, 263: 10, 256: 10, 302: 10, 299: 10, 295: 10, 298: 10, 304: 10, 313: 10, 316: 10, 353: 10, 369: 10, 390: 10, 385: 10, 413: 10, 407: 10, 405: 10, 395: 10, 421: 10, 453: 10, 463: 10, 460: 10, 472: 10, 488: 10, 493: 10, 477: 10, 484: 10, 499: 10, 494: 10, 507: 10, 516: 10, 541: 10, 536: 10, 545: 10, 561: 10, 565: 10, 554: 10, 584: 10, 598: 10, 596: 10, 630: 10, 641: 10, 639: 10, 634: 10, 645: 10, 650: 10, 655: 10, 670: 10, 703: 10, 707: 10, 709: 10, 725: 10, 731: 10, 740: 10, 735: 10, 738: 10, 741: 10, 771: 10, 757: 10, 768: 10, 764: 10, 793: 10, 781: 10, 788: 10, 795: 10, 811: 10, 822: 10, 887: 10, 1: 9, 40: 9, 109: 9, 129: 9, 117: 9, 138: 9, 172: 9, 159: 9, 189: 9, 176: 9, 196: 9, 228: 9, 244: 9, 265: 9, 257: 9, 327: 9, 329: 9, 352: 9, 391: 9, 410: 9, 429: 9, 440: 9, 475: 9, 483: 9, 519: 9, 550: 9, 540: 9, 559: 9, 592: 9, 632: 9, 635: 9, 656: 9, 680: 9, 711: 9, 752: 9, 807: 9, 826: 9, 819: 9, 834: 9, 849: 9, 862: 9, 19: 8, 62: 8, 173: 8, 198: 8, 227: 8, 276: 8, 556: 8, 611: 8, 668: 8, 715: 8, 844: 8, 867: 8, 230: 7, 560: 7, 651: 7, 237: 6, 266: 6, 696: 5})
fit_time: 7.506046079000001

Accuracy for 44 task(s): 	 [Class-IL]: 66.29 % 	 [Task-IL]: 29.23 %

CLASS_IL_ACC: 
	[71.64948453608247, 63.24786324786324, 74.01574803149606, 62.727272727272734, 62.38532110091744, 63.63636363636363, 75.21367521367522, 61.224489795918366, 45.04504504504504, 74.03846153846155, 56.86274509803921, 73.46938775510205, 69.38775510204081, 68.14159292035397, 65.57377049180327, 76.04166666666666, 62.5, 46.017699115044245, 64.95726495726495, 77.19298245614034, 67.82608695652173, 73.48484848484848, 51.9607843137255, 76.76767676767676, 76.52173913043478, 51.515151515151516, 71.69811320754717, 53.57142857142857, 56.19047619047619, 71.84466019417476, 71.68141592920354, 57.98319327731093, 76.85950413223141, 77.87610619469027, 70.40816326530613, 73.73737373737373, 55.75221238938053, 60.78431372549019, 70.58823529411765, 60.0, 74.52830188679245, 67.21311475409836, 60.9375, 73.50427350427351]
TASK_IL_ACC: 
	[53.608247422680414, 24.786324786324787, 23.62204724409449, 29.09090909090909, 31.19266055045872, 30.303030303030305, 29.914529914529915, 22.448979591836736, 26.126126126126124, 28.846153846153843, 29.411764705882355, 25.510204081632654, 26.53061224489796, 30.08849557522124, 22.950819672131146, 25.0, 25.0, 30.973451327433626, 28.205128205128204, 30.701754385964914, 26.08695652173913, 29.545454545454547, 24.509803921568626, 29.292929292929294, 15.65217391304348, 24.242424242424242, 32.075471698113205, 25.0, 24.761904761904763, 28.155339805825243, 26.548672566371685, 24.369747899159663, 27.27272727272727, 32.743362831858406, 25.510204081632654, 25.252525252525253, 23.008849557522122, 24.509803921568626, 31.092436974789916, 27.0, 28.30188679245283, 30.327868852459016, 35.9375, 90.5982905982906]
f1_micro: 66.50396583282489
f1_macro: 60.98687827522779
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.00      0.00      0.00         4
           2       1.00      1.00      1.00         4
           3       0.71      1.00      0.83         5
           4       1.00      1.00      1.00         9
           5       0.80      0.80      0.80         5
           6       0.44      0.80      0.57         5
           7       0.86      0.67      0.75         9
           8       0.00      0.00      0.00         4
           9       1.00      1.00      1.00         4
          10       0.00      0.00      0.00         4
          11       1.00      1.00      1.00         4
          12       0.64      1.00      0.78         9
          13       1.00      1.00      1.00         4
          14       0.75      0.75      0.75         4
          15       0.75      0.75      0.75         4
          16       0.60      0.75      0.67         4
          17       0.80      0.89      0.84         9
          18       0.89      0.89      0.89         9
          19       1.00      0.50      0.67         4
          20       0.89      0.89      0.89         9
          21       0.75      0.67      0.71         9
          22       0.80      0.89      0.84         9
          23       0.33      0.60      0.43         5
          24       0.08      0.22      0.12         9
          25       0.12      0.75      0.21         4
          26       0.56      1.00      0.71         5
          27       0.00      0.00      0.00         4
          28       1.00      1.00      1.00         5
          29       0.82      1.00      0.90         9
          30       1.00      1.00      1.00         5
          31       0.00      0.00      0.00         4
          32       1.00      0.20      0.33         5
          33       0.80      1.00      0.89         4
          34       1.00      1.00      1.00         4
          35       0.50      0.25      0.33         4
          36       0.70      0.78      0.74         9
          37       1.00      0.75      0.86         4
          38       0.00      0.00      0.00         4
          39       0.00      0.00      0.00         9
          40       0.00      0.00      0.00         4
          41       1.00      0.75      0.86         4
          42       0.75      0.75      0.75         4
          43       0.75      0.75      0.75         4
          44       0.88      0.78      0.82         9
          45       1.00      0.80      0.89         5
          46       1.00      0.75      0.86         4
          47       1.00      0.40      0.57         5
          48       1.00      0.75      0.86         4
          49       1.00      0.89      0.94         9
          50       0.00      0.00      0.00         4
          51       0.75      1.00      0.86         9
          52       1.00      0.89      0.94         9
          53       0.75      0.67      0.71         9
          54       1.00      0.50      0.67         4
          55       0.67      1.00      0.80         4
          56       0.88      0.78      0.82         9
          57       1.00      1.00      1.00         4
          58       1.00      1.00      1.00         4
          59       1.00      1.00      1.00         5
          60       1.00      0.75      0.86         4
          61       0.80      0.80      0.80         5
          62       0.80      1.00      0.89         4
          63       1.00      0.50      0.67         4
          64       0.62      0.56      0.59         9
          65       1.00      1.00      1.00         9
          66       0.80      0.89      0.84         9
          67       0.40      0.67      0.50         9
          68       0.78      0.78      0.78         9
          69       1.00      1.00      1.00         9
          70       0.00      0.00      0.00         9
          71       0.50      0.25      0.33         4
          72       1.00      0.78      0.88         9
          73       1.00      0.75      0.86         4
          74       0.22      0.50      0.31         4
          75       1.00      1.00      1.00         4
          76       1.00      1.00      1.00         4
          77       1.00      0.44      0.62         9
          78       0.54      0.88      0.67         8
          79       0.57      1.00      0.73         4
          80       0.75      0.75      0.75         4
          81       0.80      1.00      0.89         4
          82       0.80      1.00      0.89         4
          83       0.86      0.67      0.75         9
          84       0.88      0.88      0.88         8
          85       0.25      0.25      0.25         4
          86       1.00      1.00      1.00         5
          87       1.00      0.25      0.40         4
          88       0.67      0.50      0.57         4
          89       0.60      0.60      0.60         5
          90       1.00      1.00      1.00         4
          91       0.00      0.00      0.00         4
          92       0.00      0.00      0.00         9
          93       0.11      0.44      0.18         9
          94       0.89      0.89      0.89         9
          95       0.60      0.75      0.67         4
          96       1.00      1.00      1.00         5
          97       0.78      0.78      0.78         9
          98       0.00      0.00      0.00         4
          99       0.09      0.75      0.16         4
         100       0.67      0.44      0.53         9
         101       0.67      0.50      0.57         4
         102       0.44      0.80      0.57         5
         103       1.00      1.00      1.00         9
         104       0.50      1.00      0.67         4
         105       0.75      0.60      0.67         5
         106       0.00      0.00      0.00         4
         107       0.00      0.00      0.00         4
         108       0.00      0.00      0.00         4
         109       0.60      0.75      0.67         4
         110       0.89      0.89      0.89         9
         111       0.00      0.00      0.00         5
         112       0.07      0.25      0.11         4
         113       1.00      1.00      1.00         4
         114       0.00      0.00      0.00         4
         115       1.00      1.00      1.00         4
         116       1.00      1.00      1.00         4
         117       0.00      0.00      0.00         4
         118       0.75      0.50      0.60         6
         119       0.75      1.00      0.86         9
         120       0.70      0.78      0.74         9
         121       0.89      0.89      0.89         9
         122       0.80      0.80      0.80         5
         123       0.00      0.00      0.00         4
         124       1.00      0.75      0.86         4
         125       1.00      0.75      0.86         4
         126       0.71      1.00      0.83         5
         127       0.00      0.00      0.00         4
         128       0.00      0.00      0.00         4
         129       0.50      0.75      0.60         4
         130       0.00      0.00      0.00         4
         131       0.67      1.00      0.80         4
         132       0.80      1.00      0.89         4
         133       0.08      0.50      0.14         4
         134       0.14      1.00      0.25         4
         135       0.80      0.89      0.84         9
         136       0.89      0.89      0.89         9
         137       0.67      1.00      0.80         4
         138       0.00      0.00      0.00         4
         139       0.80      0.44      0.57         9
         140       0.82      1.00      0.90         9
         141       0.80      1.00      0.89         4
         142       0.80      0.80      0.80         5
         143       1.00      1.00      1.00         4
         144       0.75      0.75      0.75         4
         145       0.50      0.50      0.50         4
         146       0.60      0.75      0.67         4
         147       1.00      1.00      1.00         4
         148       0.67      0.40      0.50         5
         149       0.50      0.33      0.40         9
         150       1.00      1.00      1.00         9
         151       0.47      0.78      0.58         9
         152       0.60      0.75      0.67         4
         153       1.00      0.75      0.86         4
         154       1.00      0.25      0.40         4
         155       0.50      0.25      0.33         4
         156       0.67      0.50      0.57         4
         157       0.00      0.00      0.00         4
         158       0.40      1.00      0.57         4
         159       0.00      0.00      0.00         4
         160       0.00      0.00      0.00         4
         161       0.00      0.00      0.00         4
         162       0.88      0.78      0.82         9
         163       1.00      1.00      1.00         5
         164       1.00      1.00      1.00         5
         165       0.12      0.75      0.20         4
         166       1.00      0.75      0.86         4
         167       1.00      0.80      0.89         5
         168       0.67      0.89      0.76         9
         169       0.80      1.00      0.89         4
         170       0.64      1.00      0.78         9
         171       0.75      0.75      0.75         4
         172       0.00      0.00      0.00         4
         173       0.50      0.25      0.33         4
         174       0.12      0.75      0.21         4
         175       0.75      0.75      0.75         4
         176       0.00      0.00      0.00         4
         177       0.00      0.00      0.00         4
         178       0.50      0.50      0.50         4
         179       0.00      0.00      0.00         9
         180       0.75      0.75      0.75         4
         181       0.00      0.00      0.00         4
         182       0.67      0.80      0.73         5
         183       1.00      0.67      0.80         9
         184       1.00      0.89      0.94         9
         185       0.00      0.00      0.00         9
         186       0.00      0.00      0.00         4
         187       0.80      1.00      0.89         4
         188       0.80      1.00      0.89         4
         189       1.00      1.00      1.00         4
         190       0.00      0.00      0.00         9
         191       0.67      0.89      0.76         9
         192       1.00      0.25      0.40         4
         193       0.00      0.00      0.00         4
         194       1.00      0.78      0.88         9
         195       1.00      1.00      1.00         4
         196       1.00      1.00      1.00         4
         197       0.00      0.00      0.00         4
         198       0.80      1.00      0.89         4
         199       0.60      1.00      0.75         9
         200       1.00      0.50      0.67         4
         201       1.00      0.89      0.94         9
         202       1.00      0.75      0.86         4
         203       0.00      0.00      0.00         4
         204       0.89      0.89      0.89         9
         205       1.00      1.00      1.00         4
         206       0.00      0.00      0.00         4
         207       0.80      1.00      0.89         4
         208       1.00      0.50      0.67         4
         209       0.83      1.00      0.91         5
         210       1.00      1.00      1.00         5
         211       0.00      0.00      0.00         5
         212       0.80      0.80      0.80         5
         213       1.00      1.00      1.00         4
         214       0.80      1.00      0.89         4
         215       0.00      0.00      0.00         4
         216       0.50      0.40      0.44         5
         217       0.00      0.00      0.00         4
         218       1.00      1.00      1.00         4
         219       0.53      1.00      0.69         9
         220       0.00      0.00      0.00         4
         221       0.43      0.33      0.38         9
         222       0.00      0.00      0.00         4
         223       1.00      1.00      1.00         5
         224       0.00      0.00      0.00         4
         225       0.75      0.67      0.71         9
         226       1.00      0.22      0.36         9
         227       0.67      1.00      0.80         4
         228       1.00      1.00      1.00         4
         229       0.75      0.75      0.75         4
         230       1.00      0.50      0.67         4
         231       1.00      0.75      0.86         4
         232       1.00      0.75      0.86         4
         233       1.00      1.00      1.00         4
         234       1.00      1.00      1.00         4
         235       1.00      0.75      0.86         4
         236       0.80      1.00      0.89         4
         237       1.00      1.00      1.00         4
         238       0.50      0.40      0.44         5
         239       0.00      0.00      0.00         4
         240       0.00      0.00      0.00         4
         241       1.00      0.80      0.89         5
         242       0.43      0.75      0.55         4
         243       0.33      0.89      0.48         9
         244       0.57      1.00      0.73         4
         245       0.83      1.00      0.91         5
         246       0.00      0.00      0.00         4
         247       0.78      0.78      0.78         9
         248       1.00      1.00      1.00         4
         249       0.00      0.00      0.00         4
         250       0.80      1.00      0.89         4
         251       1.00      1.00      1.00         9
         252       1.00      0.75      0.86         4
         253       1.00      1.00      1.00         4
         254       0.90      1.00      0.95         9
         255       0.00      0.00      0.00         4
         256       1.00      1.00      1.00         4
         257       0.80      1.00      0.89         4
         258       0.00      0.00      0.00         4
         259       0.83      1.00      0.91         5
         260       0.00      0.00      0.00         4
         261       0.50      0.75      0.60         4
         262       0.67      0.80      0.73         5
         263       1.00      0.50      0.67         4
         264       1.00      0.50      0.67         4
         265       1.00      0.25      0.40         4
         266       1.00      1.00      1.00         4
         267       0.38      0.75      0.50         4
         268       0.88      0.78      0.82         9
         269       1.00      1.00      1.00         4
         270       0.67      1.00      0.80         4
         271       0.00      0.00      0.00         4
         272       1.00      1.00      1.00         5
         273       0.70      0.78      0.74         9
         274       0.67      0.22      0.33         9
         275       1.00      1.00      1.00         4
         276       1.00      1.00      1.00         4
         277       0.43      0.75      0.55         4
         278       1.00      0.89      0.94         9
         279       0.60      0.67      0.63         9
         280       0.00      0.00      0.00         4
         281       0.00      0.00      0.00         4
         282       0.78      0.78      0.78         9
         283       0.75      0.60      0.67         5
         284       1.00      1.00      1.00         4
         285       1.00      1.00      1.00         4
         286       0.00      0.00      0.00         4
         287       0.70      0.78      0.74         9
         288       1.00      0.75      0.86         4
         289       0.67      0.80      0.73         5
         290       1.00      1.00      1.00         9
         291       0.67      0.80      0.73         5
         292       0.18      0.50      0.27         4
         293       0.38      0.75      0.50         4
         294       0.00      0.00      0.00         9
         295       1.00      0.25      0.40         4
         296       0.75      0.75      0.75         4
         297       0.80      1.00      0.89         4
         298       1.00      1.00      1.00         4
         299       1.00      1.00      1.00         4
         300       0.88      0.78      0.82         9
         301       0.78      0.78      0.78         9
         302       1.00      0.75      0.86         4
         303       0.88      0.78      0.82         9
         304       0.00      0.00      0.00         4
         305       1.00      0.89      0.94         9
         306       1.00      1.00      1.00         9
         307       0.50      0.60      0.55         5
         308       0.82      1.00      0.90         9
         309       0.00      0.00      0.00         9
         310       0.67      0.50      0.57         4
         311       0.71      1.00      0.83         5
         312       1.00      1.00      1.00         4
         313       0.00      0.00      0.00         4
         314       0.12      0.75      0.20         4
         315       0.57      0.80      0.67         5
         316       0.00      0.00      0.00         4
         317       1.00      0.80      0.89         5
         318       1.00      0.50      0.67         4
         319       0.71      1.00      0.83         5
         320       1.00      1.00      1.00         9
         321       0.36      1.00      0.53         4
         322       0.88      1.00      0.93         7
         323       0.43      0.75      0.55         4
         324       1.00      0.50      0.67         4
         325       0.75      0.75      0.75         4
         326       1.00      0.50      0.67         4
         327       0.80      1.00      0.89         4
         328       0.00      0.00      0.00         4
         329       1.00      1.00      1.00         4
         330       0.75      0.75      0.75         4
         331       0.80      0.89      0.84         9
         332       0.17      0.50      0.25         4
         333       1.00      1.00      1.00         4
         334       0.00      0.00      0.00         4
         335       0.80      0.80      0.80         5
         336       0.71      1.00      0.83         5
         337       1.00      0.80      0.89         5
         338       0.54      0.78      0.64         9
         339       1.00      1.00      1.00         4
         340       0.15      0.89      0.25         9
         341       1.00      0.56      0.71         9
         342       1.00      1.00      1.00         4
         343       1.00      0.75      0.86         4
         344       0.33      0.11      0.17         9
         345       0.62      0.56      0.59         9
         346       0.50      1.00      0.67         4
         347       0.80      0.89      0.84         9
         348       0.00      0.00      0.00         9
         349       1.00      0.89      0.94         9
         350       1.00      0.25      0.40         4
         351       1.00      1.00      1.00         9
         352       0.00      0.00      0.00         4
         353       0.00      0.00      0.00         4
         354       0.00      0.00      0.00         4
         355       0.00      0.00      0.00         5
         356       1.00      1.00      1.00         9
         357       1.00      1.00      1.00         4
         358       0.00      0.00      0.00         4
         359       0.00      0.00      0.00         9
         360       0.50      1.00      0.67         4
         361       0.44      0.78      0.56         9
         362       0.24      1.00      0.39         9
         363       0.50      0.22      0.31         9
         364       0.00      0.00      0.00         4
         365       0.00      0.00      0.00         4
         366       0.73      0.89      0.80         9
         367       1.00      0.75      0.86         4
         368       0.00      0.00      0.00         5
         369       1.00      1.00      1.00         4
         370       0.00      0.00      0.00         5
         371       0.00      0.00      0.00         4
         372       0.00      0.00      0.00         4
         373       0.67      0.50      0.57         4
         374       0.00      0.00      0.00         9
         375       0.78      0.78      0.78         9
         376       0.60      1.00      0.75         9
         377       1.00      1.00      1.00         4
         378       1.00      1.00      1.00         5
         379       0.67      1.00      0.80         4
         380       0.00      0.00      0.00         4
         381       1.00      0.89      0.94         9
         382       0.00      0.00      0.00         4
         383       0.88      0.88      0.88         8
         384       0.33      0.60      0.43         5
         385       0.75      0.75      0.75         4
         386       1.00      0.67      0.80         9
         387       1.00      1.00      1.00         4
         388       0.36      1.00      0.53         4
         389       1.00      0.25      0.40         4
         390       0.80      1.00      0.89         4
         391       1.00      1.00      1.00         4
         392       0.33      0.11      0.17         9
         393       0.67      0.40      0.50         5
         394       0.40      0.40      0.40         5
         395       0.00      0.00      0.00         4
         396       0.75      0.75      0.75         4
         397       0.67      0.50      0.57         4
         398       1.00      1.00      1.00         9
         399       0.80      0.89      0.84         9
         400       0.00      0.00      0.00         4
         401       1.00      0.75      0.86         4
         402       0.83      1.00      0.91         5
         403       0.82      1.00      0.90         9
         404       1.00      1.00      1.00         4
         405       0.67      1.00      0.80         4
         406       0.90      1.00      0.95         9
         407       0.33      0.25      0.29         4
         408       1.00      1.00      1.00         9
         409       1.00      0.67      0.80         9
         410       1.00      1.00      1.00         4
         411       1.00      1.00      1.00         5
         412       0.60      0.60      0.60         5
         413       1.00      0.50      0.67         4
         414       0.00      0.00      0.00         9
         415       1.00      0.50      0.67         4
         416       0.56      1.00      0.71         5
         417       1.00      1.00      1.00         4
         418       1.00      0.80      0.89         5
         419       0.80      1.00      0.89         4
         420       1.00      1.00      1.00         4
         421       0.40      1.00      0.57         4
         422       1.00      1.00      1.00         4
         423       0.62      0.56      0.59         9
         424       0.67      0.40      0.50         5
         425       0.75      1.00      0.86         9
         426       1.00      1.00      1.00         9
         427       1.00      0.80      0.89         5
         428       1.00      1.00      1.00         4
         429       0.00      0.00      0.00         4
         430       0.60      0.33      0.43         9
         431       0.83      1.00      0.91         5
         432       0.83      0.56      0.67         9
         433       0.33      0.25      0.29         4
         434       0.50      0.75      0.60         4
         435       0.88      0.78      0.82         9
         436       0.13      0.89      0.23         9
         437       0.00      0.00      0.00         4
         438       0.13      0.50      0.21         4
         439       1.00      0.89      0.94         9
         440       0.00      0.00      0.00         4
         441       0.73      0.89      0.80         9
         442       0.80      1.00      0.89         4
         443       0.56      1.00      0.72         9
         444       0.80      1.00      0.89         4
         445       1.00      1.00      1.00         5
         446       1.00      0.44      0.62         9
         447       1.00      1.00      1.00         5
         448       1.00      0.78      0.88         9
         449       1.00      0.75      0.86         4
         450       0.00      0.00      0.00         9
         451       0.89      0.89      0.89         9
         452       1.00      0.89      0.94         9
         453       0.67      1.00      0.80         4
         454       0.67      1.00      0.80         4
         455       0.00      0.00      0.00         4
         456       0.50      0.60      0.55         5
         457       0.00      0.00      0.00         4
         458       0.75      0.60      0.67         5
         459       0.00      0.00      0.00         4
         460       1.00      0.25      0.40         4
         461       1.00      0.20      0.33         5
         462       0.86      0.67      0.75         9
         463       1.00      0.40      0.57         5
         464       0.75      0.75      0.75         4
         465       0.42      0.56      0.48         9
         466       0.58      1.00      0.74         7
         467       1.00      0.75      0.86         4
         468       0.00      0.00      0.00         4
         469       0.67      0.50      0.57         4
         470       0.50      0.50      0.50         4
         471       0.80      1.00      0.89         4
         472       1.00      0.25      0.40         4
         473       0.55      0.67      0.60         9
         474       1.00      1.00      1.00         4
         475       1.00      1.00      1.00         4
         476       0.67      0.89      0.76         9
         477       1.00      0.75      0.86         4
         478       0.67      0.50      0.57         4
         479       0.57      1.00      0.73         4
         480       1.00      0.40      0.57         5
         481       0.69      1.00      0.82         9
         482       1.00      1.00      1.00         5
         483       1.00      1.00      1.00         4
         484       1.00      0.25      0.40         4
         485       0.67      0.40      0.50         5
         486       1.00      1.00      1.00         4
         487       0.31      1.00      0.47         4
         488       0.27      0.75      0.40         4
         489       1.00      0.75      0.86         4
         490       0.00      0.00      0.00         4
         491       1.00      1.00      1.00         4
         492       1.00      0.56      0.71         9
         493       1.00      1.00      1.00         5
         494       0.60      0.75      0.67         4
         495       1.00      1.00      1.00         4
         496       1.00      1.00      1.00         4
         497       1.00      1.00      1.00         4
         498       0.00      0.00      0.00         4
         499       0.67      0.50      0.57         4
         500       0.00      0.00      0.00         4
         501       0.82      1.00      0.90         9
         502       0.80      0.89      0.84         9
         503       0.00      0.00      0.00         4
         504       0.62      0.89      0.73         9
         505       1.00      0.60      0.75         5
         506       0.64      0.78      0.70         9
         507       1.00      1.00      1.00         4
         508       0.82      1.00      0.90         9
         509       0.75      0.60      0.67         5
         510       0.71      1.00      0.83         5
         511       1.00      1.00      1.00         5
         512       0.50      0.60      0.55         5
         513       1.00      0.78      0.88         9
         514       0.00      0.00      0.00         4
         515       0.83      1.00      0.91         5
         516       0.50      0.25      0.33         4
         517       0.60      0.75      0.67         4
         518       0.75      0.75      0.75         4
         519       1.00      0.50      0.67         4
         520       1.00      1.00      1.00         4
         521       0.00      0.00      0.00         9
         522       1.00      1.00      1.00         5
         523       0.00      0.00      0.00         4
         524       1.00      1.00      1.00         4
         525       1.00      0.50      0.67         4
         526       1.00      0.75      0.86         4
         527       0.73      0.89      0.80         9
         528       1.00      0.22      0.36         9
         529       0.00      0.00      0.00         5
         530       0.80      1.00      0.89         4
         531       0.00      0.00      0.00         4
         532       0.00      0.00      0.00         4
         533       0.62      1.00      0.77         5
         534       0.67      1.00      0.80         4
         535       1.00      1.00      1.00         9
         536       0.00      0.00      0.00         4
         537       0.90      1.00      0.95         9
         538       0.67      0.50      0.57         4
         539       0.00      0.00      0.00         4
         540       1.00      1.00      1.00         4
         541       0.00      0.00      0.00         4
         542       0.57      1.00      0.73         4
         543       0.82      1.00      0.90         9
         544       0.50      1.00      0.67         5
         545       1.00      0.75      0.86         4
         546       0.67      0.50      0.57         4
         547       1.00      1.00      1.00         4
         548       0.67      1.00      0.80         4
         549       0.00      0.00      0.00         9
         550       1.00      1.00      1.00         4
         551       0.00      0.00      0.00         4
         552       1.00      1.00      1.00         9
         553       0.80      1.00      0.89         4
         554       0.00      0.00      0.00         4
         555       1.00      1.00      1.00         4
         556       0.00      0.00      0.00         4
         557       1.00      0.40      0.57         5
         558       0.50      0.50      0.50         4
         559       0.14      1.00      0.24         4
         560       1.00      0.75      0.86         4
         561       0.00      0.00      0.00         4
         562       1.00      1.00      1.00         4
         563       1.00      0.80      0.89         5
         564       0.40      0.40      0.40         5
         565       1.00      0.50      0.67         4
         566       0.00      0.00      0.00         4
         567       0.00      0.00      0.00         4
         568       0.00      0.00      0.00         4
         569       1.00      0.50      0.67         4
         570       0.12      0.75      0.21         4
         571       1.00      1.00      1.00         4
         572       0.33      1.00      0.50         5
         573       0.67      1.00      0.80         4
         574       0.88      0.78      0.82         9
         575       0.00      0.00      0.00         4
         576       1.00      0.78      0.88         9
         577       0.67      0.50      0.57         4
         578       0.80      1.00      0.89         4
         579       1.00      0.75      0.86         4
         580       0.75      0.67      0.71         9
         581       0.00      0.00      0.00         4
         582       1.00      0.60      0.75         5
         583       0.00      0.00      0.00         4
         584       0.80      1.00      0.89         4
         585       0.00      0.00      0.00         4
         586       1.00      0.25      0.40         4
         587       0.43      0.67      0.52         9
         588       0.00      0.00      0.00         5
         589       1.00      1.00      1.00         5
         590       0.50      1.00      0.67         5
         591       0.20      0.20      0.20         5
         592       1.00      0.25      0.40         4
         593       0.57      1.00      0.73         4
         594       0.67      0.67      0.67         9
         595       0.67      1.00      0.80         4
         596       0.75      0.75      0.75         4
         597       0.56      1.00      0.71         5
         598       0.00      0.00      0.00         4
         599       0.80      1.00      0.89         4
         600       0.82      1.00      0.90         9
         601       1.00      0.89      0.94         9
         602       0.50      1.00      0.67         4
         603       0.00      0.00      0.00         4
         604       1.00      1.00      1.00         4
         605       1.00      0.50      0.67         4
         606       1.00      1.00      1.00         4
         607       1.00      1.00      1.00         4
         608       0.60      0.75      0.67         4
         609       0.40      0.50      0.44         4
         610       1.00      1.00      1.00         5
         611       0.50      0.25      0.33         4
         612       0.50      0.56      0.53         9
         613       0.20      0.20      0.20         5
         614       0.67      0.89      0.76         9
         615       0.00      0.00      0.00         4
         616       1.00      1.00      1.00         4
         617       1.00      0.80      0.89         5
         618       0.56      1.00      0.71         5
         619       0.00      0.00      0.00         4
         620       0.83      0.56      0.67         9
         621       1.00      0.75      0.86         4
         622       0.00      0.00      0.00         4
         623       1.00      0.67      0.80         9
         624       0.50      1.00      0.67         4
         625       0.88      0.78      0.82         9
         626       1.00      1.00      1.00         9
         627       1.00      1.00      1.00         4
         628       0.12      0.75      0.20         4
         629       0.78      0.78      0.78         9
         630       0.67      0.50      0.57         4
         631       0.40      0.50      0.44         4
         632       0.43      0.75      0.55         4
         633       1.00      1.00      1.00         5
         634       1.00      1.00      1.00         5
         635       1.00      0.50      0.67         4
         636       1.00      0.60      0.75         5
         637       0.67      0.67      0.67         9
         638       1.00      0.25      0.40         4
         639       0.40      0.50      0.44         4
         640       0.90      1.00      0.95         9
         641       0.60      0.75      0.67         4
         642       0.00      0.00      0.00         9
         643       0.37      0.78      0.50         9
         644       0.69      1.00      0.82         9
         645       0.00      0.00      0.00         4
         646       0.75      0.75      0.75         4
         647       1.00      0.80      0.89         5
         648       1.00      1.00      1.00         4
         649       1.00      1.00      1.00         5
         650       0.00      0.00      0.00         4
         651       0.00      0.00      0.00         4
         652       0.75      0.67      0.71         9
         653       0.00      0.00      0.00         9
         654       0.60      0.75      0.67         4
         655       0.00      0.00      0.00         4
         656       0.00      0.00      0.00         4
         657       0.69      1.00      0.82         9
         658       0.67      1.00      0.80         4
         659       0.90      1.00      0.95         9
         660       0.00      0.00      0.00         4
         661       0.60      0.75      0.67         4
         662       0.89      0.89      0.89         9
         663       1.00      0.78      0.88         9
         664       0.80      0.89      0.84         9
         665       0.13      1.00      0.24         4
         666       1.00      1.00      1.00         9
         667       1.00      1.00      1.00         9
         668       1.00      1.00      1.00         4
         669       0.00      0.00      0.00         4
         670       0.60      0.75      0.67         4
         671       1.00      1.00      1.00         9
         672       0.00      0.00      0.00         4
         673       1.00      0.80      0.89         5
         674       0.89      0.89      0.89         9
         675       1.00      0.75      0.86         4
         676       0.30      0.75      0.43         4
         677       1.00      0.89      0.94         9
         678       1.00      1.00      1.00         4
         679       0.80      0.89      0.84         9
         680       0.00      0.00      0.00         4
         681       1.00      0.40      0.57         5
         682       1.00      0.50      0.67         4
         683       0.86      0.67      0.75         9
         684       1.00      1.00      1.00         4
         685       1.00      0.75      0.86         4
         686       0.73      0.89      0.80         9
         687       1.00      0.75      0.86         4
         688       1.00      0.50      0.67         4
         689       0.80      1.00      0.89         4
         690       1.00      0.80      0.89         5
         691       0.60      1.00      0.75         9
         692       1.00      1.00      1.00         5
         693       1.00      0.50      0.67         4
         694       1.00      0.75      0.86         4
         695       1.00      1.00      1.00         4
         696       0.00      0.00      0.00         4
         697       1.00      1.00      1.00         5
         698       0.71      1.00      0.83         5
         699       0.00      0.00      0.00         4
         700       1.00      1.00      1.00         9
         701       1.00      1.00      1.00         5
         702       0.90      1.00      0.95         9
         703       1.00      0.25      0.40         4
         704       0.50      1.00      0.67         5
         705       1.00      1.00      1.00         4
         706       1.00      1.00      1.00         4
         707       1.00      0.50      0.67         4
         708       0.80      0.80      0.80         5
         709       0.00      0.00      0.00         4
         710       0.67      1.00      0.80         4
         711       1.00      0.25      0.40         4
         712       0.80      1.00      0.89         4
         713       0.00      0.00      0.00         7
         714       1.00      1.00      1.00         5
         715       0.00      0.00      0.00         4
         716       1.00      1.00      1.00         4
         717       0.80      1.00      0.89         4
         718       1.00      0.75      0.86         4
         719       0.71      1.00      0.83         5
         720       1.00      1.00      1.00         4
         721       1.00      0.50      0.67         4
         722       0.67      0.67      0.67         9
         723       0.67      0.80      0.73         5
         724       0.50      0.25      0.33         4
         725       0.24      1.00      0.38         4
         726       0.47      0.89      0.62         9
         727       1.00      0.25      0.40         4
         728       0.67      0.50      0.57         4
         729       1.00      1.00      1.00         9
         730       1.00      0.75      0.86         4
         731       1.00      0.25      0.40         4
         732       1.00      0.60      0.75         5
         733       1.00      1.00      1.00         4
         734       0.38      0.56      0.45         9
         735       1.00      0.25      0.40         4
         736       1.00      0.60      0.75         5
         737       0.00      0.00      0.00         4
         738       0.43      0.75      0.55         4
         739       0.00      0.00      0.00         4
         740       0.00      0.00      0.00         4
         741       0.00      0.00      0.00         4
         742       0.00      0.00      0.00         4
         743       0.00      0.00      0.00         4
         744       0.00      0.00      0.00         4
         745       1.00      0.78      0.88         9
         746       0.50      0.80      0.62         5
         747       0.89      0.89      0.89         9
         748       0.67      1.00      0.80         4
         749       0.78      0.78      0.78         9
         750       0.83      1.00      0.91         5
         751       0.57      0.44      0.50         9
         752       1.00      0.75      0.86         4
         753       0.56      1.00      0.72         9
         754       0.50      0.25      0.33         4
         755       0.50      0.60      0.55         5
         756       0.50      0.20      0.29         5
         757       0.80      1.00      0.89         4
         758       1.00      0.60      0.75         5
         759       0.80      0.80      0.80         5
         760       0.50      0.75      0.60         4
         761       0.88      0.78      0.82         9
         762       1.00      0.78      0.88         9
         763       0.90      1.00      0.95         9
         764       1.00      0.25      0.40         4
         765       1.00      0.50      0.67         4
         766       0.00      0.00      0.00         4
         767       0.57      1.00      0.73         4
         768       1.00      0.25      0.40         4
         769       0.67      0.40      0.50         5
         770       1.00      1.00      1.00         5
         771       0.33      0.25      0.29         4
         772       0.80      1.00      0.89         4
         773       0.00      0.00      0.00         5
         774       0.00      0.00      0.00         4
         775       0.90      1.00      0.95         9
         776       0.82      1.00      0.90         9
         777       0.00      0.00      0.00         9
         778       1.00      0.75      0.86         4
         779       0.50      0.50      0.50         4
         780       0.67      0.67      0.67         9
         781       1.00      1.00      1.00         4
         782       0.00      0.00      0.00         4
         783       0.45      1.00      0.62         5
         784       1.00      1.00      1.00         9
         785       0.38      0.60      0.46         5
         786       0.36      0.80      0.50         5
         787       1.00      0.78      0.88         9
         788       1.00      1.00      1.00         4
         789       0.64      0.78      0.70         9
         790       0.50      0.50      0.50         4
         791       1.00      1.00      1.00         4
         792       0.60      0.60      0.60         5
         793       1.00      0.75      0.86         4
         794       0.43      0.75      0.55         4
         795       1.00      0.75      0.86         4
         796       1.00      0.20      0.33         5
         797       1.00      0.89      0.94         9
         798       0.00      0.00      0.00         4
         799       0.50      0.75      0.60         4
         800       0.71      1.00      0.83         5
         801       1.00      0.56      0.71         9
         802       0.00      0.00      0.00         4
         803       0.25      0.50      0.33         4
         804       1.00      0.80      0.89         5
         805       0.80      1.00      0.89         4
         806       0.56      1.00      0.71         5
         807       0.00      0.00      0.00         4
         808       1.00      0.20      0.33         5
         809       0.89      0.89      0.89         9
         810       0.00      0.00      0.00         4
         811       0.18      0.50      0.27         4
         812       0.27      0.75      0.40         4
         813       0.33      0.75      0.46         4
         814       1.00      0.50      0.67         4
         815       1.00      0.78      0.88         9
         816       0.50      1.00      0.67         4
         817       0.89      0.89      0.89         9
         818       0.25      0.25      0.25         4
         819       0.67      1.00      0.80         4
         820       1.00      1.00      1.00         5
         821       0.80      1.00      0.89         4
         822       0.00      0.00      0.00         4
         823       0.71      1.00      0.83         5
         824       0.00      0.00      0.00         4
         825       1.00      0.60      0.75         5
         826       1.00      1.00      1.00         4
         827       1.00      1.00      1.00         5
         828       1.00      0.40      0.57         5
         829       0.78      0.78      0.78         9
         830       0.90      1.00      0.95         9
         831       1.00      0.75      0.86         4
         832       1.00      0.50      0.67         4
         833       0.44      0.80      0.57         5
         834       1.00      0.50      0.67         4
         835       1.00      1.00      1.00         5
         836       1.00      1.00      1.00         9
         837       1.00      1.00      1.00         9
         838       1.00      0.67      0.80         9
         839       0.00      0.00      0.00         4
         840       0.50      0.33      0.40         9
         841       1.00      0.40      0.57         5
         842       1.00      0.67      0.80         9
         843       1.00      1.00      1.00         4
         844       0.80      1.00      0.89         4
         845       0.62      0.89      0.73         9
         846       0.80      1.00      0.89         4
         847       0.90      1.00      0.95         9
         848       0.00      0.00      0.00         4
         849       0.17      0.25      0.20         4
         850       0.00      0.00      0.00         4
         851       0.40      0.50      0.44         4
         852       0.89      0.89      0.89         9
         853       0.00      0.00      0.00         4
         854       0.00      0.00      0.00         9
         855       0.44      0.78      0.56         9
         856       0.67      0.40      0.50         5
         857       1.00      1.00      1.00         5
         858       0.82      1.00      0.90         9
         859       0.80      0.44      0.57         9
         860       1.00      1.00      1.00         9
         861       0.80      1.00      0.89         4
         862       1.00      1.00      1.00         4
         863       0.80      1.00      0.89         4
         864       0.40      1.00      0.57         4
         865       1.00      0.11      0.20         9
         866       1.00      0.25      0.40         4
         867       0.00      0.00      0.00         4
         868       0.17      0.20      0.18         5
         869       0.00      0.00      0.00         9
         870       0.67      1.00      0.80         4
         871       0.89      0.89      0.89         9
         872       0.88      0.78      0.82         9
         873       0.67      1.00      0.80         4
         874       0.00      0.00      0.00         4
         875       0.00      0.00      0.00         4
         876       1.00      0.75      0.86         4
         877       0.50      1.00      0.67         4
         878       0.67      0.89      0.76         9
         879       0.00      0.00      0.00         4
         880       0.82      1.00      0.90         9
         881       0.14      0.75      0.24         4
         882       0.83      1.00      0.91         5
         883       0.82      1.00      0.90         9
         884       1.00      1.00      1.00         4
         885       0.67      0.50      0.57         4
         886       0.88      0.78      0.82         9
         887       0.00      0.00      0.00         4
         888       0.90      1.00      0.95         9
         889       0.57      0.80      0.67         5
         890       1.00      1.00      1.00         9
         891       0.40      0.50      0.44         4
         892       0.00      0.00      0.00         4
         893       0.57      0.89      0.70         9

    accuracy                           0.67      4917
   macro avg       0.64      0.64      0.61      4917
weighted avg       0.66      0.67      0.64      4917

task_train_time: {0: 0.12273348999999989, 1: 0.03431281900000016, 2: 0.03667378699999979, 3: 0.03206637599999951, 4: 0.032024347999998426, 5: 0.027821440999998615, 6: 0.03334088499999943, 7: 0.02814757400000012, 8: 0.033268581999999824, 9: 0.03097457700000028, 10: 0.030311683000000755, 11: 0.02896937299999891, 12: 0.029024881999999863, 13: 0.03142105699999931, 14: 0.03539109299999943, 15: 0.026899956999999475, 16: 0.03922671199999961, 17: 0.03175391199999922, 18: 0.03505203300000126, 19: 0.03312840899999969, 20: 0.03426298399999972, 21: 0.03909384399999993, 22: 0.029410422999999852, 23: 0.028873717999999826, 24: 0.03339607000000022, 25: 0.02954781399999895, 26: 0.03186616099999995, 27: 0.023774804000000316, 28: 0.024408682999998987, 29: 0.029089506000000043, 30: 0.02786174899999949, 31: 0.029851982000000277, 32: 0.03641224299999912, 33: 0.03251095799999959, 34: 0.02861506600000041, 35: 0.028327625000001078, 36: 0.0331075399999996, 37: 0.029994411000000554, 38: 0.03651088100000166, 39: 0.02902776699999876, 40: 0.031185673999999608, 41: 0.0383777330000008, 42: 0.03920198799999852, 43: 0.03431366399999902}
prediction_time: 0.00029063500000248155
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
