Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='f8da6566-ce27-4409-a52e-f102aa601fc9', conf_timestamp='2023-08-10 06:06:02.848020', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 62.76 % 	 [Task-IL]: 36.22 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 54.58 % 	 [Task-IL]: 27.92 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 47.94 % 	 [Task-IL]: 29.64 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 33.47 % 	 [Task-IL]: 29.39 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 30.29 % 	 [Task-IL]: 31.37 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 28.4 % 	 [Task-IL]: 31.37 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 23.97 % 	 [Task-IL]: 29.58 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 22.18 % 	 [Task-IL]: 28.53 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 25.55 % 	 [Task-IL]: 27.97 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.73 % 	 [Task-IL]: 27.75 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.3 % 	 [Task-IL]: 28.46 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 18.31 % 	 [Task-IL]: 27.9 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 13.54 % 	 [Task-IL]: 27.81 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.63 % 	 [Task-IL]: 27.63 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 14.48 % 	 [Task-IL]: 27.76 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 10.42 % 	 [Task-IL]: 28.51 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 11.52 % 	 [Task-IL]: 27.87 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 12.69 % 	 [Task-IL]: 28.01 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 12.79 % 	 [Task-IL]: 28.21 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.54 % 	 [Task-IL]: 27.86 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.88 % 	 [Task-IL]: 27.62 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 12.03 % 	 [Task-IL]: 27.46 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.42 % 	 [Task-IL]: 27.38 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 9.29 % 	 [Task-IL]: 27.52 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 8.94 % 	 [Task-IL]: 27.63 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 9.02 % 	 [Task-IL]: 27.66 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.76 % 	 [Task-IL]: 27.43 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.34 % 	 [Task-IL]: 27.62 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.27 % 	 [Task-IL]: 27.66 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.95 % 	 [Task-IL]: 27.71 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 7.05 % 	 [Task-IL]: 27.66 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.69 % 	 [Task-IL]: 27.32 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.97 % 	 [Task-IL]: 27.42 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.97 % 	 [Task-IL]: 27.18 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.79 % 	 [Task-IL]: 27.05 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.92 % 	 [Task-IL]: 26.43 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 5.39 % 	 [Task-IL]: 26.47 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.89 % 	 [Task-IL]: 26.79 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.99 % 	 [Task-IL]: 26.48 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.81 % 	 [Task-IL]: 26.42 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.97 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.97 % 	 [Task-IL]: 27.03 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.68 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74884, 126: 34, 572: 34, 143: 33, 201: 33, 233: 33, 397: 33, 663: 33, 52: 32, 98: 32, 158: 32, 189: 32, 382: 32, 728: 32, 737: 32, 775: 32, 22: 31, 44: 31, 65: 31, 74: 31, 87: 31, 94: 31, 102: 31, 146: 31, 173: 31, 160: 31, 258: 31, 256: 31, 292: 31, 319: 31, 364: 31, 398: 31, 470: 31, 490: 31, 492: 31, 543: 31, 549: 31, 606: 31, 633: 31, 627: 31, 668: 31, 680: 31, 691: 31, 702: 31, 726: 31, 766: 31, 852: 31, 843: 31, 19: 30, 28: 30, 48: 30, 71: 30, 76: 30, 103: 30, 114: 30, 190: 30, 213: 30, 272: 30, 327: 30, 340: 30, 372: 30, 416: 30, 438: 30, 491: 30, 505: 30, 519: 30, 524: 30, 573: 30, 650: 30, 674: 30, 694: 30, 732: 30, 739: 30, 810: 30, 820: 30, 829: 30, 817: 30, 835: 30, 854: 30, 14: 29, 4: 29, 10: 29, 41: 29, 54: 29, 109: 29, 199: 29, 206: 29, 264: 29, 267: 29, 282: 29, 293: 29, 308: 29, 316: 29, 345: 29, 344: 29, 350: 29, 359: 29, 375: 29, 377: 29, 415: 29, 429: 29, 432: 29, 469: 29, 479: 29, 559: 29, 575: 29, 580: 29, 583: 29, 594: 29, 613: 29, 604: 29, 610: 29, 622: 29, 631: 29, 666: 29, 667: 29, 682: 29, 759: 29, 818: 29, 853: 29, 867: 29, 871: 29, 875: 29, 33: 28, 46: 28, 68: 28, 149: 28, 153: 28, 196: 28, 218: 28, 219: 28, 220: 28, 222: 28, 281: 28, 278: 28, 288: 28, 341: 28, 395: 28, 437: 28, 461: 28, 474: 28, 495: 28, 526: 28, 517: 28, 557: 28, 564: 28, 590: 28, 596: 28, 609: 28, 614: 28, 670: 28, 736: 28, 755: 28, 790: 28, 793: 28, 783: 28, 799: 28, 797: 28, 821: 28, 893: 28, 27: 27, 43: 27, 34: 27, 223: 27, 224: 27, 217: 27, 268: 27, 259: 27, 286: 27, 276: 27, 306: 27, 309: 27, 315: 27, 331: 27, 369: 27, 391: 27, 444: 27, 449: 27, 466: 27, 529: 27, 558: 27, 592: 27, 581: 27, 634: 27, 778: 27, 842: 27, 848: 27, 50: 26, 96: 26, 121: 26, 157: 26, 240: 26, 254: 26, 294: 26, 318: 26, 346: 26, 410: 26, 537: 26, 571: 26, 664: 26, 687: 26, 698: 26, 733: 26, 743: 26, 757: 26, 763: 26, 762: 26, 782: 26, 822: 26, 860: 26, 18: 25, 80: 25, 97: 25, 169: 25, 208: 25, 228: 25, 298: 25, 366: 25, 388: 25, 402: 25, 628: 25, 651: 25, 796: 25, 2: 24, 131: 24, 174: 24, 245: 24, 385: 24, 412: 24, 471: 24, 579: 24, 612: 24, 625: 24, 679: 24, 862: 24, 433: 23, 456: 23, 180: 21, 521: 21, 551: 21, 765: 21, 58: 18, 250: 17, 252: 17, 270: 17, 300: 17, 334: 17, 384: 17, 496: 17, 567: 17, 839: 17, 29: 16, 130: 16, 150: 16, 214: 16, 231: 16, 328: 16, 339: 16, 358: 16, 422: 16, 428: 16, 414: 16, 488: 16, 671: 16, 690: 16, 704: 16, 720: 16, 767: 16, 872: 16, 9: 15, 25: 15, 7: 15, 45: 15, 55: 15, 72: 15, 125: 15, 148: 15, 147: 15, 170: 15, 167: 15, 185: 15, 212: 15, 232: 15, 248: 15, 237: 15, 326: 15, 353: 15, 337: 15, 356: 15, 383: 15, 399: 15, 460: 15, 462: 15, 486: 15, 485: 15, 518: 15, 576: 15, 574: 15, 615: 15, 659: 15, 655: 15, 692: 15, 760: 15, 780: 15, 801: 15, 813: 15, 803: 15, 838: 15, 863: 15, 888: 15, 31: 14, 11: 14, 38: 14, 59: 14, 105: 14, 200: 14, 202: 14, 204: 14, 221: 14, 253: 14, 247: 14, 297: 14, 325: 14, 361: 14, 374: 14, 396: 14, 404: 14, 400: 14, 447: 14, 441: 14, 465: 14, 464: 14, 512: 14, 531: 14, 514: 14, 548: 14, 540: 14, 552: 14, 563: 14, 555: 14, 556: 14, 582: 14, 577: 14, 584: 14, 597: 14, 599: 14, 598: 14, 621: 14, 616: 14, 643: 14, 640: 14, 642: 14, 673: 14, 685: 14, 709: 14, 723: 14, 764: 14, 785: 14, 836: 14, 865: 14, 856: 14, 874: 14, 26: 13, 3: 13, 24: 13, 20: 13, 15: 13, 64: 13, 86: 13, 81: 13, 79: 13, 112: 13, 116: 13, 140: 13, 175: 13, 182: 13, 205: 13, 229: 13, 251: 13, 284: 13, 279: 13, 302: 13, 311: 13, 296: 13, 317: 13, 321: 13, 352: 13, 355: 13, 363: 13, 386: 13, 376: 13, 426: 13, 417: 13, 423: 13, 450: 13, 452: 13, 453: 13, 468: 13, 487: 13, 503: 13, 507: 13, 504: 13, 533: 13, 536: 13, 541: 13, 553: 13, 547: 13, 603: 13, 618: 13, 630: 13, 645: 13, 636: 13, 652: 13, 654: 13, 657: 13, 660: 13, 688: 13, 683: 13, 686: 13, 696: 13, 717: 13, 718: 13, 727: 13, 731: 13, 719: 13, 750: 13, 735: 13, 748: 13, 742: 13, 749: 13, 761: 13, 770: 13, 792: 13, 777: 13, 776: 13, 794: 13, 805: 13, 828: 13, 831: 13, 855: 13, 868: 13, 873: 13, 891: 13, 882: 13, 880: 13, 16: 12, 1: 12, 32: 12, 21: 12, 8: 12, 30: 12, 5: 12, 51: 12, 39: 12, 36: 12, 35: 12, 61: 12, 62: 12, 67: 12, 69: 12, 66: 12, 90: 12, 92: 12, 78: 12, 77: 12, 85: 12, 113: 12, 106: 12, 111: 12, 124: 12, 129: 12, 117: 12, 132: 12, 123: 12, 133: 12, 137: 12, 134: 12, 165: 12, 154: 12, 161: 12, 166: 12, 159: 12, 155: 12, 191: 12, 177: 12, 179: 12, 203: 12, 211: 12, 227: 12, 215: 12, 226: 12, 238: 12, 249: 12, 236: 12, 255: 12, 271: 12, 285: 12, 280: 12, 275: 12, 287: 12, 303: 12, 299: 12, 310: 12, 312: 12, 330: 12, 333: 12, 322: 12, 348: 12, 336: 12, 342: 12, 335: 12, 360: 12, 367: 12, 357: 12, 392: 12, 389: 12, 381: 12, 379: 12, 407: 12, 401: 12, 406: 12, 409: 12, 430: 12, 419: 12, 425: 12, 436: 12, 434: 12, 446: 12, 442: 12, 455: 12, 467: 12, 454: 12, 478: 12, 480: 12, 497: 12, 513: 12, 520: 12, 515: 12, 516: 12, 544: 12, 566: 12, 591: 12, 588: 12, 586: 12, 608: 12, 605: 12, 626: 12, 619: 12, 617: 12, 638: 12, 641: 12, 661: 12, 672: 12, 675: 12, 695: 12, 712: 12, 713: 12, 705: 12, 708: 12, 697: 12, 715: 12, 721: 12, 730: 12, 738: 12, 744: 12, 753: 12, 740: 12, 747: 12, 746: 12, 768: 12, 771: 12, 769: 12, 756: 12, 772: 12, 781: 12, 786: 12, 791: 12, 809: 12, 804: 12, 812: 12, 811: 12, 825: 12, 816: 12, 826: 12, 814: 12, 824: 12, 840: 12, 841: 12, 834: 12, 861: 12, 859: 12, 885: 12, 889: 12, 884: 12, 892: 12, 878: 12, 883: 12, 887: 12, 886: 12, 12: 11, 17: 11, 37: 11, 40: 11, 53: 11, 49: 11, 60: 11, 73: 11, 56: 11, 57: 11, 88: 11, 93: 11, 91: 11, 84: 11, 107: 11, 108: 11, 100: 11, 95: 11, 115: 11, 128: 11, 122: 11, 145: 11, 136: 11, 151: 11, 168: 11, 162: 11, 163: 11, 186: 11, 187: 11, 192: 11, 184: 11, 181: 11, 188: 11, 230: 11, 234: 11, 239: 11, 244: 11, 243: 11, 241: 11, 242: 11, 262: 11, 260: 11, 269: 11, 257: 11, 290: 11, 295: 11, 304: 11, 332: 11, 320: 11, 329: 11, 314: 11, 349: 11, 351: 11, 347: 11, 338: 11, 365: 11, 368: 11, 362: 11, 370: 11, 387: 11, 393: 11, 378: 11, 390: 11, 413: 11, 408: 11, 405: 11, 420: 11, 424: 11, 451: 11, 448: 11, 445: 11, 435: 11, 440: 11, 463: 11, 473: 11, 489: 11, 493: 11, 484: 11, 482: 11, 499: 11, 500: 11, 502: 11, 506: 11, 509: 11, 527: 11, 530: 11, 525: 11, 523: 11, 546: 11, 539: 11, 550: 11, 561: 11, 565: 11, 585: 11, 589: 11, 593: 11, 587: 11, 600: 11, 595: 11, 620: 11, 629: 11, 624: 11, 647: 11, 644: 11, 649: 11, 662: 11, 669: 11, 678: 11, 677: 11, 703: 11, 706: 11, 710: 11, 711: 11, 729: 11, 714: 11, 725: 11, 734: 11, 773: 11, 754: 11, 788: 11, 779: 11, 774: 11, 802: 11, 806: 11, 833: 11, 832: 11, 823: 11, 850: 11, 869: 11, 870: 11, 866: 11, 876: 11, 879: 11, 890: 11, 42: 10, 47: 10, 70: 10, 75: 10, 83: 10, 82: 10, 104: 10, 99: 10, 110: 10, 119: 10, 118: 10, 127: 10, 152: 10, 138: 10, 144: 10, 139: 10, 141: 10, 172: 10, 193: 10, 183: 10, 178: 10, 197: 10, 209: 10, 210: 10, 198: 10, 216: 10, 246: 10, 261: 10, 273: 10, 265: 10, 263: 10, 266: 10, 283: 10, 277: 10, 274: 10, 305: 10, 313: 10, 307: 10, 301: 10, 324: 10, 354: 10, 411: 10, 394: 10, 421: 10, 457: 10, 472: 10, 477: 10, 508: 10, 498: 10, 510: 10, 494: 10, 511: 10, 528: 10, 522: 10, 542: 10, 545: 10, 535: 10, 538: 10, 568: 10, 562: 10, 560: 10, 570: 10, 554: 10, 602: 10, 611: 10, 632: 10, 653: 10, 637: 10, 639: 10, 648: 10, 656: 10, 658: 10, 689: 10, 684: 10, 681: 10, 699: 10, 700: 10, 716: 10, 724: 10, 722: 10, 752: 10, 758: 10, 789: 10, 798: 10, 808: 10, 795: 10, 800: 10, 815: 10, 849: 10, 851: 10, 844: 10, 845: 10, 847: 10, 857: 10, 881: 10, 877: 10, 13: 9, 23: 9, 6: 9, 63: 9, 120: 9, 135: 9, 164: 9, 156: 9, 194: 9, 195: 9, 207: 9, 225: 9, 235: 9, 291: 9, 289: 9, 323: 9, 373: 9, 380: 9, 403: 9, 431: 9, 418: 9, 427: 9, 443: 9, 439: 9, 459: 9, 481: 9, 483: 9, 475: 9, 476: 9, 501: 9, 569: 9, 578: 9, 601: 9, 607: 9, 623: 9, 646: 9, 635: 9, 665: 9, 701: 9, 745: 9, 741: 9, 807: 9, 830: 9, 827: 9, 837: 9, 846: 9, 864: 9, 89: 8, 101: 8, 171: 8, 176: 8, 371: 8, 458: 8, 532: 8, 676: 8, 751: 8, 787: 8, 784: 8, 819: 8, 142: 7, 343: 7, 693: 7, 707: 7, 858: 7, 534: 6})
fit_time: 7.662709659999997

Accuracy for 44 task(s): 	 [Class-IL]: 65.89 % 	 [Task-IL]: 30.87 %

CLASS_IL_ACC: 
	[67.85714285714286, 73.17073170731707, 74.76635514018692, 70.87378640776699, 69.23076923076923, 49.03846153846153, 62.5, 51.85185185185185, 70.0, 58.4070796460177, 55.46875, 70.10309278350515, 76.03305785123968, 71.66666666666667, 73.83177570093457, 67.54385964912281, 72.41379310344827, 57.407407407407405, 64.91228070175438, 81.41592920353983, 63.30275229357798, 76.69902912621359, 52.25225225225225, 65.13761467889908, 55.91397849462365, 67.56756756756756, 80.19801980198021, 75.42372881355932, 76.27118644067797, 70.24793388429752, 64.40677966101694, 58.333333333333336, 59.82905982905983, 68.14159292035397, 67.0103092783505, 65.42056074766354, 59.80392156862745, 61.016949152542374, 60.71428571428571, 57.28155339805825, 63.06306306306306, 63.716814159292035, 73.14814814814815, 55.78947368421052]
TASK_IL_ACC: 
	[58.16326530612245, 21.951219512195124, 27.102803738317753, 33.00970873786408, 36.75213675213676, 25.961538461538463, 21.153846153846153, 30.555555555555557, 28.000000000000004, 28.31858407079646, 30.46875, 22.68041237113402, 33.88429752066116, 26.666666666666668, 28.037383177570092, 39.473684210526315, 22.413793103448278, 20.37037037037037, 28.07017543859649, 35.39823008849557, 30.275229357798167, 33.00970873786408, 23.423423423423422, 30.275229357798167, 31.182795698924732, 31.53153153153153, 25.742574257425744, 30.508474576271187, 30.508474576271187, 28.09917355371901, 24.576271186440678, 29.166666666666668, 18.803418803418804, 23.893805309734514, 32.98969072164948, 21.49532710280374, 37.254901960784316, 33.05084745762712, 30.357142857142854, 34.95145631067961, 30.630630630630627, 27.43362831858407, 26.851851851851855, 93.6842105263158]
f1_micro: 66.03620093552979
f1_macro: 60.56785136291389
              precision    recall  f1-score   support

           0       1.00      0.80      0.89         5
           1       0.75      0.75      0.75         4
           2       0.80      0.89      0.84         9
           3       0.50      0.40      0.44         5
           4       0.69      1.00      0.82         9
           5       1.00      1.00      1.00         4
           6       1.00      0.80      0.89         5
           7       0.67      0.80      0.73         5
           8       0.00      0.00      0.00         4
           9       0.30      0.60      0.40         5
          10       1.00      1.00      1.00         9
          11       0.50      0.20      0.29         5
          12       1.00      0.50      0.67         4
          13       0.60      0.75      0.67         4
          14       0.00      0.00      0.00         9
          15       0.57      1.00      0.73         4
          16       0.00      0.00      0.00         4
          17       1.00      1.00      1.00         4
          18       0.64      0.78      0.70         9
          19       0.70      0.78      0.74         9
          20       0.00      0.00      0.00         4
          21       0.00      0.00      0.00         4
          22       1.00      1.00      1.00         9
          23       1.00      1.00      1.00         4
          24       0.57      1.00      0.73         4
          25       0.75      0.60      0.67         5
          26       1.00      0.75      0.86         4
          27       0.90      1.00      0.95         9
          28       0.57      0.44      0.50         9
          29       1.00      0.20      0.33         5
          30       1.00      1.00      1.00         4
          31       1.00      0.60      0.75         5
          32       1.00      0.80      0.89         5
          33       0.58      0.78      0.67         9
          34       0.50      0.78      0.61         9
          35       0.67      0.50      0.57         4
          36       0.60      0.75      0.67         4
          37       0.50      0.25      0.33         4
          38       0.75      0.75      0.75         4
          39       1.00      0.80      0.89         5
          40       1.00      1.00      1.00         5
          41       0.73      0.89      0.80         9
          42       0.00      0.00      0.00         4
          43       1.00      0.89      0.94         9
          44       0.40      0.22      0.29         9
          45       0.50      1.00      0.67         5
          46       0.73      0.89      0.80         9
          47       0.75      0.75      0.75         4
          48       1.00      0.89      0.94         9
          49       0.50      0.75      0.60         4
          50       0.89      0.89      0.89         9
          51       0.50      0.25      0.33         4
          52       1.00      1.00      1.00         9
          53       0.50      0.50      0.50         4
          54       0.82      1.00      0.90         9
          55       0.62      1.00      0.77         5
          56       0.33      0.50      0.40         4
          57       1.00      1.00      1.00         4
          58       1.00      0.17      0.29         6
          59       1.00      1.00      1.00         5
          60       1.00      1.00      1.00         4
          61       0.00      0.00      0.00         4
          62       1.00      0.80      0.89         5
          63       1.00      0.75      0.86         4
          64       0.71      1.00      0.83         5
          65       0.86      0.67      0.75         9
          66       0.44      1.00      0.62         4
          67       1.00      0.75      0.86         4
          68       0.90      1.00      0.95         9
          69       0.00      0.00      0.00         4
          70       0.57      1.00      0.73         4
          71       0.78      0.78      0.78         9
          72       1.00      1.00      1.00         5
          73       0.00      0.00      0.00         4
          74       0.60      0.67      0.63         9
          75       0.50      0.25      0.33         4
          76       0.32      0.89      0.47         9
          77       0.10      0.25      0.14         4
          78       0.60      0.60      0.60         5
          79       0.75      0.75      0.75         4
          80       1.00      0.78      0.88         9
          81       0.80      1.00      0.89         4
          82       1.00      1.00      1.00         4
          83       1.00      1.00      1.00         4
          84       0.80      1.00      0.89         4
          85       1.00      1.00      1.00         4
          86       1.00      1.00      1.00         5
          87       0.89      0.89      0.89         9
          88       1.00      1.00      1.00         5
          89       0.00      0.00      0.00         4
          90       1.00      1.00      1.00         4
          91       0.00      0.00      0.00         4
          92       0.00      0.00      0.00         4
          93       0.50      0.50      0.50         4
          94       0.90      1.00      0.95         9
          95       0.00      0.00      0.00         4
          96       0.67      0.89      0.76         9
          97       1.00      0.78      0.88         9
          98       0.67      0.67      0.67         9
          99       0.75      0.75      0.75         4
         100       0.33      0.75      0.46         4
         101       0.60      0.75      0.67         4
         102       0.86      0.67      0.75         9
         103       0.60      1.00      0.75         9
         104       0.00      0.00      0.00         4
         105       1.00      1.00      1.00         5
         106       1.00      0.50      0.67         4
         107       0.50      0.20      0.29         5
         108       0.00      0.00      0.00         4
         109       0.82      1.00      0.90         9
         110       0.00      0.00      0.00         4
         111       1.00      1.00      1.00         4
         112       1.00      0.75      0.86         4
         113       1.00      0.75      0.86         4
         114       0.82      1.00      0.90         9
         115       0.80      1.00      0.89         4
         116       0.31      1.00      0.47         4
         117       0.00      0.00      0.00         4
         118       0.33      0.25      0.29         4
         119       0.80      1.00      0.89         4
         120       0.00      0.00      0.00         4
         121       0.50      0.11      0.18         9
         122       0.80      1.00      0.89         4
         123       0.00      0.00      0.00         5
         124       0.00      0.00      0.00         4
         125       1.00      0.80      0.89         5
         126       1.00      0.67      0.80         9
         127       0.40      0.50      0.44         4
         128       0.80      1.00      0.89         4
         129       0.43      0.60      0.50         5
         130       0.62      1.00      0.77         5
         131       0.00      0.00      0.00         9
         132       0.00      0.00      0.00         4
         133       0.00      0.00      0.00         4
         134       0.75      0.75      0.75         4
         135       0.50      0.50      0.50         4
         136       0.50      0.50      0.50         4
         137       0.00      0.00      0.00         4
         138       1.00      0.75      0.86         4
         139       0.00      0.00      0.00         4
         140       1.00      0.80      0.89         5
         141       1.00      0.50      0.67         4
         142       1.00      1.00      1.00         4
         143       1.00      0.78      0.88         9
         144       1.00      0.50      0.67         4
         145       0.43      0.75      0.55         4
         146       1.00      0.44      0.62         9
         147       1.00      1.00      1.00         5
         148       0.60      0.60      0.60         5
         149       0.75      0.33      0.46         9
         150       0.38      0.60      0.46         5
         151       0.43      0.75      0.55         4
         152       0.67      1.00      0.80         4
         153       0.89      0.89      0.89         9
         154       1.00      0.25      0.40         4
         155       0.00      0.00      0.00         4
         156       0.00      0.00      0.00         4
         157       0.00      0.00      0.00         9
         158       1.00      0.89      0.94         9
         159       0.67      1.00      0.80         4
         160       0.75      0.67      0.71         9
         161       0.57      0.80      0.67         5
         162       0.00      0.00      0.00         4
         163       0.67      1.00      0.80         4
         164       0.43      0.75      0.55         4
         165       0.00      0.00      0.00         4
         166       1.00      1.00      1.00         4
         167       0.57      0.80      0.67         5
         168       0.00      0.00      0.00         4
         169       0.08      0.22      0.12         9
         170       0.56      1.00      0.71         5
         171       0.75      0.75      0.75         4
         172       0.00      0.00      0.00         4
         173       0.80      0.89      0.84         9
         174       1.00      0.44      0.62         9
         175       0.67      0.50      0.57         4
         176       0.67      0.50      0.57         4
         177       0.67      1.00      0.80         4
         178       0.80      1.00      0.89         4
         179       1.00      1.00      1.00         4
         180       0.71      0.62      0.67         8
         181       0.19      1.00      0.32         4
         182       1.00      1.00      1.00         4
         183       0.80      1.00      0.89         4
         184       0.00      0.00      0.00         4
         185       1.00      1.00      1.00         5
         186       0.07      0.25      0.11         4
         187       0.75      0.75      0.75         4
         188       1.00      0.25      0.40         4
         189       1.00      1.00      1.00         9
         190       0.62      0.89      0.73         9
         191       1.00      0.75      0.86         4
         192       0.75      0.75      0.75         4
         193       0.00      0.00      0.00         4
         194       0.40      0.50      0.44         4
         195       1.00      0.50      0.67         4
         196       0.73      0.89      0.80         9
         197       0.57      1.00      0.73         4
         198       0.80      1.00      0.89         4
         199       0.00      0.00      0.00         9
         200       0.83      1.00      0.91         5
         201       0.31      0.44      0.36         9
         202       0.75      0.60      0.67         5
         203       1.00      1.00      1.00         4
         204       0.00      0.00      0.00         4
         205       0.40      0.50      0.44         4
         206       0.80      0.89      0.84         9
         207       0.50      0.25      0.33         4
         208       1.00      0.67      0.80         9
         209       0.67      0.50      0.57         4
         210       0.00      0.00      0.00         4
         211       0.33      0.50      0.40         4
         212       0.17      0.40      0.24         5
         213       0.70      0.78      0.74         9
         214       0.75      0.60      0.67         5
         215       0.00      0.00      0.00         4
         216       0.80      1.00      0.89         4
         217       0.29      0.22      0.25         9
         218       0.82      1.00      0.90         9
         219       0.58      0.78      0.67         9
         220       1.00      0.78      0.88         9
         221       0.00      0.00      0.00         4
         222       0.67      0.22      0.33         9
         223       0.54      0.78      0.64         9
         224       1.00      0.22      0.36         9
         225       1.00      1.00      1.00         4
         226       0.00      0.00      0.00         4
         227       0.75      0.75      0.75         4
         228       0.75      0.33      0.46         9
         229       0.21      0.75      0.33         4
         230       0.00      0.00      0.00         4
         231       0.50      1.00      0.67         5
         232       0.38      0.60      0.46         5
         233       0.88      0.78      0.82         9
         234       1.00      1.00      1.00         4
         235       0.00      0.00      0.00         4
         236       0.80      0.80      0.80         5
         237       1.00      0.60      0.75         5
         238       0.33      0.25      0.29         4
         239       0.00      0.00      0.00         4
         240       1.00      0.89      0.94         9
         241       1.00      0.25      0.40         4
         242       0.67      1.00      0.80         4
         243       1.00      1.00      1.00         4
         244       1.00      0.75      0.86         4
         245       1.00      0.56      0.71         9
         246       1.00      1.00      1.00         4
         247       0.50      0.25      0.33         4
         248       1.00      1.00      1.00         5
         249       0.44      1.00      0.62         4
         250       1.00      1.00      1.00         5
         251       1.00      0.80      0.89         5
         252       1.00      0.80      0.89         5
         253       0.80      0.80      0.80         5
         254       0.78      0.78      0.78         9
         255       0.75      0.75      0.75         4
         256       0.88      0.78      0.82         9
         257       0.80      1.00      0.89         4
         258       1.00      0.89      0.94         9
         259       0.67      0.89      0.76         9
         260       0.00      0.00      0.00         4
         261       1.00      0.25      0.40         4
         262       0.14      0.75      0.23         4
         263       0.80      1.00      0.89         4
         264       0.75      1.00      0.86         9
         265       1.00      1.00      1.00         4
         266       0.00      0.00      0.00         4
         267       1.00      0.78      0.88         9
         268       1.00      1.00      1.00         9
         269       0.44      1.00      0.62         4
         270       0.29      0.40      0.33         5
         271       1.00      1.00      1.00         4
         272       1.00      0.67      0.80         9
         273       0.40      0.50      0.44         4
         274       1.00      1.00      1.00         4
         275       0.15      1.00      0.27         4
         276       1.00      0.89      0.94         9
         277       1.00      0.25      0.40         4
         278       0.89      0.89      0.89         9
         279       1.00      1.00      1.00         4
         280       1.00      0.75      0.86         4
         281       0.82      1.00      0.90         9
         282       0.70      0.78      0.74         9
         283       1.00      1.00      1.00         4
         284       0.00      0.00      0.00         4
         285       1.00      1.00      1.00         4
         286       0.88      0.78      0.82         9
         287       0.67      1.00      0.80         4
         288       0.00      0.00      0.00         9
         289       0.50      0.25      0.33         4
         290       1.00      1.00      1.00         4
         291       1.00      0.50      0.67         4
         292       0.45      0.56      0.50         9
         293       0.88      0.78      0.82         9
         294       0.90      1.00      0.95         9
         295       0.00      0.00      0.00         4
         296       1.00      1.00      1.00         4
         297       0.75      0.75      0.75         4
         298       0.56      0.56      0.56         9
         299       0.00      0.00      0.00         4
         300       0.75      0.60      0.67         5
         301       0.00      0.00      0.00         4
         302       0.09      0.50      0.15         4
         303       1.00      1.00      1.00         4
         304       0.75      0.75      0.75         4
         305       0.67      1.00      0.80         4
         306       0.50      1.00      0.67         9
         307       0.75      0.75      0.75         4
         308       1.00      1.00      1.00         9
         309       1.00      1.00      1.00         9
         310       1.00      1.00      1.00         5
         311       0.00      0.00      0.00         4
         312       1.00      0.75      0.86         4
         313       1.00      1.00      1.00         4
         314       1.00      1.00      1.00         5
         315       0.14      0.22      0.17         9
         316       0.58      0.78      0.67         9
         317       0.00      0.00      0.00         4
         318       0.44      0.44      0.44         9
         319       0.90      1.00      0.95         9
         320       1.00      0.75      0.86         4
         321       0.67      1.00      0.80         4
         322       0.80      1.00      0.89         4
         323       0.00      0.00      0.00         4
         324       0.00      0.00      0.00         4
         325       0.60      0.60      0.60         5
         326       0.80      0.80      0.80         5
         327       0.73      0.89      0.80         9
         328       1.00      0.20      0.33         5
         329       0.40      0.50      0.44         4
         330       1.00      1.00      1.00         4
         331       1.00      1.00      1.00         8
         332       0.50      1.00      0.67         4
         333       1.00      1.00      1.00         5
         334       0.43      0.60      0.50         5
         335       0.00      0.00      0.00         4
         336       0.40      1.00      0.57         4
         337       0.67      0.80      0.73         5
         338       1.00      0.50      0.67         4
         339       0.50      0.60      0.55         5
         340       0.88      0.78      0.82         9
         341       0.90      1.00      0.95         9
         342       0.80      0.80      0.80         5
         343       0.57      1.00      0.73         4
         344       1.00      0.89      0.94         9
         345       1.00      0.89      0.94         9
         346       1.00      0.78      0.88         9
         347       0.00      0.00      0.00         4
         348       0.67      0.50      0.57         4
         349       0.75      0.75      0.75         4
         350       0.08      0.44      0.13         9
         351       1.00      0.60      0.75         5
         352       0.80      1.00      0.89         4
         353       1.00      1.00      1.00         5
         354       0.60      0.75      0.67         4
         355       0.25      1.00      0.40         4
         356       0.83      1.00      0.91         5
         357       0.80      1.00      0.89         4
         358       0.80      0.80      0.80         5
         359       0.00      0.00      0.00         9
         360       0.75      0.60      0.67         5
         361       1.00      0.25      0.40         4
         362       0.67      0.50      0.57         4
         363       0.00      0.00      0.00         4
         364       0.88      0.78      0.82         9
         365       0.33      0.25      0.29         4
         366       0.82      1.00      0.90         9
         367       0.00      0.00      0.00         4
         368       0.75      0.75      0.75         4
         369       0.90      1.00      0.95         9
         370       1.00      0.75      0.86         4
         371       0.00      0.00      0.00         4
         372       0.00      0.00      0.00         9
         373       0.80      1.00      0.89         4
         374       0.50      1.00      0.67         4
         375       1.00      0.89      0.94         9
         376       0.00      0.00      0.00         4
         377       0.86      0.67      0.75         9
         378       0.13      0.75      0.22         4
         379       0.50      0.20      0.29         5
         380       1.00      0.25      0.40         4
         381       0.00      0.00      0.00         4
         382       0.78      0.78      0.78         9
         383       0.33      0.80      0.47         5
         384       0.50      0.40      0.44         5
         385       1.00      0.78      0.88         9
         386       1.00      0.20      0.33         5
         387       0.00      0.00      0.00         4
         388       1.00      1.00      1.00         9
         389       1.00      1.00      1.00         4
         390       0.44      1.00      0.62         4
         391       1.00      0.67      0.80         9
         392       0.43      0.75      0.55         4
         393       1.00      1.00      1.00         4
         394       0.75      0.75      0.75         4
         395       0.86      0.67      0.75         9
         396       0.45      1.00      0.62         5
         397       0.89      0.89      0.89         9
         398       0.89      0.89      0.89         9
         399       0.67      0.80      0.73         5
         400       0.83      1.00      0.91         5
         401       1.00      1.00      1.00         4
         402       1.00      1.00      1.00         9
         403       0.00      0.00      0.00         4
         404       0.75      0.75      0.75         4
         405       0.80      1.00      0.89         4
         406       0.80      1.00      0.89         4
         407       0.00      0.00      0.00         4
         408       0.67      1.00      0.80         4
         409       0.60      0.75      0.67         4
         410       0.88      0.78      0.82         9
         411       1.00      1.00      1.00         4
         412       1.00      0.78      0.88         9
         413       1.00      1.00      1.00         4
         414       1.00      0.80      0.89         5
         415       0.62      0.56      0.59         9
         416       0.82      1.00      0.90         9
         417       0.67      1.00      0.80         4
         418       0.00      0.00      0.00         4
         419       1.00      1.00      1.00         5
         420       0.00      0.00      0.00         4
         421       0.00      0.00      0.00         4
         422       0.80      0.80      0.80         5
         423       1.00      1.00      1.00         4
         424       0.12      0.75      0.20         4
         425       0.00      0.00      0.00         4
         426       0.57      1.00      0.73         4
         427       1.00      0.50      0.67         4
         428       1.00      1.00      1.00         5
         429       1.00      0.78      0.88         9
         430       0.00      0.00      0.00         4
         431       0.80      1.00      0.89         4
         432       1.00      0.44      0.62         9
         433       0.62      0.56      0.59         9
         434       0.80      1.00      0.89         4
         435       0.21      0.75      0.33         4
         436       1.00      1.00      1.00         4
         437       0.88      0.78      0.82         9
         438       0.46      0.67      0.55         9
         439       1.00      0.75      0.86         4
         440       1.00      0.75      0.86         4
         441       0.75      0.60      0.67         5
         442       1.00      1.00      1.00         4
         443       0.67      0.80      0.73         5
         444       0.45      1.00      0.62         9
         445       1.00      1.00      1.00         4
         446       1.00      0.25      0.40         4
         447       1.00      0.80      0.89         5
         448       0.50      1.00      0.67         4
         449       0.71      0.56      0.63         9
         450       0.50      1.00      0.67         4
         451       1.00      0.75      0.86         4
         452       0.67      1.00      0.80         4
         453       0.00      0.00      0.00         4
         454       1.00      0.25      0.40         4
         455       0.00      0.00      0.00         4
         456       1.00      0.89      0.94         9
         457       0.50      0.50      0.50         4
         458       0.67      0.50      0.57         4
         459       0.00      0.00      0.00         4
         460       0.71      1.00      0.83         5
         461       0.80      0.89      0.84         9
         462       0.80      0.80      0.80         5
         463       0.00      0.00      0.00         4
         464       0.80      0.80      0.80         5
         465       0.00      0.00      0.00         4
         466       0.67      0.67      0.67         9
         467       0.00      0.00      0.00         4
         468       1.00      0.75      0.86         4
         469       0.75      0.67      0.71         9
         470       0.70      0.78      0.74         9
         471       0.50      0.14      0.22         7
         472       1.00      0.25      0.40         4
         473       0.00      0.00      0.00         4
         474       0.78      0.78      0.78         9
         475       0.00      0.00      0.00         4
         476       1.00      1.00      1.00         4
         477       1.00      1.00      1.00         4
         478       1.00      0.75      0.86         4
         479       0.82      1.00      0.90         9
         480       0.00      0.00      0.00         4
         481       1.00      0.75      0.86         4
         482       0.40      0.50      0.44         4
         483       1.00      0.50      0.67         4
         484       0.00      0.00      0.00         4
         485       0.33      0.20      0.25         5
         486       0.60      0.60      0.60         5
         487       0.57      1.00      0.73         4
         488       1.00      0.60      0.75         5
         489       1.00      0.80      0.89         5
         490       1.00      0.78      0.88         9
         491       0.50      0.67      0.57         9
         492       1.00      0.67      0.80         9
         493       1.00      0.75      0.86         4
         494       0.75      0.75      0.75         4
         495       1.00      0.89      0.94         9
         496       1.00      1.00      1.00         5
         497       0.00      0.00      0.00         4
         498       1.00      1.00      1.00         4
         499       0.00      0.00      0.00         4
         500       1.00      0.75      0.86         4
         501       1.00      0.25      0.40         4
         502       1.00      0.50      0.67         4
         503       0.80      1.00      0.89         4
         504       1.00      0.25      0.40         4
         505       0.00      0.00      0.00         9
         506       0.00      0.00      0.00         4
         507       0.57      0.80      0.67         5
         508       1.00      0.75      0.86         4
         509       1.00      0.75      0.86         4
         510       1.00      0.75      0.86         4
         511       1.00      0.75      0.86         4
         512       0.71      1.00      0.83         5
         513       0.00      0.00      0.00         4
         514       0.71      1.00      0.83         5
         515       0.40      0.50      0.44         4
         516       0.43      0.75      0.55         4
         517       0.75      1.00      0.86         9
         518       0.67      0.80      0.73         5
         519       0.00      0.00      0.00         9
         520       0.25      0.25      0.25         4
         521       0.71      0.71      0.71         7
         522       0.80      1.00      0.89         4
         523       0.00      0.00      0.00         4
         524       1.00      1.00      1.00         9
         525       1.00      0.75      0.86         4
         526       0.78      0.78      0.78         9
         527       0.00      0.00      0.00         4
         528       0.00      0.00      0.00         4
         529       1.00      1.00      1.00         9
         530       0.14      1.00      0.25         4
         531       1.00      0.80      0.89         5
         532       0.43      0.75      0.55         4
         533       0.75      0.75      0.75         4
         534       0.00      0.00      0.00         4
         535       1.00      1.00      1.00         4
         536       1.00      0.80      0.89         5
         537       0.90      1.00      0.95         9
         538       1.00      0.75      0.86         4
         539       1.00      0.75      0.86         4
         540       0.57      1.00      0.73         4
         541       0.50      0.60      0.55         5
         542       0.67      1.00      0.80         4
         543       1.00      0.89      0.94         9
         544       0.00      0.00      0.00         4
         545       0.67      0.50      0.57         4
         546       0.75      0.75      0.75         4
         547       0.67      1.00      0.80         4
         548       0.60      0.75      0.67         4
         549       0.67      0.89      0.76         9
         550       0.67      1.00      0.80         4
         551       1.00      1.00      1.00         7
         552       0.15      1.00      0.26         4
         553       1.00      0.80      0.89         5
         554       0.00      0.00      0.00         4
         555       1.00      0.60      0.75         5
         556       0.38      1.00      0.56         5
         557       0.83      0.56      0.67         9
         558       0.64      1.00      0.78         9
         559       1.00      0.89      0.94         9
         560       0.00      0.00      0.00         4
         561       1.00      0.75      0.86         4
         562       0.80      1.00      0.89         4
         563       0.10      0.75      0.18         4
         564       0.11      0.89      0.19         9
         565       1.00      0.50      0.67         4
         566       1.00      0.25      0.40         4
         567       1.00      0.80      0.89         5
         568       0.57      1.00      0.73         4
         569       1.00      1.00      1.00         4
         570       1.00      0.75      0.86         4
         571       1.00      1.00      1.00         9
         572       0.58      0.78      0.67         9
         573       0.78      0.78      0.78         9
         574       0.57      0.80      0.67         5
         575       1.00      1.00      1.00         9
         576       0.50      0.80      0.62         5
         577       0.67      0.40      0.50         5
         578       0.80      1.00      0.89         4
         579       1.00      0.67      0.80         9
         580       0.86      0.67      0.75         9
         581       0.89      1.00      0.94         8
         582       0.33      0.50      0.40         4
         583       0.47      0.89      0.62         9
         584       0.83      1.00      0.91         5
         585       0.50      0.50      0.50         4
         586       1.00      1.00      1.00         4
         587       1.00      1.00      1.00         4
         588       0.11      0.50      0.17         4
         589       1.00      1.00      1.00         4
         590       1.00      0.56      0.71         9
         591       0.67      1.00      0.80         4
         592       1.00      0.67      0.80         9
         593       0.25      0.25      0.25         4
         594       1.00      0.89      0.94         9
         595       0.00      0.00      0.00         4
         596       0.88      0.78      0.82         9
         597       0.57      1.00      0.73         4
         598       0.12      0.50      0.20         4
         599       0.57      0.80      0.67         5
         600       0.00      0.00      0.00         4
         601       1.00      1.00      1.00         4
         602       1.00      1.00      1.00         4
         603       0.67      0.50      0.57         4
         604       0.75      1.00      0.86         9
         605       0.00      0.00      0.00         4
         606       0.90      1.00      0.95         9
         607       0.00      0.00      0.00         4
         608       0.00      0.00      0.00         4
         609       0.90      1.00      0.95         9
         610       1.00      0.78      0.88         9
         611       0.00      0.00      0.00         4
         612       0.38      0.89      0.53         9
         613       0.67      0.89      0.76         9
         614       0.88      0.78      0.82         9
         615       0.14      0.20      0.17         5
         616       1.00      0.80      0.89         5
         617       0.00      0.00      0.00         4
         618       1.00      1.00      1.00         4
         619       0.00      0.00      0.00         4
         620       0.00      0.00      0.00         4
         621       0.23      0.60      0.33         5
         622       0.88      0.78      0.82         9
         623       0.67      0.50      0.57         4
         624       0.00      0.00      0.00         4
         625       1.00      0.56      0.71         9
         626       1.00      1.00      1.00         4
         627       1.00      0.67      0.80         9
         628       0.56      1.00      0.72         9
         629       0.80      1.00      0.89         4
         630       1.00      1.00      1.00         4
         631       1.00      0.78      0.88         9
         632       0.00      0.00      0.00         4
         633       0.69      1.00      0.82         9
         634       0.50      0.67      0.57         9
         635       0.00      0.00      0.00         4
         636       0.00      0.00      0.00         4
         637       0.75      0.75      0.75         4
         638       1.00      0.25      0.40         4
         639       0.57      1.00      0.73         4
         640       0.00      0.00      0.00         4
         641       1.00      0.75      0.86         4
         642       1.00      1.00      1.00         5
         643       0.50      0.75      0.60         4
         644       0.00      0.00      0.00         4
         645       0.00      0.00      0.00         4
         646       1.00      0.50      0.67         4
         647       0.75      0.75      0.75         4
         648       1.00      0.75      0.86         4
         649       0.00      0.00      0.00         4
         650       1.00      1.00      1.00         9
         651       0.50      0.67      0.57         9
         652       0.80      1.00      0.89         4
         653       0.67      1.00      0.80         4
         654       0.00      0.00      0.00         5
         655       1.00      0.80      0.89         5
         656       1.00      1.00      1.00         4
         657       0.00      0.00      0.00         4
         658       1.00      0.80      0.89         5
         659       0.00      0.00      0.00         5
         660       1.00      1.00      1.00         5
         661       0.00      0.00      0.00         4
         662       0.00      0.00      0.00         4
         663       0.70      0.78      0.74         9
         664       1.00      0.89      0.94         9
         665       0.75      0.75      0.75         4
         666       0.62      0.89      0.73         9
         667       1.00      0.67      0.80         9
         668       0.70      0.78      0.74         9
         669       1.00      0.75      0.86         4
         670       0.00      0.00      0.00         9
         671       0.80      0.80      0.80         5
         672       0.67      0.50      0.57         4
         673       1.00      1.00      1.00         5
         674       0.80      0.89      0.84         9
         675       0.00      0.00      0.00         4
         676       0.12      0.25      0.17         4
         677       1.00      0.50      0.67         4
         678       0.25      0.25      0.25         4
         679       0.60      0.33      0.43         9
         680       0.67      0.89      0.76         9
         681       0.75      0.75      0.75         4
         682       0.00      0.00      0.00         9
         683       1.00      1.00      1.00         4
         684       0.75      0.75      0.75         4
         685       1.00      1.00      1.00         4
         686       1.00      1.00      1.00         4
         687       0.56      1.00      0.72         9
         688       1.00      1.00      1.00         5
         689       0.80      1.00      0.89         4
         690       0.44      0.80      0.57         5
         691       0.88      0.78      0.82         9
         692       0.67      0.80      0.73         5
         693       1.00      0.75      0.86         4
         694       0.50      0.89      0.64         9
         695       0.67      0.50      0.57         4
         696       0.67      0.40      0.50         5
         697       0.80      1.00      0.89         4
         698       0.82      1.00      0.90         9
         699       0.33      0.25      0.29         4
         700       0.12      0.25      0.17         4
         701       0.67      1.00      0.80         4
         702       0.89      0.89      0.89         9
         703       1.00      1.00      1.00         4
         704       0.50      0.80      0.62         5
         705       1.00      0.50      0.67         4
         706       0.00      0.00      0.00         4
         707       1.00      0.75      0.86         4
         708       1.00      0.75      0.86         4
         709       0.75      0.75      0.75         4
         710       0.00      0.00      0.00         4
         711       0.00      0.00      0.00         4
         712       0.75      0.75      0.75         4
         713       1.00      1.00      1.00         4
         714       0.80      1.00      0.89         4
         715       0.00      0.00      0.00         5
         716       0.10      0.25      0.14         4
         717       0.00      0.00      0.00         4
         718       1.00      1.00      1.00         5
         719       1.00      0.80      0.89         5
         720       1.00      1.00      1.00         5
         721       0.10      0.50      0.16         4
         722       0.00      0.00      0.00         4
         723       0.80      0.80      0.80         5
         724       1.00      0.50      0.67         4
         725       1.00      0.75      0.86         4
         726       1.00      1.00      1.00         9
         727       1.00      1.00      1.00         5
         728       0.00      0.00      0.00         9
         729       1.00      0.50      0.67         4
         730       0.60      0.75      0.67         4
         731       1.00      0.80      0.89         5
         732       0.69      1.00      0.82         9
         733       1.00      0.89      0.94         9
         734       1.00      0.20      0.33         5
         735       0.00      0.00      0.00         4
         736       0.89      0.89      0.89         9
         737       0.67      0.67      0.67         9
         738       0.14      0.75      0.24         4
         739       1.00      0.78      0.88         9
         740       0.67      1.00      0.80         4
         741       1.00      0.50      0.67         4
         742       1.00      0.60      0.75         5
         743       0.88      0.78      0.82         9
         744       1.00      1.00      1.00         4
         745       0.00      0.00      0.00         4
         746       0.80      1.00      0.89         4
         747       1.00      1.00      1.00         4
         748       0.00      0.00      0.00         4
         749       0.75      0.75      0.75         4
         750       0.00      0.00      0.00         4
         751       0.00      0.00      0.00         4
         752       1.00      0.25      0.40         4
         753       0.80      1.00      0.89         4
         754       0.75      0.75      0.75         4
         755       0.86      0.67      0.75         9
         756       0.50      0.60      0.55         5
         757       0.90      1.00      0.95         9
         758       0.00      0.00      0.00         4
         759       0.00      0.00      0.00         9
         760       1.00      1.00      1.00         5
         761       0.40      0.50      0.44         4
         762       0.00      0.00      0.00         9
         763       0.67      0.89      0.76         9
         764       1.00      1.00      1.00         4
         765       1.00      0.44      0.62         9
         766       0.58      0.78      0.67         9
         767       1.00      0.60      0.75         5
         768       0.25      0.25      0.25         4
         769       0.40      0.50      0.44         4
         770       0.50      1.00      0.67         4
         771       1.00      1.00      1.00         4
         772       1.00      1.00      1.00         4
         773       0.75      0.75      0.75         4
         774       1.00      1.00      1.00         4
         775       0.75      0.33      0.46         9
         776       0.14      1.00      0.25         4
         777       0.80      1.00      0.89         4
         778       0.89      0.89      0.89         9
         779       0.60      0.75      0.67         4
         780       0.00      0.00      0.00         5
         781       0.00      0.00      0.00         5
         782       1.00      1.00      1.00         9
         783       0.70      0.78      0.74         9
         784       1.00      0.50      0.67         4
         785       0.67      1.00      0.80         4
         786       0.50      0.25      0.33         4
         787       0.00      0.00      0.00         4
         788       0.67      0.50      0.57         4
         789       0.00      0.00      0.00         4
         790       0.78      0.78      0.78         9
         791       0.00      0.00      0.00         4
         792       0.50      0.50      0.50         4
         793       1.00      0.89      0.94         9
         794       1.00      0.75      0.86         4
         795       0.00      0.00      0.00         4
         796       1.00      0.78      0.88         9
         797       1.00      0.89      0.94         9
         798       0.00      0.00      0.00         4
         799       0.00      0.00      0.00         9
         800       1.00      1.00      1.00         4
         801       0.40      0.80      0.53         5
         802       0.50      0.50      0.50         4
         803       0.80      0.80      0.80         5
         804       0.40      0.50      0.44         4
         805       1.00      0.25      0.40         4
         806       0.67      0.50      0.57         4
         807       1.00      1.00      1.00         4
         808       0.00      0.00      0.00         4
         809       0.67      1.00      0.80         4
         810       0.80      0.44      0.57         9
         811       1.00      1.00      1.00         4
         812       0.50      0.25      0.33         4
         813       1.00      1.00      1.00         5
         814       0.57      1.00      0.73         4
         815       0.80      1.00      0.89         4
         816       1.00      0.50      0.67         4
         817       0.00      0.00      0.00         9
         818       0.80      0.89      0.84         9
         819       0.50      0.25      0.33         4
         820       0.67      0.89      0.76         9
         821       0.75      1.00      0.86         9
         822       0.75      1.00      0.86         9
         823       0.00      0.00      0.00         4
         824       0.50      0.40      0.44         5
         825       1.00      0.50      0.67         4
         826       0.57      1.00      0.73         4
         827       0.40      1.00      0.57         4
         828       0.00      0.00      0.00         4
         829       0.00      0.00      0.00         9
         830       0.67      0.50      0.57         4
         831       1.00      1.00      1.00         4
         832       0.75      0.75      0.75         4
         833       1.00      1.00      1.00         4
         834       0.43      0.75      0.55         4
         835       1.00      1.00      1.00         9
         836       0.00      0.00      0.00         4
         837       0.00      0.00      0.00         4
         838       1.00      0.60      0.75         5
         839       0.00      0.00      0.00         5
         840       0.80      1.00      0.89         4
         841       0.00      0.00      0.00         4
         842       1.00      1.00      1.00         9
         843       0.00      0.00      0.00         9
         844       0.80      1.00      0.89         4
         845       0.75      0.75      0.75         4
         846       0.80      1.00      0.89         4
         847       1.00      0.60      0.75         5
         848       0.35      0.89      0.50         9
         849       0.80      1.00      0.89         4
         850       0.75      0.75      0.75         4
         851       0.00      0.00      0.00         4
         852       0.88      0.78      0.82         9
         853       1.00      0.89      0.94         9
         854       1.00      1.00      1.00         9
         855       1.00      1.00      1.00         4
         856       0.80      1.00      0.89         4
         857       0.50      0.25      0.33         4
         858       0.50      0.50      0.50         4
         859       0.80      1.00      0.89         4
         860       0.82      1.00      0.90         9
         861       1.00      0.75      0.86         4
         862       0.38      0.56      0.45         9
         863       0.33      0.60      0.43         5
         864       0.00      0.00      0.00         4
         865       0.00      0.00      0.00         4
         866       0.00      0.00      0.00         4
         867       0.82      1.00      0.90         9
         868       0.71      1.00      0.83         5
         869       0.00      0.00      0.00         4
         870       1.00      1.00      1.00         4
         871       0.90      1.00      0.95         9
         872       0.67      0.80      0.73         5
         873       1.00      1.00      1.00         4
         874       1.00      0.80      0.89         5
         875       1.00      0.11      0.20         9
         876       1.00      0.25      0.40         4
         877       0.60      0.75      0.67         4
         878       0.00      0.00      0.00         4
         879       0.75      0.75      0.75         4
         880       1.00      1.00      1.00         5
         881       0.67      1.00      0.80         4
         882       1.00      1.00      1.00         5
         883       0.67      1.00      0.80         4
         884       0.67      0.50      0.57         4
         885       0.50      0.50      0.50         4
         886       0.00      0.00      0.00         4
         887       0.00      0.00      0.00         4
         888       1.00      1.00      1.00         5
         889       0.50      1.00      0.67         5
         890       0.00      0.00      0.00         4
         891       0.00      0.00      0.00         4
         892       0.80      1.00      0.89         4
         893       1.00      0.56      0.71         9

    accuracy                           0.66      4917
   macro avg       0.63      0.63      0.61      4917
weighted avg       0.66      0.66      0.64      4917

task_train_time: {0: 0.12253248899999925, 1: 0.03582503700000039, 2: 0.03260621799999974, 3: 0.028862621000000033, 4: 0.03522695799999909, 5: 0.030091821000000962, 6: 0.03159239500000055, 7: 0.032639005000000054, 8: 0.030962616000000054, 9: 0.033844699999999506, 10: 0.03951503599999917, 11: 0.02742492399999996, 12: 0.03571044900000153, 13: 0.034596782999999576, 14: 0.032315404000000214, 15: 0.032811633999999756, 16: 0.03419242300000036, 17: 0.03128653599999964, 18: 0.03278869799999917, 19: 0.03323852199999955, 20: 0.031790406000000715, 21: 0.02989107900000043, 22: 0.03309915999999902, 23: 0.03220822599999984, 24: 0.02832721199999888, 25: 0.03369136099999892, 26: 0.0294474479999991, 27: 0.03529505800000088, 28: 0.03504859999999965, 29: 0.03675295599999906, 30: 0.03475939700000019, 31: 0.027614584000000164, 32: 0.03718467000000025, 33: 0.03478693799999988, 34: 0.03015415900000029, 35: 0.0313794680000008, 36: 0.0305499669999989, 37: 0.03662193000000258, 38: 0.03346385200000057, 39: 0.032116371000000754, 40: 0.03334688500000027, 41: 0.034435826999999364, 42: 0.03290896600000082, 43: 0.027794944000000044}
prediction_time: 0.0002710790000008956
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
