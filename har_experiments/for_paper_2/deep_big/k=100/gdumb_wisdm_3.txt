Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='8a976f64-2296-42e3-9b53-47cf2c29291e', conf_timestamp='2023-08-13 15:21:30.139614', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 63.86 % 	 [Task-IL]: 48.02 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 56.82 % 	 [Task-IL]: 36.72 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 39.95 % 	 [Task-IL]: 36.56 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 42.6 % 	 [Task-IL]: 35.71 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 31.2 % 	 [Task-IL]: 36.28 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 31.11 % 	 [Task-IL]: 32.97 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 21.68 % 	 [Task-IL]: 33.03 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 21.87 % 	 [Task-IL]: 30.61 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.67 % 	 [Task-IL]: 30.05 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 18.25 % 	 [Task-IL]: 30.0 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 17.79 % 	 [Task-IL]: 30.61 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 15.26 % 	 [Task-IL]: 29.86 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 15.07 % 	 [Task-IL]: 29.68 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 15.25 % 	 [Task-IL]: 30.12 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 9.17 % 	 [Task-IL]: 29.77 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 10.42 % 	 [Task-IL]: 29.57 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 10.26 % 	 [Task-IL]: 28.63 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 11.84 % 	 [Task-IL]: 28.79 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 11.29 % 	 [Task-IL]: 28.42 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 7.4 % 	 [Task-IL]: 28.1 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.18 % 	 [Task-IL]: 27.75 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 10.51 % 	 [Task-IL]: 27.29 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 10.09 % 	 [Task-IL]: 27.21 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.64 % 	 [Task-IL]: 27.49 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 8.21 % 	 [Task-IL]: 27.77 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.42 % 	 [Task-IL]: 27.69 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.14 % 	 [Task-IL]: 27.56 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.99 % 	 [Task-IL]: 27.59 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 9.39 % 	 [Task-IL]: 27.09 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 5.98 % 	 [Task-IL]: 26.77 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 6.45 % 	 [Task-IL]: 26.99 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 6.55 % 	 [Task-IL]: 27.14 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.9 % 	 [Task-IL]: 26.91 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.08 % 	 [Task-IL]: 26.76 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.67 % 	 [Task-IL]: 26.81 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 7.31 % 	 [Task-IL]: 26.57 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.96 % 	 [Task-IL]: 27.02 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 6.5 % 	 [Task-IL]: 27.19 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.07 % 	 [Task-IL]: 27.24 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.14 % 	 [Task-IL]: 27.15 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.98 % 	 [Task-IL]: 27.16 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.21 % 	 [Task-IL]: 27.04 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 5.56 % 	 [Task-IL]: 27.2 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74907, 619: 34, 126: 33, 181: 33, 241: 33, 94: 32, 139: 32, 218: 32, 274: 32, 293: 32, 308: 32, 385: 32, 501: 32, 495: 32, 543: 32, 537: 32, 554: 32, 729: 32, 758: 32, 796: 32, 803: 32, 840: 32, 838: 32, 4: 31, 53: 31, 69: 31, 99: 31, 132: 31, 136: 31, 144: 31, 171: 31, 195: 31, 212: 31, 259: 31, 298: 31, 407: 31, 534: 31, 591: 31, 610: 31, 601: 31, 673: 31, 698: 31, 711: 31, 716: 31, 765: 31, 841: 31, 854: 31, 881: 31, 14: 30, 3: 30, 46: 30, 59: 30, 110: 30, 149: 30, 155: 30, 185: 30, 224: 30, 226: 30, 250: 30, 248: 30, 258: 30, 260: 30, 314: 30, 347: 30, 350: 30, 410: 30, 411: 30, 429: 30, 423: 30, 418: 30, 427: 30, 469: 30, 479: 30, 493: 30, 531: 30, 562: 30, 612: 30, 646: 30, 651: 30, 738: 30, 753: 30, 762: 30, 778: 30, 811: 30, 828: 30, 20: 29, 22: 29, 50: 29, 34: 29, 45: 29, 61: 29, 58: 29, 112: 29, 130: 29, 142: 29, 188: 29, 213: 29, 271: 29, 265: 29, 278: 29, 295: 29, 313: 29, 378: 29, 404: 29, 412: 29, 468: 29, 528: 29, 553: 29, 567: 29, 574: 29, 584: 29, 588: 29, 598: 29, 623: 29, 656: 29, 695: 29, 715: 29, 748: 29, 802: 29, 876: 29, 6: 28, 9: 28, 15: 28, 56: 28, 84: 28, 79: 28, 198: 28, 194: 28, 219: 28, 225: 28, 323: 28, 401: 28, 420: 28, 432: 28, 471: 28, 470: 28, 533: 28, 607: 28, 629: 28, 635: 28, 672: 28, 674: 28, 677: 28, 690: 28, 739: 28, 768: 28, 782: 28, 851: 28, 878: 28, 1: 27, 24: 27, 148: 27, 172: 27, 197: 27, 220: 27, 246: 27, 302: 27, 322: 27, 380: 27, 391: 27, 395: 27, 467: 27, 466: 27, 478: 27, 506: 27, 523: 27, 552: 27, 564: 27, 605: 27, 616: 27, 633: 27, 667: 27, 657: 27, 658: 27, 682: 27, 741: 27, 844: 27, 853: 27, 836: 27, 852: 27, 866: 27, 857: 27, 889: 27, 49: 26, 216: 26, 252: 26, 273: 26, 285: 26, 331: 26, 342: 26, 351: 26, 358: 26, 425: 26, 453: 26, 474: 26, 634: 26, 708: 26, 819: 26, 875: 26, 32: 25, 48: 25, 57: 25, 63: 25, 203: 25, 311: 25, 305: 25, 513: 25, 518: 25, 606: 25, 625: 25, 652: 25, 688: 25, 725: 25, 755: 25, 766: 25, 816: 25, 862: 25, 880: 25, 54: 24, 78: 24, 275: 24, 494: 24, 536: 24, 582: 24, 609: 24, 704: 24, 709: 24, 733: 24, 813: 24, 831: 24, 95: 23, 138: 23, 140: 23, 659: 23, 702: 23, 230: 22, 303: 22, 361: 22, 697: 22, 779: 19, 68: 18, 444: 18, 764: 18, 821: 18, 266: 17, 356: 17, 662: 17, 721: 17, 790: 17, 818: 17, 885: 17, 92: 16, 173: 16, 222: 16, 235: 16, 251: 16, 269: 16, 335: 16, 364: 16, 382: 16, 398: 16, 405: 16, 491: 16, 488: 16, 503: 16, 505: 16, 617: 16, 618: 16, 664: 16, 727: 16, 823: 16, 843: 16, 849: 16, 863: 16, 19: 15, 33: 15, 64: 15, 67: 15, 100: 15, 205: 15, 231: 15, 214: 15, 255: 15, 256: 15, 270: 15, 287: 15, 310: 15, 371: 15, 435: 15, 487: 15, 507: 15, 508: 15, 548: 15, 572: 15, 578: 15, 592: 15, 596: 15, 687: 15, 776: 15, 832: 15, 822: 15, 864: 15, 31: 14, 5: 14, 13: 14, 17: 14, 44: 14, 41: 14, 35: 14, 128: 14, 121: 14, 122: 14, 120: 14, 145: 14, 151: 14, 182: 14, 179: 14, 204: 14, 209: 14, 210: 14, 228: 14, 238: 14, 263: 14, 280: 14, 281: 14, 306: 14, 344: 14, 353: 14, 369: 14, 357: 14, 383: 14, 389: 14, 414: 14, 442: 14, 456: 14, 458: 14, 455: 14, 504: 14, 511: 14, 520: 14, 524: 14, 516: 14, 519: 14, 547: 14, 587: 14, 600: 14, 631: 14, 637: 14, 663: 14, 670: 14, 713: 14, 749: 14, 769: 14, 783: 14, 806: 14, 833: 14, 815: 14, 848: 14, 855: 14, 867: 14, 2: 13, 47: 13, 37: 13, 66: 13, 65: 13, 71: 13, 82: 13, 81: 13, 86: 13, 75: 13, 76: 13, 113: 13, 107: 13, 116: 13, 131: 13, 119: 13, 137: 13, 161: 13, 166: 13, 167: 13, 163: 13, 187: 13, 180: 13, 175: 13, 190: 13, 202: 13, 217: 13, 215: 13, 229: 13, 223: 13, 239: 13, 244: 13, 249: 13, 264: 13, 289: 13, 276: 13, 277: 13, 294: 13, 326: 13, 318: 13, 324: 13, 327: 13, 332: 13, 349: 13, 346: 13, 352: 13, 366: 13, 370: 13, 373: 13, 377: 13, 413: 13, 430: 13, 421: 13, 416: 13, 436: 13, 449: 13, 434: 13, 464: 13, 465: 13, 472: 13, 497: 13, 522: 13, 526: 13, 527: 13, 550: 13, 539: 13, 542: 13, 568: 13, 570: 13, 611: 13, 620: 13, 647: 13, 661: 13, 666: 13, 655: 13, 692: 13, 680: 13, 679: 13, 684: 13, 685: 13, 703: 13, 705: 13, 694: 13, 700: 13, 696: 13, 712: 13, 731: 13, 728: 13, 732: 13, 742: 13, 745: 13, 767: 13, 771: 13, 763: 13, 756: 13, 774: 13, 786: 13, 785: 13, 825: 13, 835: 13, 861: 13, 860: 13, 888: 13, 887: 13, 892: 13, 7: 12, 16: 12, 21: 12, 12: 12, 27: 12, 8: 12, 52: 12, 40: 12, 39: 12, 62: 12, 72: 12, 55: 12, 73: 12, 80: 12, 74: 12, 89: 12, 101: 12, 98: 12, 111: 12, 118: 12, 117: 12, 143: 12, 134: 12, 135: 12, 141: 12, 164: 12, 168: 12, 170: 12, 156: 12, 174: 12, 178: 12, 183: 12, 177: 12, 206: 12, 233: 12, 247: 12, 242: 12, 272: 12, 286: 12, 292: 12, 284: 12, 291: 12, 288: 12, 296: 12, 301: 12, 312: 12, 304: 12, 321: 12, 320: 12, 316: 12, 330: 12, 317: 12, 348: 12, 337: 12, 341: 12, 372: 12, 368: 12, 376: 12, 374: 12, 387: 12, 402: 12, 415: 12, 439: 12, 446: 12, 448: 12, 438: 12, 462: 12, 461: 12, 457: 12, 489: 12, 475: 12, 481: 12, 483: 12, 485: 12, 500: 12, 517: 12, 521: 12, 525: 12, 551: 12, 541: 12, 545: 12, 556: 12, 559: 12, 560: 12, 558: 12, 579: 12, 604: 12, 603: 12, 595: 12, 628: 12, 639: 12, 650: 12, 641: 12, 636: 12, 645: 12, 654: 12, 669: 12, 676: 12, 675: 12, 689: 12, 691: 12, 693: 12, 706: 12, 710: 12, 707: 12, 699: 12, 719: 12, 722: 12, 726: 12, 723: 12, 718: 12, 747: 12, 746: 12, 735: 12, 751: 12, 734: 12, 752: 12, 757: 12, 791: 12, 775: 12, 777: 12, 787: 12, 805: 12, 808: 12, 812: 12, 824: 12, 830: 12, 814: 12, 850: 12, 847: 12, 842: 12, 873: 12, 865: 12, 890: 12, 877: 12, 883: 12, 893: 12, 886: 12, 28: 11, 25: 11, 23: 11, 11: 11, 29: 11, 38: 11, 51: 11, 70: 11, 83: 11, 85: 11, 87: 11, 88: 11, 102: 11, 106: 11, 109: 11, 103: 11, 125: 11, 124: 11, 133: 11, 127: 11, 153: 11, 152: 11, 147: 11, 160: 11, 154: 11, 169: 11, 157: 11, 189: 11, 200: 11, 207: 11, 208: 11, 199: 11, 232: 11, 227: 11, 221: 11, 236: 11, 245: 11, 243: 11, 234: 11, 267: 11, 254: 11, 262: 11, 283: 11, 309: 11, 297: 11, 307: 11, 299: 11, 333: 11, 325: 11, 329: 11, 336: 11, 345: 11, 338: 11, 367: 11, 386: 11, 393: 11, 384: 11, 375: 11, 381: 11, 400: 11, 394: 11, 397: 11, 403: 11, 408: 11, 433: 11, 419: 11, 424: 11, 443: 11, 450: 11, 451: 11, 452: 11, 445: 11, 440: 11, 463: 11, 477: 11, 480: 11, 476: 11, 509: 11, 499: 11, 502: 11, 514: 11, 549: 11, 535: 11, 557: 11, 571: 11, 565: 11, 585: 11, 575: 11, 589: 11, 590: 11, 599: 11, 630: 11, 626: 11, 615: 11, 622: 11, 614: 11, 638: 11, 640: 11, 644: 11, 671: 11, 668: 11, 681: 11, 683: 11, 714: 11, 730: 11, 740: 11, 737: 11, 772: 11, 759: 11, 770: 11, 784: 11, 789: 11, 788: 11, 799: 11, 794: 11, 798: 11, 797: 11, 800: 11, 804: 11, 809: 11, 810: 11, 826: 11, 829: 11, 837: 11, 846: 11, 871: 11, 856: 11, 868: 11, 872: 11, 869: 11, 884: 11, 882: 11, 874: 11, 18: 10, 30: 10, 90: 10, 91: 10, 104: 10, 96: 10, 108: 10, 97: 10, 123: 10, 129: 10, 146: 10, 165: 10, 176: 10, 192: 10, 191: 10, 201: 10, 211: 10, 240: 10, 279: 10, 300: 10, 319: 10, 334: 10, 339: 10, 340: 10, 355: 10, 365: 10, 362: 10, 359: 10, 360: 10, 363: 10, 354: 10, 392: 10, 406: 10, 428: 10, 417: 10, 426: 10, 431: 10, 422: 10, 437: 10, 447: 10, 460: 10, 473: 10, 484: 10, 486: 10, 482: 10, 512: 10, 532: 10, 530: 10, 529: 10, 515: 10, 546: 10, 573: 10, 566: 10, 555: 10, 563: 10, 581: 10, 583: 10, 580: 10, 586: 10, 577: 10, 613: 10, 608: 10, 602: 10, 621: 10, 632: 10, 624: 10, 643: 10, 648: 10, 649: 10, 653: 10, 642: 10, 665: 10, 678: 10, 686: 10, 720: 10, 724: 10, 717: 10, 750: 10, 736: 10, 743: 10, 773: 10, 793: 10, 780: 10, 820: 10, 827: 10, 839: 10, 845: 10, 858: 10, 879: 10, 10: 9, 43: 9, 36: 9, 93: 9, 77: 9, 105: 9, 115: 9, 150: 9, 162: 9, 193: 9, 186: 9, 184: 9, 196: 9, 253: 9, 237: 9, 261: 9, 257: 9, 268: 9, 290: 9, 315: 9, 328: 9, 388: 9, 396: 9, 459: 9, 492: 9, 490: 9, 496: 9, 544: 9, 569: 9, 561: 9, 576: 9, 593: 9, 594: 9, 627: 9, 660: 9, 744: 9, 754: 9, 781: 9, 807: 9, 801: 9, 817: 9, 834: 9, 859: 9, 26: 8, 42: 8, 114: 8, 159: 8, 343: 8, 379: 8, 409: 8, 399: 8, 441: 8, 454: 8, 498: 8, 510: 8, 540: 8, 538: 8, 597: 8, 701: 8, 761: 8, 760: 8, 795: 8, 891: 8, 60: 7, 158: 7, 282: 7, 390: 7, 792: 7, 870: 6})
Total buffer: 89400
fit_time: 127.457876529

Accuracy for 44 task(s): 	 [Class-IL]: 74.93 % 	 [Task-IL]: 30.34 %

CLASS_IL_ACC: 
	[67.32673267326733, 70.94017094017094, 84.0, 70.83333333333334, 74.07407407407408, 67.32673267326733, 71.900826446281, 63.26530612244898, 81.81818181818183, 82.35294117647058, 75.39682539682539, 87.38738738738738, 78.8135593220339, 82.56880733944955, 76.85950413223141, 68.31683168316832, 79.6116504854369, 82.10526315789474, 85.29411764705883, 74.35897435897436, 74.35897435897436, 73.33333333333333, 75.0, 76.69902912621359, 80.9090909090909, 65.13761467889908, 80.7017543859649, 76.47058823529412, 73.58490566037736, 75.83333333333333, 80.53097345132744, 79.24528301886792, 66.38655462184873, 84.25925925925925, 71.42857142857143, 67.27272727272727, 65.74074074074075, 77.87610619469027, 74.48979591836735, 70.75471698113208, 75.70093457943925, 70.96774193548387, 67.96116504854369, 67.56756756756756]
TASK_IL_ACC: 
	[50.495049504950494, 24.786324786324787, 36.0, 31.25, 36.11111111111111, 22.772277227722775, 30.57851239669421, 28.57142857142857, 24.242424242424242, 35.294117647058826, 30.952380952380953, 22.52252252252252, 28.8135593220339, 35.77981651376147, 20.66115702479339, 27.722772277227726, 20.388349514563107, 30.526315789473685, 24.509803921568626, 20.51282051282051, 24.786324786324787, 28.888888888888886, 20.535714285714285, 35.92233009708738, 30.909090909090907, 27.522935779816514, 33.33333333333333, 24.509803921568626, 28.30188679245283, 25.0, 27.43362831858407, 31.132075471698112, 25.210084033613445, 31.48148148148148, 31.092436974789916, 29.09090909090909, 29.629629629629626, 29.20353982300885, 32.6530612244898, 24.528301886792452, 33.64485981308411, 20.967741935483872, 33.00970873786408, 93.69369369369369]
f1_micro: 74.82204596298556
f1_macro: 72.66302055264524
              precision    recall  f1-score   support

           0       0.75      1.00      0.86         9
           1       0.86      0.67      0.75         9
           2       0.00      0.00      0.00         4
           3       0.00      0.00      0.00         9
           4       0.80      0.89      0.84         9
           5       1.00      1.00      1.00         5
           6       1.00      1.00      1.00         9
           7       0.00      0.00      0.00         4
           8       1.00      0.75      0.86         4
           9       0.89      0.89      0.89         9
          10       0.00      0.00      0.00         4
          11       0.00      0.00      0.00         4
          12       0.00      0.00      0.00         4
          13       1.00      0.60      0.75         5
          14       0.38      0.33      0.35         9
          15       1.00      1.00      1.00         9
          16       0.00      0.00      0.00         4
          17       0.80      0.80      0.80         5
          18       0.75      0.75      0.75         4
          19       0.83      1.00      0.91         5
          20       0.30      0.33      0.32         9
          21       0.67      1.00      0.80         4
          22       1.00      0.89      0.94         9
          23       1.00      0.75      0.86         4
          24       1.00      0.78      0.88         9
          25       1.00      1.00      1.00         4
          26       1.00      0.75      0.86         4
          27       0.75      0.75      0.75         4
          28       1.00      1.00      1.00         4
          29       1.00      0.75      0.86         4
          30       0.00      0.00      0.00         4
          31       0.83      1.00      0.91         5
          32       0.90      1.00      0.95         9
          33       1.00      1.00      1.00         5
          34       0.75      0.67      0.71         9
          35       0.00      0.00      0.00         4
          36       1.00      0.75      0.86         4
          37       0.62      1.00      0.77         5
          38       0.00      0.00      0.00         4
          39       0.00      0.00      0.00         4
          40       0.67      1.00      0.80         4
          41       1.00      1.00      1.00         5
          42       1.00      1.00      1.00         4
          43       0.50      0.50      0.50         4
          44       0.00      0.00      0.00         4
          45       1.00      1.00      1.00         9
          46       1.00      0.56      0.71         9
          47       0.67      1.00      0.80         4
          48       1.00      1.00      1.00         9
          49       1.00      1.00      1.00         9
          50       0.75      1.00      0.86         9
          51       0.00      0.00      0.00         4
          52       1.00      1.00      1.00         4
          53       0.83      0.56      0.67         9
          54       1.00      0.56      0.71         9
          55       1.00      1.00      1.00         4
          56       1.00      0.78      0.88         9
          57       0.82      1.00      0.90         9
          58       1.00      0.67      0.80         9
          59       0.90      1.00      0.95         9
          60       1.00      0.75      0.86         4
          61       1.00      0.89      0.94         9
          62       0.75      0.75      0.75         4
          63       1.00      1.00      1.00         9
          64       0.67      0.80      0.73         5
          65       1.00      1.00      1.00         4
          66       0.00      0.00      0.00         4
          67       0.83      1.00      0.91         5
          68       1.00      0.86      0.92         7
          69       1.00      0.78      0.88         9
          70       0.80      1.00      0.89         4
          71       1.00      1.00      1.00         4
          72       1.00      1.00      1.00         4
          73       0.67      1.00      0.80         4
          74       0.50      0.75      0.60         4
          75       1.00      0.75      0.86         4
          76       0.00      0.00      0.00         4
          77       1.00      1.00      1.00         4
          78       0.80      0.89      0.84         9
          79       0.75      0.67      0.71         9
          80       1.00      0.50      0.67         4
          81       1.00      1.00      1.00         4
          82       0.80      1.00      0.89         4
          83       1.00      1.00      1.00         4
          84       0.90      1.00      0.95         9
          85       0.00      0.00      0.00         4
          86       1.00      1.00      1.00         4
          87       0.75      0.75      0.75         4
          88       0.75      0.75      0.75         4
          89       0.00      0.00      0.00         4
          90       1.00      0.50      0.67         4
          91       0.00      0.00      0.00         4
          92       1.00      1.00      1.00         5
          93       1.00      1.00      1.00         4
          94       1.00      0.56      0.71         9
          95       1.00      0.89      0.94         9
          96       1.00      1.00      1.00         4
          97       0.00      0.00      0.00         4
          98       1.00      1.00      1.00         5
          99       0.88      0.78      0.82         9
         100       1.00      1.00      1.00         5
         101       1.00      0.25      0.40         4
         102       1.00      1.00      1.00         4
         103       1.00      0.75      0.86         4
         104       1.00      0.75      0.86         4
         105       1.00      0.75      0.86         4
         106       1.00      1.00      1.00         4
         107       1.00      1.00      1.00         5
         108       1.00      1.00      1.00         4
         109       1.00      1.00      1.00         4
         110       0.00      0.00      0.00         9
         111       1.00      1.00      1.00         4
         112       0.88      0.78      0.82         9
         113       1.00      1.00      1.00         4
         114       0.00      0.00      0.00         4
         115       0.00      0.00      0.00         4
         116       1.00      1.00      1.00         5
         117       1.00      0.75      0.86         4
         118       0.80      1.00      0.89         4
         119       0.42      1.00      0.59         5
         120       1.00      0.80      0.89         5
         121       0.80      1.00      0.89         4
         122       1.00      0.60      0.75         5
         123       0.00      0.00      0.00         4
         124       0.60      0.75      0.67         4
         125       0.50      0.25      0.33         4
         126       0.62      0.56      0.59         9
         127       0.60      0.75      0.67         4
         128       1.00      1.00      1.00         5
         129       1.00      1.00      1.00         4
         130       0.89      0.89      0.89         9
         131       0.50      0.20      0.29         5
         132       0.75      0.67      0.71         9
         133       1.00      1.00      1.00         4
         134       0.67      0.50      0.57         4
         135       1.00      0.75      0.86         4
         136       1.00      0.89      0.94         9
         137       0.80      1.00      0.89         4
         138       0.04      0.11      0.06         9
         139       0.80      0.89      0.84         9
         140       0.88      0.78      0.82         9
         141       0.00      0.00      0.00         4
         142       1.00      0.67      0.80         9
         143       1.00      1.00      1.00         4
         144       1.00      0.78      0.88         9
         145       0.00      0.00      0.00         4
         146       1.00      1.00      1.00         4
         147       1.00      0.75      0.86         4
         148       0.90      1.00      0.95         9
         149       0.88      0.78      0.82         9
         150       1.00      0.75      0.86         4
         151       1.00      0.80      0.89         5
         152       0.60      0.75      0.67         4
         153       0.80      1.00      0.89         4
         154       1.00      0.75      0.86         4
         155       0.90      1.00      0.95         9
         156       1.00      0.80      0.89         5
         157       0.29      0.50      0.36         4
         158       1.00      0.50      0.67         4
         159       1.00      0.75      0.86         4
         160       0.75      0.75      0.75         4
         161       1.00      1.00      1.00         4
         162       1.00      1.00      1.00         4
         163       0.67      0.80      0.73         5
         164       0.75      0.75      0.75         4
         165       0.00      0.00      0.00         4
         166       0.67      0.50      0.57         4
         167       1.00      1.00      1.00         4
         168       0.00      0.00      0.00         4
         169       0.00      0.00      0.00         4
         170       0.00      0.00      0.00         4
         171       1.00      0.78      0.88         9
         172       0.67      0.67      0.67         9
         173       1.00      0.40      0.57         5
         174       1.00      1.00      1.00         4
         175       0.67      0.50      0.57         4
         176       0.80      1.00      0.89         4
         177       0.67      0.50      0.57         4
         178       0.67      0.40      0.50         5
         179       1.00      1.00      1.00         5
         180       1.00      1.00      1.00         4
         181       0.82      1.00      0.90         9
         182       1.00      0.60      0.75         5
         183       0.67      0.50      0.57         4
         184       0.80      1.00      0.89         4
         185       1.00      0.78      0.88         9
         186       1.00      1.00      1.00         4
         187       0.83      1.00      0.91         5
         188       0.69      1.00      0.82         9
         189       0.67      0.50      0.57         4
         190       1.00      0.50      0.67         4
         191       1.00      1.00      1.00         4
         192       1.00      0.75      0.86         4
         193       1.00      1.00      1.00         4
         194       0.69      1.00      0.82         9
         195       0.03      0.11      0.05         9
         196       1.00      0.50      0.67         4
         197       0.89      0.89      0.89         9
         198       1.00      0.78      0.88         9
         199       1.00      0.75      0.86         4
         200       1.00      1.00      1.00         4
         201       1.00      1.00      1.00         4
         202       1.00      0.80      0.89         5
         203       1.00      1.00      1.00         9
         204       0.60      0.60      0.60         5
         205       0.75      0.60      0.67         5
         206       1.00      1.00      1.00         4
         207       0.80      1.00      0.89         4
         208       0.80      1.00      0.89         4
         209       1.00      0.80      0.89         5
         210       0.80      1.00      0.89         4
         211       1.00      1.00      1.00         4
         212       0.90      1.00      0.95         9
         213       0.89      0.89      0.89         9
         214       1.00      0.80      0.89         5
         215       0.75      0.75      0.75         4
         216       0.00      0.00      0.00         9
         217       1.00      0.60      0.75         5
         218       0.90      1.00      0.95         9
         219       0.78      0.78      0.78         9
         220       1.00      1.00      1.00         9
         221       0.00      0.00      0.00         4
         222       0.71      1.00      0.83         5
         223       1.00      1.00      1.00         5
         224       0.82      1.00      0.90         9
         225       1.00      0.78      0.88         9
         226       0.82      1.00      0.90         9
         227       0.00      0.00      0.00         4
         228       0.67      0.50      0.57         4
         229       1.00      0.80      0.89         5
         230       0.82      1.00      0.90         9
         231       0.67      0.80      0.73         5
         232       0.60      0.75      0.67         4
         233       1.00      0.75      0.86         4
         234       0.80      1.00      0.89         4
         235       1.00      0.80      0.89         5
         236       1.00      1.00      1.00         4
         237       0.00      0.00      0.00         4
         238       1.00      1.00      1.00         5
         239       1.00      1.00      1.00         4
         240       0.80      1.00      0.89         4
         241       1.00      0.89      0.94         9
         242       1.00      1.00      1.00         5
         243       1.00      0.50      0.67         4
         244       0.67      1.00      0.80         4
         245       1.00      1.00      1.00         4
         246       0.90      1.00      0.95         9
         247       0.83      1.00      0.91         5
         248       0.90      1.00      0.95         9
         249       0.75      0.60      0.67         5
         250       0.90      1.00      0.95         9
         251       0.83      1.00      0.91         5
         252       0.80      0.89      0.84         9
         253       0.33      0.25      0.29         4
         254       0.80      0.80      0.80         5
         255       0.75      0.60      0.67         5
         256       0.62      1.00      0.77         5
         257       0.00      0.00      0.00         4
         258       1.00      0.67      0.80         9
         259       1.00      0.67      0.80         9
         260       0.80      0.89      0.84         9
         261       0.80      1.00      0.89         4
         262       1.00      0.50      0.67         4
         263       1.00      0.80      0.89         5
         264       0.67      1.00      0.80         4
         265       1.00      0.89      0.94         9
         266       1.00      0.80      0.89         5
         267       0.67      1.00      0.80         4
         268       0.75      0.75      0.75         4
         269       1.00      1.00      1.00         5
         270       0.67      0.40      0.50         5
         271       1.00      0.89      0.94         9
         272       0.83      1.00      0.91         5
         273       1.00      0.89      0.94         9
         274       0.67      0.89      0.76         9
         275       1.00      0.78      0.88         9
         276       0.00      0.00      0.00         4
         277       1.00      0.75      0.86         4
         278       0.90      1.00      0.95         9
         279       1.00      0.80      0.89         5
         280       0.83      1.00      0.91         5
         281       1.00      1.00      1.00         4
         282       1.00      1.00      1.00         4
         283       1.00      0.50      0.67         4
         284       1.00      0.75      0.86         4
         285       0.82      1.00      0.90         9
         286       0.80      1.00      0.89         4
         287       1.00      0.80      0.89         5
         288       0.00      0.00      0.00         4
         289       1.00      0.75      0.86         4
         290       0.71      1.00      0.83         5
         291       1.00      1.00      1.00         4
         292       1.00      1.00      1.00         4
         293       0.73      0.89      0.80         9
         294       0.67      1.00      0.80         4
         295       1.00      0.67      0.80         9
         296       0.80      1.00      0.89         4
         297       1.00      0.75      0.86         4
         298       0.00      0.00      0.00         9
         299       0.80      1.00      0.89         4
         300       0.80      1.00      0.89         4
         301       0.80      1.00      0.89         4
         302       1.00      0.89      0.94         9
         303       0.90      1.00      0.95         9
         304       0.00      0.00      0.00         4
         305       1.00      0.78      0.88         9
         306       0.50      0.25      0.33         4
         307       1.00      1.00      1.00         4
         308       0.64      0.78      0.70         9
         309       1.00      1.00      1.00         4
         310       0.71      1.00      0.83         5
         311       1.00      0.89      0.94         9
         312       0.80      1.00      0.89         4
         313       0.88      0.78      0.82         9
         314       0.86      0.67      0.75         9
         315       1.00      1.00      1.00         4
         316       1.00      0.75      0.86         4
         317       0.00      0.00      0.00         4
         318       0.60      0.75      0.67         4
         319       0.75      0.75      0.75         4
         320       0.00      0.00      0.00         4
         321       0.00      0.00      0.00         4
         322       0.70      0.78      0.74         9
         323       0.88      0.78      0.82         9
         324       0.80      1.00      0.89         4
         325       0.60      0.75      0.67         4
         326       1.00      0.75      0.86         4
         327       0.50      0.40      0.44         5
         328       0.80      1.00      0.89         4
         329       0.00      0.00      0.00         4
         330       1.00      1.00      1.00         4
         331       0.82      1.00      0.90         9
         332       0.60      0.75      0.67         4
         333       1.00      1.00      1.00         4
         334       1.00      1.00      1.00         4
         335       0.83      1.00      0.91         5
         336       0.80      1.00      0.89         4
         337       1.00      0.75      0.86         4
         338       0.00      0.00      0.00         4
         339       0.00      0.00      0.00         4
         340       0.75      0.75      0.75         4
         341       0.67      1.00      0.80         4
         342       0.80      0.89      0.84         9
         343       1.00      0.75      0.86         4
         344       1.00      1.00      1.00         4
         345       1.00      1.00      1.00         4
         346       0.80      0.80      0.80         5
         347       0.90      1.00      0.95         9
         348       0.00      0.00      0.00         4
         349       0.80      0.80      0.80         5
         350       0.89      0.89      0.89         9
         351       1.00      0.89      0.94         9
         352       1.00      0.75      0.86         4
         353       0.57      1.00      0.73         4
         354       0.43      0.75      0.55         4
         355       1.00      1.00      1.00         4
         356       1.00      1.00      1.00         5
         357       1.00      1.00      1.00         5
         358       0.88      0.78      0.82         9
         359       1.00      1.00      1.00         4
         360       0.60      0.75      0.67         4
         361       1.00      0.88      0.93         8
         362       0.75      0.75      0.75         4
         363       0.00      0.00      0.00         4
         364       0.50      0.80      0.62         5
         365       0.80      1.00      0.89         4
         366       0.80      1.00      0.89         4
         367       1.00      1.00      1.00         5
         368       0.00      0.00      0.00         4
         369       0.80      0.80      0.80         5
         370       1.00      1.00      1.00         4
         371       1.00      0.80      0.89         5
         372       0.80      1.00      0.89         4
         373       1.00      1.00      1.00         4
         374       1.00      0.75      0.86         4
         375       0.67      0.50      0.57         4
         376       1.00      1.00      1.00         4
         377       0.60      0.75      0.67         4
         378       0.89      0.89      0.89         9
         379       1.00      0.75      0.86         4
         380       1.00      1.00      1.00         9
         381       0.75      0.75      0.75         4
         382       0.83      1.00      0.91         5
         383       1.00      1.00      1.00         5
         384       1.00      1.00      1.00         4
         385       0.78      0.78      0.78         9
         386       1.00      1.00      1.00         4
         387       0.75      0.75      0.75         4
         388       1.00      1.00      1.00         4
         389       0.67      0.50      0.57         4
         390       1.00      1.00      1.00         4
         391       0.89      0.89      0.89         9
         392       0.80      1.00      0.89         4
         393       1.00      0.50      0.67         4
         394       1.00      1.00      1.00         4
         395       1.00      1.00      1.00         9
         396       0.00      0.00      0.00         4
         397       0.20      0.25      0.22         4
         398       1.00      0.80      0.89         5
         399       0.00      0.00      0.00         4
         400       1.00      0.75      0.86         4
         401       0.00      0.00      0.00         9
         402       1.00      1.00      1.00         4
         403       1.00      0.75      0.86         4
         404       1.00      0.89      0.94         9
         405       1.00      1.00      1.00         5
         406       1.00      1.00      1.00         4
         407       1.00      1.00      1.00         9
         408       0.00      0.00      0.00         4
         409       1.00      0.50      0.67         4
         410       0.90      1.00      0.95         9
         411       1.00      1.00      1.00         9
         412       0.75      1.00      0.86         9
         413       0.80      1.00      0.89         4
         414       0.75      0.75      0.75         4
         415       1.00      1.00      1.00         4
         416       0.60      0.75      0.67         4
         417       1.00      1.00      1.00         4
         418       0.82      1.00      0.90         9
         419       1.00      1.00      1.00         4
         420       0.88      0.78      0.82         9
         421       1.00      0.50      0.67         4
         422       0.00      0.00      0.00         4
         423       0.90      1.00      0.95         9
         424       0.80      1.00      0.89         4
         425       0.90      1.00      0.95         9
         426       0.50      0.75      0.60         4
         427       1.00      1.00      1.00         9
         428       0.80      1.00      0.89         4
         429       0.00      0.00      0.00         9
         430       1.00      1.00      1.00         5
         431       0.80      1.00      0.89         4
         432       0.00      0.00      0.00         9
         433       1.00      0.80      0.89         5
         434       1.00      1.00      1.00         5
         435       1.00      0.60      0.75         5
         436       0.00      0.00      0.00         4
         437       1.00      1.00      1.00         4
         438       0.80      1.00      0.89         4
         439       0.67      1.00      0.80         4
         440       1.00      1.00      1.00         4
         441       0.67      0.50      0.57         4
         442       0.67      0.40      0.50         5
         443       1.00      1.00      1.00         4
         444       1.00      0.60      0.75         5
         445       0.00      0.00      0.00         4
         446       0.75      0.60      0.67         5
         447       0.75      0.75      0.75         4
         448       1.00      0.75      0.86         4
         449       1.00      0.75      0.86         4
         450       0.80      1.00      0.89         4
         451       1.00      1.00      1.00         4
         452       1.00      1.00      1.00         4
         453       1.00      0.78      0.88         9
         454       0.00      0.00      0.00         4
         455       0.33      0.40      0.36         5
         456       0.00      0.00      0.00         4
         457       0.00      0.00      0.00         4
         458       0.67      0.80      0.73         5
         459       1.00      0.75      0.86         4
         460       0.75      0.75      0.75         4
         461       0.80      1.00      0.89         4
         462       1.00      1.00      1.00         4
         463       0.40      0.50      0.44         4
         464       1.00      1.00      1.00         4
         465       1.00      0.75      0.86         4
         466       0.75      0.67      0.71         9
         467       0.82      1.00      0.90         9
         468       0.67      0.89      0.76         9
         469       0.90      1.00      0.95         9
         470       1.00      1.00      1.00         9
         471       1.00      1.00      1.00         9
         472       1.00      1.00      1.00         4
         473       0.50      0.25      0.33         4
         474       1.00      1.00      1.00         9
         475       0.00      0.00      0.00         4
         476       1.00      1.00      1.00         4
         477       0.67      0.50      0.57         4
         478       1.00      1.00      1.00         9
         479       0.73      0.89      0.80         9
         480       1.00      1.00      1.00         4
         481       0.67      0.50      0.57         4
         482       1.00      1.00      1.00         4
         483       0.80      1.00      0.89         4
         484       1.00      0.50      0.67         4
         485       1.00      0.75      0.86         4
         486       0.80      1.00      0.89         4
         487       0.83      1.00      0.91         5
         488       1.00      0.60      0.75         5
         489       0.00      0.00      0.00         4
         490       0.00      0.00      0.00         4
         491       0.71      1.00      0.83         5
         492       1.00      0.75      0.86         4
         493       0.89      0.89      0.89         9
         494       0.86      0.67      0.75         9
         495       1.00      1.00      1.00         9
         496       1.00      1.00      1.00         4
         497       0.80      1.00      0.89         4
         498       1.00      1.00      1.00         4
         499       0.00      0.00      0.00         4
         500       1.00      0.75      0.86         4
         501       1.00      1.00      1.00         9
         502       0.83      1.00      0.91         5
         503       0.50      0.40      0.44         5
         504       1.00      0.75      0.86         4
         505       0.80      0.80      0.80         5
         506       0.90      1.00      0.95         9
         507       0.80      0.80      0.80         5
         508       0.83      1.00      0.91         5
         509       0.50      0.25      0.33         4
         510       1.00      1.00      1.00         4
         511       0.80      1.00      0.89         4
         512       0.00      0.00      0.00         4
         513       1.00      1.00      1.00         9
         514       1.00      0.75      0.86         4
         515       0.00      0.00      0.00         4
         516       1.00      0.80      0.89         5
         517       1.00      0.60      0.75         5
         518       0.90      1.00      0.95         9
         519       0.83      1.00      0.91         5
         520       1.00      1.00      1.00         5
         521       1.00      1.00      1.00         4
         522       1.00      1.00      1.00         4
         523       0.90      1.00      0.95         9
         524       1.00      0.75      0.86         4
         525       0.00      0.00      0.00         4
         526       1.00      0.50      0.67         4
         527       1.00      0.75      0.86         4
         528       0.56      0.56      0.56         9
         529       0.80      1.00      0.89         4
         530       1.00      0.75      0.86         4
         531       0.00      0.00      0.00         9
         532       0.00      0.00      0.00         4
         533       0.50      0.56      0.53         9
         534       0.70      0.78      0.74         9
         535       0.75      0.75      0.75         4
         536       0.75      1.00      0.86         9
         537       0.80      0.89      0.84         9
         538       1.00      0.75      0.86         4
         539       0.80      1.00      0.89         4
         540       0.00      0.00      0.00         4
         541       1.00      0.75      0.86         4
         542       1.00      1.00      1.00         5
         543       1.00      0.89      0.94         9
         544       0.80      1.00      0.89         4
         545       0.00      0.00      0.00         4
         546       0.00      0.00      0.00         4
         547       1.00      1.00      1.00         5
         548       1.00      1.00      1.00         5
         549       1.00      1.00      1.00         4
         550       1.00      0.60      0.75         5
         551       1.00      0.75      0.86         4
         552       1.00      1.00      1.00         9
         553       0.90      1.00      0.95         9
         554       0.90      1.00      0.95         9
         555       0.00      0.00      0.00         4
         556       0.60      0.75      0.67         4
         557       0.80      1.00      0.89         4
         558       1.00      0.75      0.86         4
         559       1.00      1.00      1.00         4
         560       0.00      0.00      0.00         4
         561       0.00      0.00      0.00         4
         562       1.00      1.00      1.00         9
         563       1.00      1.00      1.00         4
         564       0.70      0.78      0.74         9
         565       1.00      0.75      0.86         4
         566       0.80      1.00      0.89         4
         567       1.00      1.00      1.00         9
         568       1.00      1.00      1.00         5
         569       1.00      0.75      0.86         4
         570       0.67      0.80      0.73         5
         571       0.67      1.00      0.80         4
         572       0.00      0.00      0.00         4
         573       0.75      0.75      0.75         4
         574       0.80      0.89      0.84         9
         575       0.75      0.75      0.75         4
         576       0.80      1.00      0.89         4
         577       0.00      0.00      0.00         4
         578       0.38      1.00      0.56         5
         579       1.00      1.00      1.00         4
         580       1.00      0.75      0.86         4
         581       1.00      0.75      0.86         4
         582       0.89      1.00      0.94         8
         583       0.00      0.00      0.00         4
         584       0.89      0.89      0.89         9
         585       0.67      0.50      0.57         4
         586       0.67      0.50      0.57         4
         587       0.00      0.00      0.00         4
         588       1.00      0.89      0.94         9
         589       1.00      0.75      0.86         4
         590       0.50      0.50      0.50         4
         591       1.00      0.89      0.94         9
         592       0.83      1.00      0.91         5
         593       1.00      0.50      0.67         4
         594       1.00      0.75      0.86         4
         595       0.80      1.00      0.89         4
         596       1.00      0.80      0.89         5
         597       1.00      1.00      1.00         4
         598       0.88      0.78      0.82         9
         599       1.00      1.00      1.00         4
         600       0.00      0.00      0.00         4
         601       0.00      0.00      0.00         9
         602       0.57      1.00      0.73         4
         603       1.00      0.75      0.86         4
         604       1.00      1.00      1.00         5
         605       1.00      1.00      1.00         9
         606       1.00      1.00      1.00         9
         607       1.00      0.89      0.94         9
         608       1.00      0.75      0.86         4
         609       1.00      0.71      0.83         7
         610       0.50      0.44      0.47         9
         611       0.67      1.00      0.80         4
         612       0.89      0.89      0.89         9
         613       0.75      0.75      0.75         4
         614       0.00      0.00      0.00         4
         615       0.60      0.75      0.67         4
         616       1.00      0.78      0.88         9
         617       1.00      0.40      0.57         5
         618       0.67      0.80      0.73         5
         619       1.00      0.89      0.94         9
         620       1.00      1.00      1.00         4
         621       1.00      0.75      0.86         4
         622       0.75      0.75      0.75         4
         623       1.00      1.00      1.00         9
         624       0.67      1.00      0.80         4
         625       1.00      1.00      1.00         9
         626       1.00      0.75      0.86         4
         627       1.00      1.00      1.00         4
         628       0.00      0.00      0.00         4
         629       1.00      1.00      1.00         9
         630       0.67      0.50      0.57         4
         631       1.00      1.00      1.00         5
         632       1.00      0.75      0.86         4
         633       1.00      1.00      1.00         9
         634       0.89      0.89      0.89         9
         635       0.90      1.00      0.95         9
         636       1.00      1.00      1.00         4
         637       1.00      0.80      0.89         5
         638       0.40      0.50      0.44         4
         639       0.50      0.50      0.50         4
         640       0.67      0.50      0.57         4
         641       1.00      1.00      1.00         4
         642       0.80      1.00      0.89         4
         643       0.80      1.00      0.89         4
         644       0.00      0.00      0.00         4
         645       1.00      1.00      1.00         4
         646       0.89      0.89      0.89         9
         647       0.29      0.50      0.36         4
         648       0.00      0.00      0.00         4
         649       1.00      1.00      1.00         4
         650       1.00      0.75      0.86         4
         651       1.00      0.89      0.94         9
         652       0.80      0.89      0.84         9
         653       0.80      1.00      0.89         4
         654       1.00      0.80      0.89         5
         655       0.67      1.00      0.80         4
         656       0.46      0.67      0.55         9
         657       1.00      1.00      1.00         9
         658       0.00      0.00      0.00         9
         659       0.00      0.00      0.00         9
         660       0.80      1.00      0.89         4
         661       0.75      0.75      0.75         4
         662       0.71      1.00      0.83         5
         663       0.00      0.00      0.00         4
         664       0.83      1.00      0.91         5
         665       0.00      0.00      0.00         4
         666       1.00      0.75      0.86         4
         667       0.64      1.00      0.78         9
         668       1.00      1.00      1.00         4
         669       0.00      0.00      0.00         4
         670       1.00      1.00      1.00         5
         671       0.00      0.00      0.00         4
         672       0.82      1.00      0.90         9
         673       0.82      1.00      0.90         9
         674       0.64      0.78      0.70         9
         675       1.00      1.00      1.00         4
         676       0.00      0.00      0.00         4
         677       1.00      0.78      0.88         9
         678       1.00      1.00      1.00         4
         679       0.60      0.75      0.67         4
         680       0.71      1.00      0.83         5
         681       0.67      1.00      0.80         4
         682       1.00      1.00      1.00         9
         683       1.00      1.00      1.00         4
         684       0.75      0.75      0.75         4
         685       1.00      1.00      1.00         5
         686       0.50      0.25      0.33         4
         687       1.00      1.00      1.00         5
         688       1.00      0.89      0.94         9
         689       0.80      1.00      0.89         4
         690       1.00      0.89      0.94         9
         691       0.60      0.75      0.67         4
         692       1.00      1.00      1.00         4
         693       1.00      0.75      0.86         4
         694       0.80      1.00      0.89         4
         695       0.50      0.22      0.31         9
         696       1.00      1.00      1.00         4
         697       0.86      0.86      0.86         7
         698       0.00      0.00      0.00         9
         699       1.00      1.00      1.00         4
         700       1.00      1.00      1.00         4
         701       1.00      0.75      0.86         4
         702       0.90      1.00      0.95         9
         703       0.75      0.75      0.75         4
         704       0.80      0.89      0.84         9
         705       0.75      0.75      0.75         4
         706       1.00      1.00      1.00         4
         707       1.00      1.00      1.00         4
         708       0.88      0.78      0.82         9
         709       1.00      1.00      1.00         9
         710       1.00      0.80      0.89         5
         711       0.62      0.56      0.59         9
         712       0.00      0.00      0.00         4
         713       0.50      0.50      0.50         4
         714       0.00      0.00      0.00         4
         715       1.00      1.00      1.00         9
         716       0.00      0.00      0.00         9
         717       0.75      0.75      0.75         4
         718       0.71      1.00      0.83         5
         719       0.00      0.00      0.00         4
         720       0.60      0.75      0.67         4
         721       1.00      0.80      0.89         5
         722       0.80      0.80      0.80         5
         723       0.50      0.40      0.44         5
         724       0.67      1.00      0.80         4
         725       0.69      1.00      0.82         9
         726       1.00      1.00      1.00         4
         727       0.80      0.80      0.80         5
         728       1.00      1.00      1.00         4
         729       0.00      0.00      0.00         9
         730       1.00      1.00      1.00         4
         731       0.80      1.00      0.89         4
         732       0.80      1.00      0.89         4
         733       1.00      0.78      0.88         9
         734       0.00      0.00      0.00         4
         735       1.00      1.00      1.00         5
         736       1.00      0.75      0.86         4
         737       0.60      0.75      0.67         4
         738       1.00      0.89      0.94         9
         739       1.00      1.00      1.00         9
         740       1.00      0.50      0.67         4
         741       1.00      1.00      1.00         9
         742       0.71      1.00      0.83         5
         743       1.00      1.00      1.00         4
         744       0.00      0.00      0.00         4
         745       0.12      0.25      0.17         4
         746       0.80      1.00      0.89         4
         747       0.38      0.75      0.50         4
         748       0.90      1.00      0.95         9
         749       1.00      0.40      0.57         5
         750       0.00      0.00      0.00         4
         751       0.80      1.00      0.89         4
         752       0.00      0.00      0.00         4
         753       0.00      0.00      0.00         9
         754       1.00      0.75      0.86         4
         755       0.82      1.00      0.90         9
         756       0.67      1.00      0.80         4
         757       0.80      1.00      0.89         4
         758       1.00      1.00      1.00         9
         759       1.00      1.00      1.00         4
         760       0.75      0.75      0.75         4
         761       0.80      1.00      0.89         4
         762       0.00      0.00      0.00         9
         763       0.80      0.80      0.80         5
         764       0.56      1.00      0.71         5
         765       1.00      0.89      0.94         9
         766       0.90      1.00      0.95         9
         767       0.00      0.00      0.00         4
         768       0.75      1.00      0.86         9
         769       1.00      1.00      1.00         4
         770       0.80      1.00      0.89         4
         771       0.83      1.00      0.91         5
         772       0.00      0.00      0.00         4
         773       0.00      0.00      0.00         4
         774       1.00      0.80      0.89         5
         775       0.00      0.00      0.00         4
         776       0.43      0.60      0.50         5
         777       1.00      0.75      0.86         4
         778       1.00      0.78      0.88         9
         779       1.00      0.67      0.80         6
         780       0.80      1.00      0.89         4
         781       0.71      1.00      0.83         5
         782       0.67      0.67      0.67         9
         783       1.00      0.80      0.89         5
         784       1.00      1.00      1.00         4
         785       0.50      0.25      0.33         4
         786       0.50      0.50      0.50         4
         787       0.50      0.50      0.50         4
         788       0.80      1.00      0.89         4
         789       1.00      0.80      0.89         5
         790       0.80      0.80      0.80         5
         791       1.00      1.00      1.00         4
         792       1.00      1.00      1.00         4
         793       1.00      1.00      1.00         4
         794       1.00      1.00      1.00         4
         795       0.00      0.00      0.00         4
         796       0.70      0.78      0.74         9
         797       1.00      1.00      1.00         4
         798       1.00      1.00      1.00         4
         799       0.00      0.00      0.00         4
         800       1.00      0.80      0.89         5
         801       1.00      0.50      0.67         4
         802       1.00      0.89      0.94         9
         803       0.80      0.89      0.84         9
         804       0.75      0.75      0.75         4
         805       0.75      0.75      0.75         4
         806       0.80      1.00      0.89         4
         807       0.00      0.00      0.00         4
         808       0.00      0.00      0.00         4
         809       1.00      0.75      0.86         4
         810       1.00      1.00      1.00         4
         811       0.82      1.00      0.90         9
         812       1.00      0.50      0.67         4
         813       1.00      0.67      0.80         9
         814       1.00      0.80      0.89         5
         815       1.00      1.00      1.00         5
         816       0.86      0.67      0.75         9
         817       0.75      0.75      0.75         4
         818       1.00      0.80      0.89         5
         819       1.00      1.00      1.00         9
         820       0.00      0.00      0.00         4
         821       0.80      0.80      0.80         5
         822       1.00      1.00      1.00         5
         823       0.80      0.80      0.80         5
         824       1.00      1.00      1.00         4
         825       0.67      1.00      0.80         4
         826       1.00      0.75      0.86         4
         827       1.00      0.75      0.86         4
         828       1.00      0.89      0.94         9
         829       1.00      1.00      1.00         4
         830       0.00      0.00      0.00         4
         831       0.54      0.78      0.64         9
         832       0.67      0.80      0.73         5
         833       0.00      0.00      0.00         4
         834       1.00      0.75      0.86         4
         835       1.00      0.60      0.75         5
         836       0.75      0.67      0.71         9
         837       0.00      0.00      0.00         4
         838       1.00      0.78      0.88         9
         839       0.75      0.75      0.75         4
         840       0.00      0.00      0.00         9
         841       1.00      0.89      0.94         9
         842       1.00      1.00      1.00         4
         843       0.83      1.00      0.91         5
         844       1.00      0.78      0.88         9
         845       1.00      0.75      0.86         4
         846       0.67      0.50      0.57         4
         847       1.00      1.00      1.00         4
         848       1.00      1.00      1.00         5
         849       0.29      0.40      0.33         5
         850       0.80      1.00      0.89         4
         851       0.90      1.00      0.95         9
         852       0.89      0.89      0.89         9
         853       0.56      0.56      0.56         9
         854       0.62      0.89      0.73         9
         855       1.00      1.00      1.00         5
         856       1.00      1.00      1.00         4
         857       0.86      0.67      0.75         9
         858       1.00      0.75      0.86         4
         859       0.80      1.00      0.89         4
         860       1.00      0.75      0.86         4
         861       0.00      0.00      0.00         4
         862       0.00      0.00      0.00         9
         863       1.00      0.80      0.89         5
         864       1.00      0.80      0.89         5
         865       1.00      0.75      0.86         4
         866       1.00      1.00      1.00         9
         867       0.30      0.75      0.43         4
         868       1.00      1.00      1.00         4
         869       0.75      0.75      0.75         4
         870       0.00      0.00      0.00         4
         871       0.00      0.00      0.00         4
         872       1.00      0.75      0.86         4
         873       1.00      1.00      1.00         4
         874       1.00      1.00      1.00         4
         875       1.00      1.00      1.00         9
         876       0.78      0.78      0.78         9
         877       0.00      0.00      0.00         4
         878       0.82      1.00      0.90         9
         879       1.00      1.00      1.00         4
         880       1.00      0.88      0.93         8
         881       1.00      0.89      0.94         9
         882       0.08      0.25      0.12         4
         883       1.00      0.75      0.86         4
         884       0.67      1.00      0.80         4
         885       0.75      0.60      0.67         5
         886       1.00      1.00      1.00         4
         887       0.00      0.00      0.00         4
         888       0.43      0.60      0.50         5
         889       0.00      0.00      0.00         9
         890       0.80      1.00      0.89         4
         891       0.60      0.75      0.67         4
         892       0.67      0.50      0.57         4
         893       0.00      0.00      0.00         4

    accuracy                           0.75      4917
   macro avg       0.75      0.73      0.73      4917
weighted avg       0.76      0.75      0.75      4917

task_train_time: {0: 0.13277304200000017, 1: 0.038232649999999424, 2: 0.040665453000000795, 3: 0.027715518999999134, 4: 0.033225678999999175, 5: 0.029440336999998706, 6: 0.03708190100000053, 7: 0.031018952000000155, 8: 0.02828073499999917, 9: 0.03531532899999945, 10: 0.036852388999999874, 11: 0.03569469400000003, 12: 0.0345197689999992, 13: 0.033434292999999116, 14: 0.03511038199999916, 15: 0.031147926999999243, 16: 0.02884022600000158, 17: 0.02777953100000019, 18: 0.03130424699999956, 19: 0.0355477449999988, 20: 0.037530883000000514, 21: 0.026834726000000586, 22: 0.033463756999999816, 23: 0.029970817000000594, 24: 0.03522994200000085, 25: 0.03503264099999903, 26: 0.03453493399999985, 27: 0.028433503999998777, 28: 0.031359257000000085, 29: 0.036806384000000136, 30: 0.036349607000000006, 31: 0.032854794000000354, 32: 0.0382296740000001, 33: 0.026976857000001075, 34: 0.03617769799999948, 35: 0.028111419999998333, 36: 0.035015125000001035, 37: 0.03606898299999983, 38: 0.029244683000001714, 39: 0.0397504160000004, 40: 0.03075465699999924, 41: 0.038497054000000475, 42: 0.029668925999999374, 43: 0.03616419100000101}
prediction_time: 0.0002891420000139533
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
