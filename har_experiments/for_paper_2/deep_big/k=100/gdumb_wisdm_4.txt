Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='a6d01065-a3f3-404f-9597-5ae1e3bbf150', conf_timestamp='2023-08-13 15:24:00.922651', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 66.31 % 	 [Task-IL]: 43.85 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 55.1 % 	 [Task-IL]: 34.71 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 39.09 % 	 [Task-IL]: 31.39 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 36.35 % 	 [Task-IL]: 30.02 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 35.23 % 	 [Task-IL]: 28.42 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 26.56 % 	 [Task-IL]: 28.31 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 26.62 % 	 [Task-IL]: 28.63 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 21.02 % 	 [Task-IL]: 27.73 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 18.73 % 	 [Task-IL]: 25.85 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 16.25 % 	 [Task-IL]: 25.81 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 19.66 % 	 [Task-IL]: 25.93 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.15 % 	 [Task-IL]: 25.26 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 12.92 % 	 [Task-IL]: 25.75 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 15.04 % 	 [Task-IL]: 26.15 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 14.14 % 	 [Task-IL]: 25.51 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.82 % 	 [Task-IL]: 25.78 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 12.12 % 	 [Task-IL]: 25.88 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 10.05 % 	 [Task-IL]: 26.0 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 10.89 % 	 [Task-IL]: 25.56 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 11.16 % 	 [Task-IL]: 25.72 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 10.23 % 	 [Task-IL]: 25.53 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.23 % 	 [Task-IL]: 25.41 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.03 % 	 [Task-IL]: 25.62 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 7.55 % 	 [Task-IL]: 25.37 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 7.15 % 	 [Task-IL]: 25.67 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.38 % 	 [Task-IL]: 25.8 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 9.12 % 	 [Task-IL]: 25.62 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.53 % 	 [Task-IL]: 25.11 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 5.9 % 	 [Task-IL]: 25.4 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 8.99 % 	 [Task-IL]: 25.57 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 7.69 % 	 [Task-IL]: 25.69 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 4.19 % 	 [Task-IL]: 25.87 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 5.12 % 	 [Task-IL]: 25.64 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.08 % 	 [Task-IL]: 25.44 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 7.32 % 	 [Task-IL]: 25.77 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.4 % 	 [Task-IL]: 25.62 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.4 % 	 [Task-IL]: 26.04 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.95 % 	 [Task-IL]: 25.85 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 4.93 % 	 [Task-IL]: 25.74 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.84 % 	 [Task-IL]: 25.81 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 4.89 % 	 [Task-IL]: 26.09 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.68 % 	 [Task-IL]: 25.91 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.61 % 	 [Task-IL]: 26.06 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74903, 32: 33, 120: 33, 340: 33, 459: 33, 563: 33, 70: 32, 58: 32, 291: 32, 413: 32, 448: 32, 481: 32, 505: 32, 558: 32, 619: 32, 639: 32, 636: 32, 677: 32, 809: 32, 829: 32, 835: 32, 41: 31, 134: 31, 207: 31, 210: 31, 280: 31, 326: 31, 316: 31, 380: 31, 391: 31, 423: 31, 416: 31, 463: 31, 495: 31, 512: 31, 517: 31, 663: 31, 729: 31, 734: 31, 771: 31, 792: 31, 787: 31, 783: 31, 868: 31, 887: 31, 36: 30, 59: 30, 72: 30, 67: 30, 87: 30, 85: 30, 161: 30, 169: 30, 241: 30, 244: 30, 268: 30, 320: 30, 317: 30, 314: 30, 382: 30, 375: 30, 439: 30, 490: 30, 500: 30, 525: 30, 552: 30, 634: 30, 687: 30, 684: 30, 752: 30, 746: 30, 735: 30, 803: 30, 813: 30, 852: 30, 842: 30, 885: 30, 893: 30, 875: 30, 1: 29, 16: 29, 45: 29, 43: 29, 97: 29, 119: 29, 121: 29, 171: 29, 177: 29, 215: 29, 216: 29, 238: 29, 260: 29, 257: 29, 285: 29, 281: 29, 304: 29, 302: 29, 371: 29, 354: 29, 410: 29, 451: 29, 465: 29, 507: 29, 590: 29, 591: 29, 631: 29, 652: 29, 649: 29, 642: 29, 665: 29, 727: 29, 800: 29, 831: 29, 816: 29, 847: 29, 862: 29, 860: 29, 874: 29, 884: 29, 15: 28, 22: 28, 69: 28, 78: 28, 80: 28, 105: 28, 154: 28, 160: 28, 212: 28, 274: 28, 300: 28, 339: 28, 341: 28, 373: 28, 404: 28, 431: 28, 453: 28, 469: 28, 520: 28, 540: 28, 572: 28, 574: 28, 593: 28, 602: 28, 632: 28, 618: 28, 671: 28, 731: 28, 725: 28, 745: 28, 739: 28, 737: 28, 799: 28, 839: 28, 886: 28, 24: 27, 23: 27, 61: 27, 91: 27, 130: 27, 165: 27, 170: 27, 188: 27, 211: 27, 246: 27, 272: 27, 265: 27, 324: 27, 338: 27, 362: 27, 425: 27, 440: 27, 488: 27, 483: 27, 499: 27, 519: 27, 530: 27, 570: 27, 568: 27, 581: 27, 579: 27, 595: 27, 620: 27, 667: 27, 675: 27, 717: 27, 784: 27, 818: 27, 849: 27, 867: 27, 881: 27, 892: 27, 49: 26, 52: 26, 71: 26, 82: 26, 109: 26, 112: 26, 151: 26, 185: 26, 209: 26, 255: 26, 497: 26, 646: 26, 650: 26, 701: 26, 705: 26, 733: 26, 738: 26, 808: 26, 823: 26, 869: 26, 854: 26, 63: 25, 123: 25, 158: 25, 181: 25, 252: 25, 319: 25, 328: 25, 343: 25, 345: 25, 443: 25, 467: 25, 566: 25, 754: 25, 791: 25, 266: 24, 422: 24, 476: 24, 583: 24, 647: 24, 108: 23, 256: 23, 79: 22, 135: 22, 277: 22, 496: 22, 703: 22, 124: 20, 600: 20, 8: 18, 157: 18, 402: 18, 681: 18, 147: 17, 180: 17, 247: 17, 292: 17, 297: 17, 352: 17, 458: 17, 486: 17, 533: 17, 879: 17, 5: 16, 56: 16, 84: 16, 103: 16, 117: 16, 140: 16, 187: 16, 202: 16, 233: 16, 220: 16, 249: 16, 263: 16, 366: 16, 364: 16, 426: 16, 523: 16, 603: 16, 614: 16, 655: 16, 700: 16, 13: 15, 10: 15, 42: 15, 83: 15, 143: 15, 163: 15, 190: 15, 174: 15, 251: 15, 235: 15, 288: 15, 290: 15, 429: 15, 445: 15, 464: 15, 456: 15, 484: 15, 541: 15, 560: 15, 587: 15, 596: 15, 657: 15, 686: 15, 685: 15, 704: 15, 695: 15, 730: 15, 781: 15, 802: 15, 821: 15, 828: 15, 856: 15, 28: 14, 33: 14, 27: 14, 17: 14, 73: 14, 94: 14, 100: 14, 114: 14, 138: 14, 164: 14, 167: 14, 172: 14, 184: 14, 213: 14, 200: 14, 214: 14, 225: 14, 221: 14, 234: 14, 299: 14, 349: 14, 337: 14, 363: 14, 381: 14, 394: 14, 424: 14, 449: 14, 436: 14, 438: 14, 437: 14, 461: 14, 468: 14, 485: 14, 510: 14, 498: 14, 514: 14, 542: 14, 582: 14, 628: 14, 629: 14, 635: 14, 659: 14, 673: 14, 683: 14, 712: 14, 726: 14, 740: 14, 788: 14, 789: 14, 777: 14, 793: 14, 811: 14, 832: 14, 826: 14, 827: 14, 841: 14, 20: 13, 6: 13, 30: 13, 9: 13, 46: 13, 37: 13, 66: 13, 74: 13, 89: 13, 101: 13, 107: 13, 95: 13, 110: 13, 118: 13, 128: 13, 129: 13, 132: 13, 126: 13, 144: 13, 139: 13, 149: 13, 159: 13, 191: 13, 192: 13, 203: 13, 205: 13, 219: 13, 222: 13, 224: 13, 223: 13, 245: 13, 243: 13, 273: 13, 269: 13, 270: 13, 267: 13, 261: 13, 259: 13, 279: 13, 293: 13, 308: 13, 325: 13, 333: 13, 329: 13, 327: 13, 318: 13, 356: 13, 360: 13, 361: 13, 359: 13, 387: 13, 377: 13, 412: 13, 398: 13, 395: 13, 427: 13, 446: 13, 450: 13, 462: 13, 477: 13, 478: 13, 502: 13, 494: 13, 511: 13, 549: 13, 548: 13, 544: 13, 585: 13, 575: 13, 612: 13, 597: 13, 630: 13, 637: 13, 669: 13, 664: 13, 682: 13, 688: 13, 699: 13, 709: 13, 723: 13, 722: 13, 758: 13, 760: 13, 798: 13, 833: 13, 825: 13, 853: 13, 834: 13, 865: 13, 858: 13, 3: 12, 29: 12, 26: 12, 19: 12, 48: 12, 34: 12, 39: 12, 35: 12, 54: 12, 60: 12, 55: 12, 62: 12, 76: 12, 93: 12, 88: 12, 86: 12, 96: 12, 104: 12, 106: 12, 111: 12, 131: 12, 148: 12, 150: 12, 145: 12, 141: 12, 173: 12, 193: 12, 178: 12, 179: 12, 186: 12, 198: 12, 197: 12, 194: 12, 196: 12, 228: 12, 232: 12, 229: 12, 248: 12, 250: 12, 240: 12, 239: 12, 271: 12, 258: 12, 287: 12, 289: 12, 276: 12, 307: 12, 306: 12, 295: 12, 301: 12, 311: 12, 305: 12, 323: 12, 335: 12, 346: 12, 344: 12, 370: 12, 358: 12, 357: 12, 369: 12, 368: 12, 379: 12, 386: 12, 392: 12, 399: 12, 408: 12, 401: 12, 419: 12, 420: 12, 428: 12, 433: 12, 442: 12, 435: 12, 470: 12, 480: 12, 475: 12, 482: 12, 509: 12, 528: 12, 527: 12, 516: 12, 532: 12, 526: 12, 551: 12, 539: 12, 545: 12, 571: 12, 561: 12, 557: 12, 573: 12, 554: 12, 564: 12, 567: 12, 578: 12, 576: 12, 577: 12, 592: 12, 599: 12, 605: 12, 611: 12, 598: 12, 622: 12, 626: 12, 633: 12, 638: 12, 648: 12, 641: 12, 643: 12, 661: 12, 668: 12, 656: 12, 672: 12, 680: 12, 679: 12, 711: 12, 702: 12, 694: 12, 708: 12, 696: 12, 706: 12, 728: 12, 720: 12, 721: 12, 747: 12, 744: 12, 743: 12, 757: 12, 755: 12, 756: 12, 769: 12, 766: 12, 759: 12, 790: 12, 795: 12, 796: 12, 810: 12, 801: 12, 819: 12, 848: 12, 846: 12, 843: 12, 863: 12, 855: 12, 871: 12, 872: 12, 864: 12, 891: 12, 876: 12, 882: 12, 889: 12, 21: 11, 18: 11, 12: 11, 4: 11, 2: 11, 47: 11, 50: 11, 40: 11, 92: 11, 77: 11, 98: 11, 102: 11, 127: 11, 116: 11, 125: 11, 115: 11, 152: 11, 146: 11, 136: 11, 156: 11, 166: 11, 182: 11, 183: 11, 176: 11, 201: 11, 195: 11, 231: 11, 237: 11, 254: 11, 264: 11, 262: 11, 275: 11, 284: 11, 286: 11, 313: 11, 312: 11, 298: 11, 303: 11, 331: 11, 330: 11, 332: 11, 321: 11, 347: 11, 350: 11, 351: 11, 367: 11, 374: 11, 389: 11, 393: 11, 406: 11, 409: 11, 400: 11, 432: 11, 430: 11, 418: 11, 444: 11, 471: 11, 454: 11, 466: 11, 455: 11, 491: 11, 474: 11, 492: 11, 503: 11, 506: 11, 513: 11, 501: 11, 515: 11, 531: 11, 550: 11, 534: 11, 537: 11, 546: 11, 553: 11, 547: 11, 569: 11, 562: 11, 584: 11, 588: 11, 610: 11, 606: 11, 609: 11, 594: 11, 608: 11, 604: 11, 624: 11, 627: 11, 621: 11, 644: 11, 640: 11, 651: 11, 645: 11, 670: 11, 662: 11, 693: 11, 678: 11, 674: 11, 713: 11, 710: 11, 715: 11, 716: 11, 749: 11, 753: 11, 736: 11, 741: 11, 773: 11, 764: 11, 761: 11, 768: 11, 776: 11, 780: 11, 775: 11, 779: 11, 785: 11, 806: 11, 807: 11, 797: 11, 794: 11, 805: 11, 824: 11, 817: 11, 814: 11, 815: 11, 822: 11, 836: 11, 845: 11, 838: 11, 870: 11, 873: 11, 866: 11, 883: 11, 888: 11, 14: 10, 25: 10, 53: 10, 38: 10, 68: 10, 57: 10, 90: 10, 81: 10, 99: 10, 113: 10, 122: 10, 137: 10, 162: 10, 155: 10, 168: 10, 189: 10, 199: 10, 206: 10, 204: 10, 217: 10, 227: 10, 253: 10, 236: 10, 282: 10, 283: 10, 296: 10, 309: 10, 348: 10, 342: 10, 334: 10, 336: 10, 390: 10, 385: 10, 383: 10, 376: 10, 411: 10, 417: 10, 414: 10, 415: 10, 441: 10, 457: 10, 472: 10, 487: 10, 508: 10, 518: 10, 521: 10, 524: 10, 538: 10, 536: 10, 535: 10, 559: 10, 555: 10, 586: 10, 580: 10, 601: 10, 613: 10, 607: 10, 625: 10, 658: 10, 692: 10, 697: 10, 714: 10, 718: 10, 719: 10, 750: 10, 742: 10, 770: 10, 765: 10, 763: 10, 772: 10, 762: 10, 786: 10, 782: 10, 812: 10, 820: 10, 844: 10, 857: 10, 859: 10, 880: 10, 890: 10, 7: 9, 44: 9, 65: 9, 64: 9, 133: 9, 175: 9, 226: 9, 278: 9, 310: 9, 294: 9, 322: 9, 315: 9, 355: 9, 372: 9, 384: 9, 378: 9, 388: 9, 403: 9, 396: 9, 405: 9, 397: 9, 407: 9, 434: 9, 452: 9, 460: 9, 479: 9, 493: 9, 489: 9, 504: 9, 529: 9, 565: 9, 556: 9, 589: 9, 616: 9, 617: 9, 615: 9, 623: 9, 653: 9, 666: 9, 690: 9, 689: 9, 691: 9, 676: 9, 707: 9, 732: 9, 724: 9, 751: 9, 748: 9, 767: 9, 774: 9, 778: 9, 804: 9, 840: 9, 850: 9, 851: 9, 837: 9, 861: 9, 877: 9, 31: 8, 51: 8, 75: 8, 142: 8, 230: 8, 218: 8, 353: 8, 421: 8, 473: 8, 543: 8, 660: 8, 654: 8, 830: 8, 878: 8, 11: 7, 153: 7, 242: 7, 365: 7, 447: 7, 522: 7, 698: 7, 208: 6})
Total buffer: 89400
fit_time: 124.313716421

Accuracy for 44 task(s): 	 [Class-IL]: 73.81 % 	 [Task-IL]: 29.77 %

CLASS_IL_ACC: 
	[83.42245989304813, 70.27027027027027, 85.9375, 80.34188034188034, 68.51851851851852, 76.99115044247787, 66.66666666666666, 55.2, 66.66666666666666, 67.28971962616822, 81.25, 77.67857142857143, 71.31147540983606, 79.82456140350878, 70.40816326530613, 81.9672131147541, 86.48648648648648, 66.34615384615384, 70.87378640776699, 66.3265306122449, 85.18518518518519, 69.2982456140351, 66.66666666666666, 82.4074074074074, 78.2258064516129, 66.35514018691589, 64.51612903225806, 84.82142857142857, 74.35897435897436, 69.79166666666666, 68.51851851851852, 67.46031746031747, 71.15384615384616, 67.61904761904762, 77.55102040816327, 69.36936936936937, 74.3801652892562, 71.42857142857143, 69.72477064220183, 74.56140350877193, 77.47747747747748, 80.18018018018019, 85.71428571428571, 76.98412698412699]
TASK_IL_ACC: 
	[55.61497326203209, 25.225225225225223, 28.125, 27.350427350427353, 25.925925925925924, 26.548672566371685, 34.34343434343434, 16.0, 25.71428571428571, 18.69158878504673, 36.45833333333333, 27.67857142857143, 31.967213114754102, 27.192982456140353, 25.510204081632654, 32.78688524590164, 27.027027027027028, 26.923076923076923, 29.126213592233007, 20.408163265306122, 25.925925925925924, 26.31578947368421, 25.225225225225223, 26.851851851851855, 35.483870967741936, 26.168224299065418, 25.806451612903224, 25.892857142857146, 29.059829059829063, 30.208333333333332, 33.33333333333333, 30.952380952380953, 25.0, 29.523809523809526, 24.489795918367346, 26.126126126126124, 38.84297520661157, 28.57142857142857, 22.93577981651376, 25.438596491228072, 28.82882882882883, 31.53153153153153, 26.785714285714285, 92.06349206349206]
f1_micro: 74.08989221069757
f1_macro: 71.00246655207442
              precision    recall  f1-score   support

           0       0.83      0.56      0.67         9
           1       0.89      0.89      0.89         9
           2       1.00      1.00      1.00         4
           3       0.83      1.00      0.91         5
           4       0.80      1.00      0.89         4
           5       1.00      1.00      1.00         5
           6       1.00      0.75      0.86         4
           7       1.00      1.00      1.00         4
           8       1.00      0.80      0.89         5
           9       0.75      0.75      0.75         4
          10       1.00      0.80      0.89         5
          11       1.00      1.00      1.00         4
          12       0.50      1.00      0.67         4
          13       0.83      1.00      0.91         5
          14       1.00      1.00      1.00         4
          15       1.00      0.89      0.94         9
          16       1.00      1.00      1.00         9
          17       1.00      0.80      0.89         5
          18       0.80      0.80      0.80         5
          19       0.80      0.80      0.80         5
          20       0.00      0.00      0.00         4
          21       1.00      1.00      1.00         4
          22       0.90      1.00      0.95         9
          23       0.90      1.00      0.95         9
          24       0.86      0.67      0.75         9
          25       1.00      1.00      1.00         4
          26       1.00      0.75      0.86         4
          27       1.00      1.00      1.00         5
          28       0.75      0.60      0.67         5
          29       0.75      0.75      0.75         4
          30       0.00      0.00      0.00         4
          31       0.80      0.80      0.80         5
          32       0.89      0.89      0.89         9
          33       1.00      0.75      0.86         4
          34       0.75      0.75      0.75         4
          35       1.00      1.00      1.00         4
          36       0.80      0.89      0.84         9
          37       1.00      1.00      1.00         4
          38       0.67      1.00      0.80         4
          39       0.33      0.50      0.40         4
          40       1.00      1.00      1.00         4
          41       0.00      0.00      0.00         9
          42       0.60      0.60      0.60         5
          43       1.00      0.89      0.94         9
          44       1.00      0.75      0.86         4
          45       1.00      0.89      0.94         9
          46       0.25      0.50      0.33         4
          47       0.80      1.00      0.89         4
          48       1.00      1.00      1.00         4
          49       0.00      0.00      0.00         9
          50       0.67      1.00      0.80         4
          51       0.00      0.00      0.00         4
          52       1.00      1.00      1.00         9
          53       0.57      1.00      0.73         4
          54       1.00      1.00      1.00         4
          55       1.00      0.80      0.89         5
          56       0.83      1.00      0.91         5
          57       1.00      1.00      1.00         4
          58       0.82      1.00      0.90         9
          59       0.82      1.00      0.90         9
          60       1.00      1.00      1.00         4
          61       0.89      0.89      0.89         9
          62       1.00      0.75      0.86         4
          63       0.89      0.89      0.89         9
          64       0.40      0.50      0.44         4
          65       0.00      0.00      0.00         4
          66       0.83      1.00      0.91         5
          67       0.88      0.78      0.82         9
          68       0.00      0.00      0.00         4
          69       1.00      0.89      0.94         9
          70       1.00      1.00      1.00         9
          71       1.00      1.00      1.00         9
          72       1.00      1.00      1.00         9
          73       1.00      0.75      0.86         4
          74       1.00      0.80      0.89         5
          75       1.00      0.75      0.86         4
          76       1.00      1.00      1.00         4
          77       0.00      0.00      0.00         4
          78       1.00      1.00      1.00         9
          79       1.00      1.00      1.00         7
          80       1.00      1.00      1.00         9
          81       1.00      0.75      0.86         4
          82       1.00      0.67      0.80         9
          83       1.00      0.60      0.75         5
          84       1.00      1.00      1.00         5
          85       0.90      1.00      0.95         9
          86       0.00      0.00      0.00         4
          87       0.62      0.89      0.73         9
          88       0.75      0.75      0.75         4
          89       0.67      0.80      0.73         5
          90       0.80      1.00      0.89         4
          91       1.00      0.78      0.88         9
          92       0.75      0.75      0.75         4
          93       0.75      0.75      0.75         4
          94       0.00      0.00      0.00         4
          95       1.00      0.40      0.57         5
          96       0.67      0.50      0.57         4
          97       0.80      0.89      0.84         9
          98       1.00      0.75      0.86         4
          99       1.00      0.75      0.86         4
         100       0.83      1.00      0.91         5
         101       1.00      0.50      0.67         4
         102       0.00      0.00      0.00         4
         103       1.00      0.40      0.57         5
         104       0.00      0.00      0.00         4
         105       1.00      0.89      0.94         9
         106       0.25      0.25      0.25         4
         107       1.00      0.75      0.86         4
         108       0.90      1.00      0.95         9
         109       1.00      0.89      0.94         9
         110       0.75      0.75      0.75         4
         111       1.00      1.00      1.00         4
         112       0.88      0.78      0.82         9
         113       0.67      1.00      0.80         4
         114       1.00      0.40      0.57         5
         115       1.00      1.00      1.00         4
         116       0.00      0.00      0.00         4
         117       0.62      1.00      0.77         5
         118       0.83      1.00      0.91         5
         119       1.00      1.00      1.00         9
         120       0.82      1.00      0.90         9
         121       0.89      0.89      0.89         9
         122       1.00      0.50      0.67         4
         123       1.00      0.89      0.94         9
         124       1.00      1.00      1.00         7
         125       1.00      0.75      0.86         4
         126       1.00      0.80      0.89         5
         127       0.00      0.00      0.00         4
         128       0.80      1.00      0.89         4
         129       1.00      0.80      0.89         5
         130       0.78      0.78      0.78         9
         131       1.00      0.75      0.86         4
         132       0.00      0.00      0.00         4
         133       1.00      0.75      0.86         4
         134       0.89      0.89      0.89         9
         135       0.88      0.78      0.82         9
         136       0.67      1.00      0.80         4
         137       1.00      1.00      1.00         4
         138       0.50      0.25      0.33         4
         139       0.80      1.00      0.89         4
         140       0.71      1.00      0.83         5
         141       1.00      1.00      1.00         4
         142       1.00      0.75      0.86         4
         143       1.00      0.40      0.57         5
         144       0.00      0.00      0.00         4
         145       1.00      0.80      0.89         5
         146       0.00      0.00      0.00         4
         147       1.00      1.00      1.00         5
         148       1.00      0.75      0.86         4
         149       0.00      0.00      0.00         4
         150       0.00      0.00      0.00         4
         151       1.00      1.00      1.00         9
         152       0.00      0.00      0.00         4
         153       1.00      0.75      0.86         4
         154       0.00      0.00      0.00         9
         155       0.00      0.00      0.00         4
         156       1.00      1.00      1.00         5
         157       0.57      0.80      0.67         5
         158       0.00      0.00      0.00         9
         159       0.00      0.00      0.00         4
         160       0.89      0.89      0.89         9
         161       1.00      1.00      1.00         9
         162       1.00      0.75      0.86         4
         163       1.00      1.00      1.00         5
         164       1.00      0.60      0.75         5
         165       0.00      0.00      0.00         9
         166       0.00      0.00      0.00         4
         167       1.00      0.80      0.89         5
         168       1.00      1.00      1.00         4
         169       0.90      1.00      0.95         9
         170       0.89      0.89      0.89         9
         171       0.00      0.00      0.00         9
         172       0.75      0.75      0.75         4
         173       1.00      1.00      1.00         4
         174       0.75      0.60      0.67         5
         175       0.80      1.00      0.89         4
         176       1.00      0.50      0.67         4
         177       1.00      0.56      0.71         9
         178       0.75      0.75      0.75         4
         179       1.00      1.00      1.00         4
         180       0.60      0.60      0.60         5
         181       0.04      0.11      0.05         9
         182       0.60      0.75      0.67         4
         183       0.75      0.75      0.75         4
         184       0.56      1.00      0.71         5
         185       0.00      0.00      0.00         9
         186       0.67      0.50      0.57         4
         187       1.00      1.00      1.00         5
         188       1.00      1.00      1.00         9
         189       1.00      1.00      1.00         4
         190       0.44      0.80      0.57         5
         191       1.00      1.00      1.00         4
         192       0.80      1.00      0.89         4
         193       0.50      0.50      0.50         4
         194       0.67      0.50      0.57         4
         195       1.00      0.50      0.67         4
         196       1.00      1.00      1.00         4
         197       1.00      1.00      1.00         4
         198       0.75      0.75      0.75         4
         199       0.50      0.50      0.50         4
         200       0.67      1.00      0.80         4
         201       0.00      0.00      0.00         4
         202       0.83      1.00      0.91         5
         203       1.00      0.75      0.86         4
         204       1.00      0.25      0.40         4
         205       1.00      0.80      0.89         5
         206       0.80      1.00      0.89         4
         207       0.89      0.89      0.89         9
         208       1.00      0.25      0.40         4
         209       0.50      0.44      0.47         9
         210       1.00      1.00      1.00         9
         211       0.73      0.89      0.80         9
         212       0.07      0.11      0.08         9
         213       0.75      0.75      0.75         4
         214       0.00      0.00      0.00         4
         215       1.00      1.00      1.00         9
         216       0.89      0.89      0.89         9
         217       0.60      0.75      0.67         4
         218       1.00      1.00      1.00         4
         219       1.00      1.00      1.00         5
         220       1.00      1.00      1.00         5
         221       1.00      1.00      1.00         4
         222       0.75      0.75      0.75         4
         223       1.00      1.00      1.00         5
         224       1.00      0.50      0.67         4
         225       1.00      0.80      0.89         5
         226       1.00      1.00      1.00         5
         227       1.00      0.50      0.67         4
         228       1.00      0.75      0.86         4
         229       1.00      1.00      1.00         4
         230       1.00      0.75      0.86         4
         231       0.00      0.00      0.00         4
         232       0.80      1.00      0.89         4
         233       0.71      1.00      0.83         5
         234       0.83      1.00      0.91         5
         235       1.00      0.60      0.75         5
         236       0.80      1.00      0.89         4
         237       0.80      1.00      0.89         4
         238       0.90      1.00      0.95         9
         239       0.00      0.00      0.00         4
         240       0.00      0.00      0.00         4
         241       1.00      1.00      1.00         9
         242       1.00      0.40      0.57         5
         243       0.33      0.50      0.40         4
         244       0.89      0.89      0.89         9
         245       1.00      1.00      1.00         5
         246       1.00      1.00      1.00         9
         247       0.71      1.00      0.83         5
         248       0.80      1.00      0.89         4
         249       0.67      0.80      0.73         5
         250       0.00      0.00      0.00         4
         251       1.00      0.80      0.89         5
         252       1.00      0.89      0.94         9
         253       1.00      0.50      0.67         4
         254       0.75      0.75      0.75         4
         255       0.80      0.89      0.84         9
         256       0.83      0.56      0.67         9
         257       0.90      1.00      0.95         9
         258       0.80      1.00      0.89         4
         259       0.75      0.75      0.75         4
         260       0.80      0.89      0.84         9
         261       1.00      1.00      1.00         4
         262       1.00      1.00      1.00         4
         263       0.71      1.00      0.83         5
         264       0.00      0.00      0.00         4
         265       0.88      0.78      0.82         9
         266       1.00      0.78      0.88         9
         267       0.40      0.40      0.40         5
         268       0.00      0.00      0.00         9
         269       0.00      0.00      0.00         4
         270       1.00      1.00      1.00         4
         271       1.00      1.00      1.00         4
         272       0.90      1.00      0.95         9
         273       0.06      0.25      0.10         4
         274       0.88      0.78      0.82         9
         275       1.00      1.00      1.00         4
         276       1.00      0.60      0.75         5
         277       1.00      0.89      0.94         9
         278       0.00      0.00      0.00         4
         279       0.67      1.00      0.80         4
         280       0.90      1.00      0.95         9
         281       0.78      0.78      0.78         9
         282       0.00      0.00      0.00         4
         283       1.00      1.00      1.00         4
         284       1.00      1.00      1.00         4
         285       1.00      1.00      1.00         9
         286       0.00      0.00      0.00         4
         287       1.00      1.00      1.00         4
         288       0.83      1.00      0.91         5
         289       0.80      1.00      0.89         4
         290       1.00      1.00      1.00         5
         291       0.90      1.00      0.95         9
         292       0.83      1.00      0.91         5
         293       0.00      0.00      0.00         4
         294       1.00      0.75      0.86         4
         295       1.00      1.00      1.00         4
         296       0.33      0.50      0.40         4
         297       0.50      0.60      0.55         5
         298       0.80      1.00      0.89         4
         299       1.00      1.00      1.00         5
         300       0.90      1.00      0.95         9
         301       0.80      1.00      0.89         4
         302       1.00      0.89      0.94         9
         303       0.00      0.00      0.00         4
         304       0.89      0.89      0.89         9
         305       0.00      0.00      0.00         4
         306       0.50      0.75      0.60         4
         307       0.00      0.00      0.00         4
         308       1.00      0.75      0.86         4
         309       1.00      1.00      1.00         4
         310       0.00      0.00      0.00         4
         311       0.40      0.50      0.44         4
         312       1.00      1.00      1.00         5
         313       0.67      0.50      0.57         4
         314       1.00      0.78      0.88         9
         315       0.00      0.00      0.00         4
         316       0.90      1.00      0.95         9
         317       1.00      1.00      1.00         9
         318       1.00      1.00      1.00         4
         319       1.00      0.89      0.94         9
         320       0.78      0.78      0.78         9
         321       1.00      1.00      1.00         4
         322       1.00      1.00      1.00         4
         323       0.80      1.00      0.89         4
         324       0.89      0.89      0.89         9
         325       0.80      1.00      0.89         4
         326       1.00      1.00      1.00         9
         327       1.00      0.80      0.89         5
         328       1.00      1.00      1.00         9
         329       1.00      0.80      0.89         5
         330       0.50      0.75      0.60         4
         331       1.00      0.75      0.86         4
         332       0.00      0.00      0.00         4
         333       0.00      0.00      0.00         4
         334       1.00      1.00      1.00         4
         335       0.00      0.00      0.00         4
         336       1.00      1.00      1.00         4
         337       0.00      0.00      0.00         4
         338       0.88      0.78      0.82         9
         339       0.90      1.00      0.95         9
         340       1.00      1.00      1.00         9
         341       0.82      1.00      0.90         9
         342       1.00      0.75      0.86         4
         343       1.00      1.00      1.00         9
         344       1.00      1.00      1.00         4
         345       1.00      0.89      0.94         9
         346       1.00      0.75      0.86         4
         347       0.67      1.00      0.80         4
         348       0.75      0.75      0.75         4
         349       0.50      1.00      0.67         4
         350       1.00      1.00      1.00         4
         351       1.00      1.00      1.00         4
         352       0.80      0.80      0.80         5
         353       1.00      1.00      1.00         4
         354       0.89      0.89      0.89         9
         355       0.40      0.50      0.44         4
         356       1.00      0.50      0.67         4
         357       0.67      1.00      0.80         4
         358       0.00      0.00      0.00         4
         359       0.00      0.00      0.00         4
         360       1.00      1.00      1.00         5
         361       0.67      0.80      0.73         5
         362       0.73      0.89      0.80         9
         363       0.50      0.75      0.60         4
         364       1.00      1.00      1.00         5
         365       0.40      0.50      0.44         4
         366       0.00      0.00      0.00         4
         367       0.00      0.00      0.00         4
         368       1.00      0.60      0.75         5
         369       0.75      0.75      0.75         4
         370       1.00      0.50      0.67         4
         371       1.00      0.78      0.88         9
         372       0.67      1.00      0.80         4
         373       0.88      0.78      0.82         9
         374       1.00      1.00      1.00         4
         375       0.70      0.78      0.74         9
         376       0.50      0.25      0.33         4
         377       0.00      0.00      0.00         4
         378       1.00      0.60      0.75         5
         379       1.00      0.80      0.89         5
         380       0.89      0.89      0.89         9
         381       0.75      0.75      0.75         4
         382       1.00      1.00      1.00         9
         383       1.00      1.00      1.00         4
         384       0.80      1.00      0.89         4
         385       0.00      0.00      0.00         4
         386       0.80      1.00      0.89         4
         387       1.00      1.00      1.00         4
         388       1.00      1.00      1.00         4
         389       0.00      0.00      0.00         4
         390       0.00      0.00      0.00         4
         391       1.00      0.89      0.94         9
         392       1.00      0.40      0.57         5
         393       1.00      1.00      1.00         4
         394       1.00      0.75      0.86         4
         395       1.00      1.00      1.00         4
         396       1.00      1.00      1.00         4
         397       0.80      1.00      0.89         4
         398       0.00      0.00      0.00         4
         399       0.00      0.00      0.00         4
         400       0.80      1.00      0.89         4
         401       1.00      1.00      1.00         4
         402       0.71      1.00      0.83         5
         403       0.67      1.00      0.80         4
         404       0.00      0.00      0.00         9
         405       0.67      0.50      0.57         4
         406       0.50      0.50      0.50         4
         407       1.00      0.50      0.67         4
         408       1.00      0.80      0.89         5
         409       1.00      0.25      0.40         4
         410       1.00      0.89      0.94         9
         411       1.00      1.00      1.00         4
         412       0.83      1.00      0.91         5
         413       0.62      0.56      0.59         9
         414       0.75      0.75      0.75         4
         415       0.00      0.00      0.00         4
         416       0.73      0.89      0.80         9
         417       0.50      0.50      0.50         4
         418       0.80      1.00      0.89         4
         419       1.00      0.50      0.67         4
         420       0.75      0.75      0.75         4
         421       0.80      1.00      0.89         4
         422       1.00      1.00      1.00         9
         423       1.00      1.00      1.00         9
         424       1.00      1.00      1.00         5
         425       1.00      1.00      1.00         8
         426       0.83      1.00      0.91         5
         427       0.80      1.00      0.89         4
         428       1.00      1.00      1.00         5
         429       0.83      1.00      0.91         5
         430       0.00      0.00      0.00         4
         431       1.00      1.00      1.00         9
         432       1.00      0.75      0.86         4
         433       0.80      1.00      0.89         4
         434       1.00      1.00      1.00         4
         435       1.00      0.75      0.86         4
         436       0.13      0.75      0.22         4
         437       0.00      0.00      0.00         4
         438       0.80      0.80      0.80         5
         439       1.00      0.89      0.94         9
         440       0.00      0.00      0.00         9
         441       0.80      1.00      0.89         4
         442       0.00      0.00      0.00         4
         443       1.00      1.00      1.00         9
         444       0.40      0.50      0.44         4
         445       0.00      0.00      0.00         5
         446       1.00      0.50      0.67         4
         447       1.00      0.75      0.86         4
         448       0.70      0.78      0.74         9
         449       0.71      1.00      0.83         5
         450       1.00      0.80      0.89         5
         451       0.80      0.89      0.84         9
         452       0.80      1.00      0.89         4
         453       0.69      1.00      0.82         9
         454       0.00      0.00      0.00         4
         455       1.00      1.00      1.00         5
         456       0.60      0.60      0.60         5
         457       1.00      0.75      0.86         4
         458       0.83      1.00      0.91         5
         459       0.89      0.89      0.89         9
         460       1.00      0.25      0.40         4
         461       0.57      0.80      0.67         5
         462       0.80      1.00      0.89         4
         463       1.00      0.89      0.94         9
         464       1.00      1.00      1.00         5
         465       0.00      0.00      0.00         9
         466       0.00      0.00      0.00         4
         467       1.00      1.00      1.00         9
         468       1.00      0.80      0.89         5
         469       1.00      1.00      1.00         9
         470       0.75      0.75      0.75         4
         471       0.50      0.25      0.33         4
         472       1.00      0.50      0.67         4
         473       0.00      0.00      0.00         4
         474       1.00      1.00      1.00         4
         475       0.80      1.00      0.89         4
         476       1.00      1.00      1.00         9
         477       1.00      1.00      1.00         4
         478       1.00      0.75      0.86         4
         479       0.75      0.75      0.75         4
         480       1.00      0.75      0.86         4
         481       0.90      1.00      0.95         9
         482       1.00      0.50      0.67         4
         483       0.90      1.00      0.95         9
         484       1.00      1.00      1.00         5
         485       0.67      0.80      0.73         5
         486       1.00      0.80      0.89         5
         487       1.00      1.00      1.00         4
         488       0.80      0.44      0.57         9
         489       1.00      0.50      0.67         4
         490       0.89      0.89      0.89         9
         491       0.00      0.00      0.00         4
         492       1.00      1.00      1.00         4
         493       0.80      1.00      0.89         4
         494       1.00      1.00      1.00         4
         495       1.00      0.78      0.88         9
         496       1.00      1.00      1.00         9
         497       0.89      0.89      0.89         9
         498       1.00      0.60      0.75         5
         499       1.00      1.00      1.00         9
         500       0.73      0.89      0.80         9
         501       0.67      1.00      0.80         4
         502       0.00      0.00      0.00         4
         503       1.00      0.50      0.67         4
         504       1.00      0.80      0.89         5
         505       1.00      1.00      1.00         9
         506       1.00      1.00      1.00         4
         507       0.89      0.89      0.89         9
         508       0.80      1.00      0.89         4
         509       0.80      1.00      0.89         4
         510       0.33      0.20      0.25         5
         511       1.00      1.00      1.00         5
         512       0.00      0.00      0.00         9
         513       0.57      1.00      0.73         4
         514       0.50      0.75      0.60         4
         515       0.80      1.00      0.89         4
         516       1.00      1.00      1.00         4
         517       0.00      0.00      0.00         9
         518       1.00      1.00      1.00         4
         519       1.00      0.78      0.88         9
         520       0.43      0.67      0.52         9
         521       1.00      0.50      0.67         4
         522       1.00      1.00      1.00         4
         523       1.00      1.00      1.00         5
         524       0.75      0.75      0.75         4
         525       0.89      0.89      0.89         9
         526       0.60      0.75      0.67         4
         527       0.00      0.00      0.00         4
         528       0.50      0.25      0.33         4
         529       0.00      0.00      0.00         4
         530       0.89      0.89      0.89         9
         531       0.00      0.00      0.00         4
         532       0.80      1.00      0.89         4
         533       0.71      1.00      0.83         5
         534       1.00      1.00      1.00         4
         535       1.00      1.00      1.00         4
         536       1.00      0.25      0.40         4
         537       1.00      0.75      0.86         4
         538       1.00      1.00      1.00         4
         539       0.00      0.00      0.00         4
         540       1.00      1.00      1.00         9
         541       0.50      0.80      0.62         5
         542       0.80      0.80      0.80         5
         543       0.00      0.00      0.00         4
         544       1.00      1.00      1.00         4
         545       0.50      0.25      0.33         4
         546       0.80      1.00      0.89         4
         547       0.57      1.00      0.73         4
         548       1.00      0.80      0.89         5
         549       0.00      0.00      0.00         4
         550       0.67      1.00      0.80         4
         551       1.00      1.00      1.00         4
         552       0.00      0.00      0.00         9
         553       1.00      0.50      0.67         4
         554       1.00      0.50      0.67         4
         555       0.33      0.50      0.40         4
         556       1.00      1.00      1.00         4
         557       1.00      1.00      1.00         5
         558       0.82      1.00      0.90         9
         559       0.75      0.75      0.75         4
         560       0.00      0.00      0.00         4
         561       0.67      1.00      0.80         4
         562       0.50      0.75      0.60         4
         563       1.00      0.67      0.80         9
         564       0.80      1.00      0.89         4
         565       1.00      1.00      1.00         4
         566       1.00      1.00      1.00         9
         567       0.75      0.75      0.75         4
         568       1.00      0.89      0.94         9
         569       0.83      1.00      0.91         5
         570       0.80      0.89      0.84         9
         571       1.00      1.00      1.00         4
         572       1.00      1.00      1.00         9
         573       0.43      0.75      0.55         4
         574       0.82      1.00      0.90         9
         575       0.67      0.50      0.57         4
         576       1.00      1.00      1.00         4
         577       0.50      1.00      0.67         4
         578       0.00      0.00      0.00         4
         579       0.89      0.89      0.89         9
         580       1.00      1.00      1.00         4
         581       0.67      0.89      0.76         9
         582       1.00      0.80      0.89         5
         583       1.00      0.89      0.94         9
         584       0.00      0.00      0.00         4
         585       1.00      1.00      1.00         4
         586       0.60      0.75      0.67         4
         587       1.00      0.80      0.89         5
         588       1.00      0.75      0.86         4
         589       0.50      0.50      0.50         4
         590       0.56      0.56      0.56         9
         591       1.00      0.89      0.94         9
         592       1.00      0.25      0.40         4
         593       0.75      0.67      0.71         9
         594       0.80      1.00      0.89         4
         595       0.67      0.67      0.67         9
         596       1.00      1.00      1.00         5
         597       1.00      0.75      0.86         4
         598       0.33      0.25      0.29         4
         599       0.71      1.00      0.83         5
         600       0.67      0.57      0.62         7
         601       0.80      1.00      0.89         4
         602       0.00      0.00      0.00         9
         603       1.00      1.00      1.00         5
         604       1.00      0.75      0.86         4
         605       0.00      0.00      0.00         4
         606       0.80      1.00      0.89         4
         607       0.80      1.00      0.89         4
         608       0.50      0.50      0.50         4
         609       1.00      0.75      0.86         4
         610       1.00      0.75      0.86         4
         611       1.00      0.75      0.86         4
         612       1.00      1.00      1.00         4
         613       1.00      1.00      1.00         4
         614       0.50      0.20      0.29         5
         615       0.50      0.75      0.60         4
         616       0.67      0.80      0.73         5
         617       0.67      0.50      0.57         4
         618       0.88      0.78      0.82         9
         619       0.90      1.00      0.95         9
         620       1.00      1.00      1.00         9
         621       0.00      0.00      0.00         4
         622       1.00      0.75      0.86         4
         623       0.00      0.00      0.00         4
         624       1.00      0.75      0.86         4
         625       0.14      0.25      0.18         4
         626       0.67      1.00      0.80         4
         627       0.00      0.00      0.00         4
         628       1.00      0.80      0.89         5
         629       1.00      1.00      1.00         4
         630       0.00      0.00      0.00         4
         631       0.90      1.00      0.95         9
         632       0.67      0.89      0.76         9
         633       1.00      0.75      0.86         4
         634       1.00      0.89      0.94         9
         635       0.80      0.80      0.80         5
         636       0.00      0.00      0.00         9
         637       1.00      0.80      0.89         5
         638       0.80      1.00      0.89         4
         639       1.00      0.78      0.88         9
         640       1.00      0.75      0.86         4
         641       1.00      1.00      1.00         4
         642       0.57      0.44      0.50         9
         643       1.00      0.75      0.86         4
         644       0.00      0.00      0.00         4
         645       0.00      0.00      0.00         4
         646       1.00      1.00      1.00         9
         647       1.00      0.33      0.50         9
         648       1.00      1.00      1.00         4
         649       0.90      1.00      0.95         9
         650       0.89      0.89      0.89         9
         651       1.00      1.00      1.00         4
         652       1.00      0.88      0.93         8
         653       0.00      0.00      0.00         4
         654       0.00      0.00      0.00         4
         655       0.80      0.80      0.80         5
         656       1.00      1.00      1.00         4
         657       1.00      1.00      1.00         5
         658       0.80      1.00      0.89         4
         659       1.00      1.00      1.00         5
         660       0.50      0.25      0.33         4
         661       0.80      1.00      0.89         4
         662       0.00      0.00      0.00         4
         663       1.00      1.00      1.00         9
         664       0.00      0.00      0.00         4
         665       1.00      0.78      0.88         9
         666       1.00      1.00      1.00         4
         667       1.00      1.00      1.00         9
         668       1.00      0.50      0.67         4
         669       1.00      1.00      1.00         4
         670       0.00      0.00      0.00         4
         671       0.78      0.78      0.78         9
         672       0.00      0.00      0.00         4
         673       0.71      1.00      0.83         5
         674       0.00      0.00      0.00         4
         675       0.04      0.11      0.06         9
         676       0.75      0.75      0.75         4
         677       0.78      0.78      0.78         9
         678       0.75      0.75      0.75         4
         679       1.00      1.00      1.00         4
         680       1.00      1.00      1.00         4
         681       0.50      0.83      0.62         6
         682       0.00      0.00      0.00         4
         683       0.56      1.00      0.71         5
         684       0.75      1.00      0.86         9
         685       1.00      0.60      0.75         5
         686       0.80      0.80      0.80         5
         687       1.00      0.89      0.94         9
         688       0.00      0.00      0.00         4
         689       0.00      0.00      0.00         4
         690       0.38      0.75      0.50         4
         691       1.00      1.00      1.00         4
         692       1.00      1.00      1.00         4
         693       0.67      1.00      0.80         4
         694       1.00      0.75      0.86         4
         695       1.00      1.00      1.00         5
         696       0.80      1.00      0.89         4
         697       1.00      1.00      1.00         4
         698       0.67      0.50      0.57         4
         699       1.00      1.00      1.00         4
         700       0.71      1.00      0.83         5
         701       0.89      0.89      0.89         9
         702       0.50      1.00      0.67         4
         703       1.00      0.88      0.93         8
         704       0.56      1.00      0.71         5
         705       1.00      1.00      1.00         9
         706       0.00      0.00      0.00         4
         707       0.09      0.50      0.15         4
         708       0.57      1.00      0.73         4
         709       1.00      1.00      1.00         4
         710       0.50      0.25      0.33         4
         711       0.00      0.00      0.00         4
         712       1.00      1.00      1.00         5
         713       0.00      0.00      0.00         4
         714       0.00      0.00      0.00         4
         715       1.00      1.00      1.00         4
         716       0.00      0.00      0.00         4
         717       0.71      0.56      0.63         9
         718       1.00      0.25      0.40         4
         719       0.60      0.75      0.67         4
         720       1.00      0.75      0.86         4
         721       0.75      0.75      0.75         4
         722       0.08      0.25      0.12         4
         723       1.00      0.25      0.40         4
         724       1.00      0.75      0.86         4
         725       0.88      0.78      0.82         9
         726       1.00      1.00      1.00         4
         727       0.78      0.78      0.78         9
         728       0.00      0.00      0.00         4
         729       0.67      0.89      0.76         9
         730       1.00      1.00      1.00         5
         731       1.00      1.00      1.00         9
         732       1.00      1.00      1.00         4
         733       0.82      1.00      0.90         9
         734       1.00      1.00      1.00         9
         735       1.00      1.00      1.00         9
         736       1.00      1.00      1.00         4
         737       0.90      1.00      0.95         9
         738       0.67      0.67      0.67         9
         739       0.88      0.78      0.82         9
         740       0.40      0.50      0.44         4
         741       0.75      0.75      0.75         4
         742       0.00      0.00      0.00         4
         743       1.00      1.00      1.00         4
         744       0.80      1.00      0.89         4
         745       0.71      0.56      0.63         9
         746       0.64      0.78      0.70         9
         747       1.00      1.00      1.00         4
         748       0.00      0.00      0.00         4
         749       1.00      0.40      0.57         5
         750       1.00      1.00      1.00         4
         751       0.00      0.00      0.00         4
         752       0.90      1.00      0.95         9
         753       0.67      0.50      0.57         4
         754       0.89      0.89      0.89         9
         755       0.00      0.00      0.00         4
         756       1.00      0.60      0.75         5
         757       0.80      1.00      0.89         4
         758       0.00      0.00      0.00         4
         759       1.00      1.00      1.00         4
         760       0.67      1.00      0.80         4
         761       1.00      0.75      0.86         4
         762       1.00      0.75      0.86         4
         763       1.00      1.00      1.00         4
         764       1.00      0.75      0.86         4
         765       0.00      0.00      0.00         4
         766       0.80      1.00      0.89         4
         767       0.67      0.50      0.57         4
         768       0.40      0.50      0.44         4
         769       0.80      1.00      0.89         4
         770       0.75      0.75      0.75         4
         771       0.90      1.00      0.95         9
         772       0.50      0.50      0.50         4
         773       0.75      0.75      0.75         4
         774       0.67      0.50      0.57         4
         775       1.00      1.00      1.00         4
         776       0.00      0.00      0.00         4
         777       0.83      1.00      0.91         5
         778       1.00      1.00      1.00         4
         779       0.67      0.50      0.57         4
         780       1.00      0.50      0.67         4
         781       0.67      0.80      0.73         5
         782       1.00      0.50      0.67         4
         783       0.73      0.89      0.80         9
         784       0.69      1.00      0.82         9
         785       0.00      0.00      0.00         4
         786       0.33      0.25      0.29         4
         787       0.90      1.00      0.95         9
         788       0.25      0.40      0.31         5
         789       1.00      0.80      0.89         5
         790       1.00      1.00      1.00         4
         791       0.71      0.56      0.63         9
         792       0.75      0.67      0.71         9
         793       1.00      0.75      0.86         4
         794       0.80      1.00      0.89         4
         795       1.00      0.75      0.86         4
         796       0.80      0.80      0.80         5
         797       1.00      0.75      0.86         4
         798       0.83      1.00      0.91         5
         799       0.64      0.78      0.70         9
         800       0.00      0.00      0.00         9
         801       0.75      0.75      0.75         4
         802       0.80      0.80      0.80         5
         803       0.88      0.78      0.82         9
         804       0.67      0.50      0.57         4
         805       1.00      1.00      1.00         4
         806       1.00      1.00      1.00         4
         807       0.80      1.00      0.89         4
         808       0.75      0.67      0.71         9
         809       1.00      1.00      1.00         9
         810       1.00      1.00      1.00         4
         811       0.80      0.80      0.80         5
         812       0.50      0.50      0.50         4
         813       0.67      0.67      0.67         9
         814       0.83      1.00      0.91         5
         815       1.00      0.75      0.86         4
         816       1.00      0.78      0.88         9
         817       0.75      0.75      0.75         4
         818       0.86      0.67      0.75         9
         819       0.75      0.75      0.75         4
         820       1.00      1.00      1.00         5
         821       0.67      0.80      0.73         5
         822       0.67      1.00      0.80         4
         823       0.69      1.00      0.82         9
         824       0.00      0.00      0.00         4
         825       0.80      1.00      0.89         4
         826       0.83      1.00      0.91         5
         827       0.80      1.00      0.89         4
         828       0.83      1.00      0.91         5
         829       1.00      0.78      0.88         9
         830       0.75      0.75      0.75         4
         831       0.00      0.00      0.00         9
         832       0.80      1.00      0.89         4
         833       1.00      1.00      1.00         5
         834       1.00      1.00      1.00         5
         835       1.00      1.00      1.00         9
         836       0.80      1.00      0.89         4
         837       0.75      0.75      0.75         4
         838       0.50      0.75      0.60         4
         839       0.82      1.00      0.90         9
         840       0.00      0.00      0.00         4
         841       1.00      0.75      0.86         4
         842       0.90      1.00      0.95         9
         843       0.00      0.00      0.00         4
         844       0.75      0.75      0.75         4
         845       0.67      1.00      0.80         4
         846       0.67      0.50      0.57         4
         847       1.00      1.00      1.00         9
         848       0.80      1.00      0.89         4
         849       0.89      0.89      0.89         9
         850       0.67      0.50      0.57         4
         851       1.00      1.00      1.00         4
         852       0.89      0.89      0.89         9
         853       0.00      0.00      0.00         4
         854       0.89      0.89      0.89         9
         855       0.80      1.00      0.89         4
         856       1.00      1.00      1.00         5
         857       1.00      0.75      0.86         4
         858       1.00      0.75      0.86         4
         859       1.00      1.00      1.00         4
         860       1.00      1.00      1.00         9
         861       0.80      1.00      0.89         4
         862       1.00      1.00      1.00         9
         863       1.00      1.00      1.00         4
         864       0.00      0.00      0.00         4
         865       1.00      0.80      0.89         5
         866       0.00      0.00      0.00         4
         867       0.90      1.00      0.95         9
         868       0.70      0.78      0.74         9
         869       1.00      1.00      1.00         9
         870       1.00      1.00      1.00         4
         871       0.27      1.00      0.42         4
         872       1.00      0.75      0.86         4
         873       1.00      0.75      0.86         4
         874       1.00      0.56      0.71         9
         875       1.00      1.00      1.00         9
         876       0.75      0.75      0.75         4
         877       0.60      0.75      0.67         4
         878       1.00      0.75      0.86         4
         879       0.71      1.00      0.83         5
         880       0.67      1.00      0.80         4
         881       0.90      1.00      0.95         9
         882       1.00      1.00      1.00         4
         883       0.00      0.00      0.00         4
         884       1.00      1.00      1.00         9
         885       1.00      0.67      0.80         9
         886       1.00      0.78      0.88         9
         887       0.78      0.78      0.78         9
         888       0.60      0.75      0.67         4
         889       0.00      0.00      0.00         4
         890       1.00      0.75      0.86         4
         891       1.00      0.75      0.86         4
         892       1.00      1.00      1.00         9
         893       1.00      0.56      0.71         9

    accuracy                           0.74      4917
   macro avg       0.73      0.72      0.71      4917
weighted avg       0.76      0.74      0.74      4917

task_train_time: {0: 0.11455766599999961, 1: 0.02889406599999944, 2: 0.039007182999998946, 3: 0.026378750999999312, 4: 0.02378729400000168, 5: 0.02768850799999889, 6: 0.028336789000000806, 7: 0.035819454000000306, 8: 0.030520924999999366, 9: 0.03379087100000078, 10: 0.02749323600000153, 11: 0.034650639999998845, 12: 0.0348878370000012, 13: 0.032844735999999486, 14: 0.027772458000001166, 15: 0.03768104699999952, 16: 0.032368350999998796, 17: 0.03063298700000061, 18: 0.02936750499999974, 19: 0.02810109800000049, 20: 0.03179415700000021, 21: 0.031923566999999764, 22: 0.032834768000000736, 23: 0.03032826600000149, 24: 0.03649551200000012, 25: 0.03398037500000051, 26: 0.03021858100000152, 27: 0.032782507000000294, 28: 0.034937774999999505, 29: 0.02930220200000022, 30: 0.03175699099999996, 31: 0.0414365029999999, 32: 0.03371281500000123, 33: 0.03339298500000076, 34: 0.027313203999998592, 35: 0.03228241100000062, 36: 0.039459526999999994, 37: 0.028504567999998898, 38: 0.03251192200000119, 39: 0.03175661200000235, 40: 0.028674836000000425, 41: 0.028583253000000752, 42: 0.03291218099999682, 43: 0.04099164599999838}
prediction_time: 0.0002860859999884724
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
