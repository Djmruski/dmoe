Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='aa639fe4-c1be-40ed-9136-58500cc2317f', conf_timestamp='2023-08-13 15:16:31.870460', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 67.51 % 	 [Task-IL]: 47.72 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 54.47 % 	 [Task-IL]: 41.09 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 42.71 % 	 [Task-IL]: 38.14 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 38.5 % 	 [Task-IL]: 36.26 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 33.21 % 	 [Task-IL]: 33.61 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 23.6 % 	 [Task-IL]: 32.54 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 24.56 % 	 [Task-IL]: 31.79 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 23.29 % 	 [Task-IL]: 31.07 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 19.32 % 	 [Task-IL]: 30.68 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 21.02 % 	 [Task-IL]: 29.7 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 16.83 % 	 [Task-IL]: 29.27 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 17.44 % 	 [Task-IL]: 29.13 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 16.24 % 	 [Task-IL]: 28.73 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 12.6 % 	 [Task-IL]: 29.04 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 12.69 % 	 [Task-IL]: 29.08 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 12.76 % 	 [Task-IL]: 28.47 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 10.92 % 	 [Task-IL]: 27.65 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 9.87 % 	 [Task-IL]: 27.25 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 10.71 % 	 [Task-IL]: 27.29 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 9.91 % 	 [Task-IL]: 27.2 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 8.21 % 	 [Task-IL]: 27.71 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 8.14 % 	 [Task-IL]: 27.25 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 8.08 % 	 [Task-IL]: 27.55 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 8.83 % 	 [Task-IL]: 27.68 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 9.03 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 7.08 % 	 [Task-IL]: 26.85 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 7.73 % 	 [Task-IL]: 26.5 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 7.81 % 	 [Task-IL]: 26.46 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 6.02 % 	 [Task-IL]: 26.79 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 7.38 % 	 [Task-IL]: 26.75 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 7.84 % 	 [Task-IL]: 27.02 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 7.91 % 	 [Task-IL]: 26.63 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 6.91 % 	 [Task-IL]: 26.96 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 4.71 % 	 [Task-IL]: 26.98 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 5.72 % 	 [Task-IL]: 26.71 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 5.04 % 	 [Task-IL]: 27.14 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 4.84 % 	 [Task-IL]: 27.12 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 6.33 % 	 [Task-IL]: 27.09 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 5.77 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 5.95 % 	 [Task-IL]: 26.77 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.87 % 	 [Task-IL]: 27.11 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 5.34 % 	 [Task-IL]: 27.08 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.24 % 	 [Task-IL]: 26.99 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74905, 592: 35, 93: 33, 100: 33, 207: 33, 234: 33, 288: 33, 455: 33, 508: 33, 532: 33, 705: 33, 830: 33, 32: 32, 242: 32, 303: 32, 391: 32, 396: 32, 517: 32, 543: 32, 574: 32, 581: 32, 627: 32, 656: 32, 674: 32, 700: 32, 799: 32, 37: 31, 65: 31, 152: 31, 178: 31, 259: 31, 289: 31, 299: 31, 324: 31, 343: 31, 361: 31, 408: 31, 405: 31, 424: 31, 523: 31, 624: 31, 637: 31, 687: 31, 686: 31, 746: 31, 773: 31, 767: 31, 831: 31, 842: 31, 15: 30, 10: 30, 22: 30, 69: 30, 91: 30, 160: 30, 185: 30, 206: 30, 197: 30, 217: 30, 300: 30, 322: 30, 337: 30, 367: 30, 359: 30, 387: 30, 406: 30, 419: 30, 417: 30, 420: 30, 472: 30, 460: 30, 468: 30, 480: 30, 610: 30, 679: 30, 737: 30, 738: 30, 787: 30, 841: 30, 867: 30, 48: 29, 63: 29, 85: 29, 126: 29, 142: 29, 191: 29, 179: 29, 220: 29, 237: 29, 246: 29, 274: 29, 326: 29, 347: 29, 346: 29, 366: 29, 395: 29, 436: 29, 504: 29, 519: 29, 527: 29, 528: 29, 556: 29, 600: 29, 626: 29, 621: 29, 632: 29, 640: 29, 699: 29, 727: 29, 753: 29, 742: 29, 757: 29, 777: 29, 791: 29, 802: 29, 851: 29, 849: 29, 846: 29, 870: 29, 862: 29, 857: 29, 890: 29, 29: 28, 23: 28, 9: 28, 79: 28, 75: 28, 105: 28, 117: 28, 130: 28, 149: 28, 156: 28, 204: 28, 263: 28, 276: 28, 275: 28, 290: 28, 294: 28, 325: 28, 342: 28, 360: 28, 418: 28, 481: 28, 511: 28, 567: 28, 606: 28, 601: 28, 596: 28, 618: 28, 663: 28, 658: 28, 654: 28, 724: 28, 714: 28, 789: 28, 804: 28, 809: 28, 828: 28, 837: 28, 858: 28, 872: 28, 878: 28, 885: 28, 36: 27, 78: 27, 86: 27, 101: 27, 106: 27, 115: 27, 171: 27, 338: 27, 370: 27, 454: 27, 461: 27, 521: 27, 580: 27, 586: 27, 648: 27, 659: 27, 682: 27, 711: 27, 713: 27, 725: 27, 739: 27, 774: 27, 819: 27, 818: 27, 887: 27, 25: 26, 57: 26, 84: 26, 116: 26, 148: 26, 196: 26, 205: 26, 225: 26, 233: 26, 243: 26, 273: 26, 305: 26, 365: 26, 491: 26, 576: 26, 578: 26, 638: 26, 692: 26, 684: 26, 726: 26, 779: 26, 824: 26, 871: 26, 7: 25, 28: 25, 43: 25, 108: 25, 145: 25, 193: 25, 190: 25, 177: 25, 200: 25, 301: 25, 372: 25, 647: 25, 882: 25, 55: 24, 67: 24, 378: 24, 384: 24, 425: 24, 434: 24, 542: 24, 539: 23, 577: 23, 835: 23, 267: 22, 351: 22, 524: 22, 88: 21, 295: 21, 879: 21, 509: 19, 8: 18, 61: 18, 864: 18, 186: 17, 183: 17, 254: 17, 329: 17, 374: 17, 563: 17, 594: 17, 730: 17, 778: 17, 5: 16, 6: 16, 45: 16, 50: 16, 71: 16, 169: 16, 224: 16, 253: 16, 269: 16, 282: 16, 278: 16, 429: 16, 435: 16, 448: 16, 526: 16, 570: 16, 756: 16, 805: 16, 796: 16, 816: 16, 51: 15, 73: 15, 76: 15, 122: 15, 123: 15, 161: 15, 167: 15, 158: 15, 176: 15, 192: 15, 212: 15, 213: 15, 230: 15, 239: 15, 248: 15, 256: 15, 271: 15, 293: 15, 330: 15, 339: 15, 355: 15, 502: 15, 516: 15, 530: 15, 551: 15, 561: 15, 602: 15, 595: 15, 697: 15, 716: 15, 766: 15, 764: 15, 795: 15, 815: 15, 13: 14, 31: 14, 47: 14, 56: 14, 99: 14, 94: 14, 113: 14, 111: 14, 131: 14, 132: 14, 129: 14, 151: 14, 162: 14, 170: 14, 184: 14, 199: 14, 202: 14, 227: 14, 228: 14, 226: 14, 264: 14, 280: 14, 283: 14, 327: 14, 344: 14, 348: 14, 357: 14, 364: 14, 407: 14, 411: 14, 440: 14, 478: 14, 486: 14, 499: 14, 529: 14, 549: 14, 538: 14, 562: 14, 565: 14, 593: 14, 614: 14, 634: 14, 655: 14, 673: 14, 664: 14, 731: 14, 719: 14, 735: 14, 843: 14, 840: 14, 838: 14, 869: 14, 874: 14, 891: 14, 21: 13, 20: 13, 18: 13, 39: 13, 41: 13, 60: 13, 58: 13, 90: 13, 92: 13, 95: 13, 121: 13, 143: 13, 135: 13, 134: 13, 138: 13, 147: 13, 159: 13, 166: 13, 209: 13, 194: 13, 216: 13, 231: 13, 265: 13, 277: 13, 302: 13, 296: 13, 328: 13, 349: 13, 334: 13, 340: 13, 373: 13, 386: 13, 385: 13, 392: 13, 380: 13, 389: 13, 375: 13, 383: 13, 404: 13, 398: 13, 426: 13, 415: 13, 432: 13, 467: 13, 465: 13, 471: 13, 484: 13, 476: 13, 512: 13, 510: 13, 494: 13, 544: 13, 547: 13, 537: 13, 535: 13, 552: 13, 588: 13, 583: 13, 584: 13, 599: 13, 612: 13, 597: 13, 604: 13, 598: 13, 630: 13, 625: 13, 639: 13, 644: 13, 669: 13, 670: 13, 689: 13, 681: 13, 680: 13, 702: 13, 706: 13, 695: 13, 704: 13, 722: 13, 729: 13, 715: 13, 748: 13, 754: 13, 780: 13, 793: 13, 800: 13, 803: 13, 814: 13, 852: 13, 847: 13, 860: 13, 863: 13, 873: 13, 875: 13, 883: 13, 876: 13, 14: 12, 24: 12, 4: 12, 12: 12, 44: 12, 53: 12, 52: 12, 70: 12, 54: 12, 66: 12, 68: 12, 80: 12, 77: 12, 104: 12, 112: 12, 97: 12, 109: 12, 124: 12, 128: 12, 114: 12, 127: 12, 146: 12, 144: 12, 172: 12, 182: 12, 189: 12, 211: 12, 210: 12, 221: 12, 218: 12, 232: 12, 236: 12, 249: 12, 235: 12, 244: 12, 262: 12, 266: 12, 287: 12, 286: 12, 284: 12, 306: 12, 308: 12, 307: 12, 304: 12, 317: 12, 320: 12, 316: 12, 323: 12, 353: 12, 352: 12, 356: 12, 354: 12, 388: 12, 379: 12, 393: 12, 397: 12, 416: 12, 430: 12, 449: 12, 450: 12, 453: 12, 447: 12, 446: 12, 443: 12, 452: 12, 473: 12, 493: 12, 482: 12, 483: 12, 513: 12, 507: 12, 495: 12, 522: 12, 534: 12, 536: 12, 540: 12, 554: 12, 558: 12, 573: 12, 566: 12, 568: 12, 560: 12, 572: 12, 575: 12, 585: 12, 605: 12, 628: 12, 633: 12, 653: 12, 636: 12, 651: 12, 643: 12, 649: 12, 642: 12, 661: 12, 676: 12, 691: 12, 675: 12, 693: 12, 685: 12, 712: 12, 696: 12, 717: 12, 720: 12, 723: 12, 718: 12, 745: 12, 749: 12, 751: 12, 768: 12, 772: 12, 771: 12, 759: 12, 775: 12, 782: 12, 813: 12, 807: 12, 797: 12, 812: 12, 821: 12, 820: 12, 825: 12, 839: 12, 853: 12, 868: 12, 854: 12, 892: 12, 889: 12, 888: 12, 33: 11, 17: 11, 19: 11, 34: 11, 38: 11, 46: 11, 59: 11, 89: 11, 81: 11, 96: 11, 103: 11, 102: 11, 98: 11, 133: 11, 119: 11, 120: 11, 139: 11, 153: 11, 141: 11, 165: 11, 168: 11, 155: 11, 163: 11, 175: 11, 187: 11, 174: 11, 180: 11, 188: 11, 195: 11, 208: 11, 219: 11, 215: 11, 238: 11, 247: 11, 252: 11, 250: 11, 270: 11, 257: 11, 292: 11, 281: 11, 310: 11, 309: 11, 298: 11, 321: 11, 314: 11, 332: 11, 333: 11, 345: 11, 341: 11, 350: 11, 335: 11, 371: 11, 363: 11, 369: 11, 358: 11, 362: 11, 382: 11, 409: 11, 421: 11, 437: 11, 445: 11, 441: 11, 469: 11, 466: 11, 457: 11, 458: 11, 462: 11, 477: 11, 485: 11, 479: 11, 488: 11, 487: 11, 492: 11, 505: 11, 496: 11, 498: 11, 501: 11, 503: 11, 514: 11, 515: 11, 533: 11, 546: 11, 541: 11, 548: 11, 571: 11, 569: 11, 555: 11, 564: 11, 587: 11, 579: 11, 616: 11, 622: 11, 617: 11, 619: 11, 631: 11, 650: 11, 645: 11, 672: 11, 657: 11, 671: 11, 667: 11, 662: 11, 660: 11, 710: 11, 703: 11, 694: 11, 733: 11, 721: 11, 747: 11, 736: 11, 740: 11, 752: 11, 763: 11, 758: 11, 765: 11, 784: 11, 786: 11, 790: 11, 788: 11, 811: 11, 808: 11, 832: 11, 833: 11, 822: 11, 817: 11, 844: 11, 834: 11, 845: 11, 859: 11, 861: 11, 881: 11, 877: 11, 893: 11, 2: 10, 26: 10, 27: 10, 11: 10, 3: 10, 16: 10, 35: 10, 40: 10, 42: 10, 64: 10, 62: 10, 74: 10, 87: 10, 125: 10, 136: 10, 137: 10, 150: 10, 140: 10, 164: 10, 157: 10, 173: 10, 203: 10, 198: 10, 214: 10, 222: 10, 240: 10, 251: 10, 245: 10, 261: 10, 260: 10, 272: 10, 285: 10, 279: 10, 297: 10, 313: 10, 315: 10, 318: 10, 376: 10, 381: 10, 410: 10, 403: 10, 399: 10, 400: 10, 412: 10, 431: 10, 433: 10, 428: 10, 414: 10, 423: 10, 442: 10, 438: 10, 444: 10, 463: 10, 459: 10, 475: 10, 490: 10, 489: 10, 518: 10, 525: 10, 520: 10, 553: 10, 550: 10, 589: 10, 582: 10, 591: 10, 613: 10, 607: 10, 603: 10, 608: 10, 609: 10, 629: 10, 615: 10, 635: 10, 652: 10, 641: 10, 665: 10, 666: 10, 683: 10, 677: 10, 690: 10, 698: 10, 732: 10, 750: 10, 734: 10, 761: 10, 762: 10, 770: 10, 769: 10, 760: 10, 785: 10, 781: 10, 783: 10, 792: 10, 806: 10, 810: 10, 823: 10, 827: 10, 850: 10, 848: 10, 855: 10, 856: 10, 880: 10, 884: 10, 30: 9, 1: 9, 72: 9, 83: 9, 82: 9, 110: 9, 181: 9, 201: 9, 223: 9, 255: 9, 268: 9, 311: 9, 312: 9, 319: 9, 368: 9, 377: 9, 394: 9, 402: 9, 427: 9, 439: 9, 464: 9, 470: 9, 456: 9, 497: 9, 545: 9, 590: 9, 611: 9, 623: 9, 678: 9, 688: 9, 708: 9, 701: 9, 743: 9, 741: 9, 744: 9, 755: 9, 776: 9, 794: 9, 826: 9, 836: 9, 865: 9, 866: 9, 49: 8, 107: 8, 118: 8, 154: 8, 241: 8, 258: 8, 331: 8, 336: 8, 390: 8, 401: 8, 422: 8, 474: 8, 506: 8, 531: 8, 559: 8, 557: 8, 620: 8, 646: 8, 668: 8, 709: 8, 707: 8, 728: 8, 801: 8, 798: 8, 829: 8, 886: 8, 229: 7, 291: 7, 413: 7, 451: 7, 500: 7})
Total buffer: 89400
fit_time: 125.33364073899999

Accuracy for 44 task(s): 	 [Class-IL]: 73.82 % 	 [Task-IL]: 30.53 %

CLASS_IL_ACC: 
	[72.58883248730965, 79.04761904761905, 77.19298245614034, 81.6, 68.80733944954129, 70.9090909090909, 61.6822429906542, 83.33333333333334, 75.83333333333333, 71.42857142857143, 81.9047619047619, 70.0, 70.87378640776699, 81.35593220338984, 84.070796460177, 78.84615384615384, 75.42372881355932, 73.17073170731707, 72.11538461538461, 78.50467289719626, 63.06306306306306, 64.13043478260869, 59.45945945945946, 53.125, 72.0, 76.61290322580645, 79.7979797979798, 74.22680412371135, 79.33884297520662, 70.0, 79.46428571428571, 84.90566037735849, 71.96261682242991, 60.68376068376068, 73.83177570093457, 78.18181818181819, 62.5, 68.0, 72.97297297297297, 79.8076923076923, 83.92857142857143, 74.57627118644068, 76.06837606837607, 80.9090909090909]
TASK_IL_ACC: 
	[51.26903553299492, 30.476190476190478, 27.192982456140353, 32.0, 22.93577981651376, 27.27272727272727, 23.364485981308412, 27.450980392156865, 32.5, 28.57142857142857, 28.57142857142857, 28.18181818181818, 28.155339805825243, 33.89830508474576, 32.743362831858406, 22.115384615384613, 29.66101694915254, 19.51219512195122, 21.153846153846153, 30.8411214953271, 34.234234234234236, 38.04347826086957, 23.423423423423422, 25.0, 23.0, 26.61290322580645, 28.28282828282828, 29.896907216494846, 34.710743801652896, 28.18181818181818, 25.0, 31.132075471698112, 39.25233644859813, 24.786324786324787, 20.5607476635514, 27.27272727272727, 33.035714285714285, 25.0, 34.234234234234236, 29.807692307692307, 30.357142857142854, 28.8135593220339, 27.350427350427353, 97.27272727272728]
f1_micro: 73.90685377262558
f1_macro: 71.22976630325243
              precision    recall  f1-score   support

           0       1.00      0.78      0.88         9
           1       0.80      1.00      0.89         4
           2       1.00      0.75      0.86         4
           3       0.30      0.75      0.43         4
           4       1.00      1.00      1.00         4
           5       1.00      0.60      0.75         5
           6       0.83      1.00      0.91         5
           7       0.75      0.67      0.71         9
           8       0.83      1.00      0.91         5
           9       0.80      0.89      0.84         9
          10       0.70      0.78      0.74         9
          11       0.67      1.00      0.80         4
          12       0.00      0.00      0.00         4
          13       0.75      0.60      0.67         5
          14       1.00      1.00      1.00         5
          15       1.00      0.78      0.88         9
          16       0.00      0.00      0.00         4
          17       1.00      1.00      1.00         4
          18       0.60      0.75      0.67         4
          19       1.00      1.00      1.00         4
          20       1.00      1.00      1.00         4
          21       1.00      0.75      0.86         4
          22       0.75      0.67      0.71         9
          23       0.75      0.67      0.71         9
          24       0.50      0.50      0.50         4
          25       0.00      0.00      0.00         9
          26       1.00      0.75      0.86         4
          27       1.00      0.75      0.86         4
          28       0.86      0.67      0.75         9
          29       1.00      0.56      0.71         9
          30       1.00      1.00      1.00         4
          31       0.80      0.80      0.80         5
          32       1.00      1.00      1.00         9
          33       1.00      0.75      0.86         4
          34       0.60      0.75      0.67         4
          35       1.00      0.50      0.67         4
          36       1.00      1.00      1.00         9
          37       1.00      0.78      0.88         9
          38       0.00      0.00      0.00         4
          39       0.67      0.50      0.57         4
          40       0.80      1.00      0.89         4
          41       0.83      1.00      0.91         5
          42       1.00      0.75      0.86         4
          43       1.00      1.00      1.00         9
          44       0.75      0.75      0.75         4
          45       1.00      0.60      0.75         5
          46       0.67      1.00      0.80         4
          47       1.00      1.00      1.00         5
          48       1.00      0.89      0.94         9
          49       1.00      1.00      1.00         4
          50       0.83      1.00      0.91         5
          51       0.56      1.00      0.71         5
          52       0.67      0.50      0.57         4
          53       0.00      0.00      0.00         4
          54       0.00      0.00      0.00         4
          55       0.90      1.00      0.95         9
          56       1.00      0.50      0.67         4
          57       1.00      1.00      1.00         9
          58       0.83      1.00      0.91         5
          59       1.00      0.50      0.67         4
          60       1.00      1.00      1.00         5
          61       0.83      1.00      0.91         5
          62       0.50      0.75      0.60         4
          63       1.00      1.00      1.00         9
          64       0.00      0.00      0.00         4
          65       1.00      0.78      0.88         9
          66       0.50      0.75      0.60         4
          67       1.00      1.00      1.00         8
          68       0.00      0.00      0.00         4
          69       0.71      0.56      0.63         9
          70       1.00      1.00      1.00         4
          71       1.00      1.00      1.00         5
          72       0.75      0.75      0.75         4
          73       1.00      0.80      0.89         5
          74       1.00      1.00      1.00         4
          75       0.75      0.67      0.71         9
          76       0.83      1.00      0.91         5
          77       1.00      0.75      0.86         4
          78       0.82      1.00      0.90         9
          79       1.00      0.78      0.88         9
          80       0.00      0.00      0.00         4
          81       0.57      1.00      0.73         4
          82       1.00      1.00      1.00         4
          83       1.00      0.25      0.40         4
          84       1.00      1.00      1.00         9
          85       0.90      1.00      0.95         9
          86       0.70      0.78      0.74         9
          87       0.80      1.00      0.89         4
          88       1.00      0.75      0.86         8
          89       1.00      1.00      1.00         4
          90       0.75      0.75      0.75         4
          91       0.80      0.89      0.84         9
          92       0.00      0.00      0.00         4
          93       0.90      1.00      0.95         9
          94       0.57      1.00      0.73         4
          95       1.00      0.75      0.86         4
          96       0.67      1.00      0.80         4
          97       1.00      1.00      1.00         5
          98       0.80      1.00      0.89         4
          99       0.80      1.00      0.89         4
         100       1.00      0.78      0.88         9
         101       0.00      0.00      0.00         9
         102       1.00      0.50      0.67         4
         103       1.00      1.00      1.00         4
         104       1.00      0.75      0.86         4
         105       0.75      1.00      0.86         9
         106       1.00      0.89      0.94         9
         107       0.00      0.00      0.00         4
         108       0.00      0.00      0.00         9
         109       0.50      0.50      0.50         4
         110       1.00      0.60      0.75         5
         111       0.80      0.80      0.80         5
         112       1.00      1.00      1.00         4
         113       0.83      1.00      0.91         5
         114       0.80      1.00      0.89         4
         115       0.88      0.78      0.82         9
         116       0.00      0.00      0.00         9
         117       1.00      1.00      1.00         9
         118       0.67      0.50      0.57         4
         119       0.67      1.00      0.80         4
         120       0.67      1.00      0.80         4
         121       1.00      1.00      1.00         4
         122       0.83      1.00      0.91         5
         123       1.00      1.00      1.00         5
         124       0.75      0.60      0.67         5
         125       0.00      0.00      0.00         4
         126       0.89      0.89      0.89         9
         127       1.00      0.80      0.89         5
         128       1.00      1.00      1.00         4
         129       1.00      0.75      0.86         4
         130       0.00      0.00      0.00         9
         131       0.67      0.80      0.73         5
         132       1.00      1.00      1.00         4
         133       1.00      1.00      1.00         4
         134       0.80      1.00      0.89         4
         135       0.80      1.00      0.89         4
         136       1.00      0.75      0.86         4
         137       0.50      0.50      0.50         4
         138       0.75      0.60      0.67         5
         139       0.25      0.25      0.25         4
         140       1.00      1.00      1.00         4
         141       0.75      0.75      0.75         4
         142       0.83      0.56      0.67         9
         143       0.00      0.00      0.00         4
         144       1.00      0.50      0.67         4
         145       0.00      0.00      0.00         9
         146       0.50      0.25      0.33         4
         147       0.50      0.50      0.50         4
         148       0.80      0.89      0.84         9
         149       1.00      0.89      0.94         9
         150       1.00      0.75      0.86         4
         151       1.00      0.20      0.33         5
         152       1.00      0.89      0.94         9
         153       1.00      1.00      1.00         4
         154       0.57      1.00      0.73         4
         155       1.00      1.00      1.00         4
         156       0.86      0.67      0.75         9
         157       1.00      0.75      0.86         4
         158       0.71      1.00      0.83         5
         159       1.00      0.75      0.86         4
         160       0.80      0.89      0.84         9
         161       0.75      0.60      0.67         5
         162       0.80      0.80      0.80         5
         163       0.00      0.00      0.00         4
         164       0.80      1.00      0.89         4
         165       1.00      1.00      1.00         4
         166       0.83      1.00      0.91         5
         167       1.00      1.00      1.00         5
         168       1.00      0.75      0.86         4
         169       0.80      0.80      0.80         5
         170       1.00      1.00      1.00         5
         171       1.00      0.89      0.94         9
         172       1.00      0.75      0.86         4
         173       0.57      1.00      0.73         4
         174       1.00      1.00      1.00         4
         175       0.33      0.25      0.29         4
         176       0.83      1.00      0.91         5
         177       0.88      0.78      0.82         9
         178       0.89      0.89      0.89         9
         179       0.90      1.00      0.95         9
         180       0.80      1.00      0.89         4
         181       0.00      0.00      0.00         4
         182       0.67      0.80      0.73         5
         183       0.43      0.60      0.50         5
         184       1.00      1.00      1.00         5
         185       0.00      0.00      0.00         9
         186       0.50      0.40      0.44         5
         187       1.00      1.00      1.00         4
         188       0.50      0.75      0.60         4
         189       0.67      0.50      0.57         4
         190       1.00      1.00      1.00         8
         191       0.89      0.89      0.89         9
         192       0.83      1.00      0.91         5
         193       0.90      1.00      0.95         9
         194       1.00      1.00      1.00         4
         195       1.00      1.00      1.00         4
         196       1.00      0.89      0.94         9
         197       0.75      0.67      0.71         9
         198       0.33      0.25      0.29         4
         199       1.00      1.00      1.00         5
         200       1.00      0.89      0.94         9
         201       0.00      0.00      0.00         4
         202       0.57      0.80      0.67         5
         203       1.00      0.50      0.67         4
         204       0.00      0.00      0.00         9
         205       0.78      0.78      0.78         9
         206       0.89      0.89      0.89         9
         207       1.00      1.00      1.00         9
         208       0.60      0.75      0.67         4
         209       1.00      1.00      1.00         5
         210       0.75      0.75      0.75         4
         211       1.00      1.00      1.00         4
         212       0.00      0.00      0.00         4
         213       0.57      0.80      0.67         5
         214       0.00      0.00      0.00         4
         215       1.00      0.50      0.67         4
         216       0.00      0.00      0.00         4
         217       0.75      1.00      0.86         9
         218       1.00      0.50      0.67         4
         219       1.00      1.00      1.00         5
         220       1.00      0.89      0.94         9
         221       1.00      1.00      1.00         4
         222       1.00      1.00      1.00         4
         223       0.75      0.75      0.75         4
         224       0.40      0.80      0.53         5
         225       1.00      1.00      1.00         9
         226       0.50      1.00      0.67         4
         227       1.00      0.80      0.89         5
         228       0.80      0.80      0.80         5
         229       0.80      1.00      0.89         4
         230       0.67      0.80      0.73         5
         231       1.00      1.00      1.00         4
         232       1.00      1.00      1.00         4
         233       1.00      0.89      0.94         9
         234       0.89      0.89      0.89         9
         235       0.00      0.00      0.00         4
         236       1.00      0.50      0.67         4
         237       1.00      0.89      0.94         9
         238       0.57      1.00      0.73         4
         239       1.00      1.00      1.00         5
         240       0.00      0.00      0.00         4
         241       1.00      1.00      1.00         4
         242       1.00      1.00      1.00         9
         243       1.00      0.89      0.94         9
         244       0.50      0.80      0.62         5
         245       0.00      0.00      0.00         4
         246       0.00      0.00      0.00         9
         247       1.00      0.75      0.86         4
         248       1.00      1.00      1.00         5
         249       0.00      0.00      0.00         4
         250       0.60      0.75      0.67         4
         251       1.00      1.00      1.00         4
         252       0.62      1.00      0.77         5
         253       0.71      1.00      0.83         5
         254       0.50      0.60      0.55         5
         255       1.00      0.75      0.86         4
         256       1.00      0.80      0.89         5
         257       0.00      0.00      0.00         4
         258       1.00      0.75      0.86         4
         259       1.00      0.89      0.94         9
         260       0.00      0.00      0.00         4
         261       1.00      1.00      1.00         4
         262       1.00      0.50      0.67         4
         263       1.00      1.00      1.00         9
         264       1.00      0.80      0.89         5
         265       1.00      0.75      0.86         4
         266       0.00      0.00      0.00         4
         267       0.67      0.57      0.62         7
         268       0.00      0.00      0.00         4
         269       1.00      1.00      1.00         5
         270       1.00      1.00      1.00         4
         271       0.83      1.00      0.91         5
         272       1.00      1.00      1.00         4
         273       1.00      0.89      0.94         9
         274       0.69      1.00      0.82         9
         275       0.67      0.89      0.76         9
         276       1.00      1.00      1.00         9
         277       0.60      0.75      0.67         4
         278       1.00      1.00      1.00         5
         279       0.60      0.75      0.67         4
         280       0.50      0.20      0.29         5
         281       1.00      0.60      0.75         5
         282       1.00      1.00      1.00         5
         283       1.00      0.80      0.89         5
         284       1.00      1.00      1.00         5
         285       1.00      0.75      0.86         4
         286       1.00      1.00      1.00         5
         287       0.60      0.75      0.67         4
         288       0.88      0.78      0.82         9
         289       1.00      0.89      0.94         9
         290       0.80      0.44      0.57         9
         291       1.00      0.75      0.86         4
         292       1.00      0.75      0.86         4
         293       0.71      1.00      0.83         5
         294       0.90      1.00      0.95         9
         295       0.78      1.00      0.88         7
         296       0.75      0.75      0.75         4
         297       0.60      0.75      0.67         4
         298       1.00      1.00      1.00         4
         299       0.82      1.00      0.90         9
         300       0.89      0.89      0.89         9
         301       0.82      1.00      0.90         9
         302       1.00      0.25      0.40         4
         303       1.00      1.00      1.00         9
         304       1.00      0.75      0.86         4
         305       0.82      1.00      0.90         9
         306       1.00      1.00      1.00         4
         307       0.75      0.75      0.75         4
         308       0.75      0.75      0.75         4
         309       1.00      0.75      0.86         4
         310       1.00      1.00      1.00         4
         311       1.00      0.50      0.67         4
         312       0.00      0.00      0.00         4
         313       0.67      0.50      0.57         4
         314       0.67      0.50      0.57         4
         315       1.00      0.75      0.86         4
         316       0.67      0.50      0.57         4
         317       0.00      0.00      0.00         4
         318       1.00      1.00      1.00         4
         319       1.00      0.75      0.86         4
         320       0.80      1.00      0.89         4
         321       1.00      0.80      0.89         5
         322       1.00      1.00      1.00         9
         323       0.80      1.00      0.89         4
         324       0.89      0.89      0.89         9
         325       0.82      1.00      0.90         9
         326       1.00      0.89      0.94         9
         327       1.00      1.00      1.00         5
         328       0.80      1.00      0.89         4
         329       0.50      0.40      0.44         5
         330       1.00      1.00      1.00         5
         331       0.60      0.75      0.67         4
         332       0.60      0.75      0.67         4
         333       0.00      0.00      0.00         4
         334       0.67      1.00      0.80         4
         335       1.00      0.75      0.86         4
         336       0.80      1.00      0.89         4
         337       0.90      1.00      0.95         9
         338       0.90      1.00      0.95         9
         339       0.71      1.00      0.83         5
         340       1.00      0.60      0.75         5
         341       0.00      0.00      0.00         4
         342       0.90      1.00      0.95         9
         343       1.00      1.00      1.00         9
         344       1.00      0.50      0.67         4
         345       0.00      0.00      0.00         4
         346       0.60      0.67      0.63         9
         347       1.00      0.89      0.94         9
         348       1.00      1.00      1.00         4
         349       1.00      0.75      0.86         4
         350       0.75      0.75      0.75         4
         351       0.00      0.00      0.00         9
         352       1.00      1.00      1.00         5
         353       1.00      0.75      0.86         4
         354       1.00      1.00      1.00         4
         355       1.00      0.60      0.75         5
         356       0.80      1.00      0.89         4
         357       1.00      1.00      1.00         4
         358       0.80      1.00      0.89         4
         359       0.00      0.00      0.00         9
         360       0.78      0.78      0.78         9
         361       1.00      0.78      0.88         9
         362       0.00      0.00      0.00         4
         363       0.60      0.75      0.67         4
         364       1.00      0.80      0.89         5
         365       0.89      0.89      0.89         9
         366       1.00      0.56      0.71         9
         367       0.89      0.89      0.89         9
         368       1.00      1.00      1.00         4
         369       1.00      0.25      0.40         4
         370       1.00      1.00      1.00         9
         371       1.00      1.00      1.00         4
         372       1.00      1.00      1.00         9
         373       0.50      0.40      0.44         5
         374       0.60      0.60      0.60         5
         375       1.00      0.75      0.86         4
         376       0.00      0.00      0.00         4
         377       0.00      0.00      0.00         4
         378       0.56      0.56      0.56         9
         379       1.00      0.75      0.86         4
         380       1.00      1.00      1.00         5
         381       1.00      1.00      1.00         4
         382       1.00      1.00      1.00         4
         383       0.50      0.50      0.50         4
         384       0.80      0.89      0.84         9
         385       0.75      0.60      0.67         5
         386       1.00      0.75      0.86         4
         387       0.70      0.78      0.74         9
         388       1.00      0.80      0.89         5
         389       1.00      0.75      0.86         4
         390       0.40      0.50      0.44         4
         391       0.90      1.00      0.95         9
         392       0.75      0.75      0.75         4
         393       0.57      1.00      0.73         4
         394       1.00      0.25      0.40         4
         395       1.00      0.78      0.88         9
         396       1.00      1.00      1.00         9
         397       1.00      0.75      0.86         4
         398       1.00      1.00      1.00         4
         399       0.80      1.00      0.89         4
         400       0.00      0.00      0.00         4
         401       0.44      1.00      0.62         4
         402       0.71      1.00      0.83         5
         403       0.80      1.00      0.89         4
         404       0.06      0.25      0.10         4
         405       0.90      1.00      0.95         9
         406       1.00      1.00      1.00         9
         407       1.00      0.75      0.86         4
         408       1.00      0.89      0.94         9
         409       0.00      0.00      0.00         4
         410       0.80      1.00      0.89         4
         411       0.71      1.00      0.83         5
         412       1.00      1.00      1.00         4
         413       0.00      0.00      0.00         4
         414       0.75      0.75      0.75         4
         415       1.00      1.00      1.00         4
         416       0.00      0.00      0.00         4
         417       0.00      0.00      0.00         9
         418       0.67      0.67      0.67         9
         419       0.82      1.00      0.90         9
         420       0.00      0.00      0.00         9
         421       1.00      0.75      0.86         4
         422       0.67      0.50      0.57         4
         423       0.67      1.00      0.80         4
         424       0.80      0.89      0.84         9
         425       0.50      0.67      0.57         9
         426       0.80      1.00      0.89         4
         427       1.00      0.75      0.86         4
         428       0.75      0.75      0.75         4
         429       1.00      1.00      1.00         5
         430       0.80      1.00      0.89         4
         431       0.00      0.00      0.00         4
         432       0.50      0.75      0.60         4
         433       1.00      0.75      0.86         4
         434       1.00      0.56      0.71         9
         435       1.00      1.00      1.00         5
         436       1.00      1.00      1.00         9
         437       0.67      1.00      0.80         4
         438       1.00      1.00      1.00         4
         439       0.67      0.50      0.57         4
         440       0.00      0.00      0.00         4
         441       0.00      0.00      0.00         4
         442       0.00      0.00      0.00         4
         443       1.00      1.00      1.00         4
         444       0.75      0.75      0.75         4
         445       0.00      0.00      0.00         4
         446       0.00      0.00      0.00         4
         447       0.80      1.00      0.89         4
         448       1.00      0.80      0.89         5
         449       0.80      1.00      0.89         4
         450       0.67      0.50      0.57         4
         451       1.00      0.50      0.67         4
         452       1.00      1.00      1.00         4
         453       1.00      0.75      0.86         4
         454       0.86      0.67      0.75         9
         455       0.80      0.89      0.84         9
         456       1.00      0.25      0.40         4
         457       0.00      0.00      0.00         4
         458       0.50      0.25      0.33         4
         459       1.00      1.00      1.00         4
         460       0.89      0.89      0.89         9
         461       0.89      0.89      0.89         9
         462       0.00      0.00      0.00         4
         463       0.67      1.00      0.80         4
         464       1.00      1.00      1.00         4
         465       1.00      1.00      1.00         4
         466       0.75      0.75      0.75         4
         467       1.00      1.00      1.00         5
         468       0.00      0.00      0.00         9
         469       0.67      1.00      0.80         4
         470       1.00      1.00      1.00         4
         471       0.00      0.00      0.00         4
         472       0.00      0.00      0.00         9
         473       0.67      0.50      0.57         4
         474       0.80      1.00      0.89         4
         475       0.00      0.00      0.00         4
         476       1.00      0.25      0.40         4
         477       0.00      0.00      0.00         4
         478       0.83      1.00      0.91         5
         479       0.00      0.00      0.00         4
         480       1.00      0.89      0.94         9
         481       0.90      1.00      0.95         9
         482       1.00      0.75      0.86         4
         483       0.50      0.75      0.60         4
         484       0.00      0.00      0.00         4
         485       0.00      0.00      0.00         4
         486       1.00      1.00      1.00         4
         487       0.00      0.00      0.00         4
         488       0.00      0.00      0.00         4
         489       0.00      0.00      0.00         4
         490       0.75      0.75      0.75         4
         491       0.89      0.89      0.89         9
         492       0.00      0.00      0.00         4
         493       0.75      0.75      0.75         4
         494       0.00      0.00      0.00         4
         495       1.00      0.75      0.86         4
         496       1.00      1.00      1.00         4
         497       0.50      0.25      0.33         4
         498       1.00      0.25      0.40         4
         499       0.83      1.00      0.91         5
         500       0.40      0.50      0.44         4
         501       1.00      0.75      0.86         4
         502       1.00      0.80      0.89         5
         503       0.80      1.00      0.89         4
         504       0.58      0.78      0.67         9
         505       0.80      1.00      0.89         4
         506       0.00      0.00      0.00         4
         507       0.67      0.50      0.57         4
         508       1.00      1.00      1.00         9
         509       0.71      0.83      0.77         6
         510       0.29      0.50      0.36         4
         511       1.00      1.00      1.00         9
         512       1.00      1.00      1.00         4
         513       0.75      0.60      0.67         5
         514       1.00      0.75      0.86         4
         515       1.00      0.75      0.86         4
         516       1.00      1.00      1.00         5
         517       0.88      0.78      0.82         9
         518       0.50      0.50      0.50         4
         519       1.00      0.56      0.71         9
         520       1.00      0.50      0.67         4
         521       0.75      1.00      0.86         9
         522       1.00      1.00      1.00         4
         523       1.00      0.89      0.94         9
         524       1.00      1.00      1.00         9
         525       1.00      1.00      1.00         4
         526       0.83      1.00      0.91         5
         527       0.73      0.89      0.80         9
         528       0.78      0.78      0.78         9
         529       1.00      0.80      0.89         5
         530       1.00      0.80      0.89         5
         531       0.80      1.00      0.89         4
         532       0.00      0.00      0.00         9
         533       0.50      0.50      0.50         4
         534       0.67      0.50      0.57         4
         535       0.75      0.75      0.75         4
         536       1.00      1.00      1.00         4
         537       1.00      0.50      0.67         4
         538       0.50      0.80      0.62         5
         539       0.70      0.78      0.74         9
         540       0.75      0.75      0.75         4
         541       0.67      1.00      0.80         4
         542       0.67      0.89      0.76         9
         543       0.82      1.00      0.90         9
         544       1.00      1.00      1.00         5
         545       1.00      1.00      1.00         4
         546       1.00      0.75      0.86         4
         547       1.00      0.80      0.89         5
         548       0.67      0.50      0.57         4
         549       0.40      0.50      0.44         4
         550       0.67      1.00      0.80         4
         551       0.67      0.80      0.73         5
         552       1.00      0.75      0.86         4
         553       1.00      0.50      0.67         4
         554       0.83      1.00      0.91         5
         555       0.75      0.75      0.75         4
         556       0.70      0.78      0.74         9
         557       1.00      1.00      1.00         4
         558       0.33      0.25      0.29         4
         559       1.00      0.50      0.67         4
         560       1.00      0.75      0.86         4
         561       1.00      1.00      1.00         5
         562       1.00      0.50      0.67         4
         563       0.83      1.00      0.91         5
         564       0.71      1.00      0.83         5
         565       0.83      1.00      0.91         5
         566       1.00      1.00      1.00         4
         567       0.70      0.78      0.74         9
         568       1.00      0.40      0.57         5
         569       1.00      0.50      0.67         4
         570       0.75      0.60      0.67         5
         571       1.00      0.25      0.40         4
         572       1.00      0.75      0.86         4
         573       1.00      0.75      0.86         4
         574       1.00      1.00      1.00         9
         575       1.00      1.00      1.00         4
         576       0.50      0.56      0.53         9
         577       1.00      1.00      1.00         9
         578       0.82      1.00      0.90         9
         579       0.75      0.75      0.75         4
         580       1.00      1.00      1.00         9
         581       0.90      1.00      0.95         9
         582       0.00      0.00      0.00         4
         583       1.00      1.00      1.00         5
         584       1.00      0.75      0.86         4
         585       0.57      1.00      0.73         4
         586       0.58      0.78      0.67         9
         587       0.67      0.50      0.57         4
         588       0.50      0.75      0.60         4
         589       0.00      0.00      0.00         4
         590       1.00      0.25      0.40         4
         591       0.11      0.25      0.15         4
         592       1.00      1.00      1.00         9
         593       0.80      1.00      0.89         4
         594       1.00      0.60      0.75         5
         595       0.71      1.00      0.83         5
         596       1.00      0.78      0.88         9
         597       0.00      0.00      0.00         4
         598       1.00      0.80      0.89         5
         599       0.80      0.80      0.80         5
         600       0.86      0.67      0.75         9
         601       1.00      0.67      0.80         9
         602       0.83      1.00      0.91         5
         603       1.00      1.00      1.00         4
         604       0.00      0.00      0.00         4
         605       0.38      0.75      0.50         4
         606       1.00      1.00      1.00         9
         607       0.67      1.00      0.80         4
         608       1.00      0.75      0.86         4
         609       0.00      0.00      0.00         4
         610       0.60      0.67      0.63         9
         611       1.00      1.00      1.00         4
         612       1.00      1.00      1.00         4
         613       0.00      0.00      0.00         4
         614       1.00      1.00      1.00         4
         615       1.00      0.75      0.86         4
         616       1.00      1.00      1.00         4
         617       0.00      0.00      0.00         4
         618       1.00      1.00      1.00         9
         619       0.67      1.00      0.80         4
         620       0.00      0.00      0.00         4
         621       0.80      0.89      0.84         9
         622       0.50      0.80      0.62         5
         623       1.00      0.50      0.67         4
         624       0.69      1.00      0.82         9
         625       1.00      1.00      1.00         4
         626       0.90      1.00      0.95         9
         627       0.80      0.89      0.84         9
         628       0.83      1.00      0.91         5
         629       0.25      0.25      0.25         4
         630       0.00      0.00      0.00         4
         631       1.00      0.75      0.86         4
         632       0.90      1.00      0.95         9
         633       1.00      0.75      0.86         4
         634       0.71      1.00      0.83         5
         635       1.00      0.50      0.67         4
         636       1.00      1.00      1.00         4
         637       1.00      0.89      0.94         9
         638       0.90      1.00      0.95         9
         639       1.00      1.00      1.00         4
         640       0.69      1.00      0.82         9
         641       1.00      0.50      0.67         4
         642       1.00      0.75      0.86         4
         643       1.00      1.00      1.00         4
         644       1.00      0.75      0.86         4
         645       1.00      1.00      1.00         4
         646       1.00      0.50      0.67         4
         647       1.00      0.89      0.94         9
         648       0.78      0.78      0.78         9
         649       0.80      1.00      0.89         4
         650       0.00      0.00      0.00         4
         651       1.00      1.00      1.00         4
         652       1.00      1.00      1.00         4
         653       0.67      1.00      0.80         4
         654       0.90      1.00      0.95         9
         655       1.00      1.00      1.00         4
         656       1.00      1.00      1.00         9
         657       1.00      1.00      1.00         4
         658       1.00      0.89      0.94         9
         659       0.62      0.56      0.59         9
         660       1.00      1.00      1.00         4
         661       1.00      1.00      1.00         4
         662       0.00      0.00      0.00         4
         663       0.80      0.89      0.84         9
         664       0.00      0.00      0.00         4
         665       1.00      0.50      0.67         4
         666       0.00      0.00      0.00         4
         667       1.00      1.00      1.00         4
         668       0.00      0.00      0.00         4
         669       1.00      1.00      1.00         5
         670       1.00      0.75      0.86         4
         671       1.00      1.00      1.00         4
         672       0.50      0.50      0.50         4
         673       1.00      0.40      0.57         5
         674       0.00      0.00      0.00         9
         675       0.07      0.25      0.11         4
         676       0.00      0.00      0.00         4
         677       1.00      0.80      0.89         5
         678       1.00      0.75      0.86         4
         679       0.83      0.56      0.67         9
         680       0.80      1.00      0.89         4
         681       1.00      0.75      0.86         4
         682       0.71      0.56      0.63         9
         683       0.80      1.00      0.89         4
         684       1.00      1.00      1.00         9
         685       0.00      0.00      0.00         4
         686       0.89      0.89      0.89         9
         687       0.88      0.78      0.82         9
         688       1.00      0.50      0.67         4
         689       0.83      1.00      0.91         5
         690       0.00      0.00      0.00         4
         691       0.00      0.00      0.00         4
         692       0.58      0.78      0.67         9
         693       1.00      1.00      1.00         4
         694       0.75      0.75      0.75         4
         695       0.00      0.00      0.00         4
         696       0.00      0.00      0.00         4
         697       1.00      0.60      0.75         5
         698       0.60      0.75      0.67         4
         699       1.00      0.44      0.62         9
         700       1.00      0.89      0.94         9
         701       1.00      1.00      1.00         4
         702       0.50      0.75      0.60         4
         703       0.80      1.00      0.89         4
         704       0.09      0.50      0.15         4
         705       1.00      1.00      1.00         9
         706       1.00      1.00      1.00         5
         707       0.60      0.75      0.67         4
         708       1.00      1.00      1.00         4
         709       0.00      0.00      0.00         4
         710       1.00      1.00      1.00         4
         711       1.00      0.89      0.94         9
         712       0.75      0.75      0.75         4
         713       1.00      1.00      1.00         9
         714       0.83      0.56      0.67         9
         715       0.50      0.50      0.50         4
         716       0.67      0.80      0.73         5
         717       0.00      0.00      0.00         4
         718       1.00      1.00      1.00         4
         719       1.00      0.80      0.89         5
         720       1.00      1.00      1.00         4
         721       0.67      0.50      0.57         4
         722       0.83      1.00      0.91         5
         723       0.60      0.75      0.67         4
         724       1.00      1.00      1.00         9
         725       1.00      0.89      0.94         9
         726       0.88      0.78      0.82         9
         727       1.00      1.00      1.00         9
         728       0.75      0.75      0.75         4
         729       0.36      1.00      0.53         4
         730       1.00      1.00      1.00         5
         731       1.00      1.00      1.00         5
         732       0.00      0.00      0.00         4
         733       1.00      0.75      0.86         4
         734       1.00      1.00      1.00         4
         735       0.75      0.75      0.75         4
         736       1.00      0.75      0.86         4
         737       0.89      0.89      0.89         9
         738       0.80      0.89      0.84         9
         739       0.90      1.00      0.95         9
         740       0.00      0.00      0.00         4
         741       0.00      0.00      0.00         4
         742       0.75      1.00      0.86         9
         743       1.00      1.00      1.00         4
         744       0.00      0.00      0.00         4
         745       0.50      0.75      0.60         4
         746       0.82      1.00      0.90         9
         747       1.00      0.50      0.67         4
         748       0.00      0.00      0.00         4
         749       1.00      0.80      0.89         5
         750       1.00      0.80      0.89         5
         751       0.00      0.00      0.00         4
         752       0.00      0.00      0.00         4
         753       0.00      0.00      0.00         9
         754       0.00      0.00      0.00         4
         755       1.00      1.00      1.00         4
         756       1.00      0.80      0.89         5
         757       0.00      0.00      0.00         9
         758       0.60      0.75      0.67         4
         759       0.00      0.00      0.00         4
         760       0.80      1.00      0.89         4
         761       1.00      0.50      0.67         4
         762       1.00      1.00      1.00         4
         763       0.00      0.00      0.00         4
         764       0.71      1.00      0.83         5
         765       1.00      0.40      0.57         5
         766       1.00      1.00      1.00         5
         767       1.00      1.00      1.00         9
         768       1.00      0.75      0.86         4
         769       1.00      0.75      0.86         4
         770       0.80      1.00      0.89         4
         771       1.00      1.00      1.00         5
         772       0.80      1.00      0.89         4
         773       0.88      0.78      0.82         9
         774       0.78      0.78      0.78         9
         775       0.50      1.00      0.67         4
         776       0.00      0.00      0.00         4
         777       0.90      1.00      0.95         9
         778       1.00      1.00      1.00         5
         779       0.80      0.89      0.84         9
         780       0.75      0.75      0.75         4
         781       0.75      0.75      0.75         4
         782       0.00      0.00      0.00         4
         783       1.00      1.00      1.00         4
         784       0.80      1.00      0.89         4
         785       1.00      1.00      1.00         4
         786       1.00      1.00      1.00         4
         787       0.67      0.44      0.53         9
         788       0.00      0.00      0.00         4
         789       0.89      0.89      0.89         9
         790       0.50      0.75      0.60         4
         791       1.00      0.89      0.94         9
         792       1.00      0.50      0.67         4
         793       0.50      0.25      0.33         4
         794       1.00      1.00      1.00         4
         795       1.00      1.00      1.00         5
         796       0.83      1.00      0.91         5
         797       1.00      0.75      0.86         4
         798       0.67      1.00      0.80         4
         799       1.00      0.89      0.94         9
         800       0.67      0.50      0.57         4
         801       1.00      1.00      1.00         4
         802       0.90      1.00      0.95         9
         803       1.00      1.00      1.00         4
         804       0.70      0.78      0.74         9
         805       0.80      0.80      0.80         5
         806       0.60      0.75      0.67         4
         807       0.75      0.60      0.67         5
         808       0.00      0.00      0.00         4
         809       1.00      0.89      0.94         9
         810       0.00      0.00      0.00         4
         811       1.00      1.00      1.00         4
         812       0.75      0.75      0.75         4
         813       1.00      0.75      0.86         4
         814       1.00      0.50      0.67         4
         815       1.00      1.00      1.00         5
         816       0.80      0.80      0.80         5
         817       0.80      1.00      0.89         4
         818       1.00      0.78      0.88         9
         819       0.82      1.00      0.90         9
         820       1.00      0.75      0.86         4
         821       0.80      1.00      0.89         4
         822       1.00      1.00      1.00         4
         823       0.17      0.25      0.20         4
         824       1.00      0.89      0.94         9
         825       1.00      0.50      0.67         4
         826       0.67      1.00      0.80         4
         827       0.75      0.75      0.75         4
         828       0.90      1.00      0.95         9
         829       0.57      1.00      0.73         4
         830       1.00      1.00      1.00         9
         831       0.64      0.78      0.70         9
         832       1.00      0.75      0.86         4
         833       0.67      0.50      0.57         4
         834       1.00      1.00      1.00         4
         835       0.82      1.00      0.90         9
         836       0.00      0.00      0.00         4
         837       1.00      0.89      0.94         9
         838       1.00      1.00      1.00         5
         839       1.00      0.75      0.86         4
         840       1.00      0.80      0.89         5
         841       0.71      0.56      0.63         9
         842       0.00      0.00      0.00         9
         843       1.00      0.80      0.89         5
         844       1.00      0.75      0.86         4
         845       0.80      1.00      0.89         4
         846       0.90      1.00      0.95         9
         847       0.75      0.75      0.75         4
         848       0.80      1.00      0.89         4
         849       0.78      0.78      0.78         9
         850       1.00      0.75      0.86         4
         851       1.00      1.00      1.00         9
         852       1.00      1.00      1.00         4
         853       0.00      0.00      0.00         4
         854       0.80      1.00      0.89         4
         855       1.00      1.00      1.00         4
         856       0.60      0.75      0.67         4
         857       0.90      1.00      0.95         9
         858       1.00      0.67      0.80         9
         859       1.00      0.50      0.67         4
         860       0.75      0.75      0.75         4
         861       0.75      0.75      0.75         4
         862       0.00      0.00      0.00         9
         863       1.00      1.00      1.00         4
         864       1.00      1.00      1.00         5
         865       1.00      0.75      0.86         4
         866       1.00      1.00      1.00         4
         867       1.00      1.00      1.00         9
         868       0.75      0.75      0.75         4
         869       0.00      0.00      0.00         4
         870       0.90      1.00      0.95         9
         871       0.80      0.89      0.84         9
         872       0.89      0.89      0.89         9
         873       0.40      0.40      0.40         5
         874       0.83      1.00      0.91         5
         875       1.00      1.00      1.00         4
         876       0.75      0.75      0.75         4
         877       0.80      1.00      0.89         4
         878       1.00      1.00      1.00         9
         879       0.88      1.00      0.93         7
         880       1.00      1.00      1.00         4
         881       0.00      0.00      0.00         4
         882       0.89      0.89      0.89         9
         883       0.60      0.60      0.60         5
         884       0.80      1.00      0.89         4
         885       0.82      1.00      0.90         9
         886       0.00      0.00      0.00         4
         887       0.64      0.78      0.70         9
         888       0.06      0.25      0.10         4
         889       0.00      0.00      0.00         4
         890       0.82      1.00      0.90         9
         891       1.00      1.00      1.00         4
         892       0.67      1.00      0.80         4
         893       0.80      1.00      0.89         4

    accuracy                           0.74      4917
   macro avg       0.74      0.72      0.71      4917
weighted avg       0.76      0.74      0.74      4917

task_train_time: {0: 0.13122808900000038, 1: 0.03191076600000109, 2: 0.03575819799999991, 3: 0.03537460299999928, 4: 0.03119170499999946, 5: 0.041868438999999924, 6: 0.03169383700000061, 7: 0.030767952000001486, 8: 0.03322301799999927, 9: 0.035794338000000536, 10: 0.030148240000000825, 11: 0.03434990899999946, 12: 0.027887725999999446, 13: 0.03633280600000077, 14: 0.032203007999999755, 15: 0.030350277000000148, 16: 0.037082113000000305, 17: 0.03514273799999934, 18: 0.02984493200000138, 19: 0.0321727160000016, 20: 0.03326425200000038, 21: 0.027096815000000163, 22: 0.034856981000000786, 23: 0.03133492299999929, 24: 0.028770847000000543, 25: 0.03662997599999862, 26: 0.029140686999999943, 27: 0.028525152000000276, 28: 0.03800137599999864, 29: 0.03305079500000119, 30: 0.03337739399999862, 31: 0.032995618999999365, 32: 0.03303162799999981, 33: 0.038190257999996646, 34: 0.02689059900000146, 35: 0.02687924900000027, 36: 0.025127654999998583, 37: 0.026876766000000885, 38: 0.033351514999999665, 39: 0.03182227599999976, 40: 0.03379551899999811, 41: 0.03476398400000136, 42: 0.03707707299999896, 43: 0.0358394440000005}
prediction_time: 0.0003279050000060124
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
