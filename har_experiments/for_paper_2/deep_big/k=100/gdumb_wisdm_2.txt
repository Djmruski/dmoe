Namespace(backbone_type=None, batch_size=20, buffer_size=100, cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
Namespace(backbone_type='incremental', batch_size=20, buffer_size=100, conf_host='elquinto', conf_jobnum='3f13f244-bfa6-4d5c-be52-0c2389d260f2', conf_timestamp='2023-08-13 15:19:03.170957', cutmix_alpha=None, dataid=5, dataset='mod-har', debug_mode=0, disable_log=0, distributed='no', fitting_epochs=250, ignore_other_metrics=0, load_data='', lr=0.0001, maxlr=0.05, minibatch_size=20, minlr=0.0005, model='gdumb_har', n_epochs=1, non_verbose=0, notes=None, nowand=0, ntask=44, optim_mom=0.0, optim_nesterov=0, optim_wd=0.0001, save_path='', seed=None, validation=0, wandb_entity='frahman', wandb_project='mammoth')
====TRAINING TASK: 0
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=34, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=34, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=34, bias=True)
    )
  )
)

Accuracy for 1 task(s): 	 [Class-IL]: 70.0 % 	 [Task-IL]: 49.47 %

====TRAINING TASK: 1
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=54, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=54, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=54, bias=True)
    )
  )
)

Accuracy for 2 task(s): 	 [Class-IL]: 53.64 % 	 [Task-IL]: 40.79 %

====TRAINING TASK: 2
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=74, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=74, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=74, bias=True)
    )
  )
)

Accuracy for 3 task(s): 	 [Class-IL]: 51.45 % 	 [Task-IL]: 35.45 %

====TRAINING TASK: 3
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=94, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=94, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=94, bias=True)
    )
  )
)

Accuracy for 4 task(s): 	 [Class-IL]: 46.08 % 	 [Task-IL]: 30.09 %

====TRAINING TASK: 4
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=114, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=114, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=114, bias=True)
    )
  )
)

Accuracy for 5 task(s): 	 [Class-IL]: 37.05 % 	 [Task-IL]: 29.87 %

====TRAINING TASK: 5
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=134, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=134, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=134, bias=True)
    )
  )
)

Accuracy for 6 task(s): 	 [Class-IL]: 32.67 % 	 [Task-IL]: 27.36 %

====TRAINING TASK: 6
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=154, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=154, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=154, bias=True)
    )
  )
)

Accuracy for 7 task(s): 	 [Class-IL]: 24.62 % 	 [Task-IL]: 27.95 %

====TRAINING TASK: 7
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=174, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=174, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=174, bias=True)
    )
  )
)

Accuracy for 8 task(s): 	 [Class-IL]: 20.8 % 	 [Task-IL]: 27.59 %

====TRAINING TASK: 8
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=194, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=194, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=194, bias=True)
    )
  )
)

Accuracy for 9 task(s): 	 [Class-IL]: 21.78 % 	 [Task-IL]: 27.31 %

====TRAINING TASK: 9
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=214, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=214, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=214, bias=True)
    )
  )
)

Accuracy for 10 task(s): 	 [Class-IL]: 17.42 % 	 [Task-IL]: 27.15 %

====TRAINING TASK: 10
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=234, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=234, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=234, bias=True)
    )
  )
)

Accuracy for 11 task(s): 	 [Class-IL]: 14.65 % 	 [Task-IL]: 26.33 %

====TRAINING TASK: 11
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=254, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=254, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=254, bias=True)
    )
  )
)

Accuracy for 12 task(s): 	 [Class-IL]: 13.13 % 	 [Task-IL]: 26.31 %

====TRAINING TASK: 12
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=274, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=274, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=274, bias=True)
    )
  )
)

Accuracy for 13 task(s): 	 [Class-IL]: 16.27 % 	 [Task-IL]: 26.85 %

====TRAINING TASK: 13
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=294, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=294, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=294, bias=True)
    )
  )
)

Accuracy for 14 task(s): 	 [Class-IL]: 14.49 % 	 [Task-IL]: 27.2 %

====TRAINING TASK: 14
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=314, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=314, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=314, bias=True)
    )
  )
)

Accuracy for 15 task(s): 	 [Class-IL]: 14.2 % 	 [Task-IL]: 26.73 %

====TRAINING TASK: 15
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=334, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=334, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=334, bias=True)
    )
  )
)

Accuracy for 16 task(s): 	 [Class-IL]: 14.31 % 	 [Task-IL]: 26.15 %

====TRAINING TASK: 16
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=354, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=354, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=354, bias=True)
    )
  )
)

Accuracy for 17 task(s): 	 [Class-IL]: 8.54 % 	 [Task-IL]: 25.95 %

====TRAINING TASK: 17
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=374, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=374, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=374, bias=True)
    )
  )
)

Accuracy for 18 task(s): 	 [Class-IL]: 11.36 % 	 [Task-IL]: 25.69 %

====TRAINING TASK: 18
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=394, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=394, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=394, bias=True)
    )
  )
)

Accuracy for 19 task(s): 	 [Class-IL]: 12.31 % 	 [Task-IL]: 25.97 %

====TRAINING TASK: 19
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=414, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=414, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=414, bias=True)
    )
  )
)

Accuracy for 20 task(s): 	 [Class-IL]: 13.03 % 	 [Task-IL]: 26.05 %

====TRAINING TASK: 20
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=434, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=434, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=434, bias=True)
    )
  )
)

Accuracy for 21 task(s): 	 [Class-IL]: 9.78 % 	 [Task-IL]: 26.23 %

====TRAINING TASK: 21
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=454, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=454, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=454, bias=True)
    )
  )
)

Accuracy for 22 task(s): 	 [Class-IL]: 10.11 % 	 [Task-IL]: 25.96 %

====TRAINING TASK: 22
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=474, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=474, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=474, bias=True)
    )
  )
)

Accuracy for 23 task(s): 	 [Class-IL]: 9.81 % 	 [Task-IL]: 25.79 %

====TRAINING TASK: 23
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=494, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=494, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=494, bias=True)
    )
  )
)

Accuracy for 24 task(s): 	 [Class-IL]: 10.14 % 	 [Task-IL]: 25.7 %

====TRAINING TASK: 24
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=514, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=514, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=514, bias=True)
    )
  )
)

Accuracy for 25 task(s): 	 [Class-IL]: 8.58 % 	 [Task-IL]: 26.22 %

====TRAINING TASK: 25
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=534, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=534, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=534, bias=True)
    )
  )
)

Accuracy for 26 task(s): 	 [Class-IL]: 8.01 % 	 [Task-IL]: 26.51 %

====TRAINING TASK: 26
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=554, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=554, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=554, bias=True)
    )
  )
)

Accuracy for 27 task(s): 	 [Class-IL]: 6.13 % 	 [Task-IL]: 26.73 %

====TRAINING TASK: 27
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=574, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=574, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=574, bias=True)
    )
  )
)

Accuracy for 28 task(s): 	 [Class-IL]: 6.48 % 	 [Task-IL]: 26.87 %

====TRAINING TASK: 28
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=594, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=594, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=594, bias=True)
    )
  )
)

Accuracy for 29 task(s): 	 [Class-IL]: 7.16 % 	 [Task-IL]: 26.46 %

====TRAINING TASK: 29
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=614, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=614, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=614, bias=True)
    )
  )
)

Accuracy for 30 task(s): 	 [Class-IL]: 6.3 % 	 [Task-IL]: 26.69 %

====TRAINING TASK: 30
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=634, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=634, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=634, bias=True)
    )
  )
)

Accuracy for 31 task(s): 	 [Class-IL]: 5.62 % 	 [Task-IL]: 27.11 %

====TRAINING TASK: 31
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=654, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=654, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=654, bias=True)
    )
  )
)

Accuracy for 32 task(s): 	 [Class-IL]: 5.4 % 	 [Task-IL]: 27.23 %

====TRAINING TASK: 32
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=674, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=674, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=674, bias=True)
    )
  )
)

Accuracy for 33 task(s): 	 [Class-IL]: 7.09 % 	 [Task-IL]: 26.81 %

====TRAINING TASK: 33
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=694, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=694, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=694, bias=True)
    )
  )
)

Accuracy for 34 task(s): 	 [Class-IL]: 6.82 % 	 [Task-IL]: 26.84 %

====TRAINING TASK: 34
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=714, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=714, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=714, bias=True)
    )
  )
)

Accuracy for 35 task(s): 	 [Class-IL]: 6.47 % 	 [Task-IL]: 26.49 %

====TRAINING TASK: 35
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=734, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=734, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=734, bias=True)
    )
  )
)

Accuracy for 36 task(s): 	 [Class-IL]: 6.69 % 	 [Task-IL]: 26.7 %

====TRAINING TASK: 36
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=754, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=754, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=754, bias=True)
    )
  )
)

Accuracy for 37 task(s): 	 [Class-IL]: 6.99 % 	 [Task-IL]: 26.45 %

====TRAINING TASK: 37
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=774, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=774, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=774, bias=True)
    )
  )
)

Accuracy for 38 task(s): 	 [Class-IL]: 5.12 % 	 [Task-IL]: 26.17 %

====TRAINING TASK: 38
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=794, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=794, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=794, bias=True)
    )
  )
)

Accuracy for 39 task(s): 	 [Class-IL]: 6.68 % 	 [Task-IL]: 25.95 %

====TRAINING TASK: 39
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=814, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=814, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=814, bias=True)
    )
  )
)

Accuracy for 40 task(s): 	 [Class-IL]: 4.33 % 	 [Task-IL]: 26.05 %

====TRAINING TASK: 40
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=834, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=834, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=834, bias=True)
    )
  )
)

Accuracy for 41 task(s): 	 [Class-IL]: 5.1 % 	 [Task-IL]: 26.33 %

====TRAINING TASK: 41
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=854, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=854, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=854, bias=True)
    )
  )
)

Accuracy for 42 task(s): 	 [Class-IL]: 4.57 % 	 [Task-IL]: 26.23 %

====TRAINING TASK: 42
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=874, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=874, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=874, bias=True)
    )
  )
)

Accuracy for 43 task(s): 	 [Class-IL]: 4.66 % 	 [Task-IL]: 25.84 %

====TRAINING TASK: 43
SimpleMLP(
  (fc1): Linear(in_features=91, out_features=1000, bias=True)
  (fc2): Linear(in_features=1000, out_features=894, bias=True)
  (_features): Identity()
  (classifier): Sequential(
    (0): Linear(in_features=91, out_features=1000, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1000, out_features=894, bias=True)
  )
  (net): Sequential(
    (0): Identity()
    (1): Sequential(
      (0): Linear(in_features=91, out_features=1000, bias=True)
      (1): ReLU()
      (2): Linear(in_features=1000, out_features=894, bias=True)
    )
  )
)
torch.Size([89400, 91])
	LABELS: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503
 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521
 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539
 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557
 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575
 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593
 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611
 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629
 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647
 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665
 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683
 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701
 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719
 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737
 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755
 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773
 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791
 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809
 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827
 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845
 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863
 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881
 882 883 884 885 886 887 888 889 890 891 892 893]	Counter({0: 74907, 534: 34, 873: 34, 83: 33, 646: 33, 694: 33, 798: 33, 844: 33, 863: 33, 161: 32, 183: 32, 223: 32, 326: 32, 351: 32, 605: 32, 630: 32, 771: 32, 835: 32, 867: 32, 882: 32, 24: 31, 16: 31, 53: 31, 64: 31, 97: 31, 100: 31, 94: 31, 127: 31, 135: 31, 169: 31, 232: 31, 246: 31, 274: 31, 391: 31, 469: 31, 498: 31, 606: 31, 615: 31, 677: 31, 687: 31, 759: 31, 840: 31, 11: 30, 37: 30, 63: 30, 89: 30, 166: 30, 206: 30, 214: 30, 250: 30, 238: 30, 288: 30, 276: 30, 292: 30, 320: 30, 350: 30, 344: 30, 395: 30, 431: 30, 446: 30, 464: 30, 470: 30, 495: 30, 529: 30, 527: 30, 569: 30, 591: 30, 578: 30, 647: 30, 650: 30, 661: 30, 748: 30, 739: 30, 743: 30, 772: 30, 765: 30, 808: 30, 818: 30, 851: 30, 866: 30, 7: 29, 32: 29, 21: 29, 48: 29, 93: 29, 96: 29, 133: 29, 156: 29, 165: 29, 193: 29, 181: 29, 209: 29, 213: 29, 234: 29, 346: 29, 352: 29, 370: 29, 365: 29, 356: 29, 430: 29, 419: 29, 420: 29, 439: 29, 490: 29, 539: 29, 537: 29, 582: 29, 613: 29, 607: 29, 638: 29, 657: 29, 654: 29, 685: 29, 731: 29, 751: 29, 796: 29, 813: 29, 67: 28, 106: 28, 105: 28, 121: 28, 124: 28, 143: 28, 164: 28, 221: 28, 224: 28, 229: 28, 242: 28, 269: 28, 285: 28, 290: 28, 287: 28, 294: 28, 315: 28, 367: 28, 433: 28, 457: 28, 488: 28, 492: 28, 475: 28, 508: 28, 518: 28, 519: 28, 536: 28, 576: 28, 588: 28, 616: 28, 626: 28, 653: 28, 693: 28, 763: 28, 777: 28, 794: 28, 805: 28, 838: 28, 865: 28, 884: 28, 883: 28, 10: 27, 8: 27, 108: 27, 137: 27, 150: 27, 159: 27, 230: 27, 227: 27, 237: 27, 301: 27, 303: 27, 376: 27, 382: 27, 448: 27, 447: 27, 472: 27, 497: 27, 525: 27, 524: 27, 570: 27, 564: 27, 579: 27, 596: 27, 627: 27, 665: 27, 678: 27, 713: 27, 714: 27, 780: 27, 795: 27, 832: 27, 862: 27, 44: 26, 39: 26, 92: 26, 103: 26, 182: 26, 254: 26, 289: 26, 389: 26, 379: 26, 394: 26, 418: 26, 416: 26, 483: 26, 509: 26, 514: 26, 540: 26, 601: 26, 689: 26, 778: 26, 876: 26, 120: 25, 167: 25, 259: 25, 334: 25, 341: 25, 371: 25, 610: 25, 617: 25, 644: 25, 667: 25, 783: 25, 803: 25, 815: 25, 861: 25, 101: 24, 162: 24, 240: 24, 249: 24, 612: 24, 618: 24, 634: 24, 698: 24, 820: 24, 864: 24, 202: 23, 443: 23, 456: 22, 860: 22, 38: 20, 12: 19, 18: 19, 184: 19, 20: 17, 144: 17, 357: 17, 423: 17, 528: 17, 602: 17, 662: 17, 729: 17, 66: 16, 58: 16, 111: 16, 122: 16, 177: 16, 174: 16, 175: 16, 225: 16, 236: 16, 265: 16, 343: 16, 372: 16, 392: 16, 387: 16, 521: 16, 574: 16, 614: 16, 671: 16, 691: 16, 785: 16, 782: 16, 839: 16, 47: 15, 73: 15, 81: 15, 90: 15, 112: 15, 141: 15, 173: 15, 154: 15, 205: 15, 203: 15, 198: 15, 199: 15, 200: 15, 241: 15, 256: 15, 264: 15, 312: 15, 307: 15, 325: 15, 330: 15, 335: 15, 403: 15, 405: 15, 442: 15, 468: 15, 507: 15, 543: 15, 558: 15, 560: 15, 581: 15, 629: 15, 700: 15, 699: 15, 720: 15, 764: 15, 817: 15, 830: 15, 874: 15, 33: 14, 5: 14, 15: 14, 128: 14, 151: 14, 172: 14, 233: 14, 272: 14, 283: 14, 300: 14, 329: 14, 353: 14, 340: 14, 347: 14, 338: 14, 437: 14, 434: 14, 444: 14, 462: 14, 485: 14, 474: 14, 502: 14, 506: 14, 544: 14, 535: 14, 554: 14, 642: 14, 655: 14, 702: 14, 708: 14, 724: 14, 715: 14, 762: 14, 768: 14, 779: 14, 793: 14, 781: 14, 800: 14, 807: 14, 799: 14, 881: 14, 887: 14, 877: 14, 6: 13, 45: 13, 40: 13, 46: 13, 60: 13, 59: 13, 82: 13, 76: 13, 84: 13, 104: 13, 110: 13, 115: 13, 126: 13, 139: 13, 138: 13, 136: 13, 192: 13, 195: 13, 196: 13, 226: 13, 231: 13, 222: 13, 252: 13, 253: 13, 248: 13, 266: 13, 257: 13, 282: 13, 278: 13, 286: 13, 296: 13, 317: 13, 323: 13, 348: 13, 386: 13, 385: 13, 381: 13, 400: 13, 408: 13, 409: 13, 425: 13, 427: 13, 429: 13, 440: 13, 452: 13, 451: 13, 450: 13, 466: 13, 467: 13, 459: 13, 484: 13, 491: 13, 479: 13, 486: 13, 477: 13, 503: 13, 511: 13, 516: 13, 523: 13, 546: 13, 556: 13, 568: 13, 555: 13, 565: 13, 557: 13, 566: 13, 587: 13, 590: 13, 598: 13, 609: 13, 600: 13, 595: 13, 623: 13, 633: 13, 622: 13, 624: 13, 620: 13, 641: 13, 636: 13, 672: 13, 659: 13, 658: 13, 690: 13, 686: 13, 688: 13, 675: 13, 696: 13, 712: 13, 725: 13, 718: 13, 738: 13, 737: 13, 749: 13, 757: 13, 755: 13, 769: 13, 754: 13, 792: 13, 776: 13, 790: 13, 812: 13, 811: 13, 802: 13, 826: 13, 825: 13, 821: 13, 829: 13, 827: 13, 841: 13, 854: 13, 856: 13, 885: 13, 888: 13, 886: 13, 31: 12, 19: 12, 3: 12, 42: 12, 50: 12, 49: 12, 51: 12, 72: 12, 62: 12, 86: 12, 87: 12, 91: 12, 77: 12, 109: 12, 129: 12, 125: 12, 131: 12, 147: 12, 146: 12, 149: 12, 171: 12, 155: 12, 187: 12, 211: 12, 194: 12, 204: 12, 239: 12, 235: 12, 263: 12, 255: 12, 262: 12, 261: 12, 268: 12, 271: 12, 293: 12, 291: 12, 310: 12, 304: 12, 308: 12, 297: 12, 295: 12, 305: 12, 309: 12, 302: 12, 333: 12, 318: 12, 342: 12, 336: 12, 363: 12, 373: 12, 360: 12, 359: 12, 362: 12, 375: 12, 388: 12, 374: 12, 393: 12, 390: 12, 377: 12, 411: 12, 398: 12, 413: 12, 406: 12, 401: 12, 410: 12, 397: 12, 422: 12, 424: 12, 414: 12, 426: 12, 445: 12, 458: 12, 465: 12, 471: 12, 478: 12, 476: 12, 499: 12, 513: 12, 504: 12, 526: 12, 522: 12, 530: 12, 532: 12, 533: 12, 547: 12, 538: 12, 551: 12, 550: 12, 541: 12, 545: 12, 571: 12, 583: 12, 593: 12, 608: 12, 599: 12, 603: 12, 625: 12, 631: 12, 639: 12, 652: 12, 648: 12, 640: 12, 660: 12, 656: 12, 668: 12, 666: 12, 679: 12, 710: 12, 703: 12, 716: 12, 719: 12, 726: 12, 752: 12, 734: 12, 746: 12, 750: 12, 740: 12, 787: 12, 775: 12, 809: 12, 823: 12, 822: 12, 833: 12, 819: 12, 848: 12, 852: 12, 871: 12, 868: 12, 857: 12, 859: 12, 889: 12, 875: 12, 1: 11, 27: 11, 9: 11, 25: 11, 4: 11, 71: 11, 65: 11, 69: 11, 61: 11, 54: 11, 88: 11, 75: 11, 80: 11, 79: 11, 74: 11, 98: 11, 99: 11, 113: 11, 130: 11, 117: 11, 132: 11, 118: 11, 116: 11, 119: 11, 114: 11, 145: 11, 168: 11, 157: 11, 163: 11, 158: 11, 191: 11, 186: 11, 180: 11, 179: 11, 207: 11, 197: 11, 219: 11, 217: 11, 247: 11, 251: 11, 245: 11, 270: 11, 260: 11, 284: 11, 280: 11, 277: 11, 321: 11, 324: 11, 319: 11, 327: 11, 349: 11, 339: 11, 337: 11, 358: 11, 366: 11, 354: 11, 361: 11, 380: 11, 421: 11, 415: 11, 441: 11, 461: 11, 454: 11, 487: 11, 482: 11, 493: 11, 505: 11, 500: 11, 510: 11, 512: 11, 496: 11, 515: 11, 517: 11, 553: 11, 562: 11, 573: 11, 563: 11, 592: 11, 577: 11, 604: 11, 597: 11, 594: 11, 611: 11, 621: 11, 635: 11, 637: 11, 649: 11, 664: 11, 663: 11, 673: 11, 684: 11, 692: 11, 704: 11, 695: 11, 705: 11, 727: 11, 721: 11, 733: 11, 741: 11, 736: 11, 745: 11, 758: 11, 789: 11, 774: 11, 788: 11, 784: 11, 801: 11, 797: 11, 824: 11, 831: 11, 814: 11, 836: 11, 847: 11, 853: 11, 846: 11, 849: 11, 858: 11, 879: 11, 878: 11, 892: 11, 23: 10, 29: 10, 13: 10, 30: 10, 43: 10, 52: 10, 36: 10, 57: 10, 55: 10, 68: 10, 70: 10, 102: 10, 107: 10, 123: 10, 140: 10, 152: 10, 142: 10, 153: 10, 160: 10, 189: 10, 185: 10, 210: 10, 201: 10, 212: 10, 216: 10, 228: 10, 218: 10, 215: 10, 243: 10, 258: 10, 273: 10, 279: 10, 306: 10, 299: 10, 313: 10, 298: 10, 316: 10, 328: 10, 331: 10, 322: 10, 345: 10, 369: 10, 368: 10, 378: 10, 383: 10, 399: 10, 407: 10, 404: 10, 396: 10, 412: 10, 402: 10, 432: 10, 449: 10, 435: 10, 455: 10, 460: 10, 481: 10, 489: 10, 501: 10, 552: 10, 567: 10, 561: 10, 572: 10, 575: 10, 589: 10, 585: 10, 580: 10, 584: 10, 632: 10, 669: 10, 683: 10, 676: 10, 682: 10, 711: 10, 707: 10, 701: 10, 706: 10, 732: 10, 722: 10, 730: 10, 728: 10, 717: 10, 747: 10, 770: 10, 773: 10, 760: 10, 761: 10, 791: 10, 804: 10, 810: 10, 816: 10, 845: 10, 850: 10, 869: 10, 870: 10, 855: 10, 872: 10, 891: 10, 890: 10, 893: 10, 17: 9, 14: 9, 2: 9, 28: 9, 22: 9, 26: 9, 41: 9, 34: 9, 35: 9, 78: 9, 95: 9, 148: 9, 176: 9, 178: 9, 244: 9, 267: 9, 281: 9, 311: 9, 314: 9, 332: 9, 355: 9, 364: 9, 428: 9, 453: 9, 438: 9, 436: 9, 463: 9, 520: 9, 531: 9, 548: 9, 549: 9, 559: 9, 586: 9, 628: 9, 619: 9, 645: 9, 670: 9, 680: 9, 681: 9, 697: 9, 709: 9, 723: 9, 735: 9, 744: 9, 756: 9, 786: 9, 806: 9, 843: 9, 842: 9, 837: 9, 834: 9, 880: 9, 56: 8, 85: 8, 134: 8, 170: 8, 190: 8, 220: 8, 417: 8, 494: 8, 542: 8, 651: 8, 643: 8, 674: 8, 742: 8, 766: 8, 767: 8, 828: 8, 188: 7, 208: 7, 275: 7, 384: 7, 473: 7, 480: 7, 753: 7})
Total buffer: 89400
fit_time: 124.413083086

Accuracy for 44 task(s): 	 [Class-IL]: 74.07 % 	 [Task-IL]: 31.02 %

CLASS_IL_ACC: 
	[71.57894736842105, 82.72727272727273, 70.70707070707071, 67.3076923076923, 84.375, 70.64220183486239, 74.03846153846155, 81.88976377952756, 76.19047619047619, 61.904761904761905, 83.87096774193549, 88.6178861788618, 73.73737373737373, 63.114754098360656, 76.53061224489795, 70.40816326530613, 72.1311475409836, 70.09345794392523, 84.25925925925925, 65.95744680851064, 64.65517241379311, 74.76635514018692, 82.88288288288288, 80.37383177570094, 71.55963302752293, 83.19327731092437, 71.55963302752293, 78.0, 69.02654867256636, 85.48387096774194, 77.31092436974791, 67.82608695652173, 69.0909090909091, 60.36036036036037, 65.3061224489796, 56.38297872340425, 66.33663366336634, 66.97247706422019, 79.8076923076923, 79.03225806451613, 87.25490196078431, 73.14814814814815, 72.0, 86.79245283018868]
TASK_IL_ACC: 
	[58.94736842105262, 33.63636363636363, 25.252525252525253, 22.115384615384613, 30.46875, 18.34862385321101, 31.73076923076923, 25.984251968503933, 24.761904761904763, 24.761904761904763, 21.774193548387096, 28.455284552845526, 34.34343434343434, 27.049180327868854, 28.57142857142857, 24.489795918367346, 24.59016393442623, 25.233644859813083, 30.555555555555557, 36.17021276595745, 26.72413793103448, 28.037383177570092, 27.927927927927925, 26.168224299065418, 35.77981651376147, 31.932773109243694, 39.44954128440367, 27.0, 33.6283185840708, 25.0, 37.81512605042017, 28.695652173913043, 31.818181818181817, 28.82882882882883, 33.6734693877551, 27.659574468085108, 27.722772277227726, 24.770642201834864, 32.69230769230769, 35.483870967741936, 31.372549019607842, 30.555555555555557, 17.599999999999998, 97.16981132075472]
f1_micro: 74.27293064876959
f1_macro: 71.53821630810391
              precision    recall  f1-score   support

           0       0.88      0.78      0.82         9
           1       1.00      1.00      1.00         4
           2       0.67      1.00      0.80         4
           3       1.00      1.00      1.00         4
           4       0.00      0.00      0.00         4
           5       1.00      0.50      0.67         4
           6       0.57      1.00      0.73         4
           7       0.47      0.89      0.62         9
           8       1.00      0.89      0.94         9
           9       0.00      0.00      0.00         4
          10       0.80      0.89      0.84         9
          11       0.67      0.67      0.67         9
          12       0.33      0.40      0.36         5
          13       0.00      0.00      0.00         4
          14       0.00      0.00      0.00         4
          15       1.00      0.80      0.89         5
          16       1.00      0.89      0.94         9
          17       1.00      1.00      1.00         4
          18       0.50      0.43      0.46         7
          19       0.60      0.60      0.60         5
          20       0.80      0.80      0.80         5
          21       0.90      1.00      0.95         9
          22       0.00      0.00      0.00         4
          23       0.80      1.00      0.89         4
          24       1.00      0.89      0.94         9
          25       1.00      1.00      1.00         5
          26       1.00      1.00      1.00         4
          27       0.80      1.00      0.89         4
          28       1.00      0.75      0.86         4
          29       1.00      0.75      0.86         4
          30       0.50      0.25      0.33         4
          31       0.00      0.00      0.00         4
          32       0.90      1.00      0.95         9
          33       0.75      0.60      0.67         5
          34       0.80      1.00      0.89         4
          35       0.75      0.75      0.75         4
          36       1.00      1.00      1.00         5
          37       1.00      1.00      1.00         9
          38       1.00      1.00      1.00         7
          39       0.88      0.88      0.88         8
          40       0.57      1.00      0.73         4
          41       0.00      0.00      0.00         4
          42       1.00      0.75      0.86         4
          43       1.00      1.00      1.00         4
          44       0.89      0.89      0.89         9
          45       0.25      0.50      0.33         4
          46       0.00      0.00      0.00         4
          47       1.00      1.00      1.00         5
          48       0.82      1.00      0.90         9
          49       0.80      1.00      0.89         4
          50       0.00      0.00      0.00         4
          51       1.00      1.00      1.00         5
          52       1.00      0.75      0.86         4
          53       1.00      1.00      1.00         9
          54       0.80      1.00      0.89         4
          55       1.00      0.75      0.86         4
          56       0.00      0.00      0.00         4
          57       0.60      0.75      0.67         4
          58       1.00      1.00      1.00         5
          59       1.00      1.00      1.00         4
          60       0.75      0.75      0.75         4
          61       0.40      0.40      0.40         5
          62       0.80      1.00      0.89         4
          63       0.80      0.89      0.84         9
          64       0.00      0.00      0.00         9
          65       1.00      0.75      0.86         4
          66       0.57      0.80      0.67         5
          67       1.00      1.00      1.00         9
          68       1.00      1.00      1.00         4
          69       0.80      1.00      0.89         4
          70       0.75      0.75      0.75         4
          71       0.50      0.50      0.50         4
          72       0.00      0.00      0.00         4
          73       0.62      1.00      0.77         5
          74       1.00      0.50      0.67         4
          75       0.67      0.50      0.57         4
          76       0.67      1.00      0.80         4
          77       0.00      0.00      0.00         4
          78       0.75      0.75      0.75         4
          79       1.00      0.75      0.86         4
          80       1.00      1.00      1.00         4
          81       1.00      1.00      1.00         5
          82       0.50      0.20      0.29         5
          83       0.90      1.00      0.95         9
          84       0.00      0.00      0.00         4
          85       0.33      0.25      0.29         4
          86       0.80      1.00      0.89         4
          87       0.83      1.00      0.91         5
          88       1.00      1.00      1.00         4
          89       1.00      0.44      0.62         9
          90       0.62      1.00      0.77         5
          91       0.50      0.75      0.60         4
          92       0.60      0.33      0.43         9
          93       0.89      0.89      0.89         9
          94       1.00      0.78      0.88         9
          95       0.80      1.00      0.89         4
          96       0.90      1.00      0.95         9
          97       0.82      1.00      0.90         9
          98       0.00      0.00      0.00         4
          99       1.00      1.00      1.00         4
         100       0.80      0.89      0.84         9
         101       0.88      0.78      0.82         9
         102       1.00      1.00      1.00         4
         103       0.82      1.00      0.90         9
         104       0.67      1.00      0.80         4
         105       0.73      0.89      0.80         9
         106       0.82      1.00      0.90         9
         107       0.00      0.00      0.00         4
         108       0.90      1.00      0.95         9
         109       0.33      0.40      0.36         5
         110       0.67      0.50      0.57         4
         111       1.00      1.00      1.00         5
         112       0.67      0.80      0.73         5
         113       1.00      1.00      1.00         4
         114       0.00      0.00      0.00         4
         115       0.43      0.60      0.50         5
         116       0.75      0.75      0.75         4
         117       0.75      0.75      0.75         4
         118       1.00      1.00      1.00         4
         119       0.00      0.00      0.00         4
         120       0.90      1.00      0.95         9
         121       0.00      0.00      0.00         9
         122       1.00      1.00      1.00         5
         123       1.00      1.00      1.00         4
         124       0.73      0.89      0.80         9
         125       1.00      1.00      1.00         5
         126       1.00      0.75      0.86         4
         127       1.00      0.89      0.94         9
         128       0.83      1.00      0.91         5
         129       0.00      0.00      0.00         4
         130       0.57      1.00      0.73         4
         131       1.00      0.75      0.86         4
         132       0.50      0.25      0.33         4
         133       0.90      1.00      0.95         9
         134       1.00      0.25      0.40         4
         135       0.73      0.89      0.80         9
         136       1.00      1.00      1.00         4
         137       0.89      0.89      0.89         9
         138       1.00      0.75      0.86         4
         139       1.00      0.75      0.86         4
         140       0.60      0.75      0.67         4
         141       1.00      1.00      1.00         5
         142       0.80      1.00      0.89         4
         143       0.00      0.00      0.00         9
         144       0.75      0.60      0.67         5
         145       0.67      0.50      0.57         4
         146       0.33      0.25      0.29         4
         147       0.57      1.00      0.73         4
         148       0.80      1.00      0.89         4
         149       1.00      1.00      1.00         4
         150       1.00      1.00      1.00         9
         151       1.00      0.40      0.57         5
         152       0.83      1.00      0.91         5
         153       1.00      1.00      1.00         4
         154       0.67      0.80      0.73         5
         155       0.75      0.75      0.75         4
         156       0.07      0.33      0.12         9
         157       0.33      0.25      0.29         4
         158       0.75      0.75      0.75         4
         159       0.88      0.78      0.82         9
         160       0.80      1.00      0.89         4
         161       1.00      1.00      1.00         9
         162       0.75      0.67      0.71         9
         163       1.00      0.75      0.86         4
         164       0.89      0.89      0.89         9
         165       0.82      1.00      0.90         9
         166       0.82      1.00      0.90         9
         167       0.90      1.00      0.95         9
         168       1.00      1.00      1.00         4
         169       0.75      1.00      0.86         9
         170       0.75      0.75      0.75         4
         171       0.67      1.00      0.80         4
         172       0.60      0.75      0.67         4
         173       0.38      0.60      0.46         5
         174       0.75      0.60      0.67         5
         175       0.80      0.80      0.80         5
         176       1.00      0.75      0.86         4
         177       0.83      1.00      0.91         5
         178       1.00      1.00      1.00         4
         179       1.00      1.00      1.00         4
         180       0.00      0.00      0.00         4
         181       0.89      0.89      0.89         9
         182       1.00      1.00      1.00         9
         183       1.00      0.78      0.88         9
         184       0.83      0.83      0.83         6
         185       1.00      1.00      1.00         4
         186       0.75      0.75      0.75         4
         187       1.00      0.75      0.86         4
         188       1.00      0.75      0.86         4
         189       1.00      0.75      0.86         4
         190       0.00      0.00      0.00         4
         191       1.00      1.00      1.00         4
         192       0.00      0.00      0.00         4
         193       1.00      0.89      0.94         9
         194       0.67      0.50      0.57         4
         195       0.00      0.00      0.00         4
         196       0.80      1.00      0.89         4
         197       1.00      1.00      1.00         4
         198       1.00      0.60      0.75         5
         199       1.00      1.00      1.00         5
         200       0.83      1.00      0.91         5
         201       1.00      1.00      1.00         4
         202       0.50      0.22      0.31         9
         203       1.00      0.80      0.89         5
         204       1.00      1.00      1.00         4
         205       0.71      1.00      0.83         5
         206       0.88      0.78      0.82         9
         207       0.67      0.50      0.57         4
         208       0.67      0.50      0.57         4
         209       1.00      0.89      0.94         9
         210       0.00      0.00      0.00         4
         211       1.00      1.00      1.00         4
         212       0.00      0.00      0.00         4
         213       0.00      0.00      0.00         9
         214       0.78      0.78      0.78         9
         215       0.67      1.00      0.80         4
         216       1.00      1.00      1.00         4
         217       0.75      0.75      0.75         4
         218       1.00      1.00      1.00         4
         219       1.00      0.60      0.75         5
         220       1.00      0.75      0.86         4
         221       0.83      0.56      0.67         9
         222       0.80      1.00      0.89         4
         223       1.00      0.78      0.88         9
         224       1.00      1.00      1.00         9
         225       0.83      1.00      0.91         5
         226       1.00      1.00      1.00         4
         227       1.00      1.00      1.00         9
         228       0.80      1.00      0.89         4
         229       0.90      1.00      0.95         9
         230       1.00      0.89      0.94         9
         231       0.83      1.00      0.91         5
         232       0.75      0.33      0.46         9
         233       0.80      0.80      0.80         5
         234       0.90      1.00      0.95         9
         235       1.00      0.25      0.40         4
         236       1.00      0.80      0.89         5
         237       0.82      1.00      0.90         9
         238       0.90      1.00      0.95         9
         239       1.00      0.75      0.86         4
         240       0.82      1.00      0.90         9
         241       1.00      1.00      1.00         5
         242       0.89      0.89      0.89         9
         243       1.00      0.75      0.86         4
         244       1.00      1.00      1.00         4
         245       1.00      1.00      1.00         4
         246       1.00      1.00      1.00         9
         247       1.00      0.75      0.86         4
         248       1.00      0.40      0.57         5
         249       0.89      0.89      0.89         9
         250       0.80      0.89      0.84         9
         251       0.80      1.00      0.89         4
         252       1.00      1.00      1.00         4
         253       0.60      0.75      0.67         4
         254       0.62      0.89      0.73         9
         255       0.67      0.50      0.57         4
         256       1.00      1.00      1.00         5
         257       1.00      1.00      1.00         5
         258       0.00      0.00      0.00         4
         259       1.00      0.89      0.94         9
         260       1.00      1.00      1.00         4
         261       0.50      0.25      0.33         4
         262       0.00      0.00      0.00         4
         263       0.00      0.00      0.00         4
         264       0.71      1.00      0.83         5
         265       0.83      1.00      0.91         5
         266       0.80      1.00      0.89         4
         267       0.00      0.00      0.00         4
         268       1.00      0.75      0.86         4
         269       0.89      0.89      0.89         9
         270       1.00      1.00      1.00         4
         271       0.80      1.00      0.89         4
         272       1.00      0.75      0.86         4
         273       0.80      1.00      0.89         4
         274       1.00      0.89      0.94         9
         275       0.00      0.00      0.00         4
         276       0.90      1.00      0.95         9
         277       1.00      1.00      1.00         4
         278       0.83      1.00      0.91         5
         279       0.00      0.00      0.00         4
         280       0.00      0.00      0.00         4
         281       0.80      1.00      0.89         4
         282       0.00      0.00      0.00         4
         283       1.00      1.00      1.00         5
         284       0.00      0.00      0.00         4
         285       0.50      0.56      0.53         9
         286       0.75      0.75      0.75         4
         287       0.89      0.89      0.89         9
         288       1.00      1.00      1.00         9
         289       1.00      0.89      0.94         9
         290       0.83      0.56      0.67         9
         291       0.00      0.00      0.00         4
         292       0.00      0.00      0.00         9
         293       0.80      1.00      0.89         4
         294       0.90      1.00      0.95         9
         295       1.00      0.50      0.67         4
         296       1.00      1.00      1.00         4
         297       0.80      1.00      0.89         4
         298       0.00      0.00      0.00         4
         299       0.00      0.00      0.00         4
         300       1.00      1.00      1.00         4
         301       0.90      1.00      0.95         9
         302       0.60      0.75      0.67         4
         303       0.67      0.89      0.76         9
         304       0.80      1.00      0.89         4
         305       1.00      0.75      0.86         4
         306       0.80      1.00      0.89         4
         307       1.00      0.80      0.89         5
         308       0.50      0.40      0.44         5
         309       1.00      1.00      1.00         4
         310       0.50      0.25      0.33         4
         311       1.00      0.75      0.86         4
         312       0.75      0.60      0.67         5
         313       0.80      1.00      0.89         4
         314       1.00      1.00      1.00         4
         315       1.00      0.89      0.94         9
         316       0.00      0.00      0.00         4
         317       1.00      0.75      0.86         4
         318       0.75      0.75      0.75         4
         319       0.00      0.00      0.00         4
         320       1.00      0.89      0.94         9
         321       0.67      1.00      0.80         4
         322       1.00      1.00      1.00         4
         323       0.83      1.00      0.91         5
         324       1.00      0.75      0.86         4
         325       0.00      0.00      0.00         4
         326       1.00      0.78      0.88         9
         327       1.00      0.25      0.40         4
         328       0.25      0.25      0.25         4
         329       1.00      1.00      1.00         5
         330       1.00      1.00      1.00         5
         331       0.00      0.00      0.00         4
         332       1.00      1.00      1.00         4
         333       1.00      1.00      1.00         4
         334       1.00      1.00      1.00         9
         335       0.67      0.80      0.73         5
         336       0.60      0.60      0.60         5
         337       1.00      1.00      1.00         4
         338       0.71      1.00      0.83         5
         339       1.00      1.00      1.00         4
         340       0.80      0.80      0.80         5
         341       0.70      0.78      0.74         9
         342       1.00      1.00      1.00         4
         343       1.00      0.80      0.89         5
         344       0.90      1.00      0.95         9
         345       0.00      0.00      0.00         4
         346       0.62      0.89      0.73         9
         347       0.75      0.60      0.67         5
         348       0.00      0.00      0.00         4
         349       0.00      0.00      0.00         4
         350       0.90      1.00      0.95         9
         351       0.00      0.00      0.00         9
         352       0.75      0.67      0.71         9
         353       1.00      1.00      1.00         5
         354       1.00      1.00      1.00         4
         355       0.50      0.50      0.50         4
         356       1.00      0.89      0.94         9
         357       1.00      1.00      1.00         5
         358       0.80      1.00      0.89         4
         359       0.00      0.00      0.00         4
         360       1.00      0.25      0.40         4
         361       1.00      1.00      1.00         4
         362       0.50      0.50      0.50         4
         363       0.60      0.75      0.67         4
         364       0.75      0.75      0.75         4
         365       0.78      0.78      0.78         9
         366       0.00      0.00      0.00         4
         367       1.00      0.89      0.94         9
         368       0.75      0.75      0.75         4
         369       0.00      0.00      0.00         4
         370       1.00      1.00      1.00         9
         371       0.67      0.67      0.67         9
         372       0.75      0.60      0.67         5
         373       0.60      0.75      0.67         4
         374       1.00      0.75      0.86         4
         375       1.00      0.75      0.86         4
         376       0.86      0.67      0.75         9
         377       0.80      1.00      0.89         4
         378       1.00      0.75      0.86         4
         379       0.80      0.89      0.84         9
         380       1.00      0.50      0.67         4
         381       0.67      0.80      0.73         5
         382       0.90      1.00      0.95         9
         383       0.80      1.00      0.89         4
         384       1.00      1.00      1.00         4
         385       0.60      0.75      0.67         4
         386       0.50      0.50      0.50         4
         387       0.83      1.00      0.91         5
         388       1.00      1.00      1.00         5
         389       1.00      1.00      1.00         8
         390       0.13      0.50      0.21         4
         391       0.75      1.00      0.86         9
         392       1.00      0.80      0.89         5
         393       1.00      0.75      0.86         4
         394       0.82      1.00      0.90         9
         395       0.00      0.00      0.00         9
         396       0.80      1.00      0.89         4
         397       0.80      1.00      0.89         4
         398       0.75      0.75      0.75         4
         399       1.00      0.75      0.86         4
         400       1.00      0.80      0.89         5
         401       0.60      0.75      0.67         4
         402       0.80      1.00      0.89         4
         403       1.00      1.00      1.00         5
         404       1.00      1.00      1.00         4
         405       0.80      0.80      0.80         5
         406       0.00      0.00      0.00         4
         407       1.00      0.50      0.67         4
         408       1.00      1.00      1.00         5
         409       1.00      0.75      0.86         4
         410       0.00      0.00      0.00         4
         411       0.00      0.00      0.00         4
         412       1.00      0.50      0.67         4
         413       0.60      0.75      0.67         4
         414       1.00      0.50      0.67         4
         415       0.00      0.00      0.00         4
         416       1.00      1.00      1.00         9
         417       0.00      0.00      0.00         4
         418       0.89      0.89      0.89         9
         419       0.80      0.89      0.84         9
         420       0.80      0.89      0.84         9
         421       1.00      1.00      1.00         4
         422       1.00      0.50      0.67         4
         423       0.80      0.80      0.80         5
         424       0.80      1.00      0.89         4
         425       0.00      0.00      0.00         4
         426       1.00      1.00      1.00         4
         427       0.80      1.00      0.89         4
         428       1.00      1.00      1.00         4
         429       1.00      1.00      1.00         4
         430       0.00      0.00      0.00         9
         431       0.90      1.00      0.95         9
         432       1.00      0.25      0.40         4
         433       0.00      0.00      0.00         9
         434       0.83      1.00      0.91         5
         435       0.00      0.00      0.00         4
         436       0.17      0.25      0.20         4
         437       0.83      1.00      0.91         5
         438       0.80      1.00      0.89         4
         439       1.00      0.78      0.88         9
         440       0.40      0.50      0.44         4
         441       1.00      1.00      1.00         4
         442       0.71      1.00      0.83         5
         443       0.50      0.71      0.59         7
         444       0.67      0.80      0.73         5
         445       0.67      1.00      0.80         4
         446       0.82      1.00      0.90         9
         447       0.67      0.67      0.67         9
         448       1.00      1.00      1.00         9
         449       0.50      0.75      0.60         4
         450       0.80      1.00      0.89         4
         451       0.00      0.00      0.00         4
         452       0.75      0.75      0.75         4
         453       0.00      0.00      0.00         4
         454       0.80      1.00      0.89         4
         455       1.00      1.00      1.00         4
         456       0.86      0.75      0.80         8
         457       0.90      1.00      0.95         9
         458       0.67      0.50      0.57         4
         459       1.00      1.00      1.00         4
         460       0.67      0.50      0.57         4
         461       1.00      1.00      1.00         4
         462       0.33      0.25      0.29         4
         463       1.00      0.75      0.86         4
         464       0.64      1.00      0.78         9
         465       1.00      1.00      1.00         4
         466       1.00      1.00      1.00         4
         467       0.83      1.00      0.91         5
         468       0.83      1.00      0.91         5
         469       0.82      1.00      0.90         9
         470       0.00      0.00      0.00         9
         471       0.67      1.00      0.80         4
         472       0.90      1.00      0.95         9
         473       0.80      1.00      0.89         4
         474       1.00      0.80      0.89         5
         475       1.00      1.00      1.00         9
         476       0.75      0.75      0.75         4
         477       1.00      1.00      1.00         4
         478       1.00      1.00      1.00         4
         479       1.00      1.00      1.00         4
         480       1.00      1.00      1.00         4
         481       0.75      0.75      0.75         4
         482       0.00      0.00      0.00         4
         483       0.75      0.67      0.71         9
         484       1.00      0.50      0.67         4
         485       1.00      1.00      1.00         5
         486       0.00      0.00      0.00         4
         487       1.00      1.00      1.00         4
         488       1.00      1.00      1.00         9
         489       1.00      0.75      0.86         4
         490       1.00      0.89      0.94         9
         491       1.00      1.00      1.00         4
         492       0.90      1.00      0.95         9
         493       0.05      0.25      0.09         4
         494       0.00      0.00      0.00         4
         495       0.73      0.89      0.80         9
         496       0.00      0.00      0.00         4
         497       0.60      0.67      0.63         9
         498       1.00      1.00      1.00         9
         499       1.00      1.00      1.00         4
         500       1.00      0.25      0.40         4
         501       0.75      0.75      0.75         4
         502       0.00      0.00      0.00         4
         503       1.00      0.40      0.57         5
         504       1.00      1.00      1.00         5
         505       0.67      0.50      0.57         4
         506       1.00      1.00      1.00         5
         507       1.00      0.80      0.89         5
         508       0.50      0.56      0.53         9
         509       1.00      1.00      1.00         9
         510       1.00      0.75      0.86         4
         511       1.00      1.00      1.00         4
         512       0.80      1.00      0.89         4
         513       0.67      1.00      0.80         4
         514       1.00      0.89      0.94         9
         515       0.60      0.75      0.67         4
         516       0.67      1.00      0.80         4
         517       0.80      1.00      0.89         4
         518       0.90      1.00      0.95         9
         519       1.00      0.89      0.94         9
         520       0.67      1.00      0.80         4
         521       1.00      0.80      0.89         5
         522       1.00      1.00      1.00         4
         523       1.00      0.60      0.75         5
         524       0.75      0.67      0.71         9
         525       1.00      0.44      0.62         9
         526       1.00      0.75      0.86         4
         527       1.00      1.00      1.00         9
         528       1.00      0.80      0.89         5
         529       1.00      1.00      1.00         9
         530       1.00      0.75      0.86         4
         531       0.50      0.25      0.33         4
         532       0.62      1.00      0.77         5
         533       1.00      1.00      1.00         4
         534       0.00      0.00      0.00         9
         535       1.00      0.80      0.89         5
         536       0.89      0.89      0.89         9
         537       0.70      0.78      0.74         9
         538       0.00      0.00      0.00         4
         539       0.89      0.89      0.89         9
         540       1.00      0.78      0.88         9
         541       0.00      0.00      0.00         4
         542       1.00      0.25      0.40         4
         543       0.62      1.00      0.77         5
         544       0.83      1.00      0.91         5
         545       0.80      1.00      0.89         4
         546       1.00      1.00      1.00         4
         547       1.00      0.75      0.86         4
         548       1.00      1.00      1.00         4
         549       1.00      0.75      0.86         4
         550       0.67      1.00      0.80         4
         551       1.00      0.80      0.89         5
         552       0.75      0.75      0.75         4
         553       1.00      1.00      1.00         4
         554       1.00      1.00      1.00         5
         555       0.80      1.00      0.89         4
         556       0.75      0.60      0.67         5
         557       0.80      1.00      0.89         4
         558       0.75      0.60      0.67         5
         559       1.00      1.00      1.00         4
         560       0.83      1.00      0.91         5
         561       0.75      0.75      0.75         4
         562       1.00      0.75      0.86         4
         563       0.00      0.00      0.00         4
         564       1.00      0.89      0.94         9
         565       1.00      0.75      0.86         4
         566       0.00      0.00      0.00         4
         567       0.80      1.00      0.89         4
         568       0.80      0.80      0.80         5
         569       1.00      0.78      0.88         9
         570       1.00      0.78      0.88         9
         571       0.75      0.75      0.75         4
         572       1.00      1.00      1.00         4
         573       1.00      1.00      1.00         4
         574       1.00      0.60      0.75         5
         575       0.00      0.00      0.00         4
         576       0.90      1.00      0.95         9
         577       0.00      0.00      0.00         4
         578       0.90      1.00      0.95         9
         579       0.89      0.89      0.89         9
         580       0.75      0.75      0.75         4
         581       1.00      0.60      0.75         5
         582       1.00      0.56      0.71         9
         583       0.67      0.50      0.57         4
         584       0.60      0.75      0.67         4
         585       0.80      0.80      0.80         5
         586       1.00      0.25      0.40         4
         587       0.80      1.00      0.89         4
         588       0.89      0.89      0.89         9
         589       0.80      1.00      0.89         4
         590       1.00      0.25      0.40         4
         591       0.71      0.56      0.63         9
         592       1.00      0.75      0.86         4
         593       1.00      0.75      0.86         4
         594       0.00      0.00      0.00         4
         595       0.56      1.00      0.71         5
         596       1.00      1.00      1.00         9
         597       0.80      1.00      0.89         4
         598       0.00      0.00      0.00         4
         599       1.00      1.00      1.00         5
         600       1.00      1.00      1.00         4
         601       1.00      1.00      1.00         9
         602       1.00      0.60      0.75         5
         603       0.80      1.00      0.89         4
         604       0.00      0.00      0.00         4
         605       1.00      1.00      1.00         9
         606       1.00      0.89      0.94         9
         607       1.00      1.00      1.00         9
         608       1.00      1.00      1.00         4
         609       1.00      1.00      1.00         5
         610       1.00      0.78      0.88         9
         611       1.00      1.00      1.00         4
         612       1.00      0.89      0.94         9
         613       0.82      1.00      0.90         9
         614       1.00      1.00      1.00         5
         615       0.86      0.67      0.75         9
         616       1.00      0.89      0.94         9
         617       0.82      1.00      0.90         9
         618       1.00      0.89      0.94         9
         619       0.80      1.00      0.89         4
         620       0.00      0.00      0.00         4
         621       0.80      1.00      0.89         4
         622       1.00      0.75      0.86         4
         623       0.71      1.00      0.83         5
         624       0.50      0.50      0.50         4
         625       0.57      1.00      0.73         4
         626       0.80      0.44      0.57         9
         627       0.00      0.00      0.00         9
         628       1.00      1.00      1.00         4
         629       0.71      1.00      0.83         5
         630       1.00      1.00      1.00         9
         631       0.60      0.75      0.67         4
         632       1.00      1.00      1.00         4
         633       1.00      1.00      1.00         5
         634       0.00      0.00      0.00         9
         635       1.00      0.75      0.86         4
         636       0.60      0.75      0.67         4
         637       0.67      0.50      0.57         4
         638       0.82      1.00      0.90         9
         639       0.57      1.00      0.73         4
         640       0.00      0.00      0.00         4
         641       0.67      1.00      0.80         4
         642       1.00      0.25      0.40         4
         643       1.00      1.00      1.00         4
         644       1.00      1.00      1.00         9
         645       0.00      0.00      0.00         4
         646       0.80      0.89      0.84         9
         647       0.89      0.89      0.89         9
         648       0.00      0.00      0.00         4
         649       0.00      0.00      0.00         4
         650       1.00      1.00      1.00         9
         651       1.00      1.00      1.00         4
         652       0.67      1.00      0.80         4
         653       0.75      0.67      0.71         9
         654       1.00      1.00      1.00         9
         655       1.00      0.80      0.89         5
         656       0.11      0.25      0.15         4
         657       1.00      1.00      1.00         9
         658       0.80      1.00      0.89         4
         659       1.00      0.75      0.86         4
         660       1.00      0.75      0.86         4
         661       0.00      0.00      0.00         9
         662       1.00      1.00      1.00         5
         663       0.00      0.00      0.00         4
         664       1.00      1.00      1.00         5
         665       0.50      0.67      0.57         9
         666       1.00      0.75      0.86         4
         667       1.00      0.67      0.80         9
         668       1.00      0.75      0.86         4
         669       0.38      0.60      0.46         5
         670       1.00      0.75      0.86         4
         671       1.00      1.00      1.00         5
         672       0.00      0.00      0.00         4
         673       1.00      1.00      1.00         4
         674       0.40      0.50      0.44         4
         675       0.80      1.00      0.89         4
         676       0.80      1.00      0.89         4
         677       0.42      0.56      0.48         9
         678       0.03      0.11      0.05         9
         679       0.57      1.00      0.73         4
         680       0.67      0.50      0.57         4
         681       0.33      0.25      0.29         4
         682       0.75      0.75      0.75         4
         683       0.00      0.00      0.00         4
         684       1.00      1.00      1.00         4
         685       1.00      1.00      1.00         9
         686       0.00      0.00      0.00         4
         687       1.00      0.33      0.50         9
         688       0.00      0.00      0.00         4
         689       1.00      1.00      1.00         9
         690       0.50      0.25      0.33         4
         691       1.00      0.80      0.89         5
         692       1.00      0.75      0.86         4
         693       1.00      0.89      0.94         9
         694       0.54      0.78      0.64         9
         695       1.00      1.00      1.00         4
         696       0.80      1.00      0.89         4
         697       0.75      0.75      0.75         4
         698       0.00      0.00      0.00         9
         699       0.00      0.00      0.00         4
         700       0.80      0.80      0.80         5
         701       0.80      1.00      0.89         4
         702       0.00      0.00      0.00         4
         703       1.00      0.50      0.67         4
         704       1.00      1.00      1.00         4
         705       1.00      1.00      1.00         4
         706       1.00      0.50      0.67         4
         707       1.00      1.00      1.00         5
         708       1.00      1.00      1.00         5
         709       0.75      0.75      0.75         4
         710       1.00      1.00      1.00         4
         711       1.00      0.25      0.40         4
         712       0.00      0.00      0.00         4
         713       1.00      0.89      0.94         9
         714       1.00      0.89      0.94         9
         715       0.80      1.00      0.89         4
         716       0.00      0.00      0.00         4
         717       1.00      1.00      1.00         4
         718       0.17      0.25      0.20         4
         719       0.00      0.00      0.00         4
         720       0.71      1.00      0.83         5
         721       1.00      1.00      1.00         5
         722       0.75      0.75      0.75         4
         723       0.67      0.50      0.57         4
         724       0.50      0.60      0.55         5
         725       0.00      0.00      0.00         4
         726       0.00      0.00      0.00         4
         727       0.00      0.00      0.00         4
         728       0.00      0.00      0.00         4
         729       0.83      1.00      0.91         5
         730       1.00      0.25      0.40         4
         731       1.00      0.89      0.94         9
         732       0.80      1.00      0.89         4
         733       0.00      0.00      0.00         4
         734       1.00      1.00      1.00         4
         735       1.00      1.00      1.00         4
         736       0.60      0.75      0.67         4
         737       1.00      1.00      1.00         4
         738       0.00      0.00      0.00         4
         739       0.82      1.00      0.90         9
         740       1.00      0.75      0.86         4
         741       0.75      0.75      0.75         4
         742       0.75      0.75      0.75         4
         743       0.00      0.00      0.00         9
         744       1.00      0.50      0.67         4
         745       1.00      0.60      0.75         5
         746       1.00      0.75      0.86         4
         747       0.00      0.00      0.00         4
         748       1.00      1.00      1.00         9
         749       1.00      0.25      0.40         4
         750       1.00      1.00      1.00         4
         751       0.88      0.78      0.82         9
         752       0.75      0.75      0.75         4
         753       1.00      0.50      0.67         4
         754       1.00      0.75      0.86         4
         755       1.00      0.60      0.75         5
         756       1.00      0.75      0.86         4
         757       0.50      0.60      0.55         5
         758       1.00      1.00      1.00         4
         759       1.00      0.89      0.94         9
         760       1.00      1.00      1.00         4
         761       0.00      0.00      0.00         4
         762       0.80      1.00      0.89         4
         763       1.00      0.89      0.94         9
         764       1.00      1.00      1.00         5
         765       0.00      0.00      0.00         9
         766       1.00      0.75      0.86         4
         767       0.80      1.00      0.89         4
         768       0.71      1.00      0.83         5
         769       1.00      0.50      0.67         4
         770       1.00      0.75      0.86         4
         771       0.88      0.78      0.82         9
         772       0.00      0.00      0.00         9
         773       1.00      1.00      1.00         4
         774       0.67      0.50      0.57         4
         775       1.00      0.75      0.86         4
         776       0.80      1.00      0.89         4
         777       0.82      1.00      0.90         9
         778       0.73      0.89      0.80         9
         779       0.33      0.50      0.40         4
         780       1.00      0.89      0.94         9
         781       0.71      1.00      0.83         5
         782       0.00      0.00      0.00         4
         783       1.00      1.00      1.00         9
         784       1.00      0.75      0.86         4
         785       1.00      1.00      1.00         5
         786       0.00      0.00      0.00         4
         787       0.75      0.75      0.75         4
         788       0.60      0.60      0.60         5
         789       1.00      1.00      1.00         4
         790       1.00      1.00      1.00         4
         791       1.00      0.50      0.67         4
         792       1.00      1.00      1.00         4
         793       1.00      1.00      1.00         5
         794       1.00      0.89      0.94         9
         795       0.89      0.89      0.89         9
         796       0.89      0.89      0.89         9
         797       1.00      0.75      0.86         4
         798       0.75      0.67      0.71         9
         799       1.00      0.80      0.89         5
         800       1.00      0.80      0.89         5
         801       0.80      1.00      0.89         4
         802       0.00      0.00      0.00         4
         803       0.82      1.00      0.90         9
         804       1.00      0.25      0.40         4
         805       0.80      0.89      0.84         9
         806       1.00      0.75      0.86         4
         807       0.80      1.00      0.89         4
         808       1.00      0.89      0.94         9
         809       0.60      0.75      0.67         4
         810       1.00      1.00      1.00         4
         811       0.67      0.40      0.50         5
         812       0.83      1.00      0.91         5
         813       0.67      0.67      0.67         9
         814       1.00      0.75      0.86         4
         815       1.00      0.89      0.94         9
         816       0.75      0.75      0.75         4
         817       0.62      1.00      0.77         5
         818       0.90      1.00      0.95         9
         819       1.00      0.75      0.86         4
         820       1.00      1.00      1.00         9
         821       0.75      0.75      0.75         4
         822       0.67      1.00      0.80         4
         823       1.00      0.75      0.86         4
         824       1.00      1.00      1.00         4
         825       1.00      1.00      1.00         4
         826       0.12      0.50      0.19         4
         827       0.80      1.00      0.89         4
         828       1.00      0.50      0.67         4
         829       0.67      1.00      0.80         4
         830       0.83      1.00      0.91         5
         831       0.67      0.50      0.57         4
         832       1.00      1.00      1.00         9
         833       1.00      0.75      0.86         4
         834       0.75      0.75      0.75         4
         835       0.80      0.89      0.84         9
         836       0.75      0.75      0.75         4
         837       0.00      0.00      0.00         4
         838       1.00      1.00      1.00         9
         839       0.67      0.40      0.50         5
         840       0.88      0.78      0.82         9
         841       1.00      0.75      0.86         4
         842       1.00      1.00      1.00         4
         843       0.00      0.00      0.00         4
         844       1.00      0.67      0.80         9
         845       0.40      0.50      0.44         4
         846       1.00      1.00      1.00         4
         847       1.00      0.75      0.86         4
         848       0.80      0.80      0.80         5
         849       1.00      0.75      0.86         4
         850       1.00      1.00      1.00         4
         851       1.00      0.78      0.88         9
         852       1.00      0.80      0.89         5
         853       0.60      0.75      0.67         4
         854       0.67      1.00      0.80         4
         855       0.57      1.00      0.73         4
         856       1.00      0.75      0.86         4
         857       0.40      0.50      0.44         4
         858       1.00      0.75      0.86         4
         859       0.00      0.00      0.00         4
         860       0.78      0.78      0.78         9
         861       0.88      0.78      0.82         9
         862       0.89      0.89      0.89         9
         863       1.00      1.00      1.00         9
         864       0.70      0.78      0.74         9
         865       1.00      0.78      0.88         9
         866       0.00      0.00      0.00         9
         867       0.89      0.89      0.89         9
         868       1.00      0.75      0.86         4
         869       0.80      1.00      0.89         4
         870       0.80      1.00      0.89         4
         871       0.75      0.75      0.75         4
         872       0.00      0.00      0.00         4
         873       0.78      0.78      0.78         9
         874       0.83      1.00      0.91         5
         875       1.00      1.00      1.00         4
         876       0.89      0.89      0.89         9
         877       1.00      1.00      1.00         4
         878       0.00      0.00      0.00         4
         879       1.00      1.00      1.00         4
         880       1.00      1.00      1.00         4
         881       1.00      1.00      1.00         5
         882       0.89      0.89      0.89         9
         883       0.82      1.00      0.90         9
         884       0.88      0.78      0.82         9
         885       1.00      1.00      1.00         5
         886       1.00      1.00      1.00         4
         887       1.00      0.80      0.89         5
         888       0.50      1.00      0.67         5
         889       0.80      0.80      0.80         5
         890       1.00      1.00      1.00         4
         891       0.80      1.00      0.89         4
         892       1.00      1.00      1.00         4
         893       0.00      0.00      0.00         4

    accuracy                           0.74      4917
   macro avg       0.74      0.72      0.72      4917
weighted avg       0.76      0.74      0.74      4917

task_train_time: {0: 0.12328326399999945, 1: 0.03249257299999897, 2: 0.031204140999999908, 3: 0.030972873999999706, 4: 0.037475976999999716, 5: 0.030178703999999, 6: 0.02968940499999917, 7: 0.04029077200000053, 8: 0.02905701200000088, 9: 0.03305474899999972, 10: 0.037773938999999146, 11: 0.03705369000000047, 12: 0.03508055999999904, 13: 0.04012850699999859, 14: 0.02953717000000111, 15: 0.028219870000000924, 16: 0.03556920400000152, 17: 0.030217856000000154, 18: 0.027751823999999203, 19: 0.023902316000000923, 20: 0.03314424999999943, 21: 0.02691102699999881, 22: 0.03284554900000103, 23: 0.03477192799999962, 24: 0.0330317659999988, 25: 0.03492841300000116, 26: 0.03283004699999914, 27: 0.028510909999999612, 28: 0.03293422700000015, 29: 0.03718712300000071, 30: 0.03571246099999925, 31: 0.03506816500000021, 32: 0.03151824600000097, 33: 0.03357861099999937, 34: 0.029116972999998936, 35: 0.027580050000000966, 36: 0.030079540000000904, 37: 0.03368030100000041, 38: 0.03224672700000042, 39: 0.039169487999998864, 40: 0.028396862000001022, 41: 0.03317028500000063, 42: 0.03738746699999851, 43: 0.0310003899999991}
prediction_time: 0.0002786329999935333
Parameters: 986894
Task parameters: {0: 126034, 1: 146054, 2: 166074, 3: 186094, 4: 206114, 5: 226134, 6: 246154, 7: 266174, 8: 286194, 9: 306214, 10: 326234, 11: 346254, 12: 366274, 13: 386294, 14: 406314, 15: 426334, 16: 446354, 17: 466374, 18: 486394, 19: 506414, 20: 526434, 21: 546454, 22: 566474, 23: 586494, 24: 606514, 25: 626534, 26: 646554, 27: 666574, 28: 686594, 29: 706614, 30: 726634, 31: 746654, 32: 766674, 33: 786694, 34: 806714, 35: 826734, 36: 846754, 37: 866774, 38: 886794, 39: 906814, 40: 926834, 41: 946854, 42: 966874, 43: 986894}
